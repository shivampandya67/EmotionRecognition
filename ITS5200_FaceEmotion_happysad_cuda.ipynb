{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d080deae-f53a-4bb3-bca1-79319f15131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## Import Libaries\n",
    "\n",
    "###########################\n",
    "## Import Torch Libaries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import transforms\n",
    "###########################\n",
    "## Import standard libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "##########################\n",
    "## Import PIL\n",
    "from PIL import Image\n",
    "\n",
    "#####################\n",
    "## import SK learn libaries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "####################\n",
    "## import matplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deb6690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8069e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "##Enable CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52642ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install onnxruntime\n",
    "# !pip install onnxmltools\n",
    "import onnxruntime \n",
    "import onnxmltools\n",
    "from skl2onnx.common.data_types import FloatTensorType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc99ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de589283-baa7-4d1f-8a14-893cae118462",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "## View Class\n",
    "class View(nn.Module):\n",
    "    \n",
    "    def __init__(self, shape):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.shape = shape,\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2deffdd4-7e53-45c7-8759-0e6980cfeee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.classes = os.listdir(data_path)\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        for i, emotion_class in enumerate(self.classes):\n",
    "            class_path = os.path.join(data_path, emotion_class)\n",
    "            for image_name in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_name)\n",
    "                self.images.append(image_path)\n",
    "                self.labels.append(i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        # Open the image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert label to a single index\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "333ed755-ef87-4845-bc90-47f29f205394",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './images'  # Update this to your actual path\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "emotion_dataset = EmotionDataset(data_path=data_path, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ec41b93-a447-4bbd-bb34-ac4d9c1ac13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index = 0\n",
    "image, label = emotion_dataset[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b2c5df6-7bc5-4782-8436-7faf1d3a45e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 48, 48])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b59894e-8df6-4710-baa3-ed48ad08f491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "475ec1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################\n",
    "##  Custom CNN 2 convulutional layer model\n",
    "class Classifier_CNN_3_Layers(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Classifier_CNN_3_Layers, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "            self.pool1= nn.MaxPool2d(kernel_size=2, stride = 2)\n",
    "            self.conv2 = nn.Conv2d(64,128, kernel_size=3, stride=1, padding=1)\n",
    "            self.pool2 = nn.MaxPool2d(kernel_size=2, stride = 2)\n",
    "            self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "            self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.fc1 = nn.Linear(256 * 6 * 6, 512)\n",
    "            self.fc2 = nn.Linear(512, 1)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool1(x)\n",
    "            \n",
    "            x = self.conv2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool2(x)\n",
    "            \n",
    "            x = self.conv3(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool3(x)\n",
    "            \n",
    "            x = x.view(-1, 256 * 6 * 6)\n",
    "            x = self.fc1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a7b2cc3-f5b9-4299-a21e-b4c4c57fffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################\n",
    "##  Custom CNN 2 convulutional layer model\n",
    "class Classifier_CNN_5_Layers(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Classifier_CNN_5_Layers, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "            self.pool1= nn.MaxPool2d(kernel_size=2, stride = 2)\n",
    "            self.conv2 = nn.Conv2d(64,128, kernel_size=3, stride=1, padding=1)\n",
    "            self.pool2 = nn.MaxPool2d(kernel_size=2, stride = 2)\n",
    "            self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "            self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "            self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.conv5 = nn.Conv2d(512, 1024, kernel_size=3, padding=1)\n",
    "            self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.fc1 = nn.Linear(1024 * 6 * 6, 512)\n",
    "            self.fc2 = nn.Linear(512, 1)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool1(x)\n",
    "            \n",
    "            x = self.conv2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool2(x)\n",
    "            \n",
    "            x = self.conv3(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.pool3(x)\n",
    "            \n",
    "            x = self.conv4(x)\n",
    "            x = self.relu(x)\n",
    "      \n",
    "            \n",
    "            x = self.conv5(x)\n",
    "            x = self.relu(x)\n",
    " \n",
    "            print(x.size()) \n",
    "            \n",
    "            x = x.view(-1, 1024 * 6 * 6)\n",
    "            x = self.fc1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70cb0672",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Split the dataset into training and testing sets\n",
    "train_size = int(0.8 * len(emotion_dataset))\n",
    "test_size = len(emotion_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(emotion_dataset, [train_size, test_size])\n",
    "###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "547f4070",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "## Define Test and train data loaders\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create DataLoader instances for training and testing datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbe24428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Iteration 1/303, Loss: 0.6992462277412415\n",
      "Epoch 1/20, Iteration 2/303, Loss: 0.6821365356445312\n",
      "Epoch 1/20, Iteration 3/303, Loss: 0.6866430044174194\n",
      "Epoch 1/20, Iteration 4/303, Loss: 0.6871508955955505\n",
      "Epoch 1/20, Iteration 5/303, Loss: 0.6466887593269348\n",
      "Epoch 1/20, Iteration 6/303, Loss: 0.6477553248405457\n",
      "Epoch 1/20, Iteration 7/303, Loss: 0.6816120743751526\n",
      "Epoch 1/20, Iteration 8/303, Loss: 0.6459097266197205\n",
      "Epoch 1/20, Iteration 9/303, Loss: 0.6680840849876404\n",
      "Epoch 1/20, Iteration 10/303, Loss: 0.6586099863052368\n",
      "Epoch 1/20, Iteration 11/303, Loss: 0.68919837474823\n",
      "Epoch 1/20, Iteration 12/303, Loss: 0.6575819849967957\n",
      "Epoch 1/20, Iteration 13/303, Loss: 0.6770915985107422\n",
      "Epoch 1/20, Iteration 14/303, Loss: 0.6877940893173218\n",
      "Epoch 1/20, Iteration 15/303, Loss: 0.6295236945152283\n",
      "Epoch 1/20, Iteration 16/303, Loss: 0.7046793699264526\n",
      "Epoch 1/20, Iteration 17/303, Loss: 0.7011417150497437\n",
      "Epoch 1/20, Iteration 18/303, Loss: 0.6742302775382996\n",
      "Epoch 1/20, Iteration 19/303, Loss: 0.7208762764930725\n",
      "Epoch 1/20, Iteration 20/303, Loss: 0.6722877025604248\n",
      "Epoch 1/20, Iteration 21/303, Loss: 0.6747879981994629\n",
      "Epoch 1/20, Iteration 22/303, Loss: 0.7410608530044556\n",
      "Epoch 1/20, Iteration 23/303, Loss: 0.6919533014297485\n",
      "Epoch 1/20, Iteration 24/303, Loss: 0.6801756620407104\n",
      "Epoch 1/20, Iteration 25/303, Loss: 0.6518857479095459\n",
      "Epoch 1/20, Iteration 26/303, Loss: 0.6444774270057678\n",
      "Epoch 1/20, Iteration 27/303, Loss: 0.6699202060699463\n",
      "Epoch 1/20, Iteration 28/303, Loss: 0.6848500967025757\n",
      "Epoch 1/20, Iteration 29/303, Loss: 0.6430283784866333\n",
      "Epoch 1/20, Iteration 30/303, Loss: 0.6412463784217834\n",
      "Epoch 1/20, Iteration 31/303, Loss: 0.6542378067970276\n",
      "Epoch 1/20, Iteration 32/303, Loss: 0.7403162717819214\n",
      "Epoch 1/20, Iteration 33/303, Loss: 0.6602345705032349\n",
      "Epoch 1/20, Iteration 34/303, Loss: 0.6160344481468201\n",
      "Epoch 1/20, Iteration 35/303, Loss: 0.6511861681938171\n",
      "Epoch 1/20, Iteration 36/303, Loss: 0.6037279367446899\n",
      "Epoch 1/20, Iteration 37/303, Loss: 0.7045003771781921\n",
      "Epoch 1/20, Iteration 38/303, Loss: 0.6659476161003113\n",
      "Epoch 1/20, Iteration 39/303, Loss: 0.6856891512870789\n",
      "Epoch 1/20, Iteration 40/303, Loss: 0.6785565614700317\n",
      "Epoch 1/20, Iteration 41/303, Loss: 0.6572485566139221\n",
      "Epoch 1/20, Iteration 42/303, Loss: 0.6638156175613403\n",
      "Epoch 1/20, Iteration 43/303, Loss: 0.6273863315582275\n",
      "Epoch 1/20, Iteration 44/303, Loss: 0.7501718997955322\n",
      "Epoch 1/20, Iteration 45/303, Loss: 0.7312940359115601\n",
      "Epoch 1/20, Iteration 46/303, Loss: 0.6823387742042542\n",
      "Epoch 1/20, Iteration 47/303, Loss: 0.6752840876579285\n",
      "Epoch 1/20, Iteration 48/303, Loss: 0.6656805276870728\n",
      "Epoch 1/20, Iteration 49/303, Loss: 0.6138986945152283\n",
      "Epoch 1/20, Iteration 50/303, Loss: 0.6732640862464905\n",
      "Epoch 1/20, Iteration 51/303, Loss: 0.6923924088478088\n",
      "Epoch 1/20, Iteration 52/303, Loss: 0.6738314032554626\n",
      "Epoch 1/20, Iteration 53/303, Loss: 0.6308361291885376\n",
      "Epoch 1/20, Iteration 54/303, Loss: 0.6319831013679504\n",
      "Epoch 1/20, Iteration 55/303, Loss: 0.6107794046401978\n",
      "Epoch 1/20, Iteration 56/303, Loss: 0.7408825755119324\n",
      "Epoch 1/20, Iteration 57/303, Loss: 0.6937811374664307\n",
      "Epoch 1/20, Iteration 58/303, Loss: 0.7400340437889099\n",
      "Epoch 1/20, Iteration 59/303, Loss: 0.6768229007720947\n",
      "Epoch 1/20, Iteration 60/303, Loss: 0.6451063752174377\n",
      "Epoch 1/20, Iteration 61/303, Loss: 0.6535949110984802\n",
      "Epoch 1/20, Iteration 62/303, Loss: 0.6847648620605469\n",
      "Epoch 1/20, Iteration 63/303, Loss: 0.694939136505127\n",
      "Epoch 1/20, Iteration 64/303, Loss: 0.6973299384117126\n",
      "Epoch 1/20, Iteration 65/303, Loss: 0.6038767695426941\n",
      "Epoch 1/20, Iteration 66/303, Loss: 0.6643314361572266\n",
      "Epoch 1/20, Iteration 67/303, Loss: 0.6988864541053772\n",
      "Epoch 1/20, Iteration 68/303, Loss: 0.7044402360916138\n",
      "Epoch 1/20, Iteration 69/303, Loss: 0.6903781890869141\n",
      "Epoch 1/20, Iteration 70/303, Loss: 0.7096083760261536\n",
      "Epoch 1/20, Iteration 71/303, Loss: 0.6703063249588013\n",
      "Epoch 1/20, Iteration 72/303, Loss: 0.657566487789154\n",
      "Epoch 1/20, Iteration 73/303, Loss: 0.6691890358924866\n",
      "Epoch 1/20, Iteration 74/303, Loss: 0.6381592154502869\n",
      "Epoch 1/20, Iteration 75/303, Loss: 0.6922276020050049\n",
      "Epoch 1/20, Iteration 76/303, Loss: 0.7053828239440918\n",
      "Epoch 1/20, Iteration 77/303, Loss: 0.728571355342865\n",
      "Epoch 1/20, Iteration 78/303, Loss: 0.6845725774765015\n",
      "Epoch 1/20, Iteration 79/303, Loss: 0.6901941895484924\n",
      "Epoch 1/20, Iteration 80/303, Loss: 0.656539261341095\n",
      "Epoch 1/20, Iteration 81/303, Loss: 0.6541394591331482\n",
      "Epoch 1/20, Iteration 82/303, Loss: 0.6486372947692871\n",
      "Epoch 1/20, Iteration 83/303, Loss: 0.6355823278427124\n",
      "Epoch 1/20, Iteration 84/303, Loss: 0.737563967704773\n",
      "Epoch 1/20, Iteration 85/303, Loss: 0.6668816804885864\n",
      "Epoch 1/20, Iteration 86/303, Loss: 0.681304931640625\n",
      "Epoch 1/20, Iteration 87/303, Loss: 0.6840047240257263\n",
      "Epoch 1/20, Iteration 88/303, Loss: 0.6587288975715637\n",
      "Epoch 1/20, Iteration 89/303, Loss: 0.5942047834396362\n",
      "Epoch 1/20, Iteration 90/303, Loss: 0.6682628393173218\n",
      "Epoch 1/20, Iteration 91/303, Loss: 0.6666846871376038\n",
      "Epoch 1/20, Iteration 92/303, Loss: 0.6585754156112671\n",
      "Epoch 1/20, Iteration 93/303, Loss: 0.6651853919029236\n",
      "Epoch 1/20, Iteration 94/303, Loss: 0.6887142062187195\n",
      "Epoch 1/20, Iteration 95/303, Loss: 0.6629683375358582\n",
      "Epoch 1/20, Iteration 96/303, Loss: 0.7304036617279053\n",
      "Epoch 1/20, Iteration 97/303, Loss: 0.6351075768470764\n",
      "Epoch 1/20, Iteration 98/303, Loss: 0.6702421307563782\n",
      "Epoch 1/20, Iteration 99/303, Loss: 0.6875890493392944\n",
      "Epoch 1/20, Iteration 100/303, Loss: 0.6902389526367188\n",
      "Epoch 1/20, Iteration 101/303, Loss: 0.6950831413269043\n",
      "Epoch 1/20, Iteration 102/303, Loss: 0.6363143920898438\n",
      "Epoch 1/20, Iteration 103/303, Loss: 0.7168692350387573\n",
      "Epoch 1/20, Iteration 104/303, Loss: 0.7035568952560425\n",
      "Epoch 1/20, Iteration 105/303, Loss: 0.689213752746582\n",
      "Epoch 1/20, Iteration 106/303, Loss: 0.6291602849960327\n",
      "Epoch 1/20, Iteration 107/303, Loss: 0.6580800414085388\n",
      "Epoch 1/20, Iteration 108/303, Loss: 0.6933351159095764\n",
      "Epoch 1/20, Iteration 109/303, Loss: 0.684954047203064\n",
      "Epoch 1/20, Iteration 110/303, Loss: 0.6880749464035034\n",
      "Epoch 1/20, Iteration 111/303, Loss: 0.6822217702865601\n",
      "Epoch 1/20, Iteration 112/303, Loss: 0.6389846205711365\n",
      "Epoch 1/20, Iteration 113/303, Loss: 0.6194058656692505\n",
      "Epoch 1/20, Iteration 114/303, Loss: 0.772212028503418\n",
      "Epoch 1/20, Iteration 115/303, Loss: 0.6690917015075684\n",
      "Epoch 1/20, Iteration 116/303, Loss: 0.7054174542427063\n",
      "Epoch 1/20, Iteration 117/303, Loss: 0.6220641136169434\n",
      "Epoch 1/20, Iteration 118/303, Loss: 0.6271677017211914\n",
      "Epoch 1/20, Iteration 119/303, Loss: 0.8057008981704712\n",
      "Epoch 1/20, Iteration 120/303, Loss: 0.6507139205932617\n",
      "Epoch 1/20, Iteration 121/303, Loss: 0.6555149555206299\n",
      "Epoch 1/20, Iteration 122/303, Loss: 0.6177185773849487\n",
      "Epoch 1/20, Iteration 123/303, Loss: 0.7381982207298279\n",
      "Epoch 1/20, Iteration 124/303, Loss: 0.7087059617042542\n",
      "Epoch 1/20, Iteration 125/303, Loss: 0.7004750967025757\n",
      "Epoch 1/20, Iteration 126/303, Loss: 0.6978467106819153\n",
      "Epoch 1/20, Iteration 127/303, Loss: 0.6831536889076233\n",
      "Epoch 1/20, Iteration 128/303, Loss: 0.6697050333023071\n",
      "Epoch 1/20, Iteration 129/303, Loss: 0.6805890798568726\n",
      "Epoch 1/20, Iteration 130/303, Loss: 0.6893728971481323\n",
      "Epoch 1/20, Iteration 131/303, Loss: 0.6532090306282043\n",
      "Epoch 1/20, Iteration 132/303, Loss: 0.6400430202484131\n",
      "Epoch 1/20, Iteration 133/303, Loss: 0.6311540603637695\n",
      "Epoch 1/20, Iteration 134/303, Loss: 0.5686417818069458\n",
      "Epoch 1/20, Iteration 135/303, Loss: 0.7005496621131897\n",
      "Epoch 1/20, Iteration 136/303, Loss: 0.6897886991500854\n",
      "Epoch 1/20, Iteration 137/303, Loss: 0.6579720973968506\n",
      "Epoch 1/20, Iteration 138/303, Loss: 0.7205499410629272\n",
      "Epoch 1/20, Iteration 139/303, Loss: 0.6230254173278809\n",
      "Epoch 1/20, Iteration 140/303, Loss: 0.7271885871887207\n",
      "Epoch 1/20, Iteration 141/303, Loss: 0.6892613172531128\n",
      "Epoch 1/20, Iteration 142/303, Loss: 0.6729456186294556\n",
      "Epoch 1/20, Iteration 143/303, Loss: 0.7013736367225647\n",
      "Epoch 1/20, Iteration 144/303, Loss: 0.6968175172805786\n",
      "Epoch 1/20, Iteration 145/303, Loss: 0.6503715515136719\n",
      "Epoch 1/20, Iteration 146/303, Loss: 0.7052960991859436\n",
      "Epoch 1/20, Iteration 147/303, Loss: 0.6827669739723206\n",
      "Epoch 1/20, Iteration 148/303, Loss: 0.6689997315406799\n",
      "Epoch 1/20, Iteration 149/303, Loss: 0.6306993961334229\n",
      "Epoch 1/20, Iteration 150/303, Loss: 0.6171676516532898\n",
      "Epoch 1/20, Iteration 151/303, Loss: 0.6113414764404297\n",
      "Epoch 1/20, Iteration 152/303, Loss: 0.7102705240249634\n",
      "Epoch 1/20, Iteration 153/303, Loss: 0.630203366279602\n",
      "Epoch 1/20, Iteration 154/303, Loss: 0.6568946838378906\n",
      "Epoch 1/20, Iteration 155/303, Loss: 0.7557920217514038\n",
      "Epoch 1/20, Iteration 156/303, Loss: 0.6826178431510925\n",
      "Epoch 1/20, Iteration 157/303, Loss: 0.6785988211631775\n",
      "Epoch 1/20, Iteration 158/303, Loss: 0.685464084148407\n",
      "Epoch 1/20, Iteration 159/303, Loss: 0.6844369173049927\n",
      "Epoch 1/20, Iteration 160/303, Loss: 0.6829988956451416\n",
      "Epoch 1/20, Iteration 161/303, Loss: 0.6665278077125549\n",
      "Epoch 1/20, Iteration 162/303, Loss: 0.6788990497589111\n",
      "Epoch 1/20, Iteration 163/303, Loss: 0.6603150367736816\n",
      "Epoch 1/20, Iteration 164/303, Loss: 0.6721702218055725\n",
      "Epoch 1/20, Iteration 165/303, Loss: 0.6948829293251038\n",
      "Epoch 1/20, Iteration 166/303, Loss: 0.7127330899238586\n",
      "Epoch 1/20, Iteration 167/303, Loss: 0.6776784062385559\n",
      "Epoch 1/20, Iteration 168/303, Loss: 0.694222092628479\n",
      "Epoch 1/20, Iteration 169/303, Loss: 0.6517530083656311\n",
      "Epoch 1/20, Iteration 170/303, Loss: 0.7047510147094727\n",
      "Epoch 1/20, Iteration 171/303, Loss: 0.6556803584098816\n",
      "Epoch 1/20, Iteration 172/303, Loss: 0.5909819602966309\n",
      "Epoch 1/20, Iteration 173/303, Loss: 0.6225771903991699\n",
      "Epoch 1/20, Iteration 174/303, Loss: 0.5897723436355591\n",
      "Epoch 1/20, Iteration 175/303, Loss: 0.7163229584693909\n",
      "Epoch 1/20, Iteration 176/303, Loss: 0.6306401491165161\n",
      "Epoch 1/20, Iteration 177/303, Loss: 0.6749018430709839\n",
      "Epoch 1/20, Iteration 178/303, Loss: 0.6248521208763123\n",
      "Epoch 1/20, Iteration 179/303, Loss: 0.6506454944610596\n",
      "Epoch 1/20, Iteration 180/303, Loss: 0.6402019262313843\n",
      "Epoch 1/20, Iteration 181/303, Loss: 0.6808575391769409\n",
      "Epoch 1/20, Iteration 182/303, Loss: 0.7102919220924377\n",
      "Epoch 1/20, Iteration 183/303, Loss: 0.6368570327758789\n",
      "Epoch 1/20, Iteration 184/303, Loss: 0.6900872588157654\n",
      "Epoch 1/20, Iteration 185/303, Loss: 0.5852909684181213\n",
      "Epoch 1/20, Iteration 186/303, Loss: 0.7140856385231018\n",
      "Epoch 1/20, Iteration 187/303, Loss: 0.6230523586273193\n",
      "Epoch 1/20, Iteration 188/303, Loss: 0.6739750504493713\n",
      "Epoch 1/20, Iteration 189/303, Loss: 0.6738682985305786\n",
      "Epoch 1/20, Iteration 190/303, Loss: 0.6783208847045898\n",
      "Epoch 1/20, Iteration 191/303, Loss: 0.668005108833313\n",
      "Epoch 1/20, Iteration 192/303, Loss: 0.6516351103782654\n",
      "Epoch 1/20, Iteration 193/303, Loss: 0.6382433772087097\n",
      "Epoch 1/20, Iteration 194/303, Loss: 0.6416367292404175\n",
      "Epoch 1/20, Iteration 195/303, Loss: 0.7154010534286499\n",
      "Epoch 1/20, Iteration 196/303, Loss: 0.6602592468261719\n",
      "Epoch 1/20, Iteration 197/303, Loss: 0.6469002366065979\n",
      "Epoch 1/20, Iteration 198/303, Loss: 0.6953902840614319\n",
      "Epoch 1/20, Iteration 199/303, Loss: 0.6458255052566528\n",
      "Epoch 1/20, Iteration 200/303, Loss: 0.7046558260917664\n",
      "Epoch 1/20, Iteration 201/303, Loss: 0.7091426849365234\n",
      "Epoch 1/20, Iteration 202/303, Loss: 0.6469637751579285\n",
      "Epoch 1/20, Iteration 203/303, Loss: 0.6925917863845825\n",
      "Epoch 1/20, Iteration 204/303, Loss: 0.6845070123672485\n",
      "Epoch 1/20, Iteration 205/303, Loss: 0.6908942461013794\n",
      "Epoch 1/20, Iteration 206/303, Loss: 0.6899607181549072\n",
      "Epoch 1/20, Iteration 207/303, Loss: 0.7050202488899231\n",
      "Epoch 1/20, Iteration 208/303, Loss: 0.6812800168991089\n",
      "Epoch 1/20, Iteration 209/303, Loss: 0.668100118637085\n",
      "Epoch 1/20, Iteration 210/303, Loss: 0.6621394753456116\n",
      "Epoch 1/20, Iteration 211/303, Loss: 0.7280501127243042\n",
      "Epoch 1/20, Iteration 212/303, Loss: 0.6514027118682861\n",
      "Epoch 1/20, Iteration 213/303, Loss: 0.6337230205535889\n",
      "Epoch 1/20, Iteration 214/303, Loss: 0.750648558139801\n",
      "Epoch 1/20, Iteration 215/303, Loss: 0.665851354598999\n",
      "Epoch 1/20, Iteration 216/303, Loss: 0.6924012899398804\n",
      "Epoch 1/20, Iteration 217/303, Loss: 0.6549385786056519\n",
      "Epoch 1/20, Iteration 218/303, Loss: 0.689018726348877\n",
      "Epoch 1/20, Iteration 219/303, Loss: 0.6949838399887085\n",
      "Epoch 1/20, Iteration 220/303, Loss: 0.6518911719322205\n",
      "Epoch 1/20, Iteration 221/303, Loss: 0.6573863625526428\n",
      "Epoch 1/20, Iteration 222/303, Loss: 0.6646681427955627\n",
      "Epoch 1/20, Iteration 223/303, Loss: 0.6926835179328918\n",
      "Epoch 1/20, Iteration 224/303, Loss: 0.6638802289962769\n",
      "Epoch 1/20, Iteration 225/303, Loss: 0.702639639377594\n",
      "Epoch 1/20, Iteration 226/303, Loss: 0.7080651521682739\n",
      "Epoch 1/20, Iteration 227/303, Loss: 0.6723415851593018\n",
      "Epoch 1/20, Iteration 228/303, Loss: 0.6642926335334778\n",
      "Epoch 1/20, Iteration 229/303, Loss: 0.6861282587051392\n",
      "Epoch 1/20, Iteration 230/303, Loss: 0.6810550689697266\n",
      "Epoch 1/20, Iteration 231/303, Loss: 0.6550624370574951\n",
      "Epoch 1/20, Iteration 232/303, Loss: 0.6529537439346313\n",
      "Epoch 1/20, Iteration 233/303, Loss: 0.6957955956459045\n",
      "Epoch 1/20, Iteration 234/303, Loss: 0.6639236807823181\n",
      "Epoch 1/20, Iteration 235/303, Loss: 0.6667619347572327\n",
      "Epoch 1/20, Iteration 236/303, Loss: 0.7018806338310242\n",
      "Epoch 1/20, Iteration 237/303, Loss: 0.6695702075958252\n",
      "Epoch 1/20, Iteration 238/303, Loss: 0.6655992269515991\n",
      "Epoch 1/20, Iteration 239/303, Loss: 0.6714427471160889\n",
      "Epoch 1/20, Iteration 240/303, Loss: 0.6687061786651611\n",
      "Epoch 1/20, Iteration 241/303, Loss: 0.6322650909423828\n",
      "Epoch 1/20, Iteration 242/303, Loss: 0.645184338092804\n",
      "Epoch 1/20, Iteration 243/303, Loss: 0.6831291913986206\n",
      "Epoch 1/20, Iteration 244/303, Loss: 0.6972253918647766\n",
      "Epoch 1/20, Iteration 245/303, Loss: 0.6555601954460144\n",
      "Epoch 1/20, Iteration 246/303, Loss: 0.6669460535049438\n",
      "Epoch 1/20, Iteration 247/303, Loss: 0.6973305344581604\n",
      "Epoch 1/20, Iteration 248/303, Loss: 0.7126091718673706\n",
      "Epoch 1/20, Iteration 249/303, Loss: 0.6874688267707825\n",
      "Epoch 1/20, Iteration 250/303, Loss: 0.6299884915351868\n",
      "Epoch 1/20, Iteration 251/303, Loss: 0.622448205947876\n",
      "Epoch 1/20, Iteration 252/303, Loss: 0.6130774021148682\n",
      "Epoch 1/20, Iteration 253/303, Loss: 0.7102487683296204\n",
      "Epoch 1/20, Iteration 254/303, Loss: 0.6297576427459717\n",
      "Epoch 1/20, Iteration 255/303, Loss: 0.6885324716567993\n",
      "Epoch 1/20, Iteration 256/303, Loss: 0.6362007856369019\n",
      "Epoch 1/20, Iteration 257/303, Loss: 0.6736425161361694\n",
      "Epoch 1/20, Iteration 258/303, Loss: 0.6276659965515137\n",
      "Epoch 1/20, Iteration 259/303, Loss: 0.6523659825325012\n",
      "Epoch 1/20, Iteration 260/303, Loss: 0.650943398475647\n",
      "Epoch 1/20, Iteration 261/303, Loss: 0.596170961856842\n",
      "Epoch 1/20, Iteration 262/303, Loss: 0.6883943676948547\n",
      "Epoch 1/20, Iteration 263/303, Loss: 0.6726781129837036\n",
      "Epoch 1/20, Iteration 264/303, Loss: 0.6721905469894409\n",
      "Epoch 1/20, Iteration 265/303, Loss: 0.5991970300674438\n",
      "Epoch 1/20, Iteration 266/303, Loss: 0.7526687979698181\n",
      "Epoch 1/20, Iteration 267/303, Loss: 0.6696295142173767\n",
      "Epoch 1/20, Iteration 268/303, Loss: 0.665835976600647\n",
      "Epoch 1/20, Iteration 269/303, Loss: 0.6951535940170288\n",
      "Epoch 1/20, Iteration 270/303, Loss: 0.6795085072517395\n",
      "Epoch 1/20, Iteration 271/303, Loss: 0.6396083235740662\n",
      "Epoch 1/20, Iteration 272/303, Loss: 0.6665608286857605\n",
      "Epoch 1/20, Iteration 273/303, Loss: 0.7017941474914551\n",
      "Epoch 1/20, Iteration 274/303, Loss: 0.6544554233551025\n",
      "Epoch 1/20, Iteration 275/303, Loss: 0.6248749494552612\n",
      "Epoch 1/20, Iteration 276/303, Loss: 0.616948127746582\n",
      "Epoch 1/20, Iteration 277/303, Loss: 0.7065703868865967\n",
      "Epoch 1/20, Iteration 278/303, Loss: 0.6747602224349976\n",
      "Epoch 1/20, Iteration 279/303, Loss: 0.645686149597168\n",
      "Epoch 1/20, Iteration 280/303, Loss: 0.6661587953567505\n",
      "Epoch 1/20, Iteration 281/303, Loss: 0.7188276052474976\n",
      "Epoch 1/20, Iteration 282/303, Loss: 0.6749163269996643\n",
      "Epoch 1/20, Iteration 283/303, Loss: 0.6518025398254395\n",
      "Epoch 1/20, Iteration 284/303, Loss: 0.7078797817230225\n",
      "Epoch 1/20, Iteration 285/303, Loss: 0.7057814598083496\n",
      "Epoch 1/20, Iteration 286/303, Loss: 0.6410243511199951\n",
      "Epoch 1/20, Iteration 287/303, Loss: 0.6923797726631165\n",
      "Epoch 1/20, Iteration 288/303, Loss: 0.6713131666183472\n",
      "Epoch 1/20, Iteration 289/303, Loss: 0.6464831829071045\n",
      "Epoch 1/20, Iteration 290/303, Loss: 0.6174178123474121\n",
      "Epoch 1/20, Iteration 291/303, Loss: 0.5756241679191589\n",
      "Epoch 1/20, Iteration 292/303, Loss: 0.6802700757980347\n",
      "Epoch 1/20, Iteration 293/303, Loss: 0.592625617980957\n",
      "Epoch 1/20, Iteration 294/303, Loss: 0.6564215421676636\n",
      "Epoch 1/20, Iteration 295/303, Loss: 0.691254198551178\n",
      "Epoch 1/20, Iteration 296/303, Loss: 0.676498293876648\n",
      "Epoch 1/20, Iteration 297/303, Loss: 0.697780430316925\n",
      "Epoch 1/20, Iteration 298/303, Loss: 0.6366998553276062\n",
      "Epoch 1/20, Iteration 299/303, Loss: 0.652957558631897\n",
      "Epoch 1/20, Iteration 300/303, Loss: 0.6754553318023682\n",
      "Epoch 1/20, Iteration 301/303, Loss: 0.6914916634559631\n",
      "Epoch 1/20, Iteration 302/303, Loss: 0.661071240901947\n",
      "Epoch 1/20, Iteration 303/303, Loss: 0.6638646721839905\n",
      "Epoch 2/20, Iteration 1/303, Loss: 0.652259349822998\n",
      "Epoch 2/20, Iteration 2/303, Loss: 0.639940619468689\n",
      "Epoch 2/20, Iteration 3/303, Loss: 0.6325636506080627\n",
      "Epoch 2/20, Iteration 4/303, Loss: 0.5980908870697021\n",
      "Epoch 2/20, Iteration 5/303, Loss: 0.656944751739502\n",
      "Epoch 2/20, Iteration 6/303, Loss: 0.6400150060653687\n",
      "Epoch 2/20, Iteration 7/303, Loss: 0.6094830632209778\n",
      "Epoch 2/20, Iteration 8/303, Loss: 0.5775001645088196\n",
      "Epoch 2/20, Iteration 9/303, Loss: 0.7393704056739807\n",
      "Epoch 2/20, Iteration 10/303, Loss: 0.6791432499885559\n",
      "Epoch 2/20, Iteration 11/303, Loss: 0.6423774361610413\n",
      "Epoch 2/20, Iteration 12/303, Loss: 0.6863201260566711\n",
      "Epoch 2/20, Iteration 13/303, Loss: 0.6526147127151489\n",
      "Epoch 2/20, Iteration 14/303, Loss: 0.657973051071167\n",
      "Epoch 2/20, Iteration 15/303, Loss: 0.603274941444397\n",
      "Epoch 2/20, Iteration 16/303, Loss: 0.6556454300880432\n",
      "Epoch 2/20, Iteration 17/303, Loss: 0.661981463432312\n",
      "Epoch 2/20, Iteration 18/303, Loss: 0.6535592079162598\n",
      "Epoch 2/20, Iteration 19/303, Loss: 0.668797492980957\n",
      "Epoch 2/20, Iteration 20/303, Loss: 0.7267574667930603\n",
      "Epoch 2/20, Iteration 21/303, Loss: 0.6591329574584961\n",
      "Epoch 2/20, Iteration 22/303, Loss: 0.6569340825080872\n",
      "Epoch 2/20, Iteration 23/303, Loss: 0.6616004109382629\n",
      "Epoch 2/20, Iteration 24/303, Loss: 0.6688792109489441\n",
      "Epoch 2/20, Iteration 25/303, Loss: 0.6615599393844604\n",
      "Epoch 2/20, Iteration 26/303, Loss: 0.666668176651001\n",
      "Epoch 2/20, Iteration 27/303, Loss: 0.6879062652587891\n",
      "Epoch 2/20, Iteration 28/303, Loss: 0.6299709677696228\n",
      "Epoch 2/20, Iteration 29/303, Loss: 0.645419180393219\n",
      "Epoch 2/20, Iteration 30/303, Loss: 0.6302869319915771\n",
      "Epoch 2/20, Iteration 31/303, Loss: 0.5328179001808167\n",
      "Epoch 2/20, Iteration 32/303, Loss: 0.6563419103622437\n",
      "Epoch 2/20, Iteration 33/303, Loss: 0.774124801158905\n",
      "Epoch 2/20, Iteration 34/303, Loss: 0.6759902834892273\n",
      "Epoch 2/20, Iteration 35/303, Loss: 0.6612012386322021\n",
      "Epoch 2/20, Iteration 36/303, Loss: 0.6327459812164307\n",
      "Epoch 2/20, Iteration 37/303, Loss: 0.5392932295799255\n",
      "Epoch 2/20, Iteration 38/303, Loss: 0.7018015384674072\n",
      "Epoch 2/20, Iteration 39/303, Loss: 0.6622093915939331\n",
      "Epoch 2/20, Iteration 40/303, Loss: 0.6206791400909424\n",
      "Epoch 2/20, Iteration 41/303, Loss: 0.6858082413673401\n",
      "Epoch 2/20, Iteration 42/303, Loss: 0.6520586013793945\n",
      "Epoch 2/20, Iteration 43/303, Loss: 0.6518882513046265\n",
      "Epoch 2/20, Iteration 44/303, Loss: 0.7082683444023132\n",
      "Epoch 2/20, Iteration 45/303, Loss: 0.6428995728492737\n",
      "Epoch 2/20, Iteration 46/303, Loss: 0.6600633263587952\n",
      "Epoch 2/20, Iteration 47/303, Loss: 0.6348514556884766\n",
      "Epoch 2/20, Iteration 48/303, Loss: 0.6344826221466064\n",
      "Epoch 2/20, Iteration 49/303, Loss: 0.6234957575798035\n",
      "Epoch 2/20, Iteration 50/303, Loss: 0.6240905523300171\n",
      "Epoch 2/20, Iteration 51/303, Loss: 0.5987478494644165\n",
      "Epoch 2/20, Iteration 52/303, Loss: 0.6784533858299255\n",
      "Epoch 2/20, Iteration 53/303, Loss: 0.6411178112030029\n",
      "Epoch 2/20, Iteration 54/303, Loss: 0.6811019778251648\n",
      "Epoch 2/20, Iteration 55/303, Loss: 0.6543099880218506\n",
      "Epoch 2/20, Iteration 56/303, Loss: 0.7065386176109314\n",
      "Epoch 2/20, Iteration 57/303, Loss: 0.678441047668457\n",
      "Epoch 2/20, Iteration 58/303, Loss: 0.6805270314216614\n",
      "Epoch 2/20, Iteration 59/303, Loss: 0.6468803882598877\n",
      "Epoch 2/20, Iteration 60/303, Loss: 0.6863142251968384\n",
      "Epoch 2/20, Iteration 61/303, Loss: 0.6340339779853821\n",
      "Epoch 2/20, Iteration 62/303, Loss: 0.6994558572769165\n",
      "Epoch 2/20, Iteration 63/303, Loss: 0.6434236168861389\n",
      "Epoch 2/20, Iteration 64/303, Loss: 0.6537864804267883\n",
      "Epoch 2/20, Iteration 65/303, Loss: 0.6390174031257629\n",
      "Epoch 2/20, Iteration 66/303, Loss: 0.6360992789268494\n",
      "Epoch 2/20, Iteration 67/303, Loss: 0.6335175037384033\n",
      "Epoch 2/20, Iteration 68/303, Loss: 0.6175761222839355\n",
      "Epoch 2/20, Iteration 69/303, Loss: 0.6061533689498901\n",
      "Epoch 2/20, Iteration 70/303, Loss: 0.7459715604782104\n",
      "Epoch 2/20, Iteration 71/303, Loss: 0.6972604393959045\n",
      "Epoch 2/20, Iteration 72/303, Loss: 0.6569449305534363\n",
      "Epoch 2/20, Iteration 73/303, Loss: 0.7583585977554321\n",
      "Epoch 2/20, Iteration 74/303, Loss: 0.6385631561279297\n",
      "Epoch 2/20, Iteration 75/303, Loss: 0.601438045501709\n",
      "Epoch 2/20, Iteration 76/303, Loss: 0.5936161875724792\n",
      "Epoch 2/20, Iteration 77/303, Loss: 0.5017243027687073\n",
      "Epoch 2/20, Iteration 78/303, Loss: 0.8850762844085693\n",
      "Epoch 2/20, Iteration 79/303, Loss: 0.6604724526405334\n",
      "Epoch 2/20, Iteration 80/303, Loss: 0.6798055171966553\n",
      "Epoch 2/20, Iteration 81/303, Loss: 0.6597160696983337\n",
      "Epoch 2/20, Iteration 82/303, Loss: 0.6728787422180176\n",
      "Epoch 2/20, Iteration 83/303, Loss: 0.6434236764907837\n",
      "Epoch 2/20, Iteration 84/303, Loss: 0.6682004332542419\n",
      "Epoch 2/20, Iteration 85/303, Loss: 0.6645777821540833\n",
      "Epoch 2/20, Iteration 86/303, Loss: 0.6341745257377625\n",
      "Epoch 2/20, Iteration 87/303, Loss: 0.6506284475326538\n",
      "Epoch 2/20, Iteration 88/303, Loss: 0.7045971751213074\n",
      "Epoch 2/20, Iteration 89/303, Loss: 0.602755606174469\n",
      "Epoch 2/20, Iteration 90/303, Loss: 0.6347574591636658\n",
      "Epoch 2/20, Iteration 91/303, Loss: 0.6427425742149353\n",
      "Epoch 2/20, Iteration 92/303, Loss: 0.6512033343315125\n",
      "Epoch 2/20, Iteration 93/303, Loss: 0.662524938583374\n",
      "Epoch 2/20, Iteration 94/303, Loss: 0.6241288185119629\n",
      "Epoch 2/20, Iteration 95/303, Loss: 0.6077091693878174\n",
      "Epoch 2/20, Iteration 96/303, Loss: 0.6341191530227661\n",
      "Epoch 2/20, Iteration 97/303, Loss: 0.6223447918891907\n",
      "Epoch 2/20, Iteration 98/303, Loss: 0.6314646601676941\n",
      "Epoch 2/20, Iteration 99/303, Loss: 0.6352053284645081\n",
      "Epoch 2/20, Iteration 100/303, Loss: 0.6252173185348511\n",
      "Epoch 2/20, Iteration 101/303, Loss: 0.6182918548583984\n",
      "Epoch 2/20, Iteration 102/303, Loss: 0.7430343627929688\n",
      "Epoch 2/20, Iteration 103/303, Loss: 0.6209016442298889\n",
      "Epoch 2/20, Iteration 104/303, Loss: 0.6525135040283203\n",
      "Epoch 2/20, Iteration 105/303, Loss: 0.5939294695854187\n",
      "Epoch 2/20, Iteration 106/303, Loss: 0.7299565672874451\n",
      "Epoch 2/20, Iteration 107/303, Loss: 0.6547019481658936\n",
      "Epoch 2/20, Iteration 108/303, Loss: 0.6004790663719177\n",
      "Epoch 2/20, Iteration 109/303, Loss: 0.5913257598876953\n",
      "Epoch 2/20, Iteration 110/303, Loss: 0.5626519918441772\n",
      "Epoch 2/20, Iteration 111/303, Loss: 0.5645060539245605\n",
      "Epoch 2/20, Iteration 112/303, Loss: 0.6224936246871948\n",
      "Epoch 2/20, Iteration 113/303, Loss: 0.5331181883811951\n",
      "Epoch 2/20, Iteration 114/303, Loss: 0.6955685019493103\n",
      "Epoch 2/20, Iteration 115/303, Loss: 0.6347059011459351\n",
      "Epoch 2/20, Iteration 116/303, Loss: 0.632489800453186\n",
      "Epoch 2/20, Iteration 117/303, Loss: 0.6436649560928345\n",
      "Epoch 2/20, Iteration 118/303, Loss: 0.6002264022827148\n",
      "Epoch 2/20, Iteration 119/303, Loss: 0.5706436038017273\n",
      "Epoch 2/20, Iteration 120/303, Loss: 0.629988431930542\n",
      "Epoch 2/20, Iteration 121/303, Loss: 0.7031147480010986\n",
      "Epoch 2/20, Iteration 122/303, Loss: 0.6470810770988464\n",
      "Epoch 2/20, Iteration 123/303, Loss: 0.622260570526123\n",
      "Epoch 2/20, Iteration 124/303, Loss: 0.7014606595039368\n",
      "Epoch 2/20, Iteration 125/303, Loss: 0.5967419147491455\n",
      "Epoch 2/20, Iteration 126/303, Loss: 0.6610376238822937\n",
      "Epoch 2/20, Iteration 127/303, Loss: 0.6157299280166626\n",
      "Epoch 2/20, Iteration 128/303, Loss: 0.6770555973052979\n",
      "Epoch 2/20, Iteration 129/303, Loss: 0.7187573313713074\n",
      "Epoch 2/20, Iteration 130/303, Loss: 0.6375371217727661\n",
      "Epoch 2/20, Iteration 131/303, Loss: 0.6066564917564392\n",
      "Epoch 2/20, Iteration 132/303, Loss: 0.576240062713623\n",
      "Epoch 2/20, Iteration 133/303, Loss: 0.6139084696769714\n",
      "Epoch 2/20, Iteration 134/303, Loss: 0.6048197746276855\n",
      "Epoch 2/20, Iteration 135/303, Loss: 0.6961312294006348\n",
      "Epoch 2/20, Iteration 136/303, Loss: 0.6964573264122009\n",
      "Epoch 2/20, Iteration 137/303, Loss: 0.6311300992965698\n",
      "Epoch 2/20, Iteration 138/303, Loss: 0.644607424736023\n",
      "Epoch 2/20, Iteration 139/303, Loss: 0.6077505350112915\n",
      "Epoch 2/20, Iteration 140/303, Loss: 0.6011516451835632\n",
      "Epoch 2/20, Iteration 141/303, Loss: 0.632099986076355\n",
      "Epoch 2/20, Iteration 142/303, Loss: 0.610863208770752\n",
      "Epoch 2/20, Iteration 143/303, Loss: 0.7003932595252991\n",
      "Epoch 2/20, Iteration 144/303, Loss: 0.6724960207939148\n",
      "Epoch 2/20, Iteration 145/303, Loss: 0.7538547515869141\n",
      "Epoch 2/20, Iteration 146/303, Loss: 0.6403967142105103\n",
      "Epoch 2/20, Iteration 147/303, Loss: 0.7206857204437256\n",
      "Epoch 2/20, Iteration 148/303, Loss: 0.6220579147338867\n",
      "Epoch 2/20, Iteration 149/303, Loss: 0.7011762261390686\n",
      "Epoch 2/20, Iteration 150/303, Loss: 0.6325391530990601\n",
      "Epoch 2/20, Iteration 151/303, Loss: 0.6312716007232666\n",
      "Epoch 2/20, Iteration 152/303, Loss: 0.6394534111022949\n",
      "Epoch 2/20, Iteration 153/303, Loss: 0.5996888279914856\n",
      "Epoch 2/20, Iteration 154/303, Loss: 0.6566425561904907\n",
      "Epoch 2/20, Iteration 155/303, Loss: 0.5891721248626709\n",
      "Epoch 2/20, Iteration 156/303, Loss: 0.6884106397628784\n",
      "Epoch 2/20, Iteration 157/303, Loss: 0.6438953876495361\n",
      "Epoch 2/20, Iteration 158/303, Loss: 0.6220930814743042\n",
      "Epoch 2/20, Iteration 159/303, Loss: 0.6647226214408875\n",
      "Epoch 2/20, Iteration 160/303, Loss: 0.6285384297370911\n",
      "Epoch 2/20, Iteration 161/303, Loss: 0.611919641494751\n",
      "Epoch 2/20, Iteration 162/303, Loss: 0.618804395198822\n",
      "Epoch 2/20, Iteration 163/303, Loss: 0.5737303495407104\n",
      "Epoch 2/20, Iteration 164/303, Loss: 0.6575055122375488\n",
      "Epoch 2/20, Iteration 165/303, Loss: 0.5675166845321655\n",
      "Epoch 2/20, Iteration 166/303, Loss: 0.6849560737609863\n",
      "Epoch 2/20, Iteration 167/303, Loss: 0.673304557800293\n",
      "Epoch 2/20, Iteration 168/303, Loss: 0.6679723262786865\n",
      "Epoch 2/20, Iteration 169/303, Loss: 0.5757761001586914\n",
      "Epoch 2/20, Iteration 170/303, Loss: 0.6392339468002319\n",
      "Epoch 2/20, Iteration 171/303, Loss: 0.6442904472351074\n",
      "Epoch 2/20, Iteration 172/303, Loss: 0.4866081476211548\n",
      "Epoch 2/20, Iteration 173/303, Loss: 0.6253246068954468\n",
      "Epoch 2/20, Iteration 174/303, Loss: 0.5417604446411133\n",
      "Epoch 2/20, Iteration 175/303, Loss: 0.6939932703971863\n",
      "Epoch 2/20, Iteration 176/303, Loss: 0.7117970585823059\n",
      "Epoch 2/20, Iteration 177/303, Loss: 0.6142088174819946\n",
      "Epoch 2/20, Iteration 178/303, Loss: 0.5648556351661682\n",
      "Epoch 2/20, Iteration 179/303, Loss: 0.6168961524963379\n",
      "Epoch 2/20, Iteration 180/303, Loss: 0.543928861618042\n",
      "Epoch 2/20, Iteration 181/303, Loss: 0.5320180058479309\n",
      "Epoch 2/20, Iteration 182/303, Loss: 0.6484197378158569\n",
      "Epoch 2/20, Iteration 183/303, Loss: 0.7546737194061279\n",
      "Epoch 2/20, Iteration 184/303, Loss: 0.6722659468650818\n",
      "Epoch 2/20, Iteration 185/303, Loss: 0.6813212633132935\n",
      "Epoch 2/20, Iteration 186/303, Loss: 0.6466532349586487\n",
      "Epoch 2/20, Iteration 187/303, Loss: 0.6424824595451355\n",
      "Epoch 2/20, Iteration 188/303, Loss: 0.6392802000045776\n",
      "Epoch 2/20, Iteration 189/303, Loss: 0.683850884437561\n",
      "Epoch 2/20, Iteration 190/303, Loss: 0.6603856682777405\n",
      "Epoch 2/20, Iteration 191/303, Loss: 0.6581494808197021\n",
      "Epoch 2/20, Iteration 192/303, Loss: 0.6701920628547668\n",
      "Epoch 2/20, Iteration 193/303, Loss: 0.6804137229919434\n",
      "Epoch 2/20, Iteration 194/303, Loss: 0.5742406845092773\n",
      "Epoch 2/20, Iteration 195/303, Loss: 0.5992704629898071\n",
      "Epoch 2/20, Iteration 196/303, Loss: 0.6896828413009644\n",
      "Epoch 2/20, Iteration 197/303, Loss: 0.5940977334976196\n",
      "Epoch 2/20, Iteration 198/303, Loss: 0.6738430261611938\n",
      "Epoch 2/20, Iteration 199/303, Loss: 0.6182228326797485\n",
      "Epoch 2/20, Iteration 200/303, Loss: 0.5607895851135254\n",
      "Epoch 2/20, Iteration 201/303, Loss: 0.5298550724983215\n",
      "Epoch 2/20, Iteration 202/303, Loss: 0.7436460256576538\n",
      "Epoch 2/20, Iteration 203/303, Loss: 0.6303163170814514\n",
      "Epoch 2/20, Iteration 204/303, Loss: 0.5406852960586548\n",
      "Epoch 2/20, Iteration 205/303, Loss: 0.6969782114028931\n",
      "Epoch 2/20, Iteration 206/303, Loss: 0.5797688961029053\n",
      "Epoch 2/20, Iteration 207/303, Loss: 0.4690324664115906\n",
      "Epoch 2/20, Iteration 208/303, Loss: 0.5798777341842651\n",
      "Epoch 2/20, Iteration 209/303, Loss: 0.55619877576828\n",
      "Epoch 2/20, Iteration 210/303, Loss: 0.5510316491127014\n",
      "Epoch 2/20, Iteration 211/303, Loss: 0.6193386912345886\n",
      "Epoch 2/20, Iteration 212/303, Loss: 0.5249806046485901\n",
      "Epoch 2/20, Iteration 213/303, Loss: 0.7015393376350403\n",
      "Epoch 2/20, Iteration 214/303, Loss: 0.6079311370849609\n",
      "Epoch 2/20, Iteration 215/303, Loss: 0.563058078289032\n",
      "Epoch 2/20, Iteration 216/303, Loss: 0.519081175327301\n",
      "Epoch 2/20, Iteration 217/303, Loss: 0.6114503741264343\n",
      "Epoch 2/20, Iteration 218/303, Loss: 0.5370601415634155\n",
      "Epoch 2/20, Iteration 219/303, Loss: 0.6138454675674438\n",
      "Epoch 2/20, Iteration 220/303, Loss: 0.6758055090904236\n",
      "Epoch 2/20, Iteration 221/303, Loss: 0.6313353180885315\n",
      "Epoch 2/20, Iteration 222/303, Loss: 0.6013274192810059\n",
      "Epoch 2/20, Iteration 223/303, Loss: 0.576592206954956\n",
      "Epoch 2/20, Iteration 224/303, Loss: 0.661486804485321\n",
      "Epoch 2/20, Iteration 225/303, Loss: 0.748558521270752\n",
      "Epoch 2/20, Iteration 226/303, Loss: 0.7383331656455994\n",
      "Epoch 2/20, Iteration 227/303, Loss: 0.5898230075836182\n",
      "Epoch 2/20, Iteration 228/303, Loss: 0.5486679673194885\n",
      "Epoch 2/20, Iteration 229/303, Loss: 0.5385012626647949\n",
      "Epoch 2/20, Iteration 230/303, Loss: 0.6194260120391846\n",
      "Epoch 2/20, Iteration 231/303, Loss: 0.5825222730636597\n",
      "Epoch 2/20, Iteration 232/303, Loss: 0.5970298051834106\n",
      "Epoch 2/20, Iteration 233/303, Loss: 0.5393083691596985\n",
      "Epoch 2/20, Iteration 234/303, Loss: 0.5893105864524841\n",
      "Epoch 2/20, Iteration 235/303, Loss: 0.7315914034843445\n",
      "Epoch 2/20, Iteration 236/303, Loss: 0.5525602102279663\n",
      "Epoch 2/20, Iteration 237/303, Loss: 0.545445442199707\n",
      "Epoch 2/20, Iteration 238/303, Loss: 0.6231456995010376\n",
      "Epoch 2/20, Iteration 239/303, Loss: 0.5526176691055298\n",
      "Epoch 2/20, Iteration 240/303, Loss: 0.6558384895324707\n",
      "Epoch 2/20, Iteration 241/303, Loss: 0.5497480630874634\n",
      "Epoch 2/20, Iteration 242/303, Loss: 0.5522329807281494\n",
      "Epoch 2/20, Iteration 243/303, Loss: 0.6140509843826294\n",
      "Epoch 2/20, Iteration 244/303, Loss: 0.5730882287025452\n",
      "Epoch 2/20, Iteration 245/303, Loss: 0.5424491763114929\n",
      "Epoch 2/20, Iteration 246/303, Loss: 0.6609570980072021\n",
      "Epoch 2/20, Iteration 247/303, Loss: 0.616245448589325\n",
      "Epoch 2/20, Iteration 248/303, Loss: 0.5445836782455444\n",
      "Epoch 2/20, Iteration 249/303, Loss: 0.5765049457550049\n",
      "Epoch 2/20, Iteration 250/303, Loss: 0.6372297406196594\n",
      "Epoch 2/20, Iteration 251/303, Loss: 0.44743943214416504\n",
      "Epoch 2/20, Iteration 252/303, Loss: 0.6074990034103394\n",
      "Epoch 2/20, Iteration 253/303, Loss: 0.4705611765384674\n",
      "Epoch 2/20, Iteration 254/303, Loss: 0.8302168846130371\n",
      "Epoch 2/20, Iteration 255/303, Loss: 0.5958190560340881\n",
      "Epoch 2/20, Iteration 256/303, Loss: 0.6254991292953491\n",
      "Epoch 2/20, Iteration 257/303, Loss: 0.6172966361045837\n",
      "Epoch 2/20, Iteration 258/303, Loss: 0.5726418495178223\n",
      "Epoch 2/20, Iteration 259/303, Loss: 0.6670938730239868\n",
      "Epoch 2/20, Iteration 260/303, Loss: 0.5428234338760376\n",
      "Epoch 2/20, Iteration 261/303, Loss: 0.6589999198913574\n",
      "Epoch 2/20, Iteration 262/303, Loss: 0.5824395418167114\n",
      "Epoch 2/20, Iteration 263/303, Loss: 0.6461787223815918\n",
      "Epoch 2/20, Iteration 264/303, Loss: 0.6931464076042175\n",
      "Epoch 2/20, Iteration 265/303, Loss: 0.6122022271156311\n",
      "Epoch 2/20, Iteration 266/303, Loss: 0.7011200189590454\n",
      "Epoch 2/20, Iteration 267/303, Loss: 0.5790212750434875\n",
      "Epoch 2/20, Iteration 268/303, Loss: 0.5193920731544495\n",
      "Epoch 2/20, Iteration 269/303, Loss: 0.5421817898750305\n",
      "Epoch 2/20, Iteration 270/303, Loss: 0.5255588889122009\n",
      "Epoch 2/20, Iteration 271/303, Loss: 0.5183571577072144\n",
      "Epoch 2/20, Iteration 272/303, Loss: 0.5915548205375671\n",
      "Epoch 2/20, Iteration 273/303, Loss: 0.5664222240447998\n",
      "Epoch 2/20, Iteration 274/303, Loss: 0.6207340359687805\n",
      "Epoch 2/20, Iteration 275/303, Loss: 0.5786105990409851\n",
      "Epoch 2/20, Iteration 276/303, Loss: 0.5544430017471313\n",
      "Epoch 2/20, Iteration 277/303, Loss: 0.572681725025177\n",
      "Epoch 2/20, Iteration 278/303, Loss: 0.7736078500747681\n",
      "Epoch 2/20, Iteration 279/303, Loss: 0.5459003448486328\n",
      "Epoch 2/20, Iteration 280/303, Loss: 0.7059082388877869\n",
      "Epoch 2/20, Iteration 281/303, Loss: 0.5600906610488892\n",
      "Epoch 2/20, Iteration 282/303, Loss: 0.607728123664856\n",
      "Epoch 2/20, Iteration 283/303, Loss: 0.7250075936317444\n",
      "Epoch 2/20, Iteration 284/303, Loss: 0.7104560136795044\n",
      "Epoch 2/20, Iteration 285/303, Loss: 0.6655929088592529\n",
      "Epoch 2/20, Iteration 286/303, Loss: 0.6050275564193726\n",
      "Epoch 2/20, Iteration 287/303, Loss: 0.5775817036628723\n",
      "Epoch 2/20, Iteration 288/303, Loss: 0.5914648771286011\n",
      "Epoch 2/20, Iteration 289/303, Loss: 0.5661816000938416\n",
      "Epoch 2/20, Iteration 290/303, Loss: 0.7398809194564819\n",
      "Epoch 2/20, Iteration 291/303, Loss: 0.574140191078186\n",
      "Epoch 2/20, Iteration 292/303, Loss: 0.7685059309005737\n",
      "Epoch 2/20, Iteration 293/303, Loss: 0.585625171661377\n",
      "Epoch 2/20, Iteration 294/303, Loss: 0.606791079044342\n",
      "Epoch 2/20, Iteration 295/303, Loss: 0.6389719247817993\n",
      "Epoch 2/20, Iteration 296/303, Loss: 0.6439712643623352\n",
      "Epoch 2/20, Iteration 297/303, Loss: 0.4731782078742981\n",
      "Epoch 2/20, Iteration 298/303, Loss: 0.7650801539421082\n",
      "Epoch 2/20, Iteration 299/303, Loss: 0.5214403867721558\n",
      "Epoch 2/20, Iteration 300/303, Loss: 0.6744521260261536\n",
      "Epoch 2/20, Iteration 301/303, Loss: 0.5418673753738403\n",
      "Epoch 2/20, Iteration 302/303, Loss: 0.5729609131813049\n",
      "Epoch 2/20, Iteration 303/303, Loss: 0.5914884209632874\n",
      "Epoch 3/20, Iteration 1/303, Loss: 0.567479133605957\n",
      "Epoch 3/20, Iteration 2/303, Loss: 0.6080653071403503\n",
      "Epoch 3/20, Iteration 3/303, Loss: 0.5347433090209961\n",
      "Epoch 3/20, Iteration 4/303, Loss: 0.48875564336776733\n",
      "Epoch 3/20, Iteration 5/303, Loss: 0.6054826974868774\n",
      "Epoch 3/20, Iteration 6/303, Loss: 0.4967668652534485\n",
      "Epoch 3/20, Iteration 7/303, Loss: 0.47795772552490234\n",
      "Epoch 3/20, Iteration 8/303, Loss: 0.8773717284202576\n",
      "Epoch 3/20, Iteration 9/303, Loss: 0.6405110955238342\n",
      "Epoch 3/20, Iteration 10/303, Loss: 0.5948407649993896\n",
      "Epoch 3/20, Iteration 11/303, Loss: 0.6430239081382751\n",
      "Epoch 3/20, Iteration 12/303, Loss: 0.6539737582206726\n",
      "Epoch 3/20, Iteration 13/303, Loss: 0.6441223621368408\n",
      "Epoch 3/20, Iteration 14/303, Loss: 0.5973021984100342\n",
      "Epoch 3/20, Iteration 15/303, Loss: 0.5238518714904785\n",
      "Epoch 3/20, Iteration 16/303, Loss: 0.47883403301239014\n",
      "Epoch 3/20, Iteration 17/303, Loss: 0.6145204901695251\n",
      "Epoch 3/20, Iteration 18/303, Loss: 0.500893235206604\n",
      "Epoch 3/20, Iteration 19/303, Loss: 0.5168850421905518\n",
      "Epoch 3/20, Iteration 20/303, Loss: 0.44555431604385376\n",
      "Epoch 3/20, Iteration 21/303, Loss: 0.7543298006057739\n",
      "Epoch 3/20, Iteration 22/303, Loss: 0.5648137927055359\n",
      "Epoch 3/20, Iteration 23/303, Loss: 0.687893807888031\n",
      "Epoch 3/20, Iteration 24/303, Loss: 0.6133237481117249\n",
      "Epoch 3/20, Iteration 25/303, Loss: 0.4976004958152771\n",
      "Epoch 3/20, Iteration 26/303, Loss: 0.6094341278076172\n",
      "Epoch 3/20, Iteration 27/303, Loss: 0.5750926733016968\n",
      "Epoch 3/20, Iteration 28/303, Loss: 0.6095705628395081\n",
      "Epoch 3/20, Iteration 29/303, Loss: 0.6111852526664734\n",
      "Epoch 3/20, Iteration 30/303, Loss: 0.5527875423431396\n",
      "Epoch 3/20, Iteration 31/303, Loss: 0.5282360315322876\n",
      "Epoch 3/20, Iteration 32/303, Loss: 0.5364009141921997\n",
      "Epoch 3/20, Iteration 33/303, Loss: 0.6516560316085815\n",
      "Epoch 3/20, Iteration 34/303, Loss: 0.6733668446540833\n",
      "Epoch 3/20, Iteration 35/303, Loss: 0.5519915223121643\n",
      "Epoch 3/20, Iteration 36/303, Loss: 0.7107754945755005\n",
      "Epoch 3/20, Iteration 37/303, Loss: 0.5754653811454773\n",
      "Epoch 3/20, Iteration 38/303, Loss: 0.5980433225631714\n",
      "Epoch 3/20, Iteration 39/303, Loss: 0.5434057712554932\n",
      "Epoch 3/20, Iteration 40/303, Loss: 0.6056864261627197\n",
      "Epoch 3/20, Iteration 41/303, Loss: 0.5776948928833008\n",
      "Epoch 3/20, Iteration 42/303, Loss: 0.5354449152946472\n",
      "Epoch 3/20, Iteration 43/303, Loss: 0.48018866777420044\n",
      "Epoch 3/20, Iteration 44/303, Loss: 0.5228701233863831\n",
      "Epoch 3/20, Iteration 45/303, Loss: 0.5404863953590393\n",
      "Epoch 3/20, Iteration 46/303, Loss: 0.5522630214691162\n",
      "Epoch 3/20, Iteration 47/303, Loss: 0.41102302074432373\n",
      "Epoch 3/20, Iteration 48/303, Loss: 0.922081470489502\n",
      "Epoch 3/20, Iteration 49/303, Loss: 0.7532990574836731\n",
      "Epoch 3/20, Iteration 50/303, Loss: 0.605715274810791\n",
      "Epoch 3/20, Iteration 51/303, Loss: 0.658920168876648\n",
      "Epoch 3/20, Iteration 52/303, Loss: 0.6105473637580872\n",
      "Epoch 3/20, Iteration 53/303, Loss: 0.6944359540939331\n",
      "Epoch 3/20, Iteration 54/303, Loss: 0.5263800621032715\n",
      "Epoch 3/20, Iteration 55/303, Loss: 0.6382643580436707\n",
      "Epoch 3/20, Iteration 56/303, Loss: 0.516965389251709\n",
      "Epoch 3/20, Iteration 57/303, Loss: 0.6151822805404663\n",
      "Epoch 3/20, Iteration 58/303, Loss: 0.6955492496490479\n",
      "Epoch 3/20, Iteration 59/303, Loss: 0.669977605342865\n",
      "Epoch 3/20, Iteration 60/303, Loss: 0.5659829378128052\n",
      "Epoch 3/20, Iteration 61/303, Loss: 0.6089963912963867\n",
      "Epoch 3/20, Iteration 62/303, Loss: 0.5407921671867371\n",
      "Epoch 3/20, Iteration 63/303, Loss: 0.5836325287818909\n",
      "Epoch 3/20, Iteration 64/303, Loss: 0.5737481117248535\n",
      "Epoch 3/20, Iteration 65/303, Loss: 0.5271227955818176\n",
      "Epoch 3/20, Iteration 66/303, Loss: 0.4681079387664795\n",
      "Epoch 3/20, Iteration 67/303, Loss: 0.5462237596511841\n",
      "Epoch 3/20, Iteration 68/303, Loss: 0.6299969553947449\n",
      "Epoch 3/20, Iteration 69/303, Loss: 0.9417185187339783\n",
      "Epoch 3/20, Iteration 70/303, Loss: 0.45037102699279785\n",
      "Epoch 3/20, Iteration 71/303, Loss: 0.6047605872154236\n",
      "Epoch 3/20, Iteration 72/303, Loss: 0.6111865043640137\n",
      "Epoch 3/20, Iteration 73/303, Loss: 0.5570064187049866\n",
      "Epoch 3/20, Iteration 74/303, Loss: 0.8478553891181946\n",
      "Epoch 3/20, Iteration 75/303, Loss: 0.6562948226928711\n",
      "Epoch 3/20, Iteration 76/303, Loss: 0.6140049695968628\n",
      "Epoch 3/20, Iteration 77/303, Loss: 0.6014799475669861\n",
      "Epoch 3/20, Iteration 78/303, Loss: 0.5223002433776855\n",
      "Epoch 3/20, Iteration 79/303, Loss: 0.6031704545021057\n",
      "Epoch 3/20, Iteration 80/303, Loss: 0.6055358648300171\n",
      "Epoch 3/20, Iteration 81/303, Loss: 0.6133798360824585\n",
      "Epoch 3/20, Iteration 82/303, Loss: 0.613974928855896\n",
      "Epoch 3/20, Iteration 83/303, Loss: 0.6579386591911316\n",
      "Epoch 3/20, Iteration 84/303, Loss: 0.6823779344558716\n",
      "Epoch 3/20, Iteration 85/303, Loss: 0.6316139698028564\n",
      "Epoch 3/20, Iteration 86/303, Loss: 0.5316407084465027\n",
      "Epoch 3/20, Iteration 87/303, Loss: 0.5002561807632446\n",
      "Epoch 3/20, Iteration 88/303, Loss: 0.5875348448753357\n",
      "Epoch 3/20, Iteration 89/303, Loss: 0.6194639801979065\n",
      "Epoch 3/20, Iteration 90/303, Loss: 0.6165784001350403\n",
      "Epoch 3/20, Iteration 91/303, Loss: 0.5901911854743958\n",
      "Epoch 3/20, Iteration 92/303, Loss: 0.7070629596710205\n",
      "Epoch 3/20, Iteration 93/303, Loss: 0.5787450671195984\n",
      "Epoch 3/20, Iteration 94/303, Loss: 0.6380688548088074\n",
      "Epoch 3/20, Iteration 95/303, Loss: 0.650368332862854\n",
      "Epoch 3/20, Iteration 96/303, Loss: 0.4980623126029968\n",
      "Epoch 3/20, Iteration 97/303, Loss: 0.6428990960121155\n",
      "Epoch 3/20, Iteration 98/303, Loss: 0.6262614727020264\n",
      "Epoch 3/20, Iteration 99/303, Loss: 0.601029634475708\n",
      "Epoch 3/20, Iteration 100/303, Loss: 0.5479390621185303\n",
      "Epoch 3/20, Iteration 101/303, Loss: 0.4854632616043091\n",
      "Epoch 3/20, Iteration 102/303, Loss: 0.5260046124458313\n",
      "Epoch 3/20, Iteration 103/303, Loss: 0.5555619597434998\n",
      "Epoch 3/20, Iteration 104/303, Loss: 0.5624024271965027\n",
      "Epoch 3/20, Iteration 105/303, Loss: 0.6760058403015137\n",
      "Epoch 3/20, Iteration 106/303, Loss: 0.48986735939979553\n",
      "Epoch 3/20, Iteration 107/303, Loss: 0.44644829630851746\n",
      "Epoch 3/20, Iteration 108/303, Loss: 0.5100705623626709\n",
      "Epoch 3/20, Iteration 109/303, Loss: 0.5331575274467468\n",
      "Epoch 3/20, Iteration 110/303, Loss: 0.6236684322357178\n",
      "Epoch 3/20, Iteration 111/303, Loss: 0.6125739812850952\n",
      "Epoch 3/20, Iteration 112/303, Loss: 0.695428729057312\n",
      "Epoch 3/20, Iteration 113/303, Loss: 0.5574431419372559\n",
      "Epoch 3/20, Iteration 114/303, Loss: 0.46499326825141907\n",
      "Epoch 3/20, Iteration 115/303, Loss: 0.6065869331359863\n",
      "Epoch 3/20, Iteration 116/303, Loss: 0.6474403142929077\n",
      "Epoch 3/20, Iteration 117/303, Loss: 0.4656691253185272\n",
      "Epoch 3/20, Iteration 118/303, Loss: 0.5855798721313477\n",
      "Epoch 3/20, Iteration 119/303, Loss: 0.6285154223442078\n",
      "Epoch 3/20, Iteration 120/303, Loss: 0.6576008796691895\n",
      "Epoch 3/20, Iteration 121/303, Loss: 0.49741238355636597\n",
      "Epoch 3/20, Iteration 122/303, Loss: 0.644394040107727\n",
      "Epoch 3/20, Iteration 123/303, Loss: 0.5445704460144043\n",
      "Epoch 3/20, Iteration 124/303, Loss: 0.5118646025657654\n",
      "Epoch 3/20, Iteration 125/303, Loss: 0.5704532861709595\n",
      "Epoch 3/20, Iteration 126/303, Loss: 0.5642653703689575\n",
      "Epoch 3/20, Iteration 127/303, Loss: 0.526389479637146\n",
      "Epoch 3/20, Iteration 128/303, Loss: 0.5703887939453125\n",
      "Epoch 3/20, Iteration 129/303, Loss: 0.5155191421508789\n",
      "Epoch 3/20, Iteration 130/303, Loss: 0.5553426742553711\n",
      "Epoch 3/20, Iteration 131/303, Loss: 0.4687807857990265\n",
      "Epoch 3/20, Iteration 132/303, Loss: 0.49276044964790344\n",
      "Epoch 3/20, Iteration 133/303, Loss: 0.5699622631072998\n",
      "Epoch 3/20, Iteration 134/303, Loss: 0.625838577747345\n",
      "Epoch 3/20, Iteration 135/303, Loss: 0.5404971241950989\n",
      "Epoch 3/20, Iteration 136/303, Loss: 0.6626399755477905\n",
      "Epoch 3/20, Iteration 137/303, Loss: 0.4740681052207947\n",
      "Epoch 3/20, Iteration 138/303, Loss: 0.5571658611297607\n",
      "Epoch 3/20, Iteration 139/303, Loss: 0.4591367244720459\n",
      "Epoch 3/20, Iteration 140/303, Loss: 0.680181622505188\n",
      "Epoch 3/20, Iteration 141/303, Loss: 0.43344855308532715\n",
      "Epoch 3/20, Iteration 142/303, Loss: 0.601250410079956\n",
      "Epoch 3/20, Iteration 143/303, Loss: 0.6571773886680603\n",
      "Epoch 3/20, Iteration 144/303, Loss: 0.4751712679862976\n",
      "Epoch 3/20, Iteration 145/303, Loss: 0.5188624858856201\n",
      "Epoch 3/20, Iteration 146/303, Loss: 0.6371781826019287\n",
      "Epoch 3/20, Iteration 147/303, Loss: 0.5290488004684448\n",
      "Epoch 3/20, Iteration 148/303, Loss: 0.5860691666603088\n",
      "Epoch 3/20, Iteration 149/303, Loss: 0.5430669784545898\n",
      "Epoch 3/20, Iteration 150/303, Loss: 0.5360143184661865\n",
      "Epoch 3/20, Iteration 151/303, Loss: 0.5069517493247986\n",
      "Epoch 3/20, Iteration 152/303, Loss: 0.4589640200138092\n",
      "Epoch 3/20, Iteration 153/303, Loss: 0.4489031136035919\n",
      "Epoch 3/20, Iteration 154/303, Loss: 0.48432838916778564\n",
      "Epoch 3/20, Iteration 155/303, Loss: 0.4834841191768646\n",
      "Epoch 3/20, Iteration 156/303, Loss: 0.40703532099723816\n",
      "Epoch 3/20, Iteration 157/303, Loss: 0.46173375844955444\n",
      "Epoch 3/20, Iteration 158/303, Loss: 0.6562104225158691\n",
      "Epoch 3/20, Iteration 159/303, Loss: 0.5053995251655579\n",
      "Epoch 3/20, Iteration 160/303, Loss: 0.498470664024353\n",
      "Epoch 3/20, Iteration 161/303, Loss: 0.6116970181465149\n",
      "Epoch 3/20, Iteration 162/303, Loss: 0.5214401483535767\n",
      "Epoch 3/20, Iteration 163/303, Loss: 0.5835404992103577\n",
      "Epoch 3/20, Iteration 164/303, Loss: 0.4879598021507263\n",
      "Epoch 3/20, Iteration 165/303, Loss: 0.5033758878707886\n",
      "Epoch 3/20, Iteration 166/303, Loss: 0.6037578582763672\n",
      "Epoch 3/20, Iteration 167/303, Loss: 0.6241002678871155\n",
      "Epoch 3/20, Iteration 168/303, Loss: 0.4453432559967041\n",
      "Epoch 3/20, Iteration 169/303, Loss: 0.646110475063324\n",
      "Epoch 3/20, Iteration 170/303, Loss: 0.5160473585128784\n",
      "Epoch 3/20, Iteration 171/303, Loss: 0.6060775518417358\n",
      "Epoch 3/20, Iteration 172/303, Loss: 0.5456163883209229\n",
      "Epoch 3/20, Iteration 173/303, Loss: 0.5322599411010742\n",
      "Epoch 3/20, Iteration 174/303, Loss: 0.5242500901222229\n",
      "Epoch 3/20, Iteration 175/303, Loss: 0.6929054856300354\n",
      "Epoch 3/20, Iteration 176/303, Loss: 0.5560168027877808\n",
      "Epoch 3/20, Iteration 177/303, Loss: 0.5719882845878601\n",
      "Epoch 3/20, Iteration 178/303, Loss: 0.5591932535171509\n",
      "Epoch 3/20, Iteration 179/303, Loss: 0.39723363518714905\n",
      "Epoch 3/20, Iteration 180/303, Loss: 0.6571788787841797\n",
      "Epoch 3/20, Iteration 181/303, Loss: 0.4652453064918518\n",
      "Epoch 3/20, Iteration 182/303, Loss: 0.3944289982318878\n",
      "Epoch 3/20, Iteration 183/303, Loss: 0.4554934501647949\n",
      "Epoch 3/20, Iteration 184/303, Loss: 0.7174899578094482\n",
      "Epoch 3/20, Iteration 185/303, Loss: 0.5272241234779358\n",
      "Epoch 3/20, Iteration 186/303, Loss: 0.5680223703384399\n",
      "Epoch 3/20, Iteration 187/303, Loss: 0.46831458806991577\n",
      "Epoch 3/20, Iteration 188/303, Loss: 0.4871634244918823\n",
      "Epoch 3/20, Iteration 189/303, Loss: 0.5295140743255615\n",
      "Epoch 3/20, Iteration 190/303, Loss: 0.6423084735870361\n",
      "Epoch 3/20, Iteration 191/303, Loss: 0.6529620885848999\n",
      "Epoch 3/20, Iteration 192/303, Loss: 0.6519500017166138\n",
      "Epoch 3/20, Iteration 193/303, Loss: 0.551766037940979\n",
      "Epoch 3/20, Iteration 194/303, Loss: 0.602440595626831\n",
      "Epoch 3/20, Iteration 195/303, Loss: 0.5129334330558777\n",
      "Epoch 3/20, Iteration 196/303, Loss: 0.4304436445236206\n",
      "Epoch 3/20, Iteration 197/303, Loss: 0.6376193761825562\n",
      "Epoch 3/20, Iteration 198/303, Loss: 0.4623238742351532\n",
      "Epoch 3/20, Iteration 199/303, Loss: 0.5725134611129761\n",
      "Epoch 3/20, Iteration 200/303, Loss: 0.43409162759780884\n",
      "Epoch 3/20, Iteration 201/303, Loss: 0.5198476314544678\n",
      "Epoch 3/20, Iteration 202/303, Loss: 0.48261409997940063\n",
      "Epoch 3/20, Iteration 203/303, Loss: 0.49604421854019165\n",
      "Epoch 3/20, Iteration 204/303, Loss: 0.4722497761249542\n",
      "Epoch 3/20, Iteration 205/303, Loss: 0.6003191471099854\n",
      "Epoch 3/20, Iteration 206/303, Loss: 0.6142088174819946\n",
      "Epoch 3/20, Iteration 207/303, Loss: 0.501442551612854\n",
      "Epoch 3/20, Iteration 208/303, Loss: 0.49412089586257935\n",
      "Epoch 3/20, Iteration 209/303, Loss: 0.6238943934440613\n",
      "Epoch 3/20, Iteration 210/303, Loss: 0.5175991058349609\n",
      "Epoch 3/20, Iteration 211/303, Loss: 0.4054601788520813\n",
      "Epoch 3/20, Iteration 212/303, Loss: 0.46227607131004333\n",
      "Epoch 3/20, Iteration 213/303, Loss: 0.4744885563850403\n",
      "Epoch 3/20, Iteration 214/303, Loss: 0.6759456396102905\n",
      "Epoch 3/20, Iteration 215/303, Loss: 0.42084044218063354\n",
      "Epoch 3/20, Iteration 216/303, Loss: 0.673525869846344\n",
      "Epoch 3/20, Iteration 217/303, Loss: 0.5628272294998169\n",
      "Epoch 3/20, Iteration 218/303, Loss: 0.6197381615638733\n",
      "Epoch 3/20, Iteration 219/303, Loss: 0.6126285791397095\n",
      "Epoch 3/20, Iteration 220/303, Loss: 0.5333904027938843\n",
      "Epoch 3/20, Iteration 221/303, Loss: 0.5342071652412415\n",
      "Epoch 3/20, Iteration 222/303, Loss: 0.547694742679596\n",
      "Epoch 3/20, Iteration 223/303, Loss: 0.4815959930419922\n",
      "Epoch 3/20, Iteration 224/303, Loss: 0.5200192928314209\n",
      "Epoch 3/20, Iteration 225/303, Loss: 0.5084106922149658\n",
      "Epoch 3/20, Iteration 226/303, Loss: 0.3953239321708679\n",
      "Epoch 3/20, Iteration 227/303, Loss: 0.6716306209564209\n",
      "Epoch 3/20, Iteration 228/303, Loss: 0.4632004499435425\n",
      "Epoch 3/20, Iteration 229/303, Loss: 0.5203534960746765\n",
      "Epoch 3/20, Iteration 230/303, Loss: 0.663718581199646\n",
      "Epoch 3/20, Iteration 231/303, Loss: 0.6572356224060059\n",
      "Epoch 3/20, Iteration 232/303, Loss: 0.4791432023048401\n",
      "Epoch 3/20, Iteration 233/303, Loss: 0.36042341589927673\n",
      "Epoch 3/20, Iteration 234/303, Loss: 0.39551204442977905\n",
      "Epoch 3/20, Iteration 235/303, Loss: 0.6121483445167542\n",
      "Epoch 3/20, Iteration 236/303, Loss: 0.48030197620391846\n",
      "Epoch 3/20, Iteration 237/303, Loss: 0.5723124146461487\n",
      "Epoch 3/20, Iteration 238/303, Loss: 0.49658462405204773\n",
      "Epoch 3/20, Iteration 239/303, Loss: 0.5033082365989685\n",
      "Epoch 3/20, Iteration 240/303, Loss: 0.5508115291595459\n",
      "Epoch 3/20, Iteration 241/303, Loss: 0.4149230718612671\n",
      "Epoch 3/20, Iteration 242/303, Loss: 0.6197175979614258\n",
      "Epoch 3/20, Iteration 243/303, Loss: 0.5085963606834412\n",
      "Epoch 3/20, Iteration 244/303, Loss: 0.39940938353538513\n",
      "Epoch 3/20, Iteration 245/303, Loss: 0.38041141629219055\n",
      "Epoch 3/20, Iteration 246/303, Loss: 0.45541566610336304\n",
      "Epoch 3/20, Iteration 247/303, Loss: 0.6255660057067871\n",
      "Epoch 3/20, Iteration 248/303, Loss: 0.544209897518158\n",
      "Epoch 3/20, Iteration 249/303, Loss: 0.5764915943145752\n",
      "Epoch 3/20, Iteration 250/303, Loss: 0.5791412591934204\n",
      "Epoch 3/20, Iteration 251/303, Loss: 0.5037838220596313\n",
      "Epoch 3/20, Iteration 252/303, Loss: 0.5729938745498657\n",
      "Epoch 3/20, Iteration 253/303, Loss: 0.5823676586151123\n",
      "Epoch 3/20, Iteration 254/303, Loss: 0.5258718132972717\n",
      "Epoch 3/20, Iteration 255/303, Loss: 0.4834100306034088\n",
      "Epoch 3/20, Iteration 256/303, Loss: 0.45879051089286804\n",
      "Epoch 3/20, Iteration 257/303, Loss: 0.5125742554664612\n",
      "Epoch 3/20, Iteration 258/303, Loss: 0.4570687413215637\n",
      "Epoch 3/20, Iteration 259/303, Loss: 0.42234912514686584\n",
      "Epoch 3/20, Iteration 260/303, Loss: 0.4872833490371704\n",
      "Epoch 3/20, Iteration 261/303, Loss: 0.5139035582542419\n",
      "Epoch 3/20, Iteration 262/303, Loss: 0.5013768672943115\n",
      "Epoch 3/20, Iteration 263/303, Loss: 0.499020516872406\n",
      "Epoch 3/20, Iteration 264/303, Loss: 0.5365365743637085\n",
      "Epoch 3/20, Iteration 265/303, Loss: 0.6825007200241089\n",
      "Epoch 3/20, Iteration 266/303, Loss: 0.6990848779678345\n",
      "Epoch 3/20, Iteration 267/303, Loss: 0.5467549562454224\n",
      "Epoch 3/20, Iteration 268/303, Loss: 0.559819221496582\n",
      "Epoch 3/20, Iteration 269/303, Loss: 0.43650925159454346\n",
      "Epoch 3/20, Iteration 270/303, Loss: 0.579371988773346\n",
      "Epoch 3/20, Iteration 271/303, Loss: 0.5359576940536499\n",
      "Epoch 3/20, Iteration 272/303, Loss: 0.5413779020309448\n",
      "Epoch 3/20, Iteration 273/303, Loss: 0.524437665939331\n",
      "Epoch 3/20, Iteration 274/303, Loss: 0.5250679850578308\n",
      "Epoch 3/20, Iteration 275/303, Loss: 0.4405105412006378\n",
      "Epoch 3/20, Iteration 276/303, Loss: 0.4670754373073578\n",
      "Epoch 3/20, Iteration 277/303, Loss: 0.44898414611816406\n",
      "Epoch 3/20, Iteration 278/303, Loss: 0.5029709935188293\n",
      "Epoch 3/20, Iteration 279/303, Loss: 0.5043468475341797\n",
      "Epoch 3/20, Iteration 280/303, Loss: 1.2859537601470947\n",
      "Epoch 3/20, Iteration 281/303, Loss: 0.624060869216919\n",
      "Epoch 3/20, Iteration 282/303, Loss: 0.47775179147720337\n",
      "Epoch 3/20, Iteration 283/303, Loss: 0.647973358631134\n",
      "Epoch 3/20, Iteration 284/303, Loss: 0.523461639881134\n",
      "Epoch 3/20, Iteration 285/303, Loss: 0.4743742346763611\n",
      "Epoch 3/20, Iteration 286/303, Loss: 0.530454695224762\n",
      "Epoch 3/20, Iteration 287/303, Loss: 0.669324517250061\n",
      "Epoch 3/20, Iteration 288/303, Loss: 0.6620786190032959\n",
      "Epoch 3/20, Iteration 289/303, Loss: 0.60723477602005\n",
      "Epoch 3/20, Iteration 290/303, Loss: 0.5675646066665649\n",
      "Epoch 3/20, Iteration 291/303, Loss: 0.5033241510391235\n",
      "Epoch 3/20, Iteration 292/303, Loss: 0.5315572023391724\n",
      "Epoch 3/20, Iteration 293/303, Loss: 0.4341554641723633\n",
      "Epoch 3/20, Iteration 294/303, Loss: 0.45600926876068115\n",
      "Epoch 3/20, Iteration 295/303, Loss: 0.5046445727348328\n",
      "Epoch 3/20, Iteration 296/303, Loss: 0.5541171431541443\n",
      "Epoch 3/20, Iteration 297/303, Loss: 0.5267612338066101\n",
      "Epoch 3/20, Iteration 298/303, Loss: 0.43028536438941956\n",
      "Epoch 3/20, Iteration 299/303, Loss: 0.5013120770454407\n",
      "Epoch 3/20, Iteration 300/303, Loss: 0.43505898118019104\n",
      "Epoch 3/20, Iteration 301/303, Loss: 0.5851253271102905\n",
      "Epoch 3/20, Iteration 302/303, Loss: 0.4878762662410736\n",
      "Epoch 3/20, Iteration 303/303, Loss: 0.5169472098350525\n",
      "Epoch 4/20, Iteration 1/303, Loss: 0.5157734751701355\n",
      "Epoch 4/20, Iteration 2/303, Loss: 0.5564695596694946\n",
      "Epoch 4/20, Iteration 3/303, Loss: 0.5313229560852051\n",
      "Epoch 4/20, Iteration 4/303, Loss: 0.4571106731891632\n",
      "Epoch 4/20, Iteration 5/303, Loss: 0.5883351564407349\n",
      "Epoch 4/20, Iteration 6/303, Loss: 0.6105093359947205\n",
      "Epoch 4/20, Iteration 7/303, Loss: 0.6338050961494446\n",
      "Epoch 4/20, Iteration 8/303, Loss: 0.49460282921791077\n",
      "Epoch 4/20, Iteration 9/303, Loss: 0.6295491456985474\n",
      "Epoch 4/20, Iteration 10/303, Loss: 0.49738702178001404\n",
      "Epoch 4/20, Iteration 11/303, Loss: 0.5345044136047363\n",
      "Epoch 4/20, Iteration 12/303, Loss: 0.4829595983028412\n",
      "Epoch 4/20, Iteration 13/303, Loss: 0.5461324453353882\n",
      "Epoch 4/20, Iteration 14/303, Loss: 0.4797118902206421\n",
      "Epoch 4/20, Iteration 15/303, Loss: 0.6074368953704834\n",
      "Epoch 4/20, Iteration 16/303, Loss: 0.4862655699253082\n",
      "Epoch 4/20, Iteration 17/303, Loss: 0.5104597210884094\n",
      "Epoch 4/20, Iteration 18/303, Loss: 0.6245981454849243\n",
      "Epoch 4/20, Iteration 19/303, Loss: 0.5565943121910095\n",
      "Epoch 4/20, Iteration 20/303, Loss: 0.46432143449783325\n",
      "Epoch 4/20, Iteration 21/303, Loss: 0.398031085729599\n",
      "Epoch 4/20, Iteration 22/303, Loss: 0.5179718732833862\n",
      "Epoch 4/20, Iteration 23/303, Loss: 0.560415506362915\n",
      "Epoch 4/20, Iteration 24/303, Loss: 0.5797220468521118\n",
      "Epoch 4/20, Iteration 25/303, Loss: 0.475574791431427\n",
      "Epoch 4/20, Iteration 26/303, Loss: 0.4749568998813629\n",
      "Epoch 4/20, Iteration 27/303, Loss: 0.6533169746398926\n",
      "Epoch 4/20, Iteration 28/303, Loss: 0.6212671995162964\n",
      "Epoch 4/20, Iteration 29/303, Loss: 0.41319739818573\n",
      "Epoch 4/20, Iteration 30/303, Loss: 0.5410253405570984\n",
      "Epoch 4/20, Iteration 31/303, Loss: 0.5184656977653503\n",
      "Epoch 4/20, Iteration 32/303, Loss: 0.5598548054695129\n",
      "Epoch 4/20, Iteration 33/303, Loss: 0.4524613618850708\n",
      "Epoch 4/20, Iteration 34/303, Loss: 0.657028079032898\n",
      "Epoch 4/20, Iteration 35/303, Loss: 0.5163874626159668\n",
      "Epoch 4/20, Iteration 36/303, Loss: 0.4779917597770691\n",
      "Epoch 4/20, Iteration 37/303, Loss: 0.5108699202537537\n",
      "Epoch 4/20, Iteration 38/303, Loss: 0.48565012216567993\n",
      "Epoch 4/20, Iteration 39/303, Loss: 0.5389887690544128\n",
      "Epoch 4/20, Iteration 40/303, Loss: 0.3759995102882385\n",
      "Epoch 4/20, Iteration 41/303, Loss: 0.49081894755363464\n",
      "Epoch 4/20, Iteration 42/303, Loss: 0.6589559316635132\n",
      "Epoch 4/20, Iteration 43/303, Loss: 0.6383877992630005\n",
      "Epoch 4/20, Iteration 44/303, Loss: 0.49844738841056824\n",
      "Epoch 4/20, Iteration 45/303, Loss: 0.5650044083595276\n",
      "Epoch 4/20, Iteration 46/303, Loss: 0.6461760997772217\n",
      "Epoch 4/20, Iteration 47/303, Loss: 0.4740687608718872\n",
      "Epoch 4/20, Iteration 48/303, Loss: 0.5577219128608704\n",
      "Epoch 4/20, Iteration 49/303, Loss: 0.4956003427505493\n",
      "Epoch 4/20, Iteration 50/303, Loss: 0.4119594395160675\n",
      "Epoch 4/20, Iteration 51/303, Loss: 0.45490360260009766\n",
      "Epoch 4/20, Iteration 52/303, Loss: 0.5330012440681458\n",
      "Epoch 4/20, Iteration 53/303, Loss: 0.6096419095993042\n",
      "Epoch 4/20, Iteration 54/303, Loss: 0.5171483159065247\n",
      "Epoch 4/20, Iteration 55/303, Loss: 0.491944819688797\n",
      "Epoch 4/20, Iteration 56/303, Loss: 0.39012840390205383\n",
      "Epoch 4/20, Iteration 57/303, Loss: 0.46147313714027405\n",
      "Epoch 4/20, Iteration 58/303, Loss: 0.5188865065574646\n",
      "Epoch 4/20, Iteration 59/303, Loss: 0.5526595115661621\n",
      "Epoch 4/20, Iteration 60/303, Loss: 0.5712621212005615\n",
      "Epoch 4/20, Iteration 61/303, Loss: 0.4914091229438782\n",
      "Epoch 4/20, Iteration 62/303, Loss: 0.5482511520385742\n",
      "Epoch 4/20, Iteration 63/303, Loss: 0.4611968398094177\n",
      "Epoch 4/20, Iteration 64/303, Loss: 0.37870705127716064\n",
      "Epoch 4/20, Iteration 65/303, Loss: 0.42355701327323914\n",
      "Epoch 4/20, Iteration 66/303, Loss: 0.4022364616394043\n",
      "Epoch 4/20, Iteration 67/303, Loss: 0.46361619234085083\n",
      "Epoch 4/20, Iteration 68/303, Loss: 0.7549030780792236\n",
      "Epoch 4/20, Iteration 69/303, Loss: 0.5357572436332703\n",
      "Epoch 4/20, Iteration 70/303, Loss: 0.406575083732605\n",
      "Epoch 4/20, Iteration 71/303, Loss: 0.4458581805229187\n",
      "Epoch 4/20, Iteration 72/303, Loss: 0.5751463174819946\n",
      "Epoch 4/20, Iteration 73/303, Loss: 0.43657609820365906\n",
      "Epoch 4/20, Iteration 74/303, Loss: 0.5418070554733276\n",
      "Epoch 4/20, Iteration 75/303, Loss: 0.5281899571418762\n",
      "Epoch 4/20, Iteration 76/303, Loss: 0.4579864740371704\n",
      "Epoch 4/20, Iteration 77/303, Loss: 0.6279510259628296\n",
      "Epoch 4/20, Iteration 78/303, Loss: 0.4290282130241394\n",
      "Epoch 4/20, Iteration 79/303, Loss: 0.3899986445903778\n",
      "Epoch 4/20, Iteration 80/303, Loss: 0.4203629791736603\n",
      "Epoch 4/20, Iteration 81/303, Loss: 0.6227516531944275\n",
      "Epoch 4/20, Iteration 82/303, Loss: 0.5352138876914978\n",
      "Epoch 4/20, Iteration 83/303, Loss: 0.5401666760444641\n",
      "Epoch 4/20, Iteration 84/303, Loss: 0.5072985291481018\n",
      "Epoch 4/20, Iteration 85/303, Loss: 0.4559885859489441\n",
      "Epoch 4/20, Iteration 86/303, Loss: 0.5448810458183289\n",
      "Epoch 4/20, Iteration 87/303, Loss: 0.45892155170440674\n",
      "Epoch 4/20, Iteration 88/303, Loss: 0.553346574306488\n",
      "Epoch 4/20, Iteration 89/303, Loss: 0.5120863914489746\n",
      "Epoch 4/20, Iteration 90/303, Loss: 0.6222993731498718\n",
      "Epoch 4/20, Iteration 91/303, Loss: 0.47116619348526\n",
      "Epoch 4/20, Iteration 92/303, Loss: 0.6332058310508728\n",
      "Epoch 4/20, Iteration 93/303, Loss: 0.5430218577384949\n",
      "Epoch 4/20, Iteration 94/303, Loss: 0.5352661609649658\n",
      "Epoch 4/20, Iteration 95/303, Loss: 0.47657492756843567\n",
      "Epoch 4/20, Iteration 96/303, Loss: 0.5190945863723755\n",
      "Epoch 4/20, Iteration 97/303, Loss: 0.5776374340057373\n",
      "Epoch 4/20, Iteration 98/303, Loss: 0.5651788711547852\n",
      "Epoch 4/20, Iteration 99/303, Loss: 0.3611593544483185\n",
      "Epoch 4/20, Iteration 100/303, Loss: 0.4466630816459656\n",
      "Epoch 4/20, Iteration 101/303, Loss: 0.4157421588897705\n",
      "Epoch 4/20, Iteration 102/303, Loss: 0.4993629455566406\n",
      "Epoch 4/20, Iteration 103/303, Loss: 0.43177664279937744\n",
      "Epoch 4/20, Iteration 104/303, Loss: 0.48577195405960083\n",
      "Epoch 4/20, Iteration 105/303, Loss: 0.42757588624954224\n",
      "Epoch 4/20, Iteration 106/303, Loss: 0.46203187108039856\n",
      "Epoch 4/20, Iteration 107/303, Loss: 0.6341530084609985\n",
      "Epoch 4/20, Iteration 108/303, Loss: 0.44319745898246765\n",
      "Epoch 4/20, Iteration 109/303, Loss: 0.5961665511131287\n",
      "Epoch 4/20, Iteration 110/303, Loss: 0.407713919878006\n",
      "Epoch 4/20, Iteration 111/303, Loss: 0.5544417500495911\n",
      "Epoch 4/20, Iteration 112/303, Loss: 0.3795489966869354\n",
      "Epoch 4/20, Iteration 113/303, Loss: 0.4897712469100952\n",
      "Epoch 4/20, Iteration 114/303, Loss: 0.3739051818847656\n",
      "Epoch 4/20, Iteration 115/303, Loss: 0.47363919019699097\n",
      "Epoch 4/20, Iteration 116/303, Loss: 0.6171931028366089\n",
      "Epoch 4/20, Iteration 117/303, Loss: 0.6194248199462891\n",
      "Epoch 4/20, Iteration 118/303, Loss: 0.5798212289810181\n",
      "Epoch 4/20, Iteration 119/303, Loss: 0.42659687995910645\n",
      "Epoch 4/20, Iteration 120/303, Loss: 0.5961107015609741\n",
      "Epoch 4/20, Iteration 121/303, Loss: 0.4638751149177551\n",
      "Epoch 4/20, Iteration 122/303, Loss: 0.47994017601013184\n",
      "Epoch 4/20, Iteration 123/303, Loss: 0.6378225088119507\n",
      "Epoch 4/20, Iteration 124/303, Loss: 0.4858883023262024\n",
      "Epoch 4/20, Iteration 125/303, Loss: 0.5722874999046326\n",
      "Epoch 4/20, Iteration 126/303, Loss: 0.40863776206970215\n",
      "Epoch 4/20, Iteration 127/303, Loss: 0.48109957575798035\n",
      "Epoch 4/20, Iteration 128/303, Loss: 0.5222002267837524\n",
      "Epoch 4/20, Iteration 129/303, Loss: 0.5762203335762024\n",
      "Epoch 4/20, Iteration 130/303, Loss: 0.5550959706306458\n",
      "Epoch 4/20, Iteration 131/303, Loss: 0.5872541069984436\n",
      "Epoch 4/20, Iteration 132/303, Loss: 0.46245890855789185\n",
      "Epoch 4/20, Iteration 133/303, Loss: 0.5839894413948059\n",
      "Epoch 4/20, Iteration 134/303, Loss: 0.4927780032157898\n",
      "Epoch 4/20, Iteration 135/303, Loss: 0.6272954940795898\n",
      "Epoch 4/20, Iteration 136/303, Loss: 0.612554132938385\n",
      "Epoch 4/20, Iteration 137/303, Loss: 0.5492763519287109\n",
      "Epoch 4/20, Iteration 138/303, Loss: 0.4273114800453186\n",
      "Epoch 4/20, Iteration 139/303, Loss: 0.44257819652557373\n",
      "Epoch 4/20, Iteration 140/303, Loss: 0.536391019821167\n",
      "Epoch 4/20, Iteration 141/303, Loss: 0.5171080231666565\n",
      "Epoch 4/20, Iteration 142/303, Loss: 0.496878057718277\n",
      "Epoch 4/20, Iteration 143/303, Loss: 0.5111402273178101\n",
      "Epoch 4/20, Iteration 144/303, Loss: 0.37246546149253845\n",
      "Epoch 4/20, Iteration 145/303, Loss: 0.4159429967403412\n",
      "Epoch 4/20, Iteration 146/303, Loss: 0.4690720736980438\n",
      "Epoch 4/20, Iteration 147/303, Loss: 0.4516335129737854\n",
      "Epoch 4/20, Iteration 148/303, Loss: 0.4324420094490051\n",
      "Epoch 4/20, Iteration 149/303, Loss: 0.6392996907234192\n",
      "Epoch 4/20, Iteration 150/303, Loss: 0.4631044268608093\n",
      "Epoch 4/20, Iteration 151/303, Loss: 0.3936220407485962\n",
      "Epoch 4/20, Iteration 152/303, Loss: 0.42104625701904297\n",
      "Epoch 4/20, Iteration 153/303, Loss: 0.5449798107147217\n",
      "Epoch 4/20, Iteration 154/303, Loss: 0.5465971231460571\n",
      "Epoch 4/20, Iteration 155/303, Loss: 0.5102575421333313\n",
      "Epoch 4/20, Iteration 156/303, Loss: 0.4814339876174927\n",
      "Epoch 4/20, Iteration 157/303, Loss: 0.45634761452674866\n",
      "Epoch 4/20, Iteration 158/303, Loss: 0.5963619351387024\n",
      "Epoch 4/20, Iteration 159/303, Loss: 0.5628836750984192\n",
      "Epoch 4/20, Iteration 160/303, Loss: 0.4268822968006134\n",
      "Epoch 4/20, Iteration 161/303, Loss: 0.40639394521713257\n",
      "Epoch 4/20, Iteration 162/303, Loss: 0.36580660939216614\n",
      "Epoch 4/20, Iteration 163/303, Loss: 0.4576284885406494\n",
      "Epoch 4/20, Iteration 164/303, Loss: 0.5007875561714172\n",
      "Epoch 4/20, Iteration 165/303, Loss: 0.5340873599052429\n",
      "Epoch 4/20, Iteration 166/303, Loss: 0.4812031090259552\n",
      "Epoch 4/20, Iteration 167/303, Loss: 0.43140995502471924\n",
      "Epoch 4/20, Iteration 168/303, Loss: 0.32711443305015564\n",
      "Epoch 4/20, Iteration 169/303, Loss: 0.4336725175380707\n",
      "Epoch 4/20, Iteration 170/303, Loss: 0.41723114252090454\n",
      "Epoch 4/20, Iteration 171/303, Loss: 0.4069172441959381\n",
      "Epoch 4/20, Iteration 172/303, Loss: 0.6385471820831299\n",
      "Epoch 4/20, Iteration 173/303, Loss: 0.42146584391593933\n",
      "Epoch 4/20, Iteration 174/303, Loss: 0.36275917291641235\n",
      "Epoch 4/20, Iteration 175/303, Loss: 0.20316654443740845\n",
      "Epoch 4/20, Iteration 176/303, Loss: 0.42691218852996826\n",
      "Epoch 4/20, Iteration 177/303, Loss: 0.6088441014289856\n",
      "Epoch 4/20, Iteration 178/303, Loss: 0.48877280950546265\n",
      "Epoch 4/20, Iteration 179/303, Loss: 0.6872168779373169\n",
      "Epoch 4/20, Iteration 180/303, Loss: 0.5326710343360901\n",
      "Epoch 4/20, Iteration 181/303, Loss: 0.5010551810264587\n",
      "Epoch 4/20, Iteration 182/303, Loss: 0.6297453045845032\n",
      "Epoch 4/20, Iteration 183/303, Loss: 0.5124179720878601\n",
      "Epoch 4/20, Iteration 184/303, Loss: 0.5707664489746094\n",
      "Epoch 4/20, Iteration 185/303, Loss: 0.5251468420028687\n",
      "Epoch 4/20, Iteration 186/303, Loss: 0.4272245168685913\n",
      "Epoch 4/20, Iteration 187/303, Loss: 0.480071485042572\n",
      "Epoch 4/20, Iteration 188/303, Loss: 0.48721516132354736\n",
      "Epoch 4/20, Iteration 189/303, Loss: 0.5140419602394104\n",
      "Epoch 4/20, Iteration 190/303, Loss: 0.4500095844268799\n",
      "Epoch 4/20, Iteration 191/303, Loss: 0.5195826292037964\n",
      "Epoch 4/20, Iteration 192/303, Loss: 0.5563046336174011\n",
      "Epoch 4/20, Iteration 193/303, Loss: 0.6202206611633301\n",
      "Epoch 4/20, Iteration 194/303, Loss: 0.3802441358566284\n",
      "Epoch 4/20, Iteration 195/303, Loss: 0.6692088842391968\n",
      "Epoch 4/20, Iteration 196/303, Loss: 0.4782989025115967\n",
      "Epoch 4/20, Iteration 197/303, Loss: 0.5266518592834473\n",
      "Epoch 4/20, Iteration 198/303, Loss: 0.5603381991386414\n",
      "Epoch 4/20, Iteration 199/303, Loss: 0.46298256516456604\n",
      "Epoch 4/20, Iteration 200/303, Loss: 0.4868348240852356\n",
      "Epoch 4/20, Iteration 201/303, Loss: 0.49180907011032104\n",
      "Epoch 4/20, Iteration 202/303, Loss: 0.4415176510810852\n",
      "Epoch 4/20, Iteration 203/303, Loss: 0.5080870985984802\n",
      "Epoch 4/20, Iteration 204/303, Loss: 0.6381906270980835\n",
      "Epoch 4/20, Iteration 205/303, Loss: 0.5264449715614319\n",
      "Epoch 4/20, Iteration 206/303, Loss: 0.46018508076667786\n",
      "Epoch 4/20, Iteration 207/303, Loss: 0.5028926730155945\n",
      "Epoch 4/20, Iteration 208/303, Loss: 0.5567691922187805\n",
      "Epoch 4/20, Iteration 209/303, Loss: 0.5538448095321655\n",
      "Epoch 4/20, Iteration 210/303, Loss: 0.4101891815662384\n",
      "Epoch 4/20, Iteration 211/303, Loss: 0.4372616112232208\n",
      "Epoch 4/20, Iteration 212/303, Loss: 0.36499840021133423\n",
      "Epoch 4/20, Iteration 213/303, Loss: 0.39834970235824585\n",
      "Epoch 4/20, Iteration 214/303, Loss: 0.5582289695739746\n",
      "Epoch 4/20, Iteration 215/303, Loss: 0.543039858341217\n",
      "Epoch 4/20, Iteration 216/303, Loss: 0.44956305623054504\n",
      "Epoch 4/20, Iteration 217/303, Loss: 0.3934294879436493\n",
      "Epoch 4/20, Iteration 218/303, Loss: 0.5124962329864502\n",
      "Epoch 4/20, Iteration 219/303, Loss: 0.4831118583679199\n",
      "Epoch 4/20, Iteration 220/303, Loss: 0.3797110319137573\n",
      "Epoch 4/20, Iteration 221/303, Loss: 0.5497971773147583\n",
      "Epoch 4/20, Iteration 222/303, Loss: 0.4987441599369049\n",
      "Epoch 4/20, Iteration 223/303, Loss: 0.5317171216011047\n",
      "Epoch 4/20, Iteration 224/303, Loss: 0.4291650652885437\n",
      "Epoch 4/20, Iteration 225/303, Loss: 0.41728439927101135\n",
      "Epoch 4/20, Iteration 226/303, Loss: 0.6432047486305237\n",
      "Epoch 4/20, Iteration 227/303, Loss: 0.6816467046737671\n",
      "Epoch 4/20, Iteration 228/303, Loss: 0.4870370924472809\n",
      "Epoch 4/20, Iteration 229/303, Loss: 0.37805238366127014\n",
      "Epoch 4/20, Iteration 230/303, Loss: 0.5122315883636475\n",
      "Epoch 4/20, Iteration 231/303, Loss: 0.49182039499282837\n",
      "Epoch 4/20, Iteration 232/303, Loss: 0.5385439395904541\n",
      "Epoch 4/20, Iteration 233/303, Loss: 0.4964955747127533\n",
      "Epoch 4/20, Iteration 234/303, Loss: 0.5751135349273682\n",
      "Epoch 4/20, Iteration 235/303, Loss: 0.36741089820861816\n",
      "Epoch 4/20, Iteration 236/303, Loss: 0.4267076849937439\n",
      "Epoch 4/20, Iteration 237/303, Loss: 0.3559652268886566\n",
      "Epoch 4/20, Iteration 238/303, Loss: 0.5591859221458435\n",
      "Epoch 4/20, Iteration 239/303, Loss: 0.43925461173057556\n",
      "Epoch 4/20, Iteration 240/303, Loss: 0.3540683090686798\n",
      "Epoch 4/20, Iteration 241/303, Loss: 0.4957769811153412\n",
      "Epoch 4/20, Iteration 242/303, Loss: 0.4165285527706146\n",
      "Epoch 4/20, Iteration 243/303, Loss: 0.3498915731906891\n",
      "Epoch 4/20, Iteration 244/303, Loss: 0.3138688802719116\n",
      "Epoch 4/20, Iteration 245/303, Loss: 0.4181402325630188\n",
      "Epoch 4/20, Iteration 246/303, Loss: 0.45859670639038086\n",
      "Epoch 4/20, Iteration 247/303, Loss: 0.8035640716552734\n",
      "Epoch 4/20, Iteration 248/303, Loss: 0.4858440160751343\n",
      "Epoch 4/20, Iteration 249/303, Loss: 0.4151279330253601\n",
      "Epoch 4/20, Iteration 250/303, Loss: 0.42675209045410156\n",
      "Epoch 4/20, Iteration 251/303, Loss: 0.560128927230835\n",
      "Epoch 4/20, Iteration 252/303, Loss: 0.3642430305480957\n",
      "Epoch 4/20, Iteration 253/303, Loss: 0.45712703466415405\n",
      "Epoch 4/20, Iteration 254/303, Loss: 0.44960781931877136\n",
      "Epoch 4/20, Iteration 255/303, Loss: 0.4999213218688965\n",
      "Epoch 4/20, Iteration 256/303, Loss: 0.578690230846405\n",
      "Epoch 4/20, Iteration 257/303, Loss: 0.41624677181243896\n",
      "Epoch 4/20, Iteration 258/303, Loss: 0.5073978900909424\n",
      "Epoch 4/20, Iteration 259/303, Loss: 0.626489520072937\n",
      "Epoch 4/20, Iteration 260/303, Loss: 0.4415224492549896\n",
      "Epoch 4/20, Iteration 261/303, Loss: 0.556685745716095\n",
      "Epoch 4/20, Iteration 262/303, Loss: 0.5426464676856995\n",
      "Epoch 4/20, Iteration 263/303, Loss: 0.6184901595115662\n",
      "Epoch 4/20, Iteration 264/303, Loss: 0.46140679717063904\n",
      "Epoch 4/20, Iteration 265/303, Loss: 0.39750853180885315\n",
      "Epoch 4/20, Iteration 266/303, Loss: 0.44335153698921204\n",
      "Epoch 4/20, Iteration 267/303, Loss: 0.4811679720878601\n",
      "Epoch 4/20, Iteration 268/303, Loss: 0.6663689613342285\n",
      "Epoch 4/20, Iteration 269/303, Loss: 0.4793410003185272\n",
      "Epoch 4/20, Iteration 270/303, Loss: 0.4483170211315155\n",
      "Epoch 4/20, Iteration 271/303, Loss: 0.5549644827842712\n",
      "Epoch 4/20, Iteration 272/303, Loss: 0.5936987996101379\n",
      "Epoch 4/20, Iteration 273/303, Loss: 0.4801363945007324\n",
      "Epoch 4/20, Iteration 274/303, Loss: 0.5085034966468811\n",
      "Epoch 4/20, Iteration 275/303, Loss: 0.6213013529777527\n",
      "Epoch 4/20, Iteration 276/303, Loss: 0.44994693994522095\n",
      "Epoch 4/20, Iteration 277/303, Loss: 0.290351539850235\n",
      "Epoch 4/20, Iteration 278/303, Loss: 0.45783066749572754\n",
      "Epoch 4/20, Iteration 279/303, Loss: 0.5071555376052856\n",
      "Epoch 4/20, Iteration 280/303, Loss: 0.36166566610336304\n",
      "Epoch 4/20, Iteration 281/303, Loss: 0.5620577335357666\n",
      "Epoch 4/20, Iteration 282/303, Loss: 0.5211336612701416\n",
      "Epoch 4/20, Iteration 283/303, Loss: 0.47675493359565735\n",
      "Epoch 4/20, Iteration 284/303, Loss: 0.5148471593856812\n",
      "Epoch 4/20, Iteration 285/303, Loss: 0.3267691433429718\n",
      "Epoch 4/20, Iteration 286/303, Loss: 0.31226208806037903\n",
      "Epoch 4/20, Iteration 287/303, Loss: 0.3805321156978607\n",
      "Epoch 4/20, Iteration 288/303, Loss: 0.43975526094436646\n",
      "Epoch 4/20, Iteration 289/303, Loss: 0.2981719970703125\n",
      "Epoch 4/20, Iteration 290/303, Loss: 0.44681409001350403\n",
      "Epoch 4/20, Iteration 291/303, Loss: 0.7238499522209167\n",
      "Epoch 4/20, Iteration 292/303, Loss: 0.396084725856781\n",
      "Epoch 4/20, Iteration 293/303, Loss: 0.5354763269424438\n",
      "Epoch 4/20, Iteration 294/303, Loss: 0.4273148477077484\n",
      "Epoch 4/20, Iteration 295/303, Loss: 0.45463335514068604\n",
      "Epoch 4/20, Iteration 296/303, Loss: 0.4912695288658142\n",
      "Epoch 4/20, Iteration 297/303, Loss: 0.46313825249671936\n",
      "Epoch 4/20, Iteration 298/303, Loss: 0.33005091547966003\n",
      "Epoch 4/20, Iteration 299/303, Loss: 0.4466594457626343\n",
      "Epoch 4/20, Iteration 300/303, Loss: 0.4737051725387573\n",
      "Epoch 4/20, Iteration 301/303, Loss: 0.7157943248748779\n",
      "Epoch 4/20, Iteration 302/303, Loss: 0.6318864822387695\n",
      "Epoch 4/20, Iteration 303/303, Loss: 0.39934515953063965\n",
      "Epoch 5/20, Iteration 1/303, Loss: 0.37404388189315796\n",
      "Epoch 5/20, Iteration 2/303, Loss: 0.39139464497566223\n",
      "Epoch 5/20, Iteration 3/303, Loss: 0.4013284146785736\n",
      "Epoch 5/20, Iteration 4/303, Loss: 0.6861134767532349\n",
      "Epoch 5/20, Iteration 5/303, Loss: 0.6432738900184631\n",
      "Epoch 5/20, Iteration 6/303, Loss: 0.570486843585968\n",
      "Epoch 5/20, Iteration 7/303, Loss: 0.5025765299797058\n",
      "Epoch 5/20, Iteration 8/303, Loss: 0.5604455471038818\n",
      "Epoch 5/20, Iteration 9/303, Loss: 0.494869202375412\n",
      "Epoch 5/20, Iteration 10/303, Loss: 0.43534791469573975\n",
      "Epoch 5/20, Iteration 11/303, Loss: 0.6207645535469055\n",
      "Epoch 5/20, Iteration 12/303, Loss: 0.3314695954322815\n",
      "Epoch 5/20, Iteration 13/303, Loss: 0.45387136936187744\n",
      "Epoch 5/20, Iteration 14/303, Loss: 0.4211473762989044\n",
      "Epoch 5/20, Iteration 15/303, Loss: 0.5250332951545715\n",
      "Epoch 5/20, Iteration 16/303, Loss: 0.6372312307357788\n",
      "Epoch 5/20, Iteration 17/303, Loss: 0.4842105507850647\n",
      "Epoch 5/20, Iteration 18/303, Loss: 0.4520259201526642\n",
      "Epoch 5/20, Iteration 19/303, Loss: 0.40337932109832764\n",
      "Epoch 5/20, Iteration 20/303, Loss: 0.4152555465698242\n",
      "Epoch 5/20, Iteration 21/303, Loss: 0.5980599522590637\n",
      "Epoch 5/20, Iteration 22/303, Loss: 0.47720053791999817\n",
      "Epoch 5/20, Iteration 23/303, Loss: 0.6404994130134583\n",
      "Epoch 5/20, Iteration 24/303, Loss: 0.4139247536659241\n",
      "Epoch 5/20, Iteration 25/303, Loss: 0.43952813744544983\n",
      "Epoch 5/20, Iteration 26/303, Loss: 0.5099204182624817\n",
      "Epoch 5/20, Iteration 27/303, Loss: 0.5241894721984863\n",
      "Epoch 5/20, Iteration 28/303, Loss: 0.48021823167800903\n",
      "Epoch 5/20, Iteration 29/303, Loss: 0.4249133765697479\n",
      "Epoch 5/20, Iteration 30/303, Loss: 0.36805814504623413\n",
      "Epoch 5/20, Iteration 31/303, Loss: 0.5405812859535217\n",
      "Epoch 5/20, Iteration 32/303, Loss: 0.48007428646087646\n",
      "Epoch 5/20, Iteration 33/303, Loss: 0.4016354978084564\n",
      "Epoch 5/20, Iteration 34/303, Loss: 0.5435287952423096\n",
      "Epoch 5/20, Iteration 35/303, Loss: 0.48112228512763977\n",
      "Epoch 5/20, Iteration 36/303, Loss: 0.6096899509429932\n",
      "Epoch 5/20, Iteration 37/303, Loss: 0.5030666589736938\n",
      "Epoch 5/20, Iteration 38/303, Loss: 0.4648512899875641\n",
      "Epoch 5/20, Iteration 39/303, Loss: 0.31297239661216736\n",
      "Epoch 5/20, Iteration 40/303, Loss: 0.4354843497276306\n",
      "Epoch 5/20, Iteration 41/303, Loss: 0.35080572962760925\n",
      "Epoch 5/20, Iteration 42/303, Loss: 0.47518566250801086\n",
      "Epoch 5/20, Iteration 43/303, Loss: 0.549513578414917\n",
      "Epoch 5/20, Iteration 44/303, Loss: 0.6158411502838135\n",
      "Epoch 5/20, Iteration 45/303, Loss: 0.4231654107570648\n",
      "Epoch 5/20, Iteration 46/303, Loss: 0.526848316192627\n",
      "Epoch 5/20, Iteration 47/303, Loss: 0.6400502920150757\n",
      "Epoch 5/20, Iteration 48/303, Loss: 0.40341073274612427\n",
      "Epoch 5/20, Iteration 49/303, Loss: 0.4467708468437195\n",
      "Epoch 5/20, Iteration 50/303, Loss: 0.5179731845855713\n",
      "Epoch 5/20, Iteration 51/303, Loss: 0.3971508741378784\n",
      "Epoch 5/20, Iteration 52/303, Loss: 0.48753592371940613\n",
      "Epoch 5/20, Iteration 53/303, Loss: 0.33428406715393066\n",
      "Epoch 5/20, Iteration 54/303, Loss: 0.43254053592681885\n",
      "Epoch 5/20, Iteration 55/303, Loss: 0.7149499654769897\n",
      "Epoch 5/20, Iteration 56/303, Loss: 0.45654305815696716\n",
      "Epoch 5/20, Iteration 57/303, Loss: 0.45403969287872314\n",
      "Epoch 5/20, Iteration 58/303, Loss: 0.3759641647338867\n",
      "Epoch 5/20, Iteration 59/303, Loss: 0.33284956216812134\n",
      "Epoch 5/20, Iteration 60/303, Loss: 0.28970593214035034\n",
      "Epoch 5/20, Iteration 61/303, Loss: 0.26814305782318115\n",
      "Epoch 5/20, Iteration 62/303, Loss: 0.4140363931655884\n",
      "Epoch 5/20, Iteration 63/303, Loss: 0.6031438112258911\n",
      "Epoch 5/20, Iteration 64/303, Loss: 0.6002669930458069\n",
      "Epoch 5/20, Iteration 65/303, Loss: 0.480127215385437\n",
      "Epoch 5/20, Iteration 66/303, Loss: 0.395663321018219\n",
      "Epoch 5/20, Iteration 67/303, Loss: 0.36016905307769775\n",
      "Epoch 5/20, Iteration 68/303, Loss: 0.3892274796962738\n",
      "Epoch 5/20, Iteration 69/303, Loss: 0.5044040679931641\n",
      "Epoch 5/20, Iteration 70/303, Loss: 0.42167025804519653\n",
      "Epoch 5/20, Iteration 71/303, Loss: 0.2568111717700958\n",
      "Epoch 5/20, Iteration 72/303, Loss: 0.6019922494888306\n",
      "Epoch 5/20, Iteration 73/303, Loss: 0.4401373565196991\n",
      "Epoch 5/20, Iteration 74/303, Loss: 0.4131121039390564\n",
      "Epoch 5/20, Iteration 75/303, Loss: 0.4847228527069092\n",
      "Epoch 5/20, Iteration 76/303, Loss: 0.554510235786438\n",
      "Epoch 5/20, Iteration 77/303, Loss: 0.3840217888355255\n",
      "Epoch 5/20, Iteration 78/303, Loss: 0.3453286290168762\n",
      "Epoch 5/20, Iteration 79/303, Loss: 0.3531028926372528\n",
      "Epoch 5/20, Iteration 80/303, Loss: 0.44364339113235474\n",
      "Epoch 5/20, Iteration 81/303, Loss: 0.6321696639060974\n",
      "Epoch 5/20, Iteration 82/303, Loss: 0.6232187747955322\n",
      "Epoch 5/20, Iteration 83/303, Loss: 0.4899342656135559\n",
      "Epoch 5/20, Iteration 84/303, Loss: 0.36301153898239136\n",
      "Epoch 5/20, Iteration 85/303, Loss: 0.5005500912666321\n",
      "Epoch 5/20, Iteration 86/303, Loss: 0.4963107705116272\n",
      "Epoch 5/20, Iteration 87/303, Loss: 0.423935204744339\n",
      "Epoch 5/20, Iteration 88/303, Loss: 0.4278744161128998\n",
      "Epoch 5/20, Iteration 89/303, Loss: 0.4216838777065277\n",
      "Epoch 5/20, Iteration 90/303, Loss: 0.3954582214355469\n",
      "Epoch 5/20, Iteration 91/303, Loss: 0.27579832077026367\n",
      "Epoch 5/20, Iteration 92/303, Loss: 0.45478543639183044\n",
      "Epoch 5/20, Iteration 93/303, Loss: 0.48437780141830444\n",
      "Epoch 5/20, Iteration 94/303, Loss: 0.6214923858642578\n",
      "Epoch 5/20, Iteration 95/303, Loss: 0.35622119903564453\n",
      "Epoch 5/20, Iteration 96/303, Loss: 0.25699546933174133\n",
      "Epoch 5/20, Iteration 97/303, Loss: 0.4186205267906189\n",
      "Epoch 5/20, Iteration 98/303, Loss: 0.519999623298645\n",
      "Epoch 5/20, Iteration 99/303, Loss: 0.4040416479110718\n",
      "Epoch 5/20, Iteration 100/303, Loss: 0.47233134508132935\n",
      "Epoch 5/20, Iteration 101/303, Loss: 0.4324284791946411\n",
      "Epoch 5/20, Iteration 102/303, Loss: 0.47785264253616333\n",
      "Epoch 5/20, Iteration 103/303, Loss: 0.4275631010532379\n",
      "Epoch 5/20, Iteration 104/303, Loss: 0.4389626681804657\n",
      "Epoch 5/20, Iteration 105/303, Loss: 0.28155529499053955\n",
      "Epoch 5/20, Iteration 106/303, Loss: 0.5080301761627197\n",
      "Epoch 5/20, Iteration 107/303, Loss: 0.4065100848674774\n",
      "Epoch 5/20, Iteration 108/303, Loss: 0.5041159391403198\n",
      "Epoch 5/20, Iteration 109/303, Loss: 0.3723270893096924\n",
      "Epoch 5/20, Iteration 110/303, Loss: 0.37830960750579834\n",
      "Epoch 5/20, Iteration 111/303, Loss: 0.5024545192718506\n",
      "Epoch 5/20, Iteration 112/303, Loss: 0.513940155506134\n",
      "Epoch 5/20, Iteration 113/303, Loss: 0.5610976219177246\n",
      "Epoch 5/20, Iteration 114/303, Loss: 0.31595614552497864\n",
      "Epoch 5/20, Iteration 115/303, Loss: 0.4994652271270752\n",
      "Epoch 5/20, Iteration 116/303, Loss: 0.5894289016723633\n",
      "Epoch 5/20, Iteration 117/303, Loss: 0.5392619371414185\n",
      "Epoch 5/20, Iteration 118/303, Loss: 0.6327970027923584\n",
      "Epoch 5/20, Iteration 119/303, Loss: 0.5619927048683167\n",
      "Epoch 5/20, Iteration 120/303, Loss: 0.37284427881240845\n",
      "Epoch 5/20, Iteration 121/303, Loss: 0.3409039080142975\n",
      "Epoch 5/20, Iteration 122/303, Loss: 0.36403822898864746\n",
      "Epoch 5/20, Iteration 123/303, Loss: 0.47182127833366394\n",
      "Epoch 5/20, Iteration 124/303, Loss: 0.45764148235321045\n",
      "Epoch 5/20, Iteration 125/303, Loss: 0.46767759323120117\n",
      "Epoch 5/20, Iteration 126/303, Loss: 0.4462636113166809\n",
      "Epoch 5/20, Iteration 127/303, Loss: 0.4356675446033478\n",
      "Epoch 5/20, Iteration 128/303, Loss: 0.4478375017642975\n",
      "Epoch 5/20, Iteration 129/303, Loss: 0.41439858078956604\n",
      "Epoch 5/20, Iteration 130/303, Loss: 0.4368054270744324\n",
      "Epoch 5/20, Iteration 131/303, Loss: 0.4974277913570404\n",
      "Epoch 5/20, Iteration 132/303, Loss: 0.3091908097267151\n",
      "Epoch 5/20, Iteration 133/303, Loss: 0.4720030725002289\n",
      "Epoch 5/20, Iteration 134/303, Loss: 0.5366754531860352\n",
      "Epoch 5/20, Iteration 135/303, Loss: 0.4451062083244324\n",
      "Epoch 5/20, Iteration 136/303, Loss: 0.428972065448761\n",
      "Epoch 5/20, Iteration 137/303, Loss: 0.4524116516113281\n",
      "Epoch 5/20, Iteration 138/303, Loss: 0.4347386360168457\n",
      "Epoch 5/20, Iteration 139/303, Loss: 0.30571097135543823\n",
      "Epoch 5/20, Iteration 140/303, Loss: 0.5143349170684814\n",
      "Epoch 5/20, Iteration 141/303, Loss: 0.46093881130218506\n",
      "Epoch 5/20, Iteration 142/303, Loss: 0.40366265177726746\n",
      "Epoch 5/20, Iteration 143/303, Loss: 0.6185857057571411\n",
      "Epoch 5/20, Iteration 144/303, Loss: 0.44999590516090393\n",
      "Epoch 5/20, Iteration 145/303, Loss: 0.6448059678077698\n",
      "Epoch 5/20, Iteration 146/303, Loss: 0.6075786352157593\n",
      "Epoch 5/20, Iteration 147/303, Loss: 0.4817136824131012\n",
      "Epoch 5/20, Iteration 148/303, Loss: 0.3995009958744049\n",
      "Epoch 5/20, Iteration 149/303, Loss: 0.40537214279174805\n",
      "Epoch 5/20, Iteration 150/303, Loss: 0.3233536183834076\n",
      "Epoch 5/20, Iteration 151/303, Loss: 0.4927707314491272\n",
      "Epoch 5/20, Iteration 152/303, Loss: 0.39443889260292053\n",
      "Epoch 5/20, Iteration 153/303, Loss: 0.4486541748046875\n",
      "Epoch 5/20, Iteration 154/303, Loss: 0.516146719455719\n",
      "Epoch 5/20, Iteration 155/303, Loss: 0.5673555135726929\n",
      "Epoch 5/20, Iteration 156/303, Loss: 0.4824855923652649\n",
      "Epoch 5/20, Iteration 157/303, Loss: 0.3816232979297638\n",
      "Epoch 5/20, Iteration 158/303, Loss: 0.3738408088684082\n",
      "Epoch 5/20, Iteration 159/303, Loss: 0.3384547233581543\n",
      "Epoch 5/20, Iteration 160/303, Loss: 0.44676023721694946\n",
      "Epoch 5/20, Iteration 161/303, Loss: 0.35278087854385376\n",
      "Epoch 5/20, Iteration 162/303, Loss: 0.32388946413993835\n",
      "Epoch 5/20, Iteration 163/303, Loss: 0.6640974283218384\n",
      "Epoch 5/20, Iteration 164/303, Loss: 0.3092086911201477\n",
      "Epoch 5/20, Iteration 165/303, Loss: 0.29320645332336426\n",
      "Epoch 5/20, Iteration 166/303, Loss: 0.5748088955879211\n",
      "Epoch 5/20, Iteration 167/303, Loss: 0.4590194821357727\n",
      "Epoch 5/20, Iteration 168/303, Loss: 0.466278076171875\n",
      "Epoch 5/20, Iteration 169/303, Loss: 0.3691544532775879\n",
      "Epoch 5/20, Iteration 170/303, Loss: 0.4548327326774597\n",
      "Epoch 5/20, Iteration 171/303, Loss: 0.3845753073692322\n",
      "Epoch 5/20, Iteration 172/303, Loss: 0.36696889996528625\n",
      "Epoch 5/20, Iteration 173/303, Loss: 0.5104660987854004\n",
      "Epoch 5/20, Iteration 174/303, Loss: 0.37229442596435547\n",
      "Epoch 5/20, Iteration 175/303, Loss: 0.41526538133621216\n",
      "Epoch 5/20, Iteration 176/303, Loss: 0.4765290319919586\n",
      "Epoch 5/20, Iteration 177/303, Loss: 0.43927863240242004\n",
      "Epoch 5/20, Iteration 178/303, Loss: 0.3857649862766266\n",
      "Epoch 5/20, Iteration 179/303, Loss: 0.4418109655380249\n",
      "Epoch 5/20, Iteration 180/303, Loss: 0.4631787836551666\n",
      "Epoch 5/20, Iteration 181/303, Loss: 0.39839133620262146\n",
      "Epoch 5/20, Iteration 182/303, Loss: 0.37265780568122864\n",
      "Epoch 5/20, Iteration 183/303, Loss: 0.25168198347091675\n",
      "Epoch 5/20, Iteration 184/303, Loss: 0.3341549038887024\n",
      "Epoch 5/20, Iteration 185/303, Loss: 0.6179286241531372\n",
      "Epoch 5/20, Iteration 186/303, Loss: 0.42589664459228516\n",
      "Epoch 5/20, Iteration 187/303, Loss: 0.46374043822288513\n",
      "Epoch 5/20, Iteration 188/303, Loss: 0.5617207288742065\n",
      "Epoch 5/20, Iteration 189/303, Loss: 0.46609562635421753\n",
      "Epoch 5/20, Iteration 190/303, Loss: 0.31128451228141785\n",
      "Epoch 5/20, Iteration 191/303, Loss: 0.597557783126831\n",
      "Epoch 5/20, Iteration 192/303, Loss: 0.3970423638820648\n",
      "Epoch 5/20, Iteration 193/303, Loss: 0.2944578528404236\n",
      "Epoch 5/20, Iteration 194/303, Loss: 0.36664915084838867\n",
      "Epoch 5/20, Iteration 195/303, Loss: 0.36276599764823914\n",
      "Epoch 5/20, Iteration 196/303, Loss: 0.4438069462776184\n",
      "Epoch 5/20, Iteration 197/303, Loss: 0.49208393692970276\n",
      "Epoch 5/20, Iteration 198/303, Loss: 0.6285356879234314\n",
      "Epoch 5/20, Iteration 199/303, Loss: 0.4797801077365875\n",
      "Epoch 5/20, Iteration 200/303, Loss: 0.5368870496749878\n",
      "Epoch 5/20, Iteration 201/303, Loss: 0.42001739144325256\n",
      "Epoch 5/20, Iteration 202/303, Loss: 0.31371843814849854\n",
      "Epoch 5/20, Iteration 203/303, Loss: 0.3079245984554291\n",
      "Epoch 5/20, Iteration 204/303, Loss: 0.3066439628601074\n",
      "Epoch 5/20, Iteration 205/303, Loss: 0.4823582172393799\n",
      "Epoch 5/20, Iteration 206/303, Loss: 0.45361262559890747\n",
      "Epoch 5/20, Iteration 207/303, Loss: 0.3773249387741089\n",
      "Epoch 5/20, Iteration 208/303, Loss: 0.6600155234336853\n",
      "Epoch 5/20, Iteration 209/303, Loss: 0.7152005434036255\n",
      "Epoch 5/20, Iteration 210/303, Loss: 0.3709889054298401\n",
      "Epoch 5/20, Iteration 211/303, Loss: 0.5292927026748657\n",
      "Epoch 5/20, Iteration 212/303, Loss: 0.4478112459182739\n",
      "Epoch 5/20, Iteration 213/303, Loss: 0.4587322473526001\n",
      "Epoch 5/20, Iteration 214/303, Loss: 0.4277076721191406\n",
      "Epoch 5/20, Iteration 215/303, Loss: 0.5228546857833862\n",
      "Epoch 5/20, Iteration 216/303, Loss: 0.48395904898643494\n",
      "Epoch 5/20, Iteration 217/303, Loss: 0.41940513253211975\n",
      "Epoch 5/20, Iteration 218/303, Loss: 0.4857881963253021\n",
      "Epoch 5/20, Iteration 219/303, Loss: 0.5382967591285706\n",
      "Epoch 5/20, Iteration 220/303, Loss: 0.4436705410480499\n",
      "Epoch 5/20, Iteration 221/303, Loss: 0.4341358542442322\n",
      "Epoch 5/20, Iteration 222/303, Loss: 0.41974422335624695\n",
      "Epoch 5/20, Iteration 223/303, Loss: 0.3786342740058899\n",
      "Epoch 5/20, Iteration 224/303, Loss: 0.38599374890327454\n",
      "Epoch 5/20, Iteration 225/303, Loss: 0.5135089159011841\n",
      "Epoch 5/20, Iteration 226/303, Loss: 0.5460979342460632\n",
      "Epoch 5/20, Iteration 227/303, Loss: 0.5150011777877808\n",
      "Epoch 5/20, Iteration 228/303, Loss: 0.576664924621582\n",
      "Epoch 5/20, Iteration 229/303, Loss: 0.45729535818099976\n",
      "Epoch 5/20, Iteration 230/303, Loss: 0.5003860592842102\n",
      "Epoch 5/20, Iteration 231/303, Loss: 0.3877109885215759\n",
      "Epoch 5/20, Iteration 232/303, Loss: 0.34132108092308044\n",
      "Epoch 5/20, Iteration 233/303, Loss: 0.5621047019958496\n",
      "Epoch 5/20, Iteration 234/303, Loss: 0.42077797651290894\n",
      "Epoch 5/20, Iteration 235/303, Loss: 0.5932594537734985\n",
      "Epoch 5/20, Iteration 236/303, Loss: 0.3821491301059723\n",
      "Epoch 5/20, Iteration 237/303, Loss: 0.5172317624092102\n",
      "Epoch 5/20, Iteration 238/303, Loss: 0.31624069809913635\n",
      "Epoch 5/20, Iteration 239/303, Loss: 0.48587989807128906\n",
      "Epoch 5/20, Iteration 240/303, Loss: 0.3375922739505768\n",
      "Epoch 5/20, Iteration 241/303, Loss: 0.3303738832473755\n",
      "Epoch 5/20, Iteration 242/303, Loss: 0.4571446478366852\n",
      "Epoch 5/20, Iteration 243/303, Loss: 0.3760402798652649\n",
      "Epoch 5/20, Iteration 244/303, Loss: 0.5078162550926208\n",
      "Epoch 5/20, Iteration 245/303, Loss: 0.35866597294807434\n",
      "Epoch 5/20, Iteration 246/303, Loss: 0.3738439083099365\n",
      "Epoch 5/20, Iteration 247/303, Loss: 0.2985857427120209\n",
      "Epoch 5/20, Iteration 248/303, Loss: 0.21898940205574036\n",
      "Epoch 5/20, Iteration 249/303, Loss: 0.45626184344291687\n",
      "Epoch 5/20, Iteration 250/303, Loss: 0.7079717516899109\n",
      "Epoch 5/20, Iteration 251/303, Loss: 0.41946205496788025\n",
      "Epoch 5/20, Iteration 252/303, Loss: 0.3672363758087158\n",
      "Epoch 5/20, Iteration 253/303, Loss: 0.5160543918609619\n",
      "Epoch 5/20, Iteration 254/303, Loss: 0.4422045052051544\n",
      "Epoch 5/20, Iteration 255/303, Loss: 0.44180184602737427\n",
      "Epoch 5/20, Iteration 256/303, Loss: 0.5832141041755676\n",
      "Epoch 5/20, Iteration 257/303, Loss: 0.3873675763607025\n",
      "Epoch 5/20, Iteration 258/303, Loss: 0.34146353602409363\n",
      "Epoch 5/20, Iteration 259/303, Loss: 0.37582480907440186\n",
      "Epoch 5/20, Iteration 260/303, Loss: 0.42053043842315674\n",
      "Epoch 5/20, Iteration 261/303, Loss: 0.41106685996055603\n",
      "Epoch 5/20, Iteration 262/303, Loss: 0.30332785844802856\n",
      "Epoch 5/20, Iteration 263/303, Loss: 0.39628466963768005\n",
      "Epoch 5/20, Iteration 264/303, Loss: 0.4285784363746643\n",
      "Epoch 5/20, Iteration 265/303, Loss: 0.4625360369682312\n",
      "Epoch 5/20, Iteration 266/303, Loss: 0.5419921875\n",
      "Epoch 5/20, Iteration 267/303, Loss: 0.47218215465545654\n",
      "Epoch 5/20, Iteration 268/303, Loss: 0.4145854711532593\n",
      "Epoch 5/20, Iteration 269/303, Loss: 0.3888184726238251\n",
      "Epoch 5/20, Iteration 270/303, Loss: 0.3801632821559906\n",
      "Epoch 5/20, Iteration 271/303, Loss: 0.35731539130210876\n",
      "Epoch 5/20, Iteration 272/303, Loss: 0.37612754106521606\n",
      "Epoch 5/20, Iteration 273/303, Loss: 0.6326645016670227\n",
      "Epoch 5/20, Iteration 274/303, Loss: 0.5043719410896301\n",
      "Epoch 5/20, Iteration 275/303, Loss: 0.4769117832183838\n",
      "Epoch 5/20, Iteration 276/303, Loss: 0.5500667691230774\n",
      "Epoch 5/20, Iteration 277/303, Loss: 0.5318164825439453\n",
      "Epoch 5/20, Iteration 278/303, Loss: 0.39308851957321167\n",
      "Epoch 5/20, Iteration 279/303, Loss: 0.3667367994785309\n",
      "Epoch 5/20, Iteration 280/303, Loss: 0.5062621235847473\n",
      "Epoch 5/20, Iteration 281/303, Loss: 0.38316619396209717\n",
      "Epoch 5/20, Iteration 282/303, Loss: 0.589849591255188\n",
      "Epoch 5/20, Iteration 283/303, Loss: 0.4083992540836334\n",
      "Epoch 5/20, Iteration 284/303, Loss: 0.42774495482444763\n",
      "Epoch 5/20, Iteration 285/303, Loss: 0.331912636756897\n",
      "Epoch 5/20, Iteration 286/303, Loss: 0.36323249340057373\n",
      "Epoch 5/20, Iteration 287/303, Loss: 0.4134523272514343\n",
      "Epoch 5/20, Iteration 288/303, Loss: 0.5377139449119568\n",
      "Epoch 5/20, Iteration 289/303, Loss: 0.32430511713027954\n",
      "Epoch 5/20, Iteration 290/303, Loss: 0.3714389204978943\n",
      "Epoch 5/20, Iteration 291/303, Loss: 0.619223415851593\n",
      "Epoch 5/20, Iteration 292/303, Loss: 0.4615577161312103\n",
      "Epoch 5/20, Iteration 293/303, Loss: 0.4821202754974365\n",
      "Epoch 5/20, Iteration 294/303, Loss: 0.2763892412185669\n",
      "Epoch 5/20, Iteration 295/303, Loss: 0.3900212049484253\n",
      "Epoch 5/20, Iteration 296/303, Loss: 0.38945770263671875\n",
      "Epoch 5/20, Iteration 297/303, Loss: 0.42054447531700134\n",
      "Epoch 5/20, Iteration 298/303, Loss: 0.2557661235332489\n",
      "Epoch 5/20, Iteration 299/303, Loss: 0.3792848289012909\n",
      "Epoch 5/20, Iteration 300/303, Loss: 0.3225734829902649\n",
      "Epoch 5/20, Iteration 301/303, Loss: 0.3766583204269409\n",
      "Epoch 5/20, Iteration 302/303, Loss: 0.36957114934921265\n",
      "Epoch 5/20, Iteration 303/303, Loss: 0.36222976446151733\n",
      "Epoch 6/20, Iteration 1/303, Loss: 0.4481227397918701\n",
      "Epoch 6/20, Iteration 2/303, Loss: 0.2321358621120453\n",
      "Epoch 6/20, Iteration 3/303, Loss: 0.5568016171455383\n",
      "Epoch 6/20, Iteration 4/303, Loss: 0.28875720500946045\n",
      "Epoch 6/20, Iteration 5/303, Loss: 0.5306652188301086\n",
      "Epoch 6/20, Iteration 6/303, Loss: 0.3665612041950226\n",
      "Epoch 6/20, Iteration 7/303, Loss: 0.3164432644844055\n",
      "Epoch 6/20, Iteration 8/303, Loss: 0.6482843160629272\n",
      "Epoch 6/20, Iteration 9/303, Loss: 0.4493793845176697\n",
      "Epoch 6/20, Iteration 10/303, Loss: 0.28767791390419006\n",
      "Epoch 6/20, Iteration 11/303, Loss: 0.33444222807884216\n",
      "Epoch 6/20, Iteration 12/303, Loss: 0.48054513335227966\n",
      "Epoch 6/20, Iteration 13/303, Loss: 0.3837396800518036\n",
      "Epoch 6/20, Iteration 14/303, Loss: 0.4402919411659241\n",
      "Epoch 6/20, Iteration 15/303, Loss: 0.45293161273002625\n",
      "Epoch 6/20, Iteration 16/303, Loss: 0.36584070324897766\n",
      "Epoch 6/20, Iteration 17/303, Loss: 0.3632090389728546\n",
      "Epoch 6/20, Iteration 18/303, Loss: 0.4370194971561432\n",
      "Epoch 6/20, Iteration 19/303, Loss: 0.3550931513309479\n",
      "Epoch 6/20, Iteration 20/303, Loss: 0.25273963809013367\n",
      "Epoch 6/20, Iteration 21/303, Loss: 0.4384985566139221\n",
      "Epoch 6/20, Iteration 22/303, Loss: 0.2671593427658081\n",
      "Epoch 6/20, Iteration 23/303, Loss: 0.581202507019043\n",
      "Epoch 6/20, Iteration 24/303, Loss: 0.3964853882789612\n",
      "Epoch 6/20, Iteration 25/303, Loss: 0.35318905115127563\n",
      "Epoch 6/20, Iteration 26/303, Loss: 0.4630226194858551\n",
      "Epoch 6/20, Iteration 27/303, Loss: 0.5296738743782043\n",
      "Epoch 6/20, Iteration 28/303, Loss: 0.41546541452407837\n",
      "Epoch 6/20, Iteration 29/303, Loss: 0.29736948013305664\n",
      "Epoch 6/20, Iteration 30/303, Loss: 0.4265512526035309\n",
      "Epoch 6/20, Iteration 31/303, Loss: 0.34300488233566284\n",
      "Epoch 6/20, Iteration 32/303, Loss: 0.48962652683258057\n",
      "Epoch 6/20, Iteration 33/303, Loss: 0.41223573684692383\n",
      "Epoch 6/20, Iteration 34/303, Loss: 0.30478334426879883\n",
      "Epoch 6/20, Iteration 35/303, Loss: 0.599079966545105\n",
      "Epoch 6/20, Iteration 36/303, Loss: 0.5024964213371277\n",
      "Epoch 6/20, Iteration 37/303, Loss: 0.4385468661785126\n",
      "Epoch 6/20, Iteration 38/303, Loss: 0.41864219307899475\n",
      "Epoch 6/20, Iteration 39/303, Loss: 0.3389175534248352\n",
      "Epoch 6/20, Iteration 40/303, Loss: 0.4546360969543457\n",
      "Epoch 6/20, Iteration 41/303, Loss: 0.36796265840530396\n",
      "Epoch 6/20, Iteration 42/303, Loss: 0.3747461140155792\n",
      "Epoch 6/20, Iteration 43/303, Loss: 0.2813775837421417\n",
      "Epoch 6/20, Iteration 44/303, Loss: 0.5435917973518372\n",
      "Epoch 6/20, Iteration 45/303, Loss: 0.3874109983444214\n",
      "Epoch 6/20, Iteration 46/303, Loss: 0.30119988322257996\n",
      "Epoch 6/20, Iteration 47/303, Loss: 0.5376483201980591\n",
      "Epoch 6/20, Iteration 48/303, Loss: 0.5327966213226318\n",
      "Epoch 6/20, Iteration 49/303, Loss: 0.34302595257759094\n",
      "Epoch 6/20, Iteration 50/303, Loss: 0.3403967022895813\n",
      "Epoch 6/20, Iteration 51/303, Loss: 0.4234706163406372\n",
      "Epoch 6/20, Iteration 52/303, Loss: 0.5232741832733154\n",
      "Epoch 6/20, Iteration 53/303, Loss: 0.3620399534702301\n",
      "Epoch 6/20, Iteration 54/303, Loss: 0.39225324988365173\n",
      "Epoch 6/20, Iteration 55/303, Loss: 0.2944996654987335\n",
      "Epoch 6/20, Iteration 56/303, Loss: 0.398599237203598\n",
      "Epoch 6/20, Iteration 57/303, Loss: 0.45326465368270874\n",
      "Epoch 6/20, Iteration 58/303, Loss: 0.49954989552497864\n",
      "Epoch 6/20, Iteration 59/303, Loss: 0.45394039154052734\n",
      "Epoch 6/20, Iteration 60/303, Loss: 0.5091855525970459\n",
      "Epoch 6/20, Iteration 61/303, Loss: 0.37517279386520386\n",
      "Epoch 6/20, Iteration 62/303, Loss: 0.352981835603714\n",
      "Epoch 6/20, Iteration 63/303, Loss: 0.6354572772979736\n",
      "Epoch 6/20, Iteration 64/303, Loss: 0.40073126554489136\n",
      "Epoch 6/20, Iteration 65/303, Loss: 0.4018411636352539\n",
      "Epoch 6/20, Iteration 66/303, Loss: 0.4367534816265106\n",
      "Epoch 6/20, Iteration 67/303, Loss: 0.3117991089820862\n",
      "Epoch 6/20, Iteration 68/303, Loss: 0.5268167853355408\n",
      "Epoch 6/20, Iteration 69/303, Loss: 0.309896856546402\n",
      "Epoch 6/20, Iteration 70/303, Loss: 0.6090683937072754\n",
      "Epoch 6/20, Iteration 71/303, Loss: 0.41151106357574463\n",
      "Epoch 6/20, Iteration 72/303, Loss: 0.3262459635734558\n",
      "Epoch 6/20, Iteration 73/303, Loss: 0.2720608711242676\n",
      "Epoch 6/20, Iteration 74/303, Loss: 0.4437187910079956\n",
      "Epoch 6/20, Iteration 75/303, Loss: 0.4114025831222534\n",
      "Epoch 6/20, Iteration 76/303, Loss: 0.4266684651374817\n",
      "Epoch 6/20, Iteration 77/303, Loss: 0.3943120241165161\n",
      "Epoch 6/20, Iteration 78/303, Loss: 0.3222196400165558\n",
      "Epoch 6/20, Iteration 79/303, Loss: 0.3438657522201538\n",
      "Epoch 6/20, Iteration 80/303, Loss: 0.3671492338180542\n",
      "Epoch 6/20, Iteration 81/303, Loss: 0.4084039628505707\n",
      "Epoch 6/20, Iteration 82/303, Loss: 0.3535929024219513\n",
      "Epoch 6/20, Iteration 83/303, Loss: 0.40798237919807434\n",
      "Epoch 6/20, Iteration 84/303, Loss: 0.384480744600296\n",
      "Epoch 6/20, Iteration 85/303, Loss: 0.4295496344566345\n",
      "Epoch 6/20, Iteration 86/303, Loss: 0.4977074861526489\n",
      "Epoch 6/20, Iteration 87/303, Loss: 0.4178832769393921\n",
      "Epoch 6/20, Iteration 88/303, Loss: 0.5417351722717285\n",
      "Epoch 6/20, Iteration 89/303, Loss: 0.35562214255332947\n",
      "Epoch 6/20, Iteration 90/303, Loss: 0.32534098625183105\n",
      "Epoch 6/20, Iteration 91/303, Loss: 0.40296050906181335\n",
      "Epoch 6/20, Iteration 92/303, Loss: 0.353877991437912\n",
      "Epoch 6/20, Iteration 93/303, Loss: 0.482960045337677\n",
      "Epoch 6/20, Iteration 94/303, Loss: 0.39276936650276184\n",
      "Epoch 6/20, Iteration 95/303, Loss: 0.32558199763298035\n",
      "Epoch 6/20, Iteration 96/303, Loss: 0.30982446670532227\n",
      "Epoch 6/20, Iteration 97/303, Loss: 0.3280467689037323\n",
      "Epoch 6/20, Iteration 98/303, Loss: 0.37646484375\n",
      "Epoch 6/20, Iteration 99/303, Loss: 0.4520294666290283\n",
      "Epoch 6/20, Iteration 100/303, Loss: 0.34582412242889404\n",
      "Epoch 6/20, Iteration 101/303, Loss: 0.5700234770774841\n",
      "Epoch 6/20, Iteration 102/303, Loss: 0.4406719505786896\n",
      "Epoch 6/20, Iteration 103/303, Loss: 0.4258006811141968\n",
      "Epoch 6/20, Iteration 104/303, Loss: 0.3977346122264862\n",
      "Epoch 6/20, Iteration 105/303, Loss: 0.40276846289634705\n",
      "Epoch 6/20, Iteration 106/303, Loss: 0.307261198759079\n",
      "Epoch 6/20, Iteration 107/303, Loss: 0.45727285742759705\n",
      "Epoch 6/20, Iteration 108/303, Loss: 0.37029051780700684\n",
      "Epoch 6/20, Iteration 109/303, Loss: 0.4298219084739685\n",
      "Epoch 6/20, Iteration 110/303, Loss: 0.5611738562583923\n",
      "Epoch 6/20, Iteration 111/303, Loss: 0.33789369463920593\n",
      "Epoch 6/20, Iteration 112/303, Loss: 0.3066897690296173\n",
      "Epoch 6/20, Iteration 113/303, Loss: 0.3394165337085724\n",
      "Epoch 6/20, Iteration 114/303, Loss: 0.3066694140434265\n",
      "Epoch 6/20, Iteration 115/303, Loss: 0.49042046070098877\n",
      "Epoch 6/20, Iteration 116/303, Loss: 0.3562809228897095\n",
      "Epoch 6/20, Iteration 117/303, Loss: 0.35766467452049255\n",
      "Epoch 6/20, Iteration 118/303, Loss: 0.37915632128715515\n",
      "Epoch 6/20, Iteration 119/303, Loss: 0.5639234185218811\n",
      "Epoch 6/20, Iteration 120/303, Loss: 0.41113534569740295\n",
      "Epoch 6/20, Iteration 121/303, Loss: 0.5894442796707153\n",
      "Epoch 6/20, Iteration 122/303, Loss: 0.5096263885498047\n",
      "Epoch 6/20, Iteration 123/303, Loss: 0.4435684382915497\n",
      "Epoch 6/20, Iteration 124/303, Loss: 0.33356741070747375\n",
      "Epoch 6/20, Iteration 125/303, Loss: 0.4691917300224304\n",
      "Epoch 6/20, Iteration 126/303, Loss: 0.36542657017707825\n",
      "Epoch 6/20, Iteration 127/303, Loss: 0.3545258641242981\n",
      "Epoch 6/20, Iteration 128/303, Loss: 0.32350093126296997\n",
      "Epoch 6/20, Iteration 129/303, Loss: 0.49428948760032654\n",
      "Epoch 6/20, Iteration 130/303, Loss: 0.5002149343490601\n",
      "Epoch 6/20, Iteration 131/303, Loss: 0.30222612619400024\n",
      "Epoch 6/20, Iteration 132/303, Loss: 0.39415282011032104\n",
      "Epoch 6/20, Iteration 133/303, Loss: 0.4064556360244751\n",
      "Epoch 6/20, Iteration 134/303, Loss: 0.40878820419311523\n",
      "Epoch 6/20, Iteration 135/303, Loss: 0.4568018317222595\n",
      "Epoch 6/20, Iteration 136/303, Loss: 0.40190714597702026\n",
      "Epoch 6/20, Iteration 137/303, Loss: 0.269207626581192\n",
      "Epoch 6/20, Iteration 138/303, Loss: 0.30754390358924866\n",
      "Epoch 6/20, Iteration 139/303, Loss: 0.28804776072502136\n",
      "Epoch 6/20, Iteration 140/303, Loss: 0.48685401678085327\n",
      "Epoch 6/20, Iteration 141/303, Loss: 0.8670387864112854\n",
      "Epoch 6/20, Iteration 142/303, Loss: 0.39140230417251587\n",
      "Epoch 6/20, Iteration 143/303, Loss: 0.35199183225631714\n",
      "Epoch 6/20, Iteration 144/303, Loss: 0.5070987343788147\n",
      "Epoch 6/20, Iteration 145/303, Loss: 0.36360785365104675\n",
      "Epoch 6/20, Iteration 146/303, Loss: 0.6079307198524475\n",
      "Epoch 6/20, Iteration 147/303, Loss: 0.4870438575744629\n",
      "Epoch 6/20, Iteration 148/303, Loss: 0.32505831122398376\n",
      "Epoch 6/20, Iteration 149/303, Loss: 0.36346250772476196\n",
      "Epoch 6/20, Iteration 150/303, Loss: 0.4571516215801239\n",
      "Epoch 6/20, Iteration 151/303, Loss: 0.465275377035141\n",
      "Epoch 6/20, Iteration 152/303, Loss: 0.2664126753807068\n",
      "Epoch 6/20, Iteration 153/303, Loss: 0.37192079424858093\n",
      "Epoch 6/20, Iteration 154/303, Loss: 0.341891348361969\n",
      "Epoch 6/20, Iteration 155/303, Loss: 0.4517477750778198\n",
      "Epoch 6/20, Iteration 156/303, Loss: 0.3962041139602661\n",
      "Epoch 6/20, Iteration 157/303, Loss: 0.37717145681381226\n",
      "Epoch 6/20, Iteration 158/303, Loss: 0.3003278076648712\n",
      "Epoch 6/20, Iteration 159/303, Loss: 0.48154526948928833\n",
      "Epoch 6/20, Iteration 160/303, Loss: 0.39721551537513733\n",
      "Epoch 6/20, Iteration 161/303, Loss: 0.5289062857627869\n",
      "Epoch 6/20, Iteration 162/303, Loss: 0.36237525939941406\n",
      "Epoch 6/20, Iteration 163/303, Loss: 0.477984756231308\n",
      "Epoch 6/20, Iteration 164/303, Loss: 0.37362515926361084\n",
      "Epoch 6/20, Iteration 165/303, Loss: 0.2857856750488281\n",
      "Epoch 6/20, Iteration 166/303, Loss: 0.4132802486419678\n",
      "Epoch 6/20, Iteration 167/303, Loss: 0.3839392066001892\n",
      "Epoch 6/20, Iteration 168/303, Loss: 0.24344360828399658\n",
      "Epoch 6/20, Iteration 169/303, Loss: 0.3507145345211029\n",
      "Epoch 6/20, Iteration 170/303, Loss: 0.3580344319343567\n",
      "Epoch 6/20, Iteration 171/303, Loss: 0.37037691473960876\n",
      "Epoch 6/20, Iteration 172/303, Loss: 0.3188917338848114\n",
      "Epoch 6/20, Iteration 173/303, Loss: 0.3556859493255615\n",
      "Epoch 6/20, Iteration 174/303, Loss: 0.305402010679245\n",
      "Epoch 6/20, Iteration 175/303, Loss: 0.3896205723285675\n",
      "Epoch 6/20, Iteration 176/303, Loss: 0.3630293905735016\n",
      "Epoch 6/20, Iteration 177/303, Loss: 0.4136863648891449\n",
      "Epoch 6/20, Iteration 178/303, Loss: 0.49813735485076904\n",
      "Epoch 6/20, Iteration 179/303, Loss: 0.37027087807655334\n",
      "Epoch 6/20, Iteration 180/303, Loss: 0.3883451223373413\n",
      "Epoch 6/20, Iteration 181/303, Loss: 0.40821361541748047\n",
      "Epoch 6/20, Iteration 182/303, Loss: 0.44281643629074097\n",
      "Epoch 6/20, Iteration 183/303, Loss: 0.4589915871620178\n",
      "Epoch 6/20, Iteration 184/303, Loss: 0.3809892535209656\n",
      "Epoch 6/20, Iteration 185/303, Loss: 0.5515084266662598\n",
      "Epoch 6/20, Iteration 186/303, Loss: 0.3478376269340515\n",
      "Epoch 6/20, Iteration 187/303, Loss: 0.40799224376678467\n",
      "Epoch 6/20, Iteration 188/303, Loss: 0.3807971775531769\n",
      "Epoch 6/20, Iteration 189/303, Loss: 0.36560702323913574\n",
      "Epoch 6/20, Iteration 190/303, Loss: 0.27006569504737854\n",
      "Epoch 6/20, Iteration 191/303, Loss: 0.34608232975006104\n",
      "Epoch 6/20, Iteration 192/303, Loss: 0.3520611524581909\n",
      "Epoch 6/20, Iteration 193/303, Loss: 0.5186091661453247\n",
      "Epoch 6/20, Iteration 194/303, Loss: 0.5600613355636597\n",
      "Epoch 6/20, Iteration 195/303, Loss: 0.3697980046272278\n",
      "Epoch 6/20, Iteration 196/303, Loss: 0.3248850703239441\n",
      "Epoch 6/20, Iteration 197/303, Loss: 0.409796804189682\n",
      "Epoch 6/20, Iteration 198/303, Loss: 0.3972986340522766\n",
      "Epoch 6/20, Iteration 199/303, Loss: 0.4440132975578308\n",
      "Epoch 6/20, Iteration 200/303, Loss: 0.4215333163738251\n",
      "Epoch 6/20, Iteration 201/303, Loss: 0.4000456631183624\n",
      "Epoch 6/20, Iteration 202/303, Loss: 0.2917502522468567\n",
      "Epoch 6/20, Iteration 203/303, Loss: 0.3435169458389282\n",
      "Epoch 6/20, Iteration 204/303, Loss: 0.24339541792869568\n",
      "Epoch 6/20, Iteration 205/303, Loss: 0.339916855096817\n",
      "Epoch 6/20, Iteration 206/303, Loss: 0.41019541025161743\n",
      "Epoch 6/20, Iteration 207/303, Loss: 0.37514182925224304\n",
      "Epoch 6/20, Iteration 208/303, Loss: 0.5968151092529297\n",
      "Epoch 6/20, Iteration 209/303, Loss: 0.4877987205982208\n",
      "Epoch 6/20, Iteration 210/303, Loss: 0.4283079206943512\n",
      "Epoch 6/20, Iteration 211/303, Loss: 0.4343453645706177\n",
      "Epoch 6/20, Iteration 212/303, Loss: 0.3061332404613495\n",
      "Epoch 6/20, Iteration 213/303, Loss: 0.3750767111778259\n",
      "Epoch 6/20, Iteration 214/303, Loss: 0.4443379342556\n",
      "Epoch 6/20, Iteration 215/303, Loss: 0.3111167550086975\n",
      "Epoch 6/20, Iteration 216/303, Loss: 0.3075487017631531\n",
      "Epoch 6/20, Iteration 217/303, Loss: 0.33586612343788147\n",
      "Epoch 6/20, Iteration 218/303, Loss: 0.4421144723892212\n",
      "Epoch 6/20, Iteration 219/303, Loss: 0.3379698395729065\n",
      "Epoch 6/20, Iteration 220/303, Loss: 0.20818594098091125\n",
      "Epoch 6/20, Iteration 221/303, Loss: 0.3848845362663269\n",
      "Epoch 6/20, Iteration 222/303, Loss: 0.3940390944480896\n",
      "Epoch 6/20, Iteration 223/303, Loss: 0.394067645072937\n",
      "Epoch 6/20, Iteration 224/303, Loss: 0.39339548349380493\n",
      "Epoch 6/20, Iteration 225/303, Loss: 0.5251007676124573\n",
      "Epoch 6/20, Iteration 226/303, Loss: 0.4168148636817932\n",
      "Epoch 6/20, Iteration 227/303, Loss: 0.2937595844268799\n",
      "Epoch 6/20, Iteration 228/303, Loss: 0.40122610330581665\n",
      "Epoch 6/20, Iteration 229/303, Loss: 0.3863312602043152\n",
      "Epoch 6/20, Iteration 230/303, Loss: 0.43321487307548523\n",
      "Epoch 6/20, Iteration 231/303, Loss: 0.5073968172073364\n",
      "Epoch 6/20, Iteration 232/303, Loss: 0.475877046585083\n",
      "Epoch 6/20, Iteration 233/303, Loss: 0.38164860010147095\n",
      "Epoch 6/20, Iteration 234/303, Loss: 0.416169673204422\n",
      "Epoch 6/20, Iteration 235/303, Loss: 0.29218918085098267\n",
      "Epoch 6/20, Iteration 236/303, Loss: 0.34217602014541626\n",
      "Epoch 6/20, Iteration 237/303, Loss: 0.663297176361084\n",
      "Epoch 6/20, Iteration 238/303, Loss: 0.37665820121765137\n",
      "Epoch 6/20, Iteration 239/303, Loss: 0.45302748680114746\n",
      "Epoch 6/20, Iteration 240/303, Loss: 0.36035579442977905\n",
      "Epoch 6/20, Iteration 241/303, Loss: 0.28711268305778503\n",
      "Epoch 6/20, Iteration 242/303, Loss: 0.3493552803993225\n",
      "Epoch 6/20, Iteration 243/303, Loss: 0.3466397821903229\n",
      "Epoch 6/20, Iteration 244/303, Loss: 0.3845565617084503\n",
      "Epoch 6/20, Iteration 245/303, Loss: 0.47514960169792175\n",
      "Epoch 6/20, Iteration 246/303, Loss: 0.43535473942756653\n",
      "Epoch 6/20, Iteration 247/303, Loss: 0.45068395137786865\n",
      "Epoch 6/20, Iteration 248/303, Loss: 0.46112966537475586\n",
      "Epoch 6/20, Iteration 249/303, Loss: 0.40097278356552124\n",
      "Epoch 6/20, Iteration 250/303, Loss: 0.2761065363883972\n",
      "Epoch 6/20, Iteration 251/303, Loss: 0.5183364152908325\n",
      "Epoch 6/20, Iteration 252/303, Loss: 0.25918906927108765\n",
      "Epoch 6/20, Iteration 253/303, Loss: 0.3800758421421051\n",
      "Epoch 6/20, Iteration 254/303, Loss: 0.3329436182975769\n",
      "Epoch 6/20, Iteration 255/303, Loss: 0.44443076848983765\n",
      "Epoch 6/20, Iteration 256/303, Loss: 0.3858228027820587\n",
      "Epoch 6/20, Iteration 257/303, Loss: 0.49929529428482056\n",
      "Epoch 6/20, Iteration 258/303, Loss: 0.45019587874412537\n",
      "Epoch 6/20, Iteration 259/303, Loss: 0.23056524991989136\n",
      "Epoch 6/20, Iteration 260/303, Loss: 0.35989201068878174\n",
      "Epoch 6/20, Iteration 261/303, Loss: 0.5014631152153015\n",
      "Epoch 6/20, Iteration 262/303, Loss: 0.4247128367424011\n",
      "Epoch 6/20, Iteration 263/303, Loss: 0.35228902101516724\n",
      "Epoch 6/20, Iteration 264/303, Loss: 0.4349210262298584\n",
      "Epoch 6/20, Iteration 265/303, Loss: 0.4028000235557556\n",
      "Epoch 6/20, Iteration 266/303, Loss: 0.4126666486263275\n",
      "Epoch 6/20, Iteration 267/303, Loss: 0.44438570737838745\n",
      "Epoch 6/20, Iteration 268/303, Loss: 0.4985077977180481\n",
      "Epoch 6/20, Iteration 269/303, Loss: 0.38190093636512756\n",
      "Epoch 6/20, Iteration 270/303, Loss: 0.25782695412635803\n",
      "Epoch 6/20, Iteration 271/303, Loss: 0.44781288504600525\n",
      "Epoch 6/20, Iteration 272/303, Loss: 0.307002454996109\n",
      "Epoch 6/20, Iteration 273/303, Loss: 0.4305327534675598\n",
      "Epoch 6/20, Iteration 274/303, Loss: 0.3380848467350006\n",
      "Epoch 6/20, Iteration 275/303, Loss: 0.2819453179836273\n",
      "Epoch 6/20, Iteration 276/303, Loss: 0.25770267844200134\n",
      "Epoch 6/20, Iteration 277/303, Loss: 0.4901900589466095\n",
      "Epoch 6/20, Iteration 278/303, Loss: 0.3635024428367615\n",
      "Epoch 6/20, Iteration 279/303, Loss: 0.36892133951187134\n",
      "Epoch 6/20, Iteration 280/303, Loss: 0.3086537718772888\n",
      "Epoch 6/20, Iteration 281/303, Loss: 0.30808672308921814\n",
      "Epoch 6/20, Iteration 282/303, Loss: 0.37927868962287903\n",
      "Epoch 6/20, Iteration 283/303, Loss: 0.34784331917762756\n",
      "Epoch 6/20, Iteration 284/303, Loss: 0.33326253294944763\n",
      "Epoch 6/20, Iteration 285/303, Loss: 0.3581024706363678\n",
      "Epoch 6/20, Iteration 286/303, Loss: 0.38057127594947815\n",
      "Epoch 6/20, Iteration 287/303, Loss: 0.3409270644187927\n",
      "Epoch 6/20, Iteration 288/303, Loss: 0.4938202202320099\n",
      "Epoch 6/20, Iteration 289/303, Loss: 0.3167123794555664\n",
      "Epoch 6/20, Iteration 290/303, Loss: 0.4807393252849579\n",
      "Epoch 6/20, Iteration 291/303, Loss: 0.34280499815940857\n",
      "Epoch 6/20, Iteration 292/303, Loss: 0.3539924621582031\n",
      "Epoch 6/20, Iteration 293/303, Loss: 0.39752036333084106\n",
      "Epoch 6/20, Iteration 294/303, Loss: 0.3050115406513214\n",
      "Epoch 6/20, Iteration 295/303, Loss: 0.5186837911605835\n",
      "Epoch 6/20, Iteration 296/303, Loss: 0.40688323974609375\n",
      "Epoch 6/20, Iteration 297/303, Loss: 0.35353559255599976\n",
      "Epoch 6/20, Iteration 298/303, Loss: 0.4031784236431122\n",
      "Epoch 6/20, Iteration 299/303, Loss: 0.3303702771663666\n",
      "Epoch 6/20, Iteration 300/303, Loss: 0.4851091504096985\n",
      "Epoch 6/20, Iteration 301/303, Loss: 0.4173547029495239\n",
      "Epoch 6/20, Iteration 302/303, Loss: 0.4914167523384094\n",
      "Epoch 6/20, Iteration 303/303, Loss: 0.4463576078414917\n",
      "Epoch 7/20, Iteration 1/303, Loss: 0.2625296711921692\n",
      "Epoch 7/20, Iteration 2/303, Loss: 0.40849247574806213\n",
      "Epoch 7/20, Iteration 3/303, Loss: 0.30582648515701294\n",
      "Epoch 7/20, Iteration 4/303, Loss: 0.3032762408256531\n",
      "Epoch 7/20, Iteration 5/303, Loss: 0.294080913066864\n",
      "Epoch 7/20, Iteration 6/303, Loss: 0.3499968945980072\n",
      "Epoch 7/20, Iteration 7/303, Loss: 0.5359930992126465\n",
      "Epoch 7/20, Iteration 8/303, Loss: 0.32120072841644287\n",
      "Epoch 7/20, Iteration 9/303, Loss: 0.43094417452812195\n",
      "Epoch 7/20, Iteration 10/303, Loss: 0.38048937916755676\n",
      "Epoch 7/20, Iteration 11/303, Loss: 0.5256398320198059\n",
      "Epoch 7/20, Iteration 12/303, Loss: 0.3956623077392578\n",
      "Epoch 7/20, Iteration 13/303, Loss: 0.4410440921783447\n",
      "Epoch 7/20, Iteration 14/303, Loss: 0.4164556860923767\n",
      "Epoch 7/20, Iteration 15/303, Loss: 0.30900081992149353\n",
      "Epoch 7/20, Iteration 16/303, Loss: 0.45543304085731506\n",
      "Epoch 7/20, Iteration 17/303, Loss: 0.4395500123500824\n",
      "Epoch 7/20, Iteration 18/303, Loss: 0.37200993299484253\n",
      "Epoch 7/20, Iteration 19/303, Loss: 0.40985724329948425\n",
      "Epoch 7/20, Iteration 20/303, Loss: 0.26242658495903015\n",
      "Epoch 7/20, Iteration 21/303, Loss: 0.25210830569267273\n",
      "Epoch 7/20, Iteration 22/303, Loss: 0.35708311200141907\n",
      "Epoch 7/20, Iteration 23/303, Loss: 0.4187491536140442\n",
      "Epoch 7/20, Iteration 24/303, Loss: 0.2037944197654724\n",
      "Epoch 7/20, Iteration 25/303, Loss: 0.3231929838657379\n",
      "Epoch 7/20, Iteration 26/303, Loss: 0.3302325904369354\n",
      "Epoch 7/20, Iteration 27/303, Loss: 0.2866218686103821\n",
      "Epoch 7/20, Iteration 28/303, Loss: 0.2720511853694916\n",
      "Epoch 7/20, Iteration 29/303, Loss: 0.2812708020210266\n",
      "Epoch 7/20, Iteration 30/303, Loss: 0.33102941513061523\n",
      "Epoch 7/20, Iteration 31/303, Loss: 0.2585146427154541\n",
      "Epoch 7/20, Iteration 32/303, Loss: 0.5733599662780762\n",
      "Epoch 7/20, Iteration 33/303, Loss: 0.37081316113471985\n",
      "Epoch 7/20, Iteration 34/303, Loss: 0.4054596424102783\n",
      "Epoch 7/20, Iteration 35/303, Loss: 0.38277193903923035\n",
      "Epoch 7/20, Iteration 36/303, Loss: 0.3094225823879242\n",
      "Epoch 7/20, Iteration 37/303, Loss: 0.2425386607646942\n",
      "Epoch 7/20, Iteration 38/303, Loss: 0.2741837501525879\n",
      "Epoch 7/20, Iteration 39/303, Loss: 0.3980843126773834\n",
      "Epoch 7/20, Iteration 40/303, Loss: 0.49700209498405457\n",
      "Epoch 7/20, Iteration 41/303, Loss: 0.34297505021095276\n",
      "Epoch 7/20, Iteration 42/303, Loss: 0.5123037099838257\n",
      "Epoch 7/20, Iteration 43/303, Loss: 0.27257663011550903\n",
      "Epoch 7/20, Iteration 44/303, Loss: 0.1593056470155716\n",
      "Epoch 7/20, Iteration 45/303, Loss: 0.5155560970306396\n",
      "Epoch 7/20, Iteration 46/303, Loss: 0.40460270643234253\n",
      "Epoch 7/20, Iteration 47/303, Loss: 0.3325856924057007\n",
      "Epoch 7/20, Iteration 48/303, Loss: 0.246813103556633\n",
      "Epoch 7/20, Iteration 49/303, Loss: 0.25937092304229736\n",
      "Epoch 7/20, Iteration 50/303, Loss: 0.38556480407714844\n",
      "Epoch 7/20, Iteration 51/303, Loss: 0.5174257159233093\n",
      "Epoch 7/20, Iteration 52/303, Loss: 0.3086339235305786\n",
      "Epoch 7/20, Iteration 53/303, Loss: 0.3369753956794739\n",
      "Epoch 7/20, Iteration 54/303, Loss: 0.42582032084465027\n",
      "Epoch 7/20, Iteration 55/303, Loss: 0.4206642508506775\n",
      "Epoch 7/20, Iteration 56/303, Loss: 0.3443470895290375\n",
      "Epoch 7/20, Iteration 57/303, Loss: 0.2781987190246582\n",
      "Epoch 7/20, Iteration 58/303, Loss: 0.3386213183403015\n",
      "Epoch 7/20, Iteration 59/303, Loss: 0.32781511545181274\n",
      "Epoch 7/20, Iteration 60/303, Loss: 0.3286229968070984\n",
      "Epoch 7/20, Iteration 61/303, Loss: 0.719618022441864\n",
      "Epoch 7/20, Iteration 62/303, Loss: 0.42009755969047546\n",
      "Epoch 7/20, Iteration 63/303, Loss: 0.32554399967193604\n",
      "Epoch 7/20, Iteration 64/303, Loss: 0.24334342777729034\n",
      "Epoch 7/20, Iteration 65/303, Loss: 0.3992093503475189\n",
      "Epoch 7/20, Iteration 66/303, Loss: 0.3610430061817169\n",
      "Epoch 7/20, Iteration 67/303, Loss: 0.4449183940887451\n",
      "Epoch 7/20, Iteration 68/303, Loss: 0.32390469312667847\n",
      "Epoch 7/20, Iteration 69/303, Loss: 0.37822458148002625\n",
      "Epoch 7/20, Iteration 70/303, Loss: 0.38619464635849\n",
      "Epoch 7/20, Iteration 71/303, Loss: 0.3756798505783081\n",
      "Epoch 7/20, Iteration 72/303, Loss: 0.5740311741828918\n",
      "Epoch 7/20, Iteration 73/303, Loss: 0.33055582642555237\n",
      "Epoch 7/20, Iteration 74/303, Loss: 0.4432986080646515\n",
      "Epoch 7/20, Iteration 75/303, Loss: 0.6078839898109436\n",
      "Epoch 7/20, Iteration 76/303, Loss: 0.40919196605682373\n",
      "Epoch 7/20, Iteration 77/303, Loss: 0.40725475549697876\n",
      "Epoch 7/20, Iteration 78/303, Loss: 0.39128556847572327\n",
      "Epoch 7/20, Iteration 79/303, Loss: 0.39572834968566895\n",
      "Epoch 7/20, Iteration 80/303, Loss: 0.278555691242218\n",
      "Epoch 7/20, Iteration 81/303, Loss: 0.3357892334461212\n",
      "Epoch 7/20, Iteration 82/303, Loss: 0.5034541487693787\n",
      "Epoch 7/20, Iteration 83/303, Loss: 0.2799096703529358\n",
      "Epoch 7/20, Iteration 84/303, Loss: 0.6557062864303589\n",
      "Epoch 7/20, Iteration 85/303, Loss: 0.29030925035476685\n",
      "Epoch 7/20, Iteration 86/303, Loss: 0.39666181802749634\n",
      "Epoch 7/20, Iteration 87/303, Loss: 0.42983490228652954\n",
      "Epoch 7/20, Iteration 88/303, Loss: 0.3055897653102875\n",
      "Epoch 7/20, Iteration 89/303, Loss: 0.27392593026161194\n",
      "Epoch 7/20, Iteration 90/303, Loss: 0.26694273948669434\n",
      "Epoch 7/20, Iteration 91/303, Loss: 0.2785428464412689\n",
      "Epoch 7/20, Iteration 92/303, Loss: 0.3294646143913269\n",
      "Epoch 7/20, Iteration 93/303, Loss: 0.40100330114364624\n",
      "Epoch 7/20, Iteration 94/303, Loss: 0.48898911476135254\n",
      "Epoch 7/20, Iteration 95/303, Loss: 0.37871819734573364\n",
      "Epoch 7/20, Iteration 96/303, Loss: 0.46576082706451416\n",
      "Epoch 7/20, Iteration 97/303, Loss: 0.4211192727088928\n",
      "Epoch 7/20, Iteration 98/303, Loss: 0.25230127573013306\n",
      "Epoch 7/20, Iteration 99/303, Loss: 0.36635398864746094\n",
      "Epoch 7/20, Iteration 100/303, Loss: 0.2900320887565613\n",
      "Epoch 7/20, Iteration 101/303, Loss: 0.392821729183197\n",
      "Epoch 7/20, Iteration 102/303, Loss: 0.42702916264533997\n",
      "Epoch 7/20, Iteration 103/303, Loss: 0.34054499864578247\n",
      "Epoch 7/20, Iteration 104/303, Loss: 0.2681446969509125\n",
      "Epoch 7/20, Iteration 105/303, Loss: 0.3191843628883362\n",
      "Epoch 7/20, Iteration 106/303, Loss: 0.454093873500824\n",
      "Epoch 7/20, Iteration 107/303, Loss: 0.3431564271450043\n",
      "Epoch 7/20, Iteration 108/303, Loss: 0.4455336928367615\n",
      "Epoch 7/20, Iteration 109/303, Loss: 0.5837556719779968\n",
      "Epoch 7/20, Iteration 110/303, Loss: 0.33840423822402954\n",
      "Epoch 7/20, Iteration 111/303, Loss: 0.4342970848083496\n",
      "Epoch 7/20, Iteration 112/303, Loss: 0.39772188663482666\n",
      "Epoch 7/20, Iteration 113/303, Loss: 0.35364285111427307\n",
      "Epoch 7/20, Iteration 114/303, Loss: 0.32329171895980835\n",
      "Epoch 7/20, Iteration 115/303, Loss: 0.3790295422077179\n",
      "Epoch 7/20, Iteration 116/303, Loss: 0.40719178318977356\n",
      "Epoch 7/20, Iteration 117/303, Loss: 0.4885299801826477\n",
      "Epoch 7/20, Iteration 118/303, Loss: 0.40807634592056274\n",
      "Epoch 7/20, Iteration 119/303, Loss: 0.45057016611099243\n",
      "Epoch 7/20, Iteration 120/303, Loss: 0.331106960773468\n",
      "Epoch 7/20, Iteration 121/303, Loss: 0.19407089054584503\n",
      "Epoch 7/20, Iteration 122/303, Loss: 0.4100140631198883\n",
      "Epoch 7/20, Iteration 123/303, Loss: 0.3112676739692688\n",
      "Epoch 7/20, Iteration 124/303, Loss: 0.2718201279640198\n",
      "Epoch 7/20, Iteration 125/303, Loss: 0.2688688337802887\n",
      "Epoch 7/20, Iteration 126/303, Loss: 0.23730920255184174\n",
      "Epoch 7/20, Iteration 127/303, Loss: 0.38857346773147583\n",
      "Epoch 7/20, Iteration 128/303, Loss: 0.2385980486869812\n",
      "Epoch 7/20, Iteration 129/303, Loss: 0.3412264287471771\n",
      "Epoch 7/20, Iteration 130/303, Loss: 0.2297547161579132\n",
      "Epoch 7/20, Iteration 131/303, Loss: 0.21629604697227478\n",
      "Epoch 7/20, Iteration 132/303, Loss: 0.3489353358745575\n",
      "Epoch 7/20, Iteration 133/303, Loss: 0.3683622479438782\n",
      "Epoch 7/20, Iteration 134/303, Loss: 0.20702604949474335\n",
      "Epoch 7/20, Iteration 135/303, Loss: 0.298529714345932\n",
      "Epoch 7/20, Iteration 136/303, Loss: 0.2820746898651123\n",
      "Epoch 7/20, Iteration 137/303, Loss: 0.35548338294029236\n",
      "Epoch 7/20, Iteration 138/303, Loss: 0.23564472794532776\n",
      "Epoch 7/20, Iteration 139/303, Loss: 0.2542828321456909\n",
      "Epoch 7/20, Iteration 140/303, Loss: 0.38152486085891724\n",
      "Epoch 7/20, Iteration 141/303, Loss: 0.40432795882225037\n",
      "Epoch 7/20, Iteration 142/303, Loss: 0.34034523367881775\n",
      "Epoch 7/20, Iteration 143/303, Loss: 0.44344958662986755\n",
      "Epoch 7/20, Iteration 144/303, Loss: 0.34844690561294556\n",
      "Epoch 7/20, Iteration 145/303, Loss: 0.24768289923667908\n",
      "Epoch 7/20, Iteration 146/303, Loss: 0.3228658139705658\n",
      "Epoch 7/20, Iteration 147/303, Loss: 0.3630349338054657\n",
      "Epoch 7/20, Iteration 148/303, Loss: 0.25455331802368164\n",
      "Epoch 7/20, Iteration 149/303, Loss: 0.3840792179107666\n",
      "Epoch 7/20, Iteration 150/303, Loss: 0.516569197177887\n",
      "Epoch 7/20, Iteration 151/303, Loss: 0.6349815726280212\n",
      "Epoch 7/20, Iteration 152/303, Loss: 0.3754828870296478\n",
      "Epoch 7/20, Iteration 153/303, Loss: 0.24576716125011444\n",
      "Epoch 7/20, Iteration 154/303, Loss: 0.4443332850933075\n",
      "Epoch 7/20, Iteration 155/303, Loss: 0.28932201862335205\n",
      "Epoch 7/20, Iteration 156/303, Loss: 0.2660062611103058\n",
      "Epoch 7/20, Iteration 157/303, Loss: 0.426827996969223\n",
      "Epoch 7/20, Iteration 158/303, Loss: 0.28373005986213684\n",
      "Epoch 7/20, Iteration 159/303, Loss: 0.39321473240852356\n",
      "Epoch 7/20, Iteration 160/303, Loss: 0.22537453472614288\n",
      "Epoch 7/20, Iteration 161/303, Loss: 0.46095287799835205\n",
      "Epoch 7/20, Iteration 162/303, Loss: 0.3073625862598419\n",
      "Epoch 7/20, Iteration 163/303, Loss: 0.4579519033432007\n",
      "Epoch 7/20, Iteration 164/303, Loss: 0.48752638697624207\n",
      "Epoch 7/20, Iteration 165/303, Loss: 0.34691300988197327\n",
      "Epoch 7/20, Iteration 166/303, Loss: 0.33234265446662903\n",
      "Epoch 7/20, Iteration 167/303, Loss: 0.4282877743244171\n",
      "Epoch 7/20, Iteration 168/303, Loss: 0.2998405992984772\n",
      "Epoch 7/20, Iteration 169/303, Loss: 0.25996196269989014\n",
      "Epoch 7/20, Iteration 170/303, Loss: 0.4334756135940552\n",
      "Epoch 7/20, Iteration 171/303, Loss: 0.6793951988220215\n",
      "Epoch 7/20, Iteration 172/303, Loss: 0.33169299364089966\n",
      "Epoch 7/20, Iteration 173/303, Loss: 0.3058964014053345\n",
      "Epoch 7/20, Iteration 174/303, Loss: 0.32702580094337463\n",
      "Epoch 7/20, Iteration 175/303, Loss: 0.3269259035587311\n",
      "Epoch 7/20, Iteration 176/303, Loss: 0.3814328610897064\n",
      "Epoch 7/20, Iteration 177/303, Loss: 0.3784312605857849\n",
      "Epoch 7/20, Iteration 178/303, Loss: 0.3877163529396057\n",
      "Epoch 7/20, Iteration 179/303, Loss: 0.3379339873790741\n",
      "Epoch 7/20, Iteration 180/303, Loss: 0.24023978412151337\n",
      "Epoch 7/20, Iteration 181/303, Loss: 0.3528258204460144\n",
      "Epoch 7/20, Iteration 182/303, Loss: 0.34064722061157227\n",
      "Epoch 7/20, Iteration 183/303, Loss: 0.5135213732719421\n",
      "Epoch 7/20, Iteration 184/303, Loss: 0.47282448410987854\n",
      "Epoch 7/20, Iteration 185/303, Loss: 0.3695155084133148\n",
      "Epoch 7/20, Iteration 186/303, Loss: 0.33918797969818115\n",
      "Epoch 7/20, Iteration 187/303, Loss: 0.3813021183013916\n",
      "Epoch 7/20, Iteration 188/303, Loss: 0.39729881286621094\n",
      "Epoch 7/20, Iteration 189/303, Loss: 0.26038673520088196\n",
      "Epoch 7/20, Iteration 190/303, Loss: 0.48489803075790405\n",
      "Epoch 7/20, Iteration 191/303, Loss: 0.30134284496307373\n",
      "Epoch 7/20, Iteration 192/303, Loss: 0.3195204734802246\n",
      "Epoch 7/20, Iteration 193/303, Loss: 0.40351760387420654\n",
      "Epoch 7/20, Iteration 194/303, Loss: 0.32492825388908386\n",
      "Epoch 7/20, Iteration 195/303, Loss: 0.2628054916858673\n",
      "Epoch 7/20, Iteration 196/303, Loss: 0.34581154584884644\n",
      "Epoch 7/20, Iteration 197/303, Loss: 0.16695716977119446\n",
      "Epoch 7/20, Iteration 198/303, Loss: 0.44377079606056213\n",
      "Epoch 7/20, Iteration 199/303, Loss: 0.5408873558044434\n",
      "Epoch 7/20, Iteration 200/303, Loss: 0.34499993920326233\n",
      "Epoch 7/20, Iteration 201/303, Loss: 0.4315887689590454\n",
      "Epoch 7/20, Iteration 202/303, Loss: 0.3640705943107605\n",
      "Epoch 7/20, Iteration 203/303, Loss: 0.41250377893447876\n",
      "Epoch 7/20, Iteration 204/303, Loss: 0.3721465468406677\n",
      "Epoch 7/20, Iteration 205/303, Loss: 0.19745492935180664\n",
      "Epoch 7/20, Iteration 206/303, Loss: 0.33778220415115356\n",
      "Epoch 7/20, Iteration 207/303, Loss: 0.2774295508861542\n",
      "Epoch 7/20, Iteration 208/303, Loss: 0.3564557731151581\n",
      "Epoch 7/20, Iteration 209/303, Loss: 0.2605079412460327\n",
      "Epoch 7/20, Iteration 210/303, Loss: 0.700435996055603\n",
      "Epoch 7/20, Iteration 211/303, Loss: 0.40231987833976746\n",
      "Epoch 7/20, Iteration 212/303, Loss: 0.4280688464641571\n",
      "Epoch 7/20, Iteration 213/303, Loss: 0.4266168773174286\n",
      "Epoch 7/20, Iteration 214/303, Loss: 0.2673700153827667\n",
      "Epoch 7/20, Iteration 215/303, Loss: 0.41190648078918457\n",
      "Epoch 7/20, Iteration 216/303, Loss: 0.23601830005645752\n",
      "Epoch 7/20, Iteration 217/303, Loss: 0.37259727716445923\n",
      "Epoch 7/20, Iteration 218/303, Loss: 0.21427612006664276\n",
      "Epoch 7/20, Iteration 219/303, Loss: 0.22687861323356628\n",
      "Epoch 7/20, Iteration 220/303, Loss: 0.26665198802948\n",
      "Epoch 7/20, Iteration 221/303, Loss: 0.20990344882011414\n",
      "Epoch 7/20, Iteration 222/303, Loss: 0.290347158908844\n",
      "Epoch 7/20, Iteration 223/303, Loss: 0.35180380940437317\n",
      "Epoch 7/20, Iteration 224/303, Loss: 0.4382190704345703\n",
      "Epoch 7/20, Iteration 225/303, Loss: 0.44314825534820557\n",
      "Epoch 7/20, Iteration 226/303, Loss: 0.35252752900123596\n",
      "Epoch 7/20, Iteration 227/303, Loss: 0.3114956319332123\n",
      "Epoch 7/20, Iteration 228/303, Loss: 0.4201647937297821\n",
      "Epoch 7/20, Iteration 229/303, Loss: 0.2820485234260559\n",
      "Epoch 7/20, Iteration 230/303, Loss: 0.37166061997413635\n",
      "Epoch 7/20, Iteration 231/303, Loss: 0.37218350172042847\n",
      "Epoch 7/20, Iteration 232/303, Loss: 0.2985019385814667\n",
      "Epoch 7/20, Iteration 233/303, Loss: 0.3146631717681885\n",
      "Epoch 7/20, Iteration 234/303, Loss: 0.5949613451957703\n",
      "Epoch 7/20, Iteration 235/303, Loss: 0.3841279447078705\n",
      "Epoch 7/20, Iteration 236/303, Loss: 0.35368436574935913\n",
      "Epoch 7/20, Iteration 237/303, Loss: 0.34144893288612366\n",
      "Epoch 7/20, Iteration 238/303, Loss: 0.25659188628196716\n",
      "Epoch 7/20, Iteration 239/303, Loss: 0.33634117245674133\n",
      "Epoch 7/20, Iteration 240/303, Loss: 0.19196228682994843\n",
      "Epoch 7/20, Iteration 241/303, Loss: 0.3264225423336029\n",
      "Epoch 7/20, Iteration 242/303, Loss: 0.27094554901123047\n",
      "Epoch 7/20, Iteration 243/303, Loss: 0.2731967866420746\n",
      "Epoch 7/20, Iteration 244/303, Loss: 0.5239990949630737\n",
      "Epoch 7/20, Iteration 245/303, Loss: 0.32946187257766724\n",
      "Epoch 7/20, Iteration 246/303, Loss: 0.3965485990047455\n",
      "Epoch 7/20, Iteration 247/303, Loss: 0.3576276898384094\n",
      "Epoch 7/20, Iteration 248/303, Loss: 0.3297269642353058\n",
      "Epoch 7/20, Iteration 249/303, Loss: 0.43971166014671326\n",
      "Epoch 7/20, Iteration 250/303, Loss: 0.4624107778072357\n",
      "Epoch 7/20, Iteration 251/303, Loss: 0.3483320474624634\n",
      "Epoch 7/20, Iteration 252/303, Loss: 0.34173887968063354\n",
      "Epoch 7/20, Iteration 253/303, Loss: 0.3526723086833954\n",
      "Epoch 7/20, Iteration 254/303, Loss: 0.30228424072265625\n",
      "Epoch 7/20, Iteration 255/303, Loss: 0.22350431978702545\n",
      "Epoch 7/20, Iteration 256/303, Loss: 0.2692308723926544\n",
      "Epoch 7/20, Iteration 257/303, Loss: 0.4073280692100525\n",
      "Epoch 7/20, Iteration 258/303, Loss: 0.3052448034286499\n",
      "Epoch 7/20, Iteration 259/303, Loss: 0.3895264267921448\n",
      "Epoch 7/20, Iteration 260/303, Loss: 0.38091763854026794\n",
      "Epoch 7/20, Iteration 261/303, Loss: 0.23151631653308868\n",
      "Epoch 7/20, Iteration 262/303, Loss: 0.39264413714408875\n",
      "Epoch 7/20, Iteration 263/303, Loss: 0.3977777063846588\n",
      "Epoch 7/20, Iteration 264/303, Loss: 0.36375245451927185\n",
      "Epoch 7/20, Iteration 265/303, Loss: 0.30905088782310486\n",
      "Epoch 7/20, Iteration 266/303, Loss: 0.36838358640670776\n",
      "Epoch 7/20, Iteration 267/303, Loss: 0.3105790615081787\n",
      "Epoch 7/20, Iteration 268/303, Loss: 0.38951748609542847\n",
      "Epoch 7/20, Iteration 269/303, Loss: 0.4503518044948578\n",
      "Epoch 7/20, Iteration 270/303, Loss: 0.3469398319721222\n",
      "Epoch 7/20, Iteration 271/303, Loss: 0.314505934715271\n",
      "Epoch 7/20, Iteration 272/303, Loss: 0.4233604669570923\n",
      "Epoch 7/20, Iteration 273/303, Loss: 0.33165639638900757\n",
      "Epoch 7/20, Iteration 274/303, Loss: 0.32226651906967163\n",
      "Epoch 7/20, Iteration 275/303, Loss: 0.21640770137310028\n",
      "Epoch 7/20, Iteration 276/303, Loss: 0.33964651823043823\n",
      "Epoch 7/20, Iteration 277/303, Loss: 0.32945314049720764\n",
      "Epoch 7/20, Iteration 278/303, Loss: 0.3797529935836792\n",
      "Epoch 7/20, Iteration 279/303, Loss: 0.5910989046096802\n",
      "Epoch 7/20, Iteration 280/303, Loss: 0.3811987340450287\n",
      "Epoch 7/20, Iteration 281/303, Loss: 0.28269830346107483\n",
      "Epoch 7/20, Iteration 282/303, Loss: 0.341463178396225\n",
      "Epoch 7/20, Iteration 283/303, Loss: 0.3612825572490692\n",
      "Epoch 7/20, Iteration 284/303, Loss: 0.334500789642334\n",
      "Epoch 7/20, Iteration 285/303, Loss: 0.26450151205062866\n",
      "Epoch 7/20, Iteration 286/303, Loss: 0.38205331563949585\n",
      "Epoch 7/20, Iteration 287/303, Loss: 0.3074754476547241\n",
      "Epoch 7/20, Iteration 288/303, Loss: 0.18304631114006042\n",
      "Epoch 7/20, Iteration 289/303, Loss: 0.37554022669792175\n",
      "Epoch 7/20, Iteration 290/303, Loss: 0.32139575481414795\n",
      "Epoch 7/20, Iteration 291/303, Loss: 0.47657090425491333\n",
      "Epoch 7/20, Iteration 292/303, Loss: 0.3727031648159027\n",
      "Epoch 7/20, Iteration 293/303, Loss: 0.26002463698387146\n",
      "Epoch 7/20, Iteration 294/303, Loss: 0.36902308464050293\n",
      "Epoch 7/20, Iteration 295/303, Loss: 0.3006496727466583\n",
      "Epoch 7/20, Iteration 296/303, Loss: 0.2622818052768707\n",
      "Epoch 7/20, Iteration 297/303, Loss: 0.4625950753688812\n",
      "Epoch 7/20, Iteration 298/303, Loss: 0.4961055815219879\n",
      "Epoch 7/20, Iteration 299/303, Loss: 0.3652431070804596\n",
      "Epoch 7/20, Iteration 300/303, Loss: 0.2725389003753662\n",
      "Epoch 7/20, Iteration 301/303, Loss: 0.6160231232643127\n",
      "Epoch 7/20, Iteration 302/303, Loss: 0.4275929033756256\n",
      "Epoch 7/20, Iteration 303/303, Loss: 0.2522212564945221\n",
      "Epoch 8/20, Iteration 1/303, Loss: 0.4472159147262573\n",
      "Epoch 8/20, Iteration 2/303, Loss: 0.30993250012397766\n",
      "Epoch 8/20, Iteration 3/303, Loss: 0.23215126991271973\n",
      "Epoch 8/20, Iteration 4/303, Loss: 0.12824496626853943\n",
      "Epoch 8/20, Iteration 5/303, Loss: 0.2442256659269333\n",
      "Epoch 8/20, Iteration 6/303, Loss: 0.40467405319213867\n",
      "Epoch 8/20, Iteration 7/303, Loss: 0.36587095260620117\n",
      "Epoch 8/20, Iteration 8/303, Loss: 0.3076602518558502\n",
      "Epoch 8/20, Iteration 9/303, Loss: 0.34887516498565674\n",
      "Epoch 8/20, Iteration 10/303, Loss: 0.23890191316604614\n",
      "Epoch 8/20, Iteration 11/303, Loss: 0.22992856800556183\n",
      "Epoch 8/20, Iteration 12/303, Loss: 0.25173160433769226\n",
      "Epoch 8/20, Iteration 13/303, Loss: 0.6215559244155884\n",
      "Epoch 8/20, Iteration 14/303, Loss: 0.36007869243621826\n",
      "Epoch 8/20, Iteration 15/303, Loss: 0.22929920256137848\n",
      "Epoch 8/20, Iteration 16/303, Loss: 0.2644771337509155\n",
      "Epoch 8/20, Iteration 17/303, Loss: 0.38413557410240173\n",
      "Epoch 8/20, Iteration 18/303, Loss: 0.22519591450691223\n",
      "Epoch 8/20, Iteration 19/303, Loss: 0.22596339881420135\n",
      "Epoch 8/20, Iteration 20/303, Loss: 0.36817270517349243\n",
      "Epoch 8/20, Iteration 21/303, Loss: 0.22226116061210632\n",
      "Epoch 8/20, Iteration 22/303, Loss: 0.3544903099536896\n",
      "Epoch 8/20, Iteration 23/303, Loss: 0.18448595702648163\n",
      "Epoch 8/20, Iteration 24/303, Loss: 0.3591196835041046\n",
      "Epoch 8/20, Iteration 25/303, Loss: 0.2989385724067688\n",
      "Epoch 8/20, Iteration 26/303, Loss: 0.5889164209365845\n",
      "Epoch 8/20, Iteration 27/303, Loss: 0.6044151782989502\n",
      "Epoch 8/20, Iteration 28/303, Loss: 0.27666017413139343\n",
      "Epoch 8/20, Iteration 29/303, Loss: 0.2582830786705017\n",
      "Epoch 8/20, Iteration 30/303, Loss: 0.20874615013599396\n",
      "Epoch 8/20, Iteration 31/303, Loss: 0.32947802543640137\n",
      "Epoch 8/20, Iteration 32/303, Loss: 0.3248756527900696\n",
      "Epoch 8/20, Iteration 33/303, Loss: 0.26456788182258606\n",
      "Epoch 8/20, Iteration 34/303, Loss: 0.30891549587249756\n",
      "Epoch 8/20, Iteration 35/303, Loss: 0.3924572467803955\n",
      "Epoch 8/20, Iteration 36/303, Loss: 0.313308984041214\n",
      "Epoch 8/20, Iteration 37/303, Loss: 0.3520297408103943\n",
      "Epoch 8/20, Iteration 38/303, Loss: 0.36974796652793884\n",
      "Epoch 8/20, Iteration 39/303, Loss: 0.1810397058725357\n",
      "Epoch 8/20, Iteration 40/303, Loss: 0.3211215138435364\n",
      "Epoch 8/20, Iteration 41/303, Loss: 0.2641718089580536\n",
      "Epoch 8/20, Iteration 42/303, Loss: 0.3131901025772095\n",
      "Epoch 8/20, Iteration 43/303, Loss: 0.29395923018455505\n",
      "Epoch 8/20, Iteration 44/303, Loss: 0.2767347991466522\n",
      "Epoch 8/20, Iteration 45/303, Loss: 0.36285310983657837\n",
      "Epoch 8/20, Iteration 46/303, Loss: 0.3541651964187622\n",
      "Epoch 8/20, Iteration 47/303, Loss: 0.3386687934398651\n",
      "Epoch 8/20, Iteration 48/303, Loss: 0.20998729765415192\n",
      "Epoch 8/20, Iteration 49/303, Loss: 0.360854834318161\n",
      "Epoch 8/20, Iteration 50/303, Loss: 0.4611026644706726\n",
      "Epoch 8/20, Iteration 51/303, Loss: 0.4407244324684143\n",
      "Epoch 8/20, Iteration 52/303, Loss: 0.41576969623565674\n",
      "Epoch 8/20, Iteration 53/303, Loss: 0.3704671263694763\n",
      "Epoch 8/20, Iteration 54/303, Loss: 0.4147043228149414\n",
      "Epoch 8/20, Iteration 55/303, Loss: 0.4197183847427368\n",
      "Epoch 8/20, Iteration 56/303, Loss: 0.2966833710670471\n",
      "Epoch 8/20, Iteration 57/303, Loss: 0.3737775683403015\n",
      "Epoch 8/20, Iteration 58/303, Loss: 0.2456105351448059\n",
      "Epoch 8/20, Iteration 59/303, Loss: 0.2871856093406677\n",
      "Epoch 8/20, Iteration 60/303, Loss: 0.16920912265777588\n",
      "Epoch 8/20, Iteration 61/303, Loss: 0.26217401027679443\n",
      "Epoch 8/20, Iteration 62/303, Loss: 0.408951073884964\n",
      "Epoch 8/20, Iteration 63/303, Loss: 0.23812107741832733\n",
      "Epoch 8/20, Iteration 64/303, Loss: 0.27182474732398987\n",
      "Epoch 8/20, Iteration 65/303, Loss: 0.25352954864501953\n",
      "Epoch 8/20, Iteration 66/303, Loss: 0.25875452160835266\n",
      "Epoch 8/20, Iteration 67/303, Loss: 0.5097325444221497\n",
      "Epoch 8/20, Iteration 68/303, Loss: 0.27292385697364807\n",
      "Epoch 8/20, Iteration 69/303, Loss: 0.312725692987442\n",
      "Epoch 8/20, Iteration 70/303, Loss: 0.30826133489608765\n",
      "Epoch 8/20, Iteration 71/303, Loss: 0.4665234088897705\n",
      "Epoch 8/20, Iteration 72/303, Loss: 0.6254595518112183\n",
      "Epoch 8/20, Iteration 73/303, Loss: 0.37622320652008057\n",
      "Epoch 8/20, Iteration 74/303, Loss: 0.25764405727386475\n",
      "Epoch 8/20, Iteration 75/303, Loss: 0.3055815100669861\n",
      "Epoch 8/20, Iteration 76/303, Loss: 0.34169360995292664\n",
      "Epoch 8/20, Iteration 77/303, Loss: 0.25906819105148315\n",
      "Epoch 8/20, Iteration 78/303, Loss: 0.3514421582221985\n",
      "Epoch 8/20, Iteration 79/303, Loss: 0.2236856371164322\n",
      "Epoch 8/20, Iteration 80/303, Loss: 0.20164082944393158\n",
      "Epoch 8/20, Iteration 81/303, Loss: 0.18358114361763\n",
      "Epoch 8/20, Iteration 82/303, Loss: 0.21553738415241241\n",
      "Epoch 8/20, Iteration 83/303, Loss: 0.32316747307777405\n",
      "Epoch 8/20, Iteration 84/303, Loss: 0.4080732762813568\n",
      "Epoch 8/20, Iteration 85/303, Loss: 0.23077628016471863\n",
      "Epoch 8/20, Iteration 86/303, Loss: 0.3378373980522156\n",
      "Epoch 8/20, Iteration 87/303, Loss: 0.19758129119873047\n",
      "Epoch 8/20, Iteration 88/303, Loss: 0.3317396640777588\n",
      "Epoch 8/20, Iteration 89/303, Loss: 0.20528343319892883\n",
      "Epoch 8/20, Iteration 90/303, Loss: 0.10647429525852203\n",
      "Epoch 8/20, Iteration 91/303, Loss: 0.3565685749053955\n",
      "Epoch 8/20, Iteration 92/303, Loss: 0.3903522789478302\n",
      "Epoch 8/20, Iteration 93/303, Loss: 0.5447415113449097\n",
      "Epoch 8/20, Iteration 94/303, Loss: 0.5567082762718201\n",
      "Epoch 8/20, Iteration 95/303, Loss: 0.22364076972007751\n",
      "Epoch 8/20, Iteration 96/303, Loss: 0.3253459632396698\n",
      "Epoch 8/20, Iteration 97/303, Loss: 0.36391007900238037\n",
      "Epoch 8/20, Iteration 98/303, Loss: 0.2703339159488678\n",
      "Epoch 8/20, Iteration 99/303, Loss: 0.33572790026664734\n",
      "Epoch 8/20, Iteration 100/303, Loss: 0.4891597628593445\n",
      "Epoch 8/20, Iteration 101/303, Loss: 0.38405346870422363\n",
      "Epoch 8/20, Iteration 102/303, Loss: 0.16116870939731598\n",
      "Epoch 8/20, Iteration 103/303, Loss: 0.16544777154922485\n",
      "Epoch 8/20, Iteration 104/303, Loss: 0.3175990581512451\n",
      "Epoch 8/20, Iteration 105/303, Loss: 0.531973659992218\n",
      "Epoch 8/20, Iteration 106/303, Loss: 0.3594686985015869\n",
      "Epoch 8/20, Iteration 107/303, Loss: 0.3247963786125183\n",
      "Epoch 8/20, Iteration 108/303, Loss: 0.13960091769695282\n",
      "Epoch 8/20, Iteration 109/303, Loss: 0.4846636950969696\n",
      "Epoch 8/20, Iteration 110/303, Loss: 0.35049790143966675\n",
      "Epoch 8/20, Iteration 111/303, Loss: 0.29338282346725464\n",
      "Epoch 8/20, Iteration 112/303, Loss: 0.3054777979850769\n",
      "Epoch 8/20, Iteration 113/303, Loss: 0.40070733428001404\n",
      "Epoch 8/20, Iteration 114/303, Loss: 0.38381147384643555\n",
      "Epoch 8/20, Iteration 115/303, Loss: 0.33586734533309937\n",
      "Epoch 8/20, Iteration 116/303, Loss: 0.33988165855407715\n",
      "Epoch 8/20, Iteration 117/303, Loss: 0.3053010404109955\n",
      "Epoch 8/20, Iteration 118/303, Loss: 0.31198689341545105\n",
      "Epoch 8/20, Iteration 119/303, Loss: 0.42650899291038513\n",
      "Epoch 8/20, Iteration 120/303, Loss: 0.30054864287376404\n",
      "Epoch 8/20, Iteration 121/303, Loss: 0.295299768447876\n",
      "Epoch 8/20, Iteration 122/303, Loss: 0.3580256700515747\n",
      "Epoch 8/20, Iteration 123/303, Loss: 0.2706623673439026\n",
      "Epoch 8/20, Iteration 124/303, Loss: 0.17325127124786377\n",
      "Epoch 8/20, Iteration 125/303, Loss: 0.3228432536125183\n",
      "Epoch 8/20, Iteration 126/303, Loss: 0.4225385785102844\n",
      "Epoch 8/20, Iteration 127/303, Loss: 0.45448508858680725\n",
      "Epoch 8/20, Iteration 128/303, Loss: 0.35268446803092957\n",
      "Epoch 8/20, Iteration 129/303, Loss: 0.2502930164337158\n",
      "Epoch 8/20, Iteration 130/303, Loss: 0.24344703555107117\n",
      "Epoch 8/20, Iteration 131/303, Loss: 0.30273857712745667\n",
      "Epoch 8/20, Iteration 132/303, Loss: 0.23434720933437347\n",
      "Epoch 8/20, Iteration 133/303, Loss: 0.42025652527809143\n",
      "Epoch 8/20, Iteration 134/303, Loss: 0.35368627309799194\n",
      "Epoch 8/20, Iteration 135/303, Loss: 0.39548832178115845\n",
      "Epoch 8/20, Iteration 136/303, Loss: 0.37138715386390686\n",
      "Epoch 8/20, Iteration 137/303, Loss: 0.36119115352630615\n",
      "Epoch 8/20, Iteration 138/303, Loss: 0.22117502987384796\n",
      "Epoch 8/20, Iteration 139/303, Loss: 0.3731149435043335\n",
      "Epoch 8/20, Iteration 140/303, Loss: 0.2233109325170517\n",
      "Epoch 8/20, Iteration 141/303, Loss: 0.32992297410964966\n",
      "Epoch 8/20, Iteration 142/303, Loss: 0.20745384693145752\n",
      "Epoch 8/20, Iteration 143/303, Loss: 0.2661186754703522\n",
      "Epoch 8/20, Iteration 144/303, Loss: 0.29750365018844604\n",
      "Epoch 8/20, Iteration 145/303, Loss: 0.23702888190746307\n",
      "Epoch 8/20, Iteration 146/303, Loss: 0.2491416037082672\n",
      "Epoch 8/20, Iteration 147/303, Loss: 0.13379770517349243\n",
      "Epoch 8/20, Iteration 148/303, Loss: 0.3258077800273895\n",
      "Epoch 8/20, Iteration 149/303, Loss: 0.2948363423347473\n",
      "Epoch 8/20, Iteration 150/303, Loss: 0.35847240686416626\n",
      "Epoch 8/20, Iteration 151/303, Loss: 0.2253417670726776\n",
      "Epoch 8/20, Iteration 152/303, Loss: 0.36976921558380127\n",
      "Epoch 8/20, Iteration 153/303, Loss: 0.25734707713127136\n",
      "Epoch 8/20, Iteration 154/303, Loss: 0.2648911476135254\n",
      "Epoch 8/20, Iteration 155/303, Loss: 0.2748536765575409\n",
      "Epoch 8/20, Iteration 156/303, Loss: 0.44730913639068604\n",
      "Epoch 8/20, Iteration 157/303, Loss: 0.3659760057926178\n",
      "Epoch 8/20, Iteration 158/303, Loss: 0.2535395622253418\n",
      "Epoch 8/20, Iteration 159/303, Loss: 0.48911935091018677\n",
      "Epoch 8/20, Iteration 160/303, Loss: 0.3216063380241394\n",
      "Epoch 8/20, Iteration 161/303, Loss: 0.3463861048221588\n",
      "Epoch 8/20, Iteration 162/303, Loss: 0.3953778147697449\n",
      "Epoch 8/20, Iteration 163/303, Loss: 0.3544062674045563\n",
      "Epoch 8/20, Iteration 164/303, Loss: 0.41288095712661743\n",
      "Epoch 8/20, Iteration 165/303, Loss: 0.20552252233028412\n",
      "Epoch 8/20, Iteration 166/303, Loss: 0.4098200798034668\n",
      "Epoch 8/20, Iteration 167/303, Loss: 0.3151017427444458\n",
      "Epoch 8/20, Iteration 168/303, Loss: 0.36833781003952026\n",
      "Epoch 8/20, Iteration 169/303, Loss: 0.2254473716020584\n",
      "Epoch 8/20, Iteration 170/303, Loss: 0.35369157791137695\n",
      "Epoch 8/20, Iteration 171/303, Loss: 0.3963163495063782\n",
      "Epoch 8/20, Iteration 172/303, Loss: 0.5019900798797607\n",
      "Epoch 8/20, Iteration 173/303, Loss: 0.36653003096580505\n",
      "Epoch 8/20, Iteration 174/303, Loss: 0.16942104697227478\n",
      "Epoch 8/20, Iteration 175/303, Loss: 0.5194376707077026\n",
      "Epoch 8/20, Iteration 176/303, Loss: 0.2861683964729309\n",
      "Epoch 8/20, Iteration 177/303, Loss: 0.33692777156829834\n",
      "Epoch 8/20, Iteration 178/303, Loss: 0.3652900755405426\n",
      "Epoch 8/20, Iteration 179/303, Loss: 0.5606403350830078\n",
      "Epoch 8/20, Iteration 180/303, Loss: 0.42047038674354553\n",
      "Epoch 8/20, Iteration 181/303, Loss: 0.31998535990715027\n",
      "Epoch 8/20, Iteration 182/303, Loss: 0.31308209896087646\n",
      "Epoch 8/20, Iteration 183/303, Loss: 0.3730916976928711\n",
      "Epoch 8/20, Iteration 184/303, Loss: 0.2644492983818054\n",
      "Epoch 8/20, Iteration 185/303, Loss: 0.32812559604644775\n",
      "Epoch 8/20, Iteration 186/303, Loss: 0.27293068170547485\n",
      "Epoch 8/20, Iteration 187/303, Loss: 0.32856473326683044\n",
      "Epoch 8/20, Iteration 188/303, Loss: 0.24251556396484375\n",
      "Epoch 8/20, Iteration 189/303, Loss: 0.45157793164253235\n",
      "Epoch 8/20, Iteration 190/303, Loss: 0.35989615321159363\n",
      "Epoch 8/20, Iteration 191/303, Loss: 0.37828654050827026\n",
      "Epoch 8/20, Iteration 192/303, Loss: 0.17678764462471008\n",
      "Epoch 8/20, Iteration 193/303, Loss: 0.24801233410835266\n",
      "Epoch 8/20, Iteration 194/303, Loss: 0.36719775199890137\n",
      "Epoch 8/20, Iteration 195/303, Loss: 0.32603326439857483\n",
      "Epoch 8/20, Iteration 196/303, Loss: 0.41595712304115295\n",
      "Epoch 8/20, Iteration 197/303, Loss: 0.3197527229785919\n",
      "Epoch 8/20, Iteration 198/303, Loss: 0.4077758193016052\n",
      "Epoch 8/20, Iteration 199/303, Loss: 0.3314560055732727\n",
      "Epoch 8/20, Iteration 200/303, Loss: 0.31705576181411743\n",
      "Epoch 8/20, Iteration 201/303, Loss: 0.3812752664089203\n",
      "Epoch 8/20, Iteration 202/303, Loss: 0.44262099266052246\n",
      "Epoch 8/20, Iteration 203/303, Loss: 0.3913504481315613\n",
      "Epoch 8/20, Iteration 204/303, Loss: 0.24383863806724548\n",
      "Epoch 8/20, Iteration 205/303, Loss: 0.29979145526885986\n",
      "Epoch 8/20, Iteration 206/303, Loss: 0.2890433967113495\n",
      "Epoch 8/20, Iteration 207/303, Loss: 0.4232904613018036\n",
      "Epoch 8/20, Iteration 208/303, Loss: 0.21405017375946045\n",
      "Epoch 8/20, Iteration 209/303, Loss: 0.34110352396965027\n",
      "Epoch 8/20, Iteration 210/303, Loss: 0.2874371111392975\n",
      "Epoch 8/20, Iteration 211/303, Loss: 0.33307644724845886\n",
      "Epoch 8/20, Iteration 212/303, Loss: 0.27614152431488037\n",
      "Epoch 8/20, Iteration 213/303, Loss: 0.27267441153526306\n",
      "Epoch 8/20, Iteration 214/303, Loss: 0.22843888401985168\n",
      "Epoch 8/20, Iteration 215/303, Loss: 0.3161102533340454\n",
      "Epoch 8/20, Iteration 216/303, Loss: 0.2601553499698639\n",
      "Epoch 8/20, Iteration 217/303, Loss: 0.40037208795547485\n",
      "Epoch 8/20, Iteration 218/303, Loss: 0.4015275537967682\n",
      "Epoch 8/20, Iteration 219/303, Loss: 0.2711043357849121\n",
      "Epoch 8/20, Iteration 220/303, Loss: 0.3266534209251404\n",
      "Epoch 8/20, Iteration 221/303, Loss: 0.26817068457603455\n",
      "Epoch 8/20, Iteration 222/303, Loss: 0.5628299713134766\n",
      "Epoch 8/20, Iteration 223/303, Loss: 0.3058449923992157\n",
      "Epoch 8/20, Iteration 224/303, Loss: 0.3119521141052246\n",
      "Epoch 8/20, Iteration 225/303, Loss: 0.31217047572135925\n",
      "Epoch 8/20, Iteration 226/303, Loss: 0.1794702410697937\n",
      "Epoch 8/20, Iteration 227/303, Loss: 0.3037360608577728\n",
      "Epoch 8/20, Iteration 228/303, Loss: 0.4573648273944855\n",
      "Epoch 8/20, Iteration 229/303, Loss: 0.3528923988342285\n",
      "Epoch 8/20, Iteration 230/303, Loss: 0.3013317883014679\n",
      "Epoch 8/20, Iteration 231/303, Loss: 0.2997274100780487\n",
      "Epoch 8/20, Iteration 232/303, Loss: 0.19099204242229462\n",
      "Epoch 8/20, Iteration 233/303, Loss: 0.30854737758636475\n",
      "Epoch 8/20, Iteration 234/303, Loss: 0.4761508107185364\n",
      "Epoch 8/20, Iteration 235/303, Loss: 0.27589672803878784\n",
      "Epoch 8/20, Iteration 236/303, Loss: 0.27042391896247864\n",
      "Epoch 8/20, Iteration 237/303, Loss: 0.31753212213516235\n",
      "Epoch 8/20, Iteration 238/303, Loss: 0.2970716953277588\n",
      "Epoch 8/20, Iteration 239/303, Loss: 0.44989675283432007\n",
      "Epoch 8/20, Iteration 240/303, Loss: 0.25916552543640137\n",
      "Epoch 8/20, Iteration 241/303, Loss: 0.2752021551132202\n",
      "Epoch 8/20, Iteration 242/303, Loss: 0.2984043061733246\n",
      "Epoch 8/20, Iteration 243/303, Loss: 0.27802354097366333\n",
      "Epoch 8/20, Iteration 244/303, Loss: 0.22169236838817596\n",
      "Epoch 8/20, Iteration 245/303, Loss: 0.27671393752098083\n",
      "Epoch 8/20, Iteration 246/303, Loss: 0.18550239503383636\n",
      "Epoch 8/20, Iteration 247/303, Loss: 0.2116638720035553\n",
      "Epoch 8/20, Iteration 248/303, Loss: 0.37804368138313293\n",
      "Epoch 8/20, Iteration 249/303, Loss: 0.35388362407684326\n",
      "Epoch 8/20, Iteration 250/303, Loss: 0.34230419993400574\n",
      "Epoch 8/20, Iteration 251/303, Loss: 0.3653543293476105\n",
      "Epoch 8/20, Iteration 252/303, Loss: 0.2097826451063156\n",
      "Epoch 8/20, Iteration 253/303, Loss: 0.25737375020980835\n",
      "Epoch 8/20, Iteration 254/303, Loss: 0.19139955937862396\n",
      "Epoch 8/20, Iteration 255/303, Loss: 0.34528231620788574\n",
      "Epoch 8/20, Iteration 256/303, Loss: 0.21756869554519653\n",
      "Epoch 8/20, Iteration 257/303, Loss: 0.2147057056427002\n",
      "Epoch 8/20, Iteration 258/303, Loss: 0.4023333489894867\n",
      "Epoch 8/20, Iteration 259/303, Loss: 0.28919270634651184\n",
      "Epoch 8/20, Iteration 260/303, Loss: 0.2785188853740692\n",
      "Epoch 8/20, Iteration 261/303, Loss: 0.2532116174697876\n",
      "Epoch 8/20, Iteration 262/303, Loss: 0.22241203486919403\n",
      "Epoch 8/20, Iteration 263/303, Loss: 0.1966419816017151\n",
      "Epoch 8/20, Iteration 264/303, Loss: 0.1869475543498993\n",
      "Epoch 8/20, Iteration 265/303, Loss: 0.5621459484100342\n",
      "Epoch 8/20, Iteration 266/303, Loss: 0.2800212502479553\n",
      "Epoch 8/20, Iteration 267/303, Loss: 0.37216874957084656\n",
      "Epoch 8/20, Iteration 268/303, Loss: 0.32839298248291016\n",
      "Epoch 8/20, Iteration 269/303, Loss: 0.21727856993675232\n",
      "Epoch 8/20, Iteration 270/303, Loss: 0.3624756336212158\n",
      "Epoch 8/20, Iteration 271/303, Loss: 0.4560757279396057\n",
      "Epoch 8/20, Iteration 272/303, Loss: 0.37663888931274414\n",
      "Epoch 8/20, Iteration 273/303, Loss: 0.2922753095626831\n",
      "Epoch 8/20, Iteration 274/303, Loss: 0.3009777367115021\n",
      "Epoch 8/20, Iteration 275/303, Loss: 0.36575475335121155\n",
      "Epoch 8/20, Iteration 276/303, Loss: 0.39760148525238037\n",
      "Epoch 8/20, Iteration 277/303, Loss: 0.29341840744018555\n",
      "Epoch 8/20, Iteration 278/303, Loss: 0.3859381675720215\n",
      "Epoch 8/20, Iteration 279/303, Loss: 0.1878717541694641\n",
      "Epoch 8/20, Iteration 280/303, Loss: 0.5603105425834656\n",
      "Epoch 8/20, Iteration 281/303, Loss: 0.42713284492492676\n",
      "Epoch 8/20, Iteration 282/303, Loss: 0.4746261239051819\n",
      "Epoch 8/20, Iteration 283/303, Loss: 0.21643716096878052\n",
      "Epoch 8/20, Iteration 284/303, Loss: 0.23026525974273682\n",
      "Epoch 8/20, Iteration 285/303, Loss: 0.5174267888069153\n",
      "Epoch 8/20, Iteration 286/303, Loss: 0.399238258600235\n",
      "Epoch 8/20, Iteration 287/303, Loss: 0.44739508628845215\n",
      "Epoch 8/20, Iteration 288/303, Loss: 0.2002640813589096\n",
      "Epoch 8/20, Iteration 289/303, Loss: 0.2059377282857895\n",
      "Epoch 8/20, Iteration 290/303, Loss: 0.20319052040576935\n",
      "Epoch 8/20, Iteration 291/303, Loss: 0.5243545174598694\n",
      "Epoch 8/20, Iteration 292/303, Loss: 0.31263256072998047\n",
      "Epoch 8/20, Iteration 293/303, Loss: 0.27580446004867554\n",
      "Epoch 8/20, Iteration 294/303, Loss: 0.22821474075317383\n",
      "Epoch 8/20, Iteration 295/303, Loss: 0.4453178644180298\n",
      "Epoch 8/20, Iteration 296/303, Loss: 0.393079936504364\n",
      "Epoch 8/20, Iteration 297/303, Loss: 0.24824586510658264\n",
      "Epoch 8/20, Iteration 298/303, Loss: 0.4774589240550995\n",
      "Epoch 8/20, Iteration 299/303, Loss: 0.31594720482826233\n",
      "Epoch 8/20, Iteration 300/303, Loss: 0.407213419675827\n",
      "Epoch 8/20, Iteration 301/303, Loss: 0.17871172726154327\n",
      "Epoch 8/20, Iteration 302/303, Loss: 0.30118101835250854\n",
      "Epoch 8/20, Iteration 303/303, Loss: 0.33784595131874084\n",
      "Epoch 9/20, Iteration 1/303, Loss: 0.32199543714523315\n",
      "Epoch 9/20, Iteration 2/303, Loss: 0.2816954255104065\n",
      "Epoch 9/20, Iteration 3/303, Loss: 0.21105742454528809\n",
      "Epoch 9/20, Iteration 4/303, Loss: 0.2520778179168701\n",
      "Epoch 9/20, Iteration 5/303, Loss: 0.2827512323856354\n",
      "Epoch 9/20, Iteration 6/303, Loss: 0.25586795806884766\n",
      "Epoch 9/20, Iteration 7/303, Loss: 0.21733549237251282\n",
      "Epoch 9/20, Iteration 8/303, Loss: 0.15025483071804047\n",
      "Epoch 9/20, Iteration 9/303, Loss: 0.24481692910194397\n",
      "Epoch 9/20, Iteration 10/303, Loss: 0.3626449704170227\n",
      "Epoch 9/20, Iteration 11/303, Loss: 0.26474499702453613\n",
      "Epoch 9/20, Iteration 12/303, Loss: 0.309053897857666\n",
      "Epoch 9/20, Iteration 13/303, Loss: 0.2685931921005249\n",
      "Epoch 9/20, Iteration 14/303, Loss: 0.32530730962753296\n",
      "Epoch 9/20, Iteration 15/303, Loss: 0.11634401977062225\n",
      "Epoch 9/20, Iteration 16/303, Loss: 0.22438129782676697\n",
      "Epoch 9/20, Iteration 17/303, Loss: 0.2842114269733429\n",
      "Epoch 9/20, Iteration 18/303, Loss: 0.31811365485191345\n",
      "Epoch 9/20, Iteration 19/303, Loss: 0.35188186168670654\n",
      "Epoch 9/20, Iteration 20/303, Loss: 0.23129436373710632\n",
      "Epoch 9/20, Iteration 21/303, Loss: 0.30173230171203613\n",
      "Epoch 9/20, Iteration 22/303, Loss: 0.2537568211555481\n",
      "Epoch 9/20, Iteration 23/303, Loss: 0.35727283358573914\n",
      "Epoch 9/20, Iteration 24/303, Loss: 0.2864013612270355\n",
      "Epoch 9/20, Iteration 25/303, Loss: 0.2711334824562073\n",
      "Epoch 9/20, Iteration 26/303, Loss: 0.2399388998746872\n",
      "Epoch 9/20, Iteration 27/303, Loss: 0.3366592228412628\n",
      "Epoch 9/20, Iteration 28/303, Loss: 0.31142571568489075\n",
      "Epoch 9/20, Iteration 29/303, Loss: 0.2387513369321823\n",
      "Epoch 9/20, Iteration 30/303, Loss: 0.3418652415275574\n",
      "Epoch 9/20, Iteration 31/303, Loss: 0.20938217639923096\n",
      "Epoch 9/20, Iteration 32/303, Loss: 0.1786293089389801\n",
      "Epoch 9/20, Iteration 33/303, Loss: 0.2857148051261902\n",
      "Epoch 9/20, Iteration 34/303, Loss: 0.35101476311683655\n",
      "Epoch 9/20, Iteration 35/303, Loss: 0.1940554529428482\n",
      "Epoch 9/20, Iteration 36/303, Loss: 0.32029989361763\n",
      "Epoch 9/20, Iteration 37/303, Loss: 0.4603988826274872\n",
      "Epoch 9/20, Iteration 38/303, Loss: 0.3692781329154968\n",
      "Epoch 9/20, Iteration 39/303, Loss: 0.24745944142341614\n",
      "Epoch 9/20, Iteration 40/303, Loss: 0.24688974022865295\n",
      "Epoch 9/20, Iteration 41/303, Loss: 0.4288492500782013\n",
      "Epoch 9/20, Iteration 42/303, Loss: 0.19988150894641876\n",
      "Epoch 9/20, Iteration 43/303, Loss: 0.4145450294017792\n",
      "Epoch 9/20, Iteration 44/303, Loss: 0.29084742069244385\n",
      "Epoch 9/20, Iteration 45/303, Loss: 0.1970061957836151\n",
      "Epoch 9/20, Iteration 46/303, Loss: 0.33378204703330994\n",
      "Epoch 9/20, Iteration 47/303, Loss: 0.13995984196662903\n",
      "Epoch 9/20, Iteration 48/303, Loss: 0.3621150851249695\n",
      "Epoch 9/20, Iteration 49/303, Loss: 0.401498019695282\n",
      "Epoch 9/20, Iteration 50/303, Loss: 0.29889625310897827\n",
      "Epoch 9/20, Iteration 51/303, Loss: 0.321719229221344\n",
      "Epoch 9/20, Iteration 52/303, Loss: 0.17849470674991608\n",
      "Epoch 9/20, Iteration 53/303, Loss: 0.17658933997154236\n",
      "Epoch 9/20, Iteration 54/303, Loss: 0.3184111416339874\n",
      "Epoch 9/20, Iteration 55/303, Loss: 0.28490376472473145\n",
      "Epoch 9/20, Iteration 56/303, Loss: 0.2714751958847046\n",
      "Epoch 9/20, Iteration 57/303, Loss: 0.38825681805610657\n",
      "Epoch 9/20, Iteration 58/303, Loss: 0.15747345983982086\n",
      "Epoch 9/20, Iteration 59/303, Loss: 0.22842037677764893\n",
      "Epoch 9/20, Iteration 60/303, Loss: 0.3014720678329468\n",
      "Epoch 9/20, Iteration 61/303, Loss: 0.2556437849998474\n",
      "Epoch 9/20, Iteration 62/303, Loss: 0.22207370400428772\n",
      "Epoch 9/20, Iteration 63/303, Loss: 0.1787114441394806\n",
      "Epoch 9/20, Iteration 64/303, Loss: 0.1196729764342308\n",
      "Epoch 9/20, Iteration 65/303, Loss: 0.3438851237297058\n",
      "Epoch 9/20, Iteration 66/303, Loss: 0.2106243073940277\n",
      "Epoch 9/20, Iteration 67/303, Loss: 0.2339792549610138\n",
      "Epoch 9/20, Iteration 68/303, Loss: 0.24458181858062744\n",
      "Epoch 9/20, Iteration 69/303, Loss: 0.38252875208854675\n",
      "Epoch 9/20, Iteration 70/303, Loss: 0.3580520749092102\n",
      "Epoch 9/20, Iteration 71/303, Loss: 0.29968366026878357\n",
      "Epoch 9/20, Iteration 72/303, Loss: 0.3064686059951782\n",
      "Epoch 9/20, Iteration 73/303, Loss: 0.2523151636123657\n",
      "Epoch 9/20, Iteration 74/303, Loss: 0.3803681433200836\n",
      "Epoch 9/20, Iteration 75/303, Loss: 0.22561302781105042\n",
      "Epoch 9/20, Iteration 76/303, Loss: 0.31073546409606934\n",
      "Epoch 9/20, Iteration 77/303, Loss: 0.3388199806213379\n",
      "Epoch 9/20, Iteration 78/303, Loss: 0.3159711956977844\n",
      "Epoch 9/20, Iteration 79/303, Loss: 0.21107973158359528\n",
      "Epoch 9/20, Iteration 80/303, Loss: 0.26471567153930664\n",
      "Epoch 9/20, Iteration 81/303, Loss: 0.30020514130592346\n",
      "Epoch 9/20, Iteration 82/303, Loss: 0.16191604733467102\n",
      "Epoch 9/20, Iteration 83/303, Loss: 0.26648202538490295\n",
      "Epoch 9/20, Iteration 84/303, Loss: 0.3472912907600403\n",
      "Epoch 9/20, Iteration 85/303, Loss: 0.23803377151489258\n",
      "Epoch 9/20, Iteration 86/303, Loss: 0.260708212852478\n",
      "Epoch 9/20, Iteration 87/303, Loss: 0.1895447075366974\n",
      "Epoch 9/20, Iteration 88/303, Loss: 0.1558544784784317\n",
      "Epoch 9/20, Iteration 89/303, Loss: 0.18824540078639984\n",
      "Epoch 9/20, Iteration 90/303, Loss: 0.3135879933834076\n",
      "Epoch 9/20, Iteration 91/303, Loss: 0.3451745808124542\n",
      "Epoch 9/20, Iteration 92/303, Loss: 0.21815653145313263\n",
      "Epoch 9/20, Iteration 93/303, Loss: 0.2483583390712738\n",
      "Epoch 9/20, Iteration 94/303, Loss: 0.17749276757240295\n",
      "Epoch 9/20, Iteration 95/303, Loss: 0.21112826466560364\n",
      "Epoch 9/20, Iteration 96/303, Loss: 0.28572893142700195\n",
      "Epoch 9/20, Iteration 97/303, Loss: 0.3272184133529663\n",
      "Epoch 9/20, Iteration 98/303, Loss: 0.13352489471435547\n",
      "Epoch 9/20, Iteration 99/303, Loss: 0.4013206660747528\n",
      "Epoch 9/20, Iteration 100/303, Loss: 0.32082000374794006\n",
      "Epoch 9/20, Iteration 101/303, Loss: 0.24147474765777588\n",
      "Epoch 9/20, Iteration 102/303, Loss: 0.3068643808364868\n",
      "Epoch 9/20, Iteration 103/303, Loss: 0.2816476821899414\n",
      "Epoch 9/20, Iteration 104/303, Loss: 0.13816513121128082\n",
      "Epoch 9/20, Iteration 105/303, Loss: 0.2965017259120941\n",
      "Epoch 9/20, Iteration 106/303, Loss: 0.24993953108787537\n",
      "Epoch 9/20, Iteration 107/303, Loss: 0.27559924125671387\n",
      "Epoch 9/20, Iteration 108/303, Loss: 0.31216126680374146\n",
      "Epoch 9/20, Iteration 109/303, Loss: 0.23064982891082764\n",
      "Epoch 9/20, Iteration 110/303, Loss: 0.13999444246292114\n",
      "Epoch 9/20, Iteration 111/303, Loss: 0.18964162468910217\n",
      "Epoch 9/20, Iteration 112/303, Loss: 0.2736422121524811\n",
      "Epoch 9/20, Iteration 113/303, Loss: 0.32419466972351074\n",
      "Epoch 9/20, Iteration 114/303, Loss: 0.46152493357658386\n",
      "Epoch 9/20, Iteration 115/303, Loss: 0.34861427545547485\n",
      "Epoch 9/20, Iteration 116/303, Loss: 0.32534778118133545\n",
      "Epoch 9/20, Iteration 117/303, Loss: 0.25162702798843384\n",
      "Epoch 9/20, Iteration 118/303, Loss: 0.40498560667037964\n",
      "Epoch 9/20, Iteration 119/303, Loss: 0.3107929825782776\n",
      "Epoch 9/20, Iteration 120/303, Loss: 0.29736781120300293\n",
      "Epoch 9/20, Iteration 121/303, Loss: 0.3127942383289337\n",
      "Epoch 9/20, Iteration 122/303, Loss: 0.3675740957260132\n",
      "Epoch 9/20, Iteration 123/303, Loss: 0.2544848322868347\n",
      "Epoch 9/20, Iteration 124/303, Loss: 0.37451687455177307\n",
      "Epoch 9/20, Iteration 125/303, Loss: 0.2347690761089325\n",
      "Epoch 9/20, Iteration 126/303, Loss: 0.31881603598594666\n",
      "Epoch 9/20, Iteration 127/303, Loss: 0.1497040092945099\n",
      "Epoch 9/20, Iteration 128/303, Loss: 0.25395122170448303\n",
      "Epoch 9/20, Iteration 129/303, Loss: 0.2673272490501404\n",
      "Epoch 9/20, Iteration 130/303, Loss: 0.2816709876060486\n",
      "Epoch 9/20, Iteration 131/303, Loss: 0.3170461058616638\n",
      "Epoch 9/20, Iteration 132/303, Loss: 0.22776629030704498\n",
      "Epoch 9/20, Iteration 133/303, Loss: 0.386766642332077\n",
      "Epoch 9/20, Iteration 134/303, Loss: 0.4807741940021515\n",
      "Epoch 9/20, Iteration 135/303, Loss: 0.19441735744476318\n",
      "Epoch 9/20, Iteration 136/303, Loss: 0.29983919858932495\n",
      "Epoch 9/20, Iteration 137/303, Loss: 0.48969781398773193\n",
      "Epoch 9/20, Iteration 138/303, Loss: 0.34899935126304626\n",
      "Epoch 9/20, Iteration 139/303, Loss: 0.15887127816677094\n",
      "Epoch 9/20, Iteration 140/303, Loss: 0.23532377183437347\n",
      "Epoch 9/20, Iteration 141/303, Loss: 0.36963897943496704\n",
      "Epoch 9/20, Iteration 142/303, Loss: 0.32685384154319763\n",
      "Epoch 9/20, Iteration 143/303, Loss: 0.17410749197006226\n",
      "Epoch 9/20, Iteration 144/303, Loss: 0.2915065586566925\n",
      "Epoch 9/20, Iteration 145/303, Loss: 0.2605969309806824\n",
      "Epoch 9/20, Iteration 146/303, Loss: 0.2365817278623581\n",
      "Epoch 9/20, Iteration 147/303, Loss: 0.36401140689849854\n",
      "Epoch 9/20, Iteration 148/303, Loss: 0.44038844108581543\n",
      "Epoch 9/20, Iteration 149/303, Loss: 0.44025692343711853\n",
      "Epoch 9/20, Iteration 150/303, Loss: 0.31928375363349915\n",
      "Epoch 9/20, Iteration 151/303, Loss: 0.31785646080970764\n",
      "Epoch 9/20, Iteration 152/303, Loss: 0.46895280480384827\n",
      "Epoch 9/20, Iteration 153/303, Loss: 0.2624000906944275\n",
      "Epoch 9/20, Iteration 154/303, Loss: 0.29357659816741943\n",
      "Epoch 9/20, Iteration 155/303, Loss: 0.1704670637845993\n",
      "Epoch 9/20, Iteration 156/303, Loss: 0.16196364164352417\n",
      "Epoch 9/20, Iteration 157/303, Loss: 0.2844129204750061\n",
      "Epoch 9/20, Iteration 158/303, Loss: 0.16019293665885925\n",
      "Epoch 9/20, Iteration 159/303, Loss: 0.2686970829963684\n",
      "Epoch 9/20, Iteration 160/303, Loss: 0.1285090446472168\n",
      "Epoch 9/20, Iteration 161/303, Loss: 0.24736300110816956\n",
      "Epoch 9/20, Iteration 162/303, Loss: 0.23589198291301727\n",
      "Epoch 9/20, Iteration 163/303, Loss: 0.21829280257225037\n",
      "Epoch 9/20, Iteration 164/303, Loss: 0.34294259548187256\n",
      "Epoch 9/20, Iteration 165/303, Loss: 0.14953017234802246\n",
      "Epoch 9/20, Iteration 166/303, Loss: 0.3439062237739563\n",
      "Epoch 9/20, Iteration 167/303, Loss: 0.4378400444984436\n",
      "Epoch 9/20, Iteration 168/303, Loss: 0.19708813726902008\n",
      "Epoch 9/20, Iteration 169/303, Loss: 0.2515060603618622\n",
      "Epoch 9/20, Iteration 170/303, Loss: 0.2587386965751648\n",
      "Epoch 9/20, Iteration 171/303, Loss: 0.26548054814338684\n",
      "Epoch 9/20, Iteration 172/303, Loss: 0.3913043737411499\n",
      "Epoch 9/20, Iteration 173/303, Loss: 0.22153735160827637\n",
      "Epoch 9/20, Iteration 174/303, Loss: 0.6137628555297852\n",
      "Epoch 9/20, Iteration 175/303, Loss: 0.41797444224357605\n",
      "Epoch 9/20, Iteration 176/303, Loss: 0.35923129320144653\n",
      "Epoch 9/20, Iteration 177/303, Loss: 0.20858703553676605\n",
      "Epoch 9/20, Iteration 178/303, Loss: 0.2576432526111603\n",
      "Epoch 9/20, Iteration 179/303, Loss: 0.3498837947845459\n",
      "Epoch 9/20, Iteration 180/303, Loss: 0.2330520749092102\n",
      "Epoch 9/20, Iteration 181/303, Loss: 0.3064141571521759\n",
      "Epoch 9/20, Iteration 182/303, Loss: 0.21220172941684723\n",
      "Epoch 9/20, Iteration 183/303, Loss: 0.28560033440589905\n",
      "Epoch 9/20, Iteration 184/303, Loss: 0.1466977894306183\n",
      "Epoch 9/20, Iteration 185/303, Loss: 0.08677109330892563\n",
      "Epoch 9/20, Iteration 186/303, Loss: 0.5304105281829834\n",
      "Epoch 9/20, Iteration 187/303, Loss: 0.4879012107849121\n",
      "Epoch 9/20, Iteration 188/303, Loss: 0.28283724188804626\n",
      "Epoch 9/20, Iteration 189/303, Loss: 0.2826613187789917\n",
      "Epoch 9/20, Iteration 190/303, Loss: 0.3058528006076813\n",
      "Epoch 9/20, Iteration 191/303, Loss: 0.3392922282218933\n",
      "Epoch 9/20, Iteration 192/303, Loss: 0.3616139888763428\n",
      "Epoch 9/20, Iteration 193/303, Loss: 0.35054320096969604\n",
      "Epoch 9/20, Iteration 194/303, Loss: 0.20438547432422638\n",
      "Epoch 9/20, Iteration 195/303, Loss: 0.37608402967453003\n",
      "Epoch 9/20, Iteration 196/303, Loss: 0.22386033833026886\n",
      "Epoch 9/20, Iteration 197/303, Loss: 0.1287534385919571\n",
      "Epoch 9/20, Iteration 198/303, Loss: 0.3519848585128784\n",
      "Epoch 9/20, Iteration 199/303, Loss: 0.22924712300300598\n",
      "Epoch 9/20, Iteration 200/303, Loss: 0.2001841515302658\n",
      "Epoch 9/20, Iteration 201/303, Loss: 0.24110738933086395\n",
      "Epoch 9/20, Iteration 202/303, Loss: 0.2676559090614319\n",
      "Epoch 9/20, Iteration 203/303, Loss: 0.29162928462028503\n",
      "Epoch 9/20, Iteration 204/303, Loss: 0.1753861904144287\n",
      "Epoch 9/20, Iteration 205/303, Loss: 0.2657843232154846\n",
      "Epoch 9/20, Iteration 206/303, Loss: 0.3153388202190399\n",
      "Epoch 9/20, Iteration 207/303, Loss: 0.35255056619644165\n",
      "Epoch 9/20, Iteration 208/303, Loss: 0.3315327763557434\n",
      "Epoch 9/20, Iteration 209/303, Loss: 0.20428837835788727\n",
      "Epoch 9/20, Iteration 210/303, Loss: 0.5557721257209778\n",
      "Epoch 9/20, Iteration 211/303, Loss: 0.24834337830543518\n",
      "Epoch 9/20, Iteration 212/303, Loss: 0.4473669230937958\n",
      "Epoch 9/20, Iteration 213/303, Loss: 0.30608439445495605\n",
      "Epoch 9/20, Iteration 214/303, Loss: 0.33549538254737854\n",
      "Epoch 9/20, Iteration 215/303, Loss: 0.21845997869968414\n",
      "Epoch 9/20, Iteration 216/303, Loss: 0.2582901418209076\n",
      "Epoch 9/20, Iteration 217/303, Loss: 0.49615997076034546\n",
      "Epoch 9/20, Iteration 218/303, Loss: 0.30907994508743286\n",
      "Epoch 9/20, Iteration 219/303, Loss: 0.15881583094596863\n",
      "Epoch 9/20, Iteration 220/303, Loss: 0.190718412399292\n",
      "Epoch 9/20, Iteration 221/303, Loss: 0.2905048131942749\n",
      "Epoch 9/20, Iteration 222/303, Loss: 0.38705718517303467\n",
      "Epoch 9/20, Iteration 223/303, Loss: 0.11976347118616104\n",
      "Epoch 9/20, Iteration 224/303, Loss: 0.25947198271751404\n",
      "Epoch 9/20, Iteration 225/303, Loss: 0.18803082406520844\n",
      "Epoch 9/20, Iteration 226/303, Loss: 0.27963313460350037\n",
      "Epoch 9/20, Iteration 227/303, Loss: 0.2090933620929718\n",
      "Epoch 9/20, Iteration 228/303, Loss: 0.19859223067760468\n",
      "Epoch 9/20, Iteration 229/303, Loss: 0.29317930340766907\n",
      "Epoch 9/20, Iteration 230/303, Loss: 0.25715237855911255\n",
      "Epoch 9/20, Iteration 231/303, Loss: 0.31810155510902405\n",
      "Epoch 9/20, Iteration 232/303, Loss: 0.3785611391067505\n",
      "Epoch 9/20, Iteration 233/303, Loss: 0.3757113516330719\n",
      "Epoch 9/20, Iteration 234/303, Loss: 0.2936103641986847\n",
      "Epoch 9/20, Iteration 235/303, Loss: 0.19389763474464417\n",
      "Epoch 9/20, Iteration 236/303, Loss: 0.25561368465423584\n",
      "Epoch 9/20, Iteration 237/303, Loss: 0.30089929699897766\n",
      "Epoch 9/20, Iteration 238/303, Loss: 0.38601934909820557\n",
      "Epoch 9/20, Iteration 239/303, Loss: 0.5114874839782715\n",
      "Epoch 9/20, Iteration 240/303, Loss: 0.2285359501838684\n",
      "Epoch 9/20, Iteration 241/303, Loss: 0.3949022591114044\n",
      "Epoch 9/20, Iteration 242/303, Loss: 0.2803828716278076\n",
      "Epoch 9/20, Iteration 243/303, Loss: 0.3522166907787323\n",
      "Epoch 9/20, Iteration 244/303, Loss: 0.20951193571090698\n",
      "Epoch 9/20, Iteration 245/303, Loss: 0.2520015835762024\n",
      "Epoch 9/20, Iteration 246/303, Loss: 0.3098917603492737\n",
      "Epoch 9/20, Iteration 247/303, Loss: 0.19354596734046936\n",
      "Epoch 9/20, Iteration 248/303, Loss: 0.4669058322906494\n",
      "Epoch 9/20, Iteration 249/303, Loss: 0.32599252462387085\n",
      "Epoch 9/20, Iteration 250/303, Loss: 0.4951061010360718\n",
      "Epoch 9/20, Iteration 251/303, Loss: 0.22948412597179413\n",
      "Epoch 9/20, Iteration 252/303, Loss: 0.15758365392684937\n",
      "Epoch 9/20, Iteration 253/303, Loss: 0.3292921781539917\n",
      "Epoch 9/20, Iteration 254/303, Loss: 0.3583413362503052\n",
      "Epoch 9/20, Iteration 255/303, Loss: 0.13746866583824158\n",
      "Epoch 9/20, Iteration 256/303, Loss: 0.18459364771842957\n",
      "Epoch 9/20, Iteration 257/303, Loss: 0.37074756622314453\n",
      "Epoch 9/20, Iteration 258/303, Loss: 0.24559761583805084\n",
      "Epoch 9/20, Iteration 259/303, Loss: 0.3746173679828644\n",
      "Epoch 9/20, Iteration 260/303, Loss: 0.21743303537368774\n",
      "Epoch 9/20, Iteration 261/303, Loss: 0.15592293441295624\n",
      "Epoch 9/20, Iteration 262/303, Loss: 0.35420799255371094\n",
      "Epoch 9/20, Iteration 263/303, Loss: 0.277119517326355\n",
      "Epoch 9/20, Iteration 264/303, Loss: 0.38184642791748047\n",
      "Epoch 9/20, Iteration 265/303, Loss: 0.23846754431724548\n",
      "Epoch 9/20, Iteration 266/303, Loss: 0.33293938636779785\n",
      "Epoch 9/20, Iteration 267/303, Loss: 0.36283451318740845\n",
      "Epoch 9/20, Iteration 268/303, Loss: 0.29331040382385254\n",
      "Epoch 9/20, Iteration 269/303, Loss: 0.432237833738327\n",
      "Epoch 9/20, Iteration 270/303, Loss: 0.2282947450876236\n",
      "Epoch 9/20, Iteration 271/303, Loss: 0.3100905418395996\n",
      "Epoch 9/20, Iteration 272/303, Loss: 0.18279293179512024\n",
      "Epoch 9/20, Iteration 273/303, Loss: 0.382961630821228\n",
      "Epoch 9/20, Iteration 274/303, Loss: 0.4350000023841858\n",
      "Epoch 9/20, Iteration 275/303, Loss: 0.3805033564567566\n",
      "Epoch 9/20, Iteration 276/303, Loss: 0.20019349455833435\n",
      "Epoch 9/20, Iteration 277/303, Loss: 0.21736733615398407\n",
      "Epoch 9/20, Iteration 278/303, Loss: 0.24832619726657867\n",
      "Epoch 9/20, Iteration 279/303, Loss: 0.19191963970661163\n",
      "Epoch 9/20, Iteration 280/303, Loss: 0.2888931632041931\n",
      "Epoch 9/20, Iteration 281/303, Loss: 0.26214665174484253\n",
      "Epoch 9/20, Iteration 282/303, Loss: 0.3742593824863434\n",
      "Epoch 9/20, Iteration 283/303, Loss: 0.2670890688896179\n",
      "Epoch 9/20, Iteration 284/303, Loss: 0.38250893354415894\n",
      "Epoch 9/20, Iteration 285/303, Loss: 0.2650304436683655\n",
      "Epoch 9/20, Iteration 286/303, Loss: 0.39858484268188477\n",
      "Epoch 9/20, Iteration 287/303, Loss: 0.47762060165405273\n",
      "Epoch 9/20, Iteration 288/303, Loss: 0.3632846772670746\n",
      "Epoch 9/20, Iteration 289/303, Loss: 0.16790571808815002\n",
      "Epoch 9/20, Iteration 290/303, Loss: 0.25164952874183655\n",
      "Epoch 9/20, Iteration 291/303, Loss: 0.25566306710243225\n",
      "Epoch 9/20, Iteration 292/303, Loss: 0.37830278277397156\n",
      "Epoch 9/20, Iteration 293/303, Loss: 0.20896202325820923\n",
      "Epoch 9/20, Iteration 294/303, Loss: 0.408512681722641\n",
      "Epoch 9/20, Iteration 295/303, Loss: 0.27906593680381775\n",
      "Epoch 9/20, Iteration 296/303, Loss: 0.30093294382095337\n",
      "Epoch 9/20, Iteration 297/303, Loss: 0.21157574653625488\n",
      "Epoch 9/20, Iteration 298/303, Loss: 0.15951929986476898\n",
      "Epoch 9/20, Iteration 299/303, Loss: 0.2687331736087799\n",
      "Epoch 9/20, Iteration 300/303, Loss: 0.23695096373558044\n",
      "Epoch 9/20, Iteration 301/303, Loss: 0.22434794902801514\n",
      "Epoch 9/20, Iteration 302/303, Loss: 0.40338751673698425\n",
      "Epoch 9/20, Iteration 303/303, Loss: 0.3130050599575043\n",
      "Epoch 10/20, Iteration 1/303, Loss: 0.20617523789405823\n",
      "Epoch 10/20, Iteration 2/303, Loss: 0.2439209222793579\n",
      "Epoch 10/20, Iteration 3/303, Loss: 0.2265588343143463\n",
      "Epoch 10/20, Iteration 4/303, Loss: 0.1342107206583023\n",
      "Epoch 10/20, Iteration 5/303, Loss: 0.2037317156791687\n",
      "Epoch 10/20, Iteration 6/303, Loss: 0.32489290833473206\n",
      "Epoch 10/20, Iteration 7/303, Loss: 0.38673314452171326\n",
      "Epoch 10/20, Iteration 8/303, Loss: 0.2757883667945862\n",
      "Epoch 10/20, Iteration 9/303, Loss: 0.21601644158363342\n",
      "Epoch 10/20, Iteration 10/303, Loss: 0.29654455184936523\n",
      "Epoch 10/20, Iteration 11/303, Loss: 0.19007548689842224\n",
      "Epoch 10/20, Iteration 12/303, Loss: 0.17307786643505096\n",
      "Epoch 10/20, Iteration 13/303, Loss: 0.3160947561264038\n",
      "Epoch 10/20, Iteration 14/303, Loss: 0.35525140166282654\n",
      "Epoch 10/20, Iteration 15/303, Loss: 0.2934809625148773\n",
      "Epoch 10/20, Iteration 16/303, Loss: 0.24230115115642548\n",
      "Epoch 10/20, Iteration 17/303, Loss: 0.26809218525886536\n",
      "Epoch 10/20, Iteration 18/303, Loss: 0.3028091490268707\n",
      "Epoch 10/20, Iteration 19/303, Loss: 0.21841898560523987\n",
      "Epoch 10/20, Iteration 20/303, Loss: 0.25889015197753906\n",
      "Epoch 10/20, Iteration 21/303, Loss: 0.12856318056583405\n",
      "Epoch 10/20, Iteration 22/303, Loss: 0.1388021856546402\n",
      "Epoch 10/20, Iteration 23/303, Loss: 0.24245312809944153\n",
      "Epoch 10/20, Iteration 24/303, Loss: 0.12760117650032043\n",
      "Epoch 10/20, Iteration 25/303, Loss: 0.21038712561130524\n",
      "Epoch 10/20, Iteration 26/303, Loss: 0.1846940815448761\n",
      "Epoch 10/20, Iteration 27/303, Loss: 0.23025549948215485\n",
      "Epoch 10/20, Iteration 28/303, Loss: 0.2615858018398285\n",
      "Epoch 10/20, Iteration 29/303, Loss: 0.3791786730289459\n",
      "Epoch 10/20, Iteration 30/303, Loss: 0.1408977508544922\n",
      "Epoch 10/20, Iteration 31/303, Loss: 0.1897786259651184\n",
      "Epoch 10/20, Iteration 32/303, Loss: 0.21942679584026337\n",
      "Epoch 10/20, Iteration 33/303, Loss: 0.3192376494407654\n",
      "Epoch 10/20, Iteration 34/303, Loss: 0.17082643508911133\n",
      "Epoch 10/20, Iteration 35/303, Loss: 0.15196926891803741\n",
      "Epoch 10/20, Iteration 36/303, Loss: 0.2545051872730255\n",
      "Epoch 10/20, Iteration 37/303, Loss: 0.14617645740509033\n",
      "Epoch 10/20, Iteration 38/303, Loss: 0.4119705259799957\n",
      "Epoch 10/20, Iteration 39/303, Loss: 0.23637458682060242\n",
      "Epoch 10/20, Iteration 40/303, Loss: 0.2995356619358063\n",
      "Epoch 10/20, Iteration 41/303, Loss: 0.6417403221130371\n",
      "Epoch 10/20, Iteration 42/303, Loss: 0.4867401421070099\n",
      "Epoch 10/20, Iteration 43/303, Loss: 0.30684149265289307\n",
      "Epoch 10/20, Iteration 44/303, Loss: 0.21745461225509644\n",
      "Epoch 10/20, Iteration 45/303, Loss: 0.2385624498128891\n",
      "Epoch 10/20, Iteration 46/303, Loss: 0.17792083323001862\n",
      "Epoch 10/20, Iteration 47/303, Loss: 0.05979941785335541\n",
      "Epoch 10/20, Iteration 48/303, Loss: 0.13711956143379211\n",
      "Epoch 10/20, Iteration 49/303, Loss: 0.16050484776496887\n",
      "Epoch 10/20, Iteration 50/303, Loss: 0.2664472758769989\n",
      "Epoch 10/20, Iteration 51/303, Loss: 0.1638178527355194\n",
      "Epoch 10/20, Iteration 52/303, Loss: 0.25604555010795593\n",
      "Epoch 10/20, Iteration 53/303, Loss: 0.1854018270969391\n",
      "Epoch 10/20, Iteration 54/303, Loss: 0.3457043766975403\n",
      "Epoch 10/20, Iteration 55/303, Loss: 0.34426072239875793\n",
      "Epoch 10/20, Iteration 56/303, Loss: 0.24796703457832336\n",
      "Epoch 10/20, Iteration 57/303, Loss: 0.1426835060119629\n",
      "Epoch 10/20, Iteration 58/303, Loss: 0.3202526271343231\n",
      "Epoch 10/20, Iteration 59/303, Loss: 0.21952782571315765\n",
      "Epoch 10/20, Iteration 60/303, Loss: 0.11490759253501892\n",
      "Epoch 10/20, Iteration 61/303, Loss: 0.14889751374721527\n",
      "Epoch 10/20, Iteration 62/303, Loss: 0.14767712354660034\n",
      "Epoch 10/20, Iteration 63/303, Loss: 0.1155884861946106\n",
      "Epoch 10/20, Iteration 64/303, Loss: 0.22926399111747742\n",
      "Epoch 10/20, Iteration 65/303, Loss: 0.19782817363739014\n",
      "Epoch 10/20, Iteration 66/303, Loss: 0.2813819646835327\n",
      "Epoch 10/20, Iteration 67/303, Loss: 0.3414386510848999\n",
      "Epoch 10/20, Iteration 68/303, Loss: 0.386345237493515\n",
      "Epoch 10/20, Iteration 69/303, Loss: 0.10266444087028503\n",
      "Epoch 10/20, Iteration 70/303, Loss: 0.18186692893505096\n",
      "Epoch 10/20, Iteration 71/303, Loss: 0.11525015532970428\n",
      "Epoch 10/20, Iteration 72/303, Loss: 0.18601849675178528\n",
      "Epoch 10/20, Iteration 73/303, Loss: 0.1244182214140892\n",
      "Epoch 10/20, Iteration 74/303, Loss: 0.29344287514686584\n",
      "Epoch 10/20, Iteration 75/303, Loss: 0.18513935804367065\n",
      "Epoch 10/20, Iteration 76/303, Loss: 0.16752250492572784\n",
      "Epoch 10/20, Iteration 77/303, Loss: 0.6378307342529297\n",
      "Epoch 10/20, Iteration 78/303, Loss: 0.2616104483604431\n",
      "Epoch 10/20, Iteration 79/303, Loss: 0.32249051332473755\n",
      "Epoch 10/20, Iteration 80/303, Loss: 0.3266790509223938\n",
      "Epoch 10/20, Iteration 81/303, Loss: 0.17993780970573425\n",
      "Epoch 10/20, Iteration 82/303, Loss: 0.27619171142578125\n",
      "Epoch 10/20, Iteration 83/303, Loss: 0.2537277340888977\n",
      "Epoch 10/20, Iteration 84/303, Loss: 0.13937179744243622\n",
      "Epoch 10/20, Iteration 85/303, Loss: 0.21669305860996246\n",
      "Epoch 10/20, Iteration 86/303, Loss: 0.24656127393245697\n",
      "Epoch 10/20, Iteration 87/303, Loss: 0.24176904559135437\n",
      "Epoch 10/20, Iteration 88/303, Loss: 0.2602424919605255\n",
      "Epoch 10/20, Iteration 89/303, Loss: 0.15404775738716125\n",
      "Epoch 10/20, Iteration 90/303, Loss: 0.19388584792613983\n",
      "Epoch 10/20, Iteration 91/303, Loss: 0.3541039228439331\n",
      "Epoch 10/20, Iteration 92/303, Loss: 0.1325927972793579\n",
      "Epoch 10/20, Iteration 93/303, Loss: 0.3921465575695038\n",
      "Epoch 10/20, Iteration 94/303, Loss: 0.15128494799137115\n",
      "Epoch 10/20, Iteration 95/303, Loss: 0.19102789461612701\n",
      "Epoch 10/20, Iteration 96/303, Loss: 0.3287721276283264\n",
      "Epoch 10/20, Iteration 97/303, Loss: 0.21004840731620789\n",
      "Epoch 10/20, Iteration 98/303, Loss: 0.22780771553516388\n",
      "Epoch 10/20, Iteration 99/303, Loss: 0.12378128618001938\n",
      "Epoch 10/20, Iteration 100/303, Loss: 0.32397934794425964\n",
      "Epoch 10/20, Iteration 101/303, Loss: 0.08095017075538635\n",
      "Epoch 10/20, Iteration 102/303, Loss: 0.09929269552230835\n",
      "Epoch 10/20, Iteration 103/303, Loss: 0.2305668294429779\n",
      "Epoch 10/20, Iteration 104/303, Loss: 0.643690824508667\n",
      "Epoch 10/20, Iteration 105/303, Loss: 0.23874573409557343\n",
      "Epoch 10/20, Iteration 106/303, Loss: 0.29636287689208984\n",
      "Epoch 10/20, Iteration 107/303, Loss: 0.3787514269351959\n",
      "Epoch 10/20, Iteration 108/303, Loss: 0.26689133048057556\n",
      "Epoch 10/20, Iteration 109/303, Loss: 0.25550827383995056\n",
      "Epoch 10/20, Iteration 110/303, Loss: 0.18928377330303192\n",
      "Epoch 10/20, Iteration 111/303, Loss: 0.3065760135650635\n",
      "Epoch 10/20, Iteration 112/303, Loss: 0.22991831600666046\n",
      "Epoch 10/20, Iteration 113/303, Loss: 0.17714130878448486\n",
      "Epoch 10/20, Iteration 114/303, Loss: 0.18932843208312988\n",
      "Epoch 10/20, Iteration 115/303, Loss: 0.11571498215198517\n",
      "Epoch 10/20, Iteration 116/303, Loss: 0.3584979176521301\n",
      "Epoch 10/20, Iteration 117/303, Loss: 0.16216300427913666\n",
      "Epoch 10/20, Iteration 118/303, Loss: 0.2350982427597046\n",
      "Epoch 10/20, Iteration 119/303, Loss: 0.11833243072032928\n",
      "Epoch 10/20, Iteration 120/303, Loss: 0.2125253975391388\n",
      "Epoch 10/20, Iteration 121/303, Loss: 0.41082578897476196\n",
      "Epoch 10/20, Iteration 122/303, Loss: 0.10643551498651505\n",
      "Epoch 10/20, Iteration 123/303, Loss: 0.2465934157371521\n",
      "Epoch 10/20, Iteration 124/303, Loss: 0.22406728565692902\n",
      "Epoch 10/20, Iteration 125/303, Loss: 0.38661786913871765\n",
      "Epoch 10/20, Iteration 126/303, Loss: 0.2043742835521698\n",
      "Epoch 10/20, Iteration 127/303, Loss: 0.23453477025032043\n",
      "Epoch 10/20, Iteration 128/303, Loss: 0.45300132036209106\n",
      "Epoch 10/20, Iteration 129/303, Loss: 0.36871573328971863\n",
      "Epoch 10/20, Iteration 130/303, Loss: 0.20189207792282104\n",
      "Epoch 10/20, Iteration 131/303, Loss: 0.133414164185524\n",
      "Epoch 10/20, Iteration 132/303, Loss: 0.2719499170780182\n",
      "Epoch 10/20, Iteration 133/303, Loss: 0.15150469541549683\n",
      "Epoch 10/20, Iteration 134/303, Loss: 0.21741515398025513\n",
      "Epoch 10/20, Iteration 135/303, Loss: 0.2542135417461395\n",
      "Epoch 10/20, Iteration 136/303, Loss: 0.39738354086875916\n",
      "Epoch 10/20, Iteration 137/303, Loss: 0.3680917024612427\n",
      "Epoch 10/20, Iteration 138/303, Loss: 0.33261001110076904\n",
      "Epoch 10/20, Iteration 139/303, Loss: 0.12786298990249634\n",
      "Epoch 10/20, Iteration 140/303, Loss: 0.1624612957239151\n",
      "Epoch 10/20, Iteration 141/303, Loss: 0.21621309220790863\n",
      "Epoch 10/20, Iteration 142/303, Loss: 0.12368730455636978\n",
      "Epoch 10/20, Iteration 143/303, Loss: 0.3601415157318115\n",
      "Epoch 10/20, Iteration 144/303, Loss: 0.3447614908218384\n",
      "Epoch 10/20, Iteration 145/303, Loss: 0.1832728087902069\n",
      "Epoch 10/20, Iteration 146/303, Loss: 0.17244133353233337\n",
      "Epoch 10/20, Iteration 147/303, Loss: 0.2238181233406067\n",
      "Epoch 10/20, Iteration 148/303, Loss: 0.3964134454727173\n",
      "Epoch 10/20, Iteration 149/303, Loss: 0.36298656463623047\n",
      "Epoch 10/20, Iteration 150/303, Loss: 0.24817971885204315\n",
      "Epoch 10/20, Iteration 151/303, Loss: 0.2944522500038147\n",
      "Epoch 10/20, Iteration 152/303, Loss: 0.1251901388168335\n",
      "Epoch 10/20, Iteration 153/303, Loss: 0.21400666236877441\n",
      "Epoch 10/20, Iteration 154/303, Loss: 0.3339161276817322\n",
      "Epoch 10/20, Iteration 155/303, Loss: 0.31698477268218994\n",
      "Epoch 10/20, Iteration 156/303, Loss: 0.5421689748764038\n",
      "Epoch 10/20, Iteration 157/303, Loss: 0.3730792701244354\n",
      "Epoch 10/20, Iteration 158/303, Loss: 0.40688756108283997\n",
      "Epoch 10/20, Iteration 159/303, Loss: 0.11718596518039703\n",
      "Epoch 10/20, Iteration 160/303, Loss: 0.5421985387802124\n",
      "Epoch 10/20, Iteration 161/303, Loss: 0.22055679559707642\n",
      "Epoch 10/20, Iteration 162/303, Loss: 0.2548182010650635\n",
      "Epoch 10/20, Iteration 163/303, Loss: 0.3024737536907196\n",
      "Epoch 10/20, Iteration 164/303, Loss: 0.21190838515758514\n",
      "Epoch 10/20, Iteration 165/303, Loss: 0.3308311402797699\n",
      "Epoch 10/20, Iteration 166/303, Loss: 0.24344652891159058\n",
      "Epoch 10/20, Iteration 167/303, Loss: 0.32919102907180786\n",
      "Epoch 10/20, Iteration 168/303, Loss: 0.2149977833032608\n",
      "Epoch 10/20, Iteration 169/303, Loss: 0.25321319699287415\n",
      "Epoch 10/20, Iteration 170/303, Loss: 0.25917574763298035\n",
      "Epoch 10/20, Iteration 171/303, Loss: 0.25946715474128723\n",
      "Epoch 10/20, Iteration 172/303, Loss: 0.12604250013828278\n",
      "Epoch 10/20, Iteration 173/303, Loss: 0.4855663478374481\n",
      "Epoch 10/20, Iteration 174/303, Loss: 0.17351873219013214\n",
      "Epoch 10/20, Iteration 175/303, Loss: 0.20887865126132965\n",
      "Epoch 10/20, Iteration 176/303, Loss: 0.284748911857605\n",
      "Epoch 10/20, Iteration 177/303, Loss: 0.32517969608306885\n",
      "Epoch 10/20, Iteration 178/303, Loss: 0.3532167673110962\n",
      "Epoch 10/20, Iteration 179/303, Loss: 0.16553831100463867\n",
      "Epoch 10/20, Iteration 180/303, Loss: 0.31976959109306335\n",
      "Epoch 10/20, Iteration 181/303, Loss: 0.21548233926296234\n",
      "Epoch 10/20, Iteration 182/303, Loss: 0.2795184254646301\n",
      "Epoch 10/20, Iteration 183/303, Loss: 0.26856303215026855\n",
      "Epoch 10/20, Iteration 184/303, Loss: 0.30663666129112244\n",
      "Epoch 10/20, Iteration 185/303, Loss: 0.25894445180892944\n",
      "Epoch 10/20, Iteration 186/303, Loss: 0.4493262767791748\n",
      "Epoch 10/20, Iteration 187/303, Loss: 0.2284390777349472\n",
      "Epoch 10/20, Iteration 188/303, Loss: 0.21619395911693573\n",
      "Epoch 10/20, Iteration 189/303, Loss: 0.40225672721862793\n",
      "Epoch 10/20, Iteration 190/303, Loss: 0.28798502683639526\n",
      "Epoch 10/20, Iteration 191/303, Loss: 0.18928521871566772\n",
      "Epoch 10/20, Iteration 192/303, Loss: 0.20806987583637238\n",
      "Epoch 10/20, Iteration 193/303, Loss: 0.36964115500450134\n",
      "Epoch 10/20, Iteration 194/303, Loss: 0.1752043068408966\n",
      "Epoch 10/20, Iteration 195/303, Loss: 0.1437571793794632\n",
      "Epoch 10/20, Iteration 196/303, Loss: 0.15539386868476868\n",
      "Epoch 10/20, Iteration 197/303, Loss: 0.3195047378540039\n",
      "Epoch 10/20, Iteration 198/303, Loss: 0.3860834836959839\n",
      "Epoch 10/20, Iteration 199/303, Loss: 0.23488211631774902\n",
      "Epoch 10/20, Iteration 200/303, Loss: 0.2637386620044708\n",
      "Epoch 10/20, Iteration 201/303, Loss: 0.1841503381729126\n",
      "Epoch 10/20, Iteration 202/303, Loss: 0.3156062960624695\n",
      "Epoch 10/20, Iteration 203/303, Loss: 0.12396412342786789\n",
      "Epoch 10/20, Iteration 204/303, Loss: 0.2664315104484558\n",
      "Epoch 10/20, Iteration 205/303, Loss: 0.19774684309959412\n",
      "Epoch 10/20, Iteration 206/303, Loss: 0.30446428060531616\n",
      "Epoch 10/20, Iteration 207/303, Loss: 0.09191255271434784\n",
      "Epoch 10/20, Iteration 208/303, Loss: 0.1950804740190506\n",
      "Epoch 10/20, Iteration 209/303, Loss: 0.17216002941131592\n",
      "Epoch 10/20, Iteration 210/303, Loss: 0.2882665693759918\n",
      "Epoch 10/20, Iteration 211/303, Loss: 0.23418627679347992\n",
      "Epoch 10/20, Iteration 212/303, Loss: 0.20313426852226257\n",
      "Epoch 10/20, Iteration 213/303, Loss: 0.2523747980594635\n",
      "Epoch 10/20, Iteration 214/303, Loss: 0.3053179383277893\n",
      "Epoch 10/20, Iteration 215/303, Loss: 0.22660429775714874\n",
      "Epoch 10/20, Iteration 216/303, Loss: 0.307503879070282\n",
      "Epoch 10/20, Iteration 217/303, Loss: 0.2533608376979828\n",
      "Epoch 10/20, Iteration 218/303, Loss: 0.23140163719654083\n",
      "Epoch 10/20, Iteration 219/303, Loss: 0.10815796256065369\n",
      "Epoch 10/20, Iteration 220/303, Loss: 0.28887829184532166\n",
      "Epoch 10/20, Iteration 221/303, Loss: 0.32863789796829224\n",
      "Epoch 10/20, Iteration 222/303, Loss: 0.07489550858736038\n",
      "Epoch 10/20, Iteration 223/303, Loss: 0.3117731809616089\n",
      "Epoch 10/20, Iteration 224/303, Loss: 0.5317696332931519\n",
      "Epoch 10/20, Iteration 225/303, Loss: 0.29388007521629333\n",
      "Epoch 10/20, Iteration 226/303, Loss: 0.24482285976409912\n",
      "Epoch 10/20, Iteration 227/303, Loss: 0.14205801486968994\n",
      "Epoch 10/20, Iteration 228/303, Loss: 0.08401608467102051\n",
      "Epoch 10/20, Iteration 229/303, Loss: 0.14485402405261993\n",
      "Epoch 10/20, Iteration 230/303, Loss: 0.34526753425598145\n",
      "Epoch 10/20, Iteration 231/303, Loss: 0.2310296893119812\n",
      "Epoch 10/20, Iteration 232/303, Loss: 0.20731979608535767\n",
      "Epoch 10/20, Iteration 233/303, Loss: 0.5115074515342712\n",
      "Epoch 10/20, Iteration 234/303, Loss: 0.3201819658279419\n",
      "Epoch 10/20, Iteration 235/303, Loss: 0.26522091031074524\n",
      "Epoch 10/20, Iteration 236/303, Loss: 0.2116239219903946\n",
      "Epoch 10/20, Iteration 237/303, Loss: 0.21672800183296204\n",
      "Epoch 10/20, Iteration 238/303, Loss: 0.17593519389629364\n",
      "Epoch 10/20, Iteration 239/303, Loss: 0.22157512605190277\n",
      "Epoch 10/20, Iteration 240/303, Loss: 0.3039318323135376\n",
      "Epoch 10/20, Iteration 241/303, Loss: 0.33080339431762695\n",
      "Epoch 10/20, Iteration 242/303, Loss: 0.1950400173664093\n",
      "Epoch 10/20, Iteration 243/303, Loss: 0.21085503697395325\n",
      "Epoch 10/20, Iteration 244/303, Loss: 0.30414465069770813\n",
      "Epoch 10/20, Iteration 245/303, Loss: 0.2008236050605774\n",
      "Epoch 10/20, Iteration 246/303, Loss: 0.1442457139492035\n",
      "Epoch 10/20, Iteration 247/303, Loss: 0.23049847781658173\n",
      "Epoch 10/20, Iteration 248/303, Loss: 0.2940995693206787\n",
      "Epoch 10/20, Iteration 249/303, Loss: 0.2905801832675934\n",
      "Epoch 10/20, Iteration 250/303, Loss: 0.15917350351810455\n",
      "Epoch 10/20, Iteration 251/303, Loss: 0.22400599718093872\n",
      "Epoch 10/20, Iteration 252/303, Loss: 0.34254831075668335\n",
      "Epoch 10/20, Iteration 253/303, Loss: 0.22772251069545746\n",
      "Epoch 10/20, Iteration 254/303, Loss: 0.17514453828334808\n",
      "Epoch 10/20, Iteration 255/303, Loss: 0.2282802015542984\n",
      "Epoch 10/20, Iteration 256/303, Loss: 0.2081359326839447\n",
      "Epoch 10/20, Iteration 257/303, Loss: 0.11584050208330154\n",
      "Epoch 10/20, Iteration 258/303, Loss: 0.1296202540397644\n",
      "Epoch 10/20, Iteration 259/303, Loss: 0.20227283239364624\n",
      "Epoch 10/20, Iteration 260/303, Loss: 0.18678611516952515\n",
      "Epoch 10/20, Iteration 261/303, Loss: 0.4492778480052948\n",
      "Epoch 10/20, Iteration 262/303, Loss: 0.17068982124328613\n",
      "Epoch 10/20, Iteration 263/303, Loss: 0.20504987239837646\n",
      "Epoch 10/20, Iteration 264/303, Loss: 0.2245027869939804\n",
      "Epoch 10/20, Iteration 265/303, Loss: 0.560612678527832\n",
      "Epoch 10/20, Iteration 266/303, Loss: 0.7015655636787415\n",
      "Epoch 10/20, Iteration 267/303, Loss: 0.26023614406585693\n",
      "Epoch 10/20, Iteration 268/303, Loss: 0.24977999925613403\n",
      "Epoch 10/20, Iteration 269/303, Loss: 0.2746725082397461\n",
      "Epoch 10/20, Iteration 270/303, Loss: 0.3144140839576721\n",
      "Epoch 10/20, Iteration 271/303, Loss: 0.29532426595687866\n",
      "Epoch 10/20, Iteration 272/303, Loss: 0.32080158591270447\n",
      "Epoch 10/20, Iteration 273/303, Loss: 0.37474796175956726\n",
      "Epoch 10/20, Iteration 274/303, Loss: 0.16342109441757202\n",
      "Epoch 10/20, Iteration 275/303, Loss: 0.13741064071655273\n",
      "Epoch 10/20, Iteration 276/303, Loss: 0.2666381895542145\n",
      "Epoch 10/20, Iteration 277/303, Loss: 0.5231606364250183\n",
      "Epoch 10/20, Iteration 278/303, Loss: 0.4559018909931183\n",
      "Epoch 10/20, Iteration 279/303, Loss: 0.25501763820648193\n",
      "Epoch 10/20, Iteration 280/303, Loss: 0.20988604426383972\n",
      "Epoch 10/20, Iteration 281/303, Loss: 0.3932535946369171\n",
      "Epoch 10/20, Iteration 282/303, Loss: 0.2535760700702667\n",
      "Epoch 10/20, Iteration 283/303, Loss: 0.3583955466747284\n",
      "Epoch 10/20, Iteration 284/303, Loss: 0.18859386444091797\n",
      "Epoch 10/20, Iteration 285/303, Loss: 0.2751818299293518\n",
      "Epoch 10/20, Iteration 286/303, Loss: 0.23465611040592194\n",
      "Epoch 10/20, Iteration 287/303, Loss: 0.2605977952480316\n",
      "Epoch 10/20, Iteration 288/303, Loss: 0.19598650932312012\n",
      "Epoch 10/20, Iteration 289/303, Loss: 0.15431062877178192\n",
      "Epoch 10/20, Iteration 290/303, Loss: 0.16923034191131592\n",
      "Epoch 10/20, Iteration 291/303, Loss: 0.2095608413219452\n",
      "Epoch 10/20, Iteration 292/303, Loss: 0.28690141439437866\n",
      "Epoch 10/20, Iteration 293/303, Loss: 0.40022966265678406\n",
      "Epoch 10/20, Iteration 294/303, Loss: 0.294350802898407\n",
      "Epoch 10/20, Iteration 295/303, Loss: 0.3564729392528534\n",
      "Epoch 10/20, Iteration 296/303, Loss: 0.12303326278924942\n",
      "Epoch 10/20, Iteration 297/303, Loss: 0.3713316321372986\n",
      "Epoch 10/20, Iteration 298/303, Loss: 0.1824558526277542\n",
      "Epoch 10/20, Iteration 299/303, Loss: 0.1692054122686386\n",
      "Epoch 10/20, Iteration 300/303, Loss: 0.13788025081157684\n",
      "Epoch 10/20, Iteration 301/303, Loss: 0.1661045402288437\n",
      "Epoch 10/20, Iteration 302/303, Loss: 0.30356892943382263\n",
      "Epoch 10/20, Iteration 303/303, Loss: 0.2797394096851349\n",
      "Epoch 11/20, Iteration 1/303, Loss: 0.16403540968894958\n",
      "Epoch 11/20, Iteration 2/303, Loss: 0.11748149245977402\n",
      "Epoch 11/20, Iteration 3/303, Loss: 0.39947667717933655\n",
      "Epoch 11/20, Iteration 4/303, Loss: 0.28034067153930664\n",
      "Epoch 11/20, Iteration 5/303, Loss: 0.2714959383010864\n",
      "Epoch 11/20, Iteration 6/303, Loss: 0.14359647035598755\n",
      "Epoch 11/20, Iteration 7/303, Loss: 0.2132112681865692\n",
      "Epoch 11/20, Iteration 8/303, Loss: 0.07822825014591217\n",
      "Epoch 11/20, Iteration 9/303, Loss: 0.11087257415056229\n",
      "Epoch 11/20, Iteration 10/303, Loss: 0.1299796849489212\n",
      "Epoch 11/20, Iteration 11/303, Loss: 0.13094069063663483\n",
      "Epoch 11/20, Iteration 12/303, Loss: 0.16807635128498077\n",
      "Epoch 11/20, Iteration 13/303, Loss: 0.09585447609424591\n",
      "Epoch 11/20, Iteration 14/303, Loss: 0.17764313519001007\n",
      "Epoch 11/20, Iteration 15/303, Loss: 0.27905702590942383\n",
      "Epoch 11/20, Iteration 16/303, Loss: 0.2207115739583969\n",
      "Epoch 11/20, Iteration 17/303, Loss: 0.188926562666893\n",
      "Epoch 11/20, Iteration 18/303, Loss: 0.1675606667995453\n",
      "Epoch 11/20, Iteration 19/303, Loss: 0.2396240234375\n",
      "Epoch 11/20, Iteration 20/303, Loss: 0.23749199509620667\n",
      "Epoch 11/20, Iteration 21/303, Loss: 0.3099779784679413\n",
      "Epoch 11/20, Iteration 22/303, Loss: 0.2180667668581009\n",
      "Epoch 11/20, Iteration 23/303, Loss: 0.15882132947444916\n",
      "Epoch 11/20, Iteration 24/303, Loss: 0.20549312233924866\n",
      "Epoch 11/20, Iteration 25/303, Loss: 0.14087724685668945\n",
      "Epoch 11/20, Iteration 26/303, Loss: 0.19237163662910461\n",
      "Epoch 11/20, Iteration 27/303, Loss: 0.13776588439941406\n",
      "Epoch 11/20, Iteration 28/303, Loss: 0.23089437186717987\n",
      "Epoch 11/20, Iteration 29/303, Loss: 0.31433242559432983\n",
      "Epoch 11/20, Iteration 30/303, Loss: 0.1552208662033081\n",
      "Epoch 11/20, Iteration 31/303, Loss: 0.16683542728424072\n",
      "Epoch 11/20, Iteration 32/303, Loss: 0.40225479006767273\n",
      "Epoch 11/20, Iteration 33/303, Loss: 0.28105413913726807\n",
      "Epoch 11/20, Iteration 34/303, Loss: 0.19349130988121033\n",
      "Epoch 11/20, Iteration 35/303, Loss: 0.11588159203529358\n",
      "Epoch 11/20, Iteration 36/303, Loss: 0.14024066925048828\n",
      "Epoch 11/20, Iteration 37/303, Loss: 0.31918349862098694\n",
      "Epoch 11/20, Iteration 38/303, Loss: 0.19309574365615845\n",
      "Epoch 11/20, Iteration 39/303, Loss: 0.25377511978149414\n",
      "Epoch 11/20, Iteration 40/303, Loss: 0.46451035141944885\n",
      "Epoch 11/20, Iteration 41/303, Loss: 0.27846425771713257\n",
      "Epoch 11/20, Iteration 42/303, Loss: 0.2663605809211731\n",
      "Epoch 11/20, Iteration 43/303, Loss: 0.2069297581911087\n",
      "Epoch 11/20, Iteration 44/303, Loss: 0.16957059502601624\n",
      "Epoch 11/20, Iteration 45/303, Loss: 0.22206424176692963\n",
      "Epoch 11/20, Iteration 46/303, Loss: 0.14241839945316315\n",
      "Epoch 11/20, Iteration 47/303, Loss: 0.2083703577518463\n",
      "Epoch 11/20, Iteration 48/303, Loss: 0.17130377888679504\n",
      "Epoch 11/20, Iteration 49/303, Loss: 0.17827486991882324\n",
      "Epoch 11/20, Iteration 50/303, Loss: 0.41815587878227234\n",
      "Epoch 11/20, Iteration 51/303, Loss: 0.4006968140602112\n",
      "Epoch 11/20, Iteration 52/303, Loss: 0.1507672667503357\n",
      "Epoch 11/20, Iteration 53/303, Loss: 0.15181821584701538\n",
      "Epoch 11/20, Iteration 54/303, Loss: 0.12913253903388977\n",
      "Epoch 11/20, Iteration 55/303, Loss: 0.10515590012073517\n",
      "Epoch 11/20, Iteration 56/303, Loss: 0.29455479979515076\n",
      "Epoch 11/20, Iteration 57/303, Loss: 0.17500664293766022\n",
      "Epoch 11/20, Iteration 58/303, Loss: 0.09786585718393326\n",
      "Epoch 11/20, Iteration 59/303, Loss: 0.1958645135164261\n",
      "Epoch 11/20, Iteration 60/303, Loss: 0.1375589817762375\n",
      "Epoch 11/20, Iteration 61/303, Loss: 0.3027375340461731\n",
      "Epoch 11/20, Iteration 62/303, Loss: 0.3064729869365692\n",
      "Epoch 11/20, Iteration 63/303, Loss: 0.1873263120651245\n",
      "Epoch 11/20, Iteration 64/303, Loss: 0.0884660929441452\n",
      "Epoch 11/20, Iteration 65/303, Loss: 0.08632609993219376\n",
      "Epoch 11/20, Iteration 66/303, Loss: 0.05484112352132797\n",
      "Epoch 11/20, Iteration 67/303, Loss: 0.21921542286872864\n",
      "Epoch 11/20, Iteration 68/303, Loss: 0.2136894315481186\n",
      "Epoch 11/20, Iteration 69/303, Loss: 0.15243764221668243\n",
      "Epoch 11/20, Iteration 70/303, Loss: 0.17014481127262115\n",
      "Epoch 11/20, Iteration 71/303, Loss: 0.16731467843055725\n",
      "Epoch 11/20, Iteration 72/303, Loss: 0.30999094247817993\n",
      "Epoch 11/20, Iteration 73/303, Loss: 0.11839330196380615\n",
      "Epoch 11/20, Iteration 74/303, Loss: 0.2011052966117859\n",
      "Epoch 11/20, Iteration 75/303, Loss: 0.14966332912445068\n",
      "Epoch 11/20, Iteration 76/303, Loss: 0.19384080171585083\n",
      "Epoch 11/20, Iteration 77/303, Loss: 0.1343104988336563\n",
      "Epoch 11/20, Iteration 78/303, Loss: 0.4164998531341553\n",
      "Epoch 11/20, Iteration 79/303, Loss: 0.18525078892707825\n",
      "Epoch 11/20, Iteration 80/303, Loss: 0.17654363811016083\n",
      "Epoch 11/20, Iteration 81/303, Loss: 0.17017094790935516\n",
      "Epoch 11/20, Iteration 82/303, Loss: 0.1881410777568817\n",
      "Epoch 11/20, Iteration 83/303, Loss: 0.24435089528560638\n",
      "Epoch 11/20, Iteration 84/303, Loss: 0.17926771938800812\n",
      "Epoch 11/20, Iteration 85/303, Loss: 0.29863303899765015\n",
      "Epoch 11/20, Iteration 86/303, Loss: 0.2268870323896408\n",
      "Epoch 11/20, Iteration 87/303, Loss: 0.11904703080654144\n",
      "Epoch 11/20, Iteration 88/303, Loss: 0.16049601137638092\n",
      "Epoch 11/20, Iteration 89/303, Loss: 0.24931225180625916\n",
      "Epoch 11/20, Iteration 90/303, Loss: 0.27454376220703125\n",
      "Epoch 11/20, Iteration 91/303, Loss: 0.1978149563074112\n",
      "Epoch 11/20, Iteration 92/303, Loss: 0.34914714097976685\n",
      "Epoch 11/20, Iteration 93/303, Loss: 0.08791812509298325\n",
      "Epoch 11/20, Iteration 94/303, Loss: 0.21197491884231567\n",
      "Epoch 11/20, Iteration 95/303, Loss: 0.23655816912651062\n",
      "Epoch 11/20, Iteration 96/303, Loss: 0.20659466087818146\n",
      "Epoch 11/20, Iteration 97/303, Loss: 0.15074802935123444\n",
      "Epoch 11/20, Iteration 98/303, Loss: 0.18317098915576935\n",
      "Epoch 11/20, Iteration 99/303, Loss: 0.07577921450138092\n",
      "Epoch 11/20, Iteration 100/303, Loss: 0.1553516834974289\n",
      "Epoch 11/20, Iteration 101/303, Loss: 0.22337472438812256\n",
      "Epoch 11/20, Iteration 102/303, Loss: 0.19651520252227783\n",
      "Epoch 11/20, Iteration 103/303, Loss: 0.23041749000549316\n",
      "Epoch 11/20, Iteration 104/303, Loss: 0.11224132776260376\n",
      "Epoch 11/20, Iteration 105/303, Loss: 0.2696249186992645\n",
      "Epoch 11/20, Iteration 106/303, Loss: 0.2981489896774292\n",
      "Epoch 11/20, Iteration 107/303, Loss: 0.22818775475025177\n",
      "Epoch 11/20, Iteration 108/303, Loss: 0.21244065463542938\n",
      "Epoch 11/20, Iteration 109/303, Loss: 0.2146535962820053\n",
      "Epoch 11/20, Iteration 110/303, Loss: 0.14152544736862183\n",
      "Epoch 11/20, Iteration 111/303, Loss: 0.19217945635318756\n",
      "Epoch 11/20, Iteration 112/303, Loss: 0.1885075718164444\n",
      "Epoch 11/20, Iteration 113/303, Loss: 0.09197192639112473\n",
      "Epoch 11/20, Iteration 114/303, Loss: 0.12059877067804337\n",
      "Epoch 11/20, Iteration 115/303, Loss: 0.1639687567949295\n",
      "Epoch 11/20, Iteration 116/303, Loss: 0.23447418212890625\n",
      "Epoch 11/20, Iteration 117/303, Loss: 0.1428929567337036\n",
      "Epoch 11/20, Iteration 118/303, Loss: 0.17071141302585602\n",
      "Epoch 11/20, Iteration 119/303, Loss: 0.17552819848060608\n",
      "Epoch 11/20, Iteration 120/303, Loss: 0.37891024351119995\n",
      "Epoch 11/20, Iteration 121/303, Loss: 0.15657858550548553\n",
      "Epoch 11/20, Iteration 122/303, Loss: 0.13441403210163116\n",
      "Epoch 11/20, Iteration 123/303, Loss: 0.214109867811203\n",
      "Epoch 11/20, Iteration 124/303, Loss: 0.14923378825187683\n",
      "Epoch 11/20, Iteration 125/303, Loss: 0.14929287135601044\n",
      "Epoch 11/20, Iteration 126/303, Loss: 0.43530428409576416\n",
      "Epoch 11/20, Iteration 127/303, Loss: 0.3775971531867981\n",
      "Epoch 11/20, Iteration 128/303, Loss: 0.256490021944046\n",
      "Epoch 11/20, Iteration 129/303, Loss: 0.17454057931900024\n",
      "Epoch 11/20, Iteration 130/303, Loss: 0.3142884373664856\n",
      "Epoch 11/20, Iteration 131/303, Loss: 0.40417397022247314\n",
      "Epoch 11/20, Iteration 132/303, Loss: 0.3478286862373352\n",
      "Epoch 11/20, Iteration 133/303, Loss: 0.4856387674808502\n",
      "Epoch 11/20, Iteration 134/303, Loss: 0.15900209546089172\n",
      "Epoch 11/20, Iteration 135/303, Loss: 0.1358272284269333\n",
      "Epoch 11/20, Iteration 136/303, Loss: 0.1878175586462021\n",
      "Epoch 11/20, Iteration 137/303, Loss: 0.2071925699710846\n",
      "Epoch 11/20, Iteration 138/303, Loss: 0.28880125284194946\n",
      "Epoch 11/20, Iteration 139/303, Loss: 0.17806099355220795\n",
      "Epoch 11/20, Iteration 140/303, Loss: 0.20056022703647614\n",
      "Epoch 11/20, Iteration 141/303, Loss: 0.3077172040939331\n",
      "Epoch 11/20, Iteration 142/303, Loss: 0.13260550796985626\n",
      "Epoch 11/20, Iteration 143/303, Loss: 0.18383058905601501\n",
      "Epoch 11/20, Iteration 144/303, Loss: 0.267429381608963\n",
      "Epoch 11/20, Iteration 145/303, Loss: 0.14710330963134766\n",
      "Epoch 11/20, Iteration 146/303, Loss: 0.14727531373500824\n",
      "Epoch 11/20, Iteration 147/303, Loss: 0.1484626978635788\n",
      "Epoch 11/20, Iteration 148/303, Loss: 0.10065966844558716\n",
      "Epoch 11/20, Iteration 149/303, Loss: 0.18947429955005646\n",
      "Epoch 11/20, Iteration 150/303, Loss: 0.4254201352596283\n",
      "Epoch 11/20, Iteration 151/303, Loss: 0.47278720140457153\n",
      "Epoch 11/20, Iteration 152/303, Loss: 0.4295670688152313\n",
      "Epoch 11/20, Iteration 153/303, Loss: 0.14040416479110718\n",
      "Epoch 11/20, Iteration 154/303, Loss: 0.5792530179023743\n",
      "Epoch 11/20, Iteration 155/303, Loss: 0.12311983853578568\n",
      "Epoch 11/20, Iteration 156/303, Loss: 0.28022459149360657\n",
      "Epoch 11/20, Iteration 157/303, Loss: 0.23272614181041718\n",
      "Epoch 11/20, Iteration 158/303, Loss: 0.24538032710552216\n",
      "Epoch 11/20, Iteration 159/303, Loss: 0.2775006890296936\n",
      "Epoch 11/20, Iteration 160/303, Loss: 0.26565513014793396\n",
      "Epoch 11/20, Iteration 161/303, Loss: 0.09220591932535172\n",
      "Epoch 11/20, Iteration 162/303, Loss: 0.1836392879486084\n",
      "Epoch 11/20, Iteration 163/303, Loss: 0.44682741165161133\n",
      "Epoch 11/20, Iteration 164/303, Loss: 0.2687684893608093\n",
      "Epoch 11/20, Iteration 165/303, Loss: 0.20981451869010925\n",
      "Epoch 11/20, Iteration 166/303, Loss: 0.18954700231552124\n",
      "Epoch 11/20, Iteration 167/303, Loss: 0.26889050006866455\n",
      "Epoch 11/20, Iteration 168/303, Loss: 0.0922362357378006\n",
      "Epoch 11/20, Iteration 169/303, Loss: 0.2758053243160248\n",
      "Epoch 11/20, Iteration 170/303, Loss: 0.3142966032028198\n",
      "Epoch 11/20, Iteration 171/303, Loss: 0.11446204036474228\n",
      "Epoch 11/20, Iteration 172/303, Loss: 0.26010099053382874\n",
      "Epoch 11/20, Iteration 173/303, Loss: 0.21040235459804535\n",
      "Epoch 11/20, Iteration 174/303, Loss: 0.23221534490585327\n",
      "Epoch 11/20, Iteration 175/303, Loss: 0.24710693955421448\n",
      "Epoch 11/20, Iteration 176/303, Loss: 0.23693467676639557\n",
      "Epoch 11/20, Iteration 177/303, Loss: 0.2430105358362198\n",
      "Epoch 11/20, Iteration 178/303, Loss: 0.28549960255622864\n",
      "Epoch 11/20, Iteration 179/303, Loss: 0.12651951611042023\n",
      "Epoch 11/20, Iteration 180/303, Loss: 0.23455193638801575\n",
      "Epoch 11/20, Iteration 181/303, Loss: 0.172593355178833\n",
      "Epoch 11/20, Iteration 182/303, Loss: 0.18104471266269684\n",
      "Epoch 11/20, Iteration 183/303, Loss: 0.23388715088367462\n",
      "Epoch 11/20, Iteration 184/303, Loss: 0.17704351246356964\n",
      "Epoch 11/20, Iteration 185/303, Loss: 0.3101865351200104\n",
      "Epoch 11/20, Iteration 186/303, Loss: 0.3180185556411743\n",
      "Epoch 11/20, Iteration 187/303, Loss: 0.322538822889328\n",
      "Epoch 11/20, Iteration 188/303, Loss: 0.18953940272331238\n",
      "Epoch 11/20, Iteration 189/303, Loss: 0.14068686962127686\n",
      "Epoch 11/20, Iteration 190/303, Loss: 0.18524445593357086\n",
      "Epoch 11/20, Iteration 191/303, Loss: 0.15358158946037292\n",
      "Epoch 11/20, Iteration 192/303, Loss: 0.2074236273765564\n",
      "Epoch 11/20, Iteration 193/303, Loss: 0.09073424339294434\n",
      "Epoch 11/20, Iteration 194/303, Loss: 0.231638565659523\n",
      "Epoch 11/20, Iteration 195/303, Loss: 0.20029188692569733\n",
      "Epoch 11/20, Iteration 196/303, Loss: 0.27036917209625244\n",
      "Epoch 11/20, Iteration 197/303, Loss: 0.19564108550548553\n",
      "Epoch 11/20, Iteration 198/303, Loss: 0.35610315203666687\n",
      "Epoch 11/20, Iteration 199/303, Loss: 0.3325924277305603\n",
      "Epoch 11/20, Iteration 200/303, Loss: 0.3037622570991516\n",
      "Epoch 11/20, Iteration 201/303, Loss: 0.2400021255016327\n",
      "Epoch 11/20, Iteration 202/303, Loss: 0.30575859546661377\n",
      "Epoch 11/20, Iteration 203/303, Loss: 0.13764017820358276\n",
      "Epoch 11/20, Iteration 204/303, Loss: 0.22397145628929138\n",
      "Epoch 11/20, Iteration 205/303, Loss: 0.18287119269371033\n",
      "Epoch 11/20, Iteration 206/303, Loss: 0.23570838570594788\n",
      "Epoch 11/20, Iteration 207/303, Loss: 0.23859037458896637\n",
      "Epoch 11/20, Iteration 208/303, Loss: 0.19493278861045837\n",
      "Epoch 11/20, Iteration 209/303, Loss: 0.40329810976982117\n",
      "Epoch 11/20, Iteration 210/303, Loss: 0.18486717343330383\n",
      "Epoch 11/20, Iteration 211/303, Loss: 0.188229501247406\n",
      "Epoch 11/20, Iteration 212/303, Loss: 0.16827990114688873\n",
      "Epoch 11/20, Iteration 213/303, Loss: 0.07635326683521271\n",
      "Epoch 11/20, Iteration 214/303, Loss: 0.20326772332191467\n",
      "Epoch 11/20, Iteration 215/303, Loss: 0.16621185839176178\n",
      "Epoch 11/20, Iteration 216/303, Loss: 0.20928338170051575\n",
      "Epoch 11/20, Iteration 217/303, Loss: 0.13241875171661377\n",
      "Epoch 11/20, Iteration 218/303, Loss: 0.19663560390472412\n",
      "Epoch 11/20, Iteration 219/303, Loss: 0.22202831506729126\n",
      "Epoch 11/20, Iteration 220/303, Loss: 0.24795302748680115\n",
      "Epoch 11/20, Iteration 221/303, Loss: 0.2731478810310364\n",
      "Epoch 11/20, Iteration 222/303, Loss: 0.15909212827682495\n",
      "Epoch 11/20, Iteration 223/303, Loss: 0.1668674498796463\n",
      "Epoch 11/20, Iteration 224/303, Loss: 0.12032046169042587\n",
      "Epoch 11/20, Iteration 225/303, Loss: 0.4867733418941498\n",
      "Epoch 11/20, Iteration 226/303, Loss: 0.1329958289861679\n",
      "Epoch 11/20, Iteration 227/303, Loss: 0.5418205857276917\n",
      "Epoch 11/20, Iteration 228/303, Loss: 0.23341602087020874\n",
      "Epoch 11/20, Iteration 229/303, Loss: 0.3194877505302429\n",
      "Epoch 11/20, Iteration 230/303, Loss: 0.1890569031238556\n",
      "Epoch 11/20, Iteration 231/303, Loss: 0.16815723478794098\n",
      "Epoch 11/20, Iteration 232/303, Loss: 0.16211287677288055\n",
      "Epoch 11/20, Iteration 233/303, Loss: 0.20164887607097626\n",
      "Epoch 11/20, Iteration 234/303, Loss: 0.19790291786193848\n",
      "Epoch 11/20, Iteration 235/303, Loss: 0.32716119289398193\n",
      "Epoch 11/20, Iteration 236/303, Loss: 0.1855996549129486\n",
      "Epoch 11/20, Iteration 237/303, Loss: 0.16868460178375244\n",
      "Epoch 11/20, Iteration 238/303, Loss: 0.27008724212646484\n",
      "Epoch 11/20, Iteration 239/303, Loss: 0.2916356325149536\n",
      "Epoch 11/20, Iteration 240/303, Loss: 0.12410789728164673\n",
      "Epoch 11/20, Iteration 241/303, Loss: 0.21188661456108093\n",
      "Epoch 11/20, Iteration 242/303, Loss: 0.2465718686580658\n",
      "Epoch 11/20, Iteration 243/303, Loss: 0.3347659409046173\n",
      "Epoch 11/20, Iteration 244/303, Loss: 0.14466364681720734\n",
      "Epoch 11/20, Iteration 245/303, Loss: 0.16668222844600677\n",
      "Epoch 11/20, Iteration 246/303, Loss: 0.1675269603729248\n",
      "Epoch 11/20, Iteration 247/303, Loss: 0.2913168668746948\n",
      "Epoch 11/20, Iteration 248/303, Loss: 0.27585944533348083\n",
      "Epoch 11/20, Iteration 249/303, Loss: 0.08535174280405045\n",
      "Epoch 11/20, Iteration 250/303, Loss: 0.2502462863922119\n",
      "Epoch 11/20, Iteration 251/303, Loss: 0.13430187106132507\n",
      "Epoch 11/20, Iteration 252/303, Loss: 0.2408497929573059\n",
      "Epoch 11/20, Iteration 253/303, Loss: 0.1405177116394043\n",
      "Epoch 11/20, Iteration 254/303, Loss: 0.23661477863788605\n",
      "Epoch 11/20, Iteration 255/303, Loss: 0.19553230702877045\n",
      "Epoch 11/20, Iteration 256/303, Loss: 0.22637838125228882\n",
      "Epoch 11/20, Iteration 257/303, Loss: 0.23395636677742004\n",
      "Epoch 11/20, Iteration 258/303, Loss: 0.32244226336479187\n",
      "Epoch 11/20, Iteration 259/303, Loss: 0.3112539052963257\n",
      "Epoch 11/20, Iteration 260/303, Loss: 0.1596779078245163\n",
      "Epoch 11/20, Iteration 261/303, Loss: 0.15772108733654022\n",
      "Epoch 11/20, Iteration 262/303, Loss: 0.12394741922616959\n",
      "Epoch 11/20, Iteration 263/303, Loss: 0.12725374102592468\n",
      "Epoch 11/20, Iteration 264/303, Loss: 0.2805592715740204\n",
      "Epoch 11/20, Iteration 265/303, Loss: 0.2009924054145813\n",
      "Epoch 11/20, Iteration 266/303, Loss: 0.1918618083000183\n",
      "Epoch 11/20, Iteration 267/303, Loss: 0.2880512475967407\n",
      "Epoch 11/20, Iteration 268/303, Loss: 0.21975113451480865\n",
      "Epoch 11/20, Iteration 269/303, Loss: 0.2569178640842438\n",
      "Epoch 11/20, Iteration 270/303, Loss: 0.2258133888244629\n",
      "Epoch 11/20, Iteration 271/303, Loss: 0.3554554581642151\n",
      "Epoch 11/20, Iteration 272/303, Loss: 0.16440293192863464\n",
      "Epoch 11/20, Iteration 273/303, Loss: 0.1535290628671646\n",
      "Epoch 11/20, Iteration 274/303, Loss: 0.21940332651138306\n",
      "Epoch 11/20, Iteration 275/303, Loss: 0.254794180393219\n",
      "Epoch 11/20, Iteration 276/303, Loss: 0.20244839787483215\n",
      "Epoch 11/20, Iteration 277/303, Loss: 0.3214648962020874\n",
      "Epoch 11/20, Iteration 278/303, Loss: 0.2143046259880066\n",
      "Epoch 11/20, Iteration 279/303, Loss: 0.3806932866573334\n",
      "Epoch 11/20, Iteration 280/303, Loss: 0.1925639808177948\n",
      "Epoch 11/20, Iteration 281/303, Loss: 0.12932254374027252\n",
      "Epoch 11/20, Iteration 282/303, Loss: 0.24099275469779968\n",
      "Epoch 11/20, Iteration 283/303, Loss: 0.21610459685325623\n",
      "Epoch 11/20, Iteration 284/303, Loss: 0.24893571436405182\n",
      "Epoch 11/20, Iteration 285/303, Loss: 0.08726664632558823\n",
      "Epoch 11/20, Iteration 286/303, Loss: 0.14396783709526062\n",
      "Epoch 11/20, Iteration 287/303, Loss: 0.20892393589019775\n",
      "Epoch 11/20, Iteration 288/303, Loss: 0.4089151918888092\n",
      "Epoch 11/20, Iteration 289/303, Loss: 0.1996249109506607\n",
      "Epoch 11/20, Iteration 290/303, Loss: 0.32569169998168945\n",
      "Epoch 11/20, Iteration 291/303, Loss: 0.5073970556259155\n",
      "Epoch 11/20, Iteration 292/303, Loss: 0.30830955505371094\n",
      "Epoch 11/20, Iteration 293/303, Loss: 0.264673113822937\n",
      "Epoch 11/20, Iteration 294/303, Loss: 0.31424346566200256\n",
      "Epoch 11/20, Iteration 295/303, Loss: 0.2859637141227722\n",
      "Epoch 11/20, Iteration 296/303, Loss: 0.23100481927394867\n",
      "Epoch 11/20, Iteration 297/303, Loss: 0.2708757221698761\n",
      "Epoch 11/20, Iteration 298/303, Loss: 0.1505584418773651\n",
      "Epoch 11/20, Iteration 299/303, Loss: 0.1556064337491989\n",
      "Epoch 11/20, Iteration 300/303, Loss: 0.09200331568717957\n",
      "Epoch 11/20, Iteration 301/303, Loss: 0.2137574702501297\n",
      "Epoch 11/20, Iteration 302/303, Loss: 0.37590286135673523\n",
      "Epoch 11/20, Iteration 303/303, Loss: 0.16117455065250397\n",
      "Epoch 12/20, Iteration 1/303, Loss: 0.21622270345687866\n",
      "Epoch 12/20, Iteration 2/303, Loss: 0.13345704972743988\n",
      "Epoch 12/20, Iteration 3/303, Loss: 0.13952425122261047\n",
      "Epoch 12/20, Iteration 4/303, Loss: 0.1261206716299057\n",
      "Epoch 12/20, Iteration 5/303, Loss: 0.19812336564064026\n",
      "Epoch 12/20, Iteration 6/303, Loss: 0.09425158053636551\n",
      "Epoch 12/20, Iteration 7/303, Loss: 0.15625587105751038\n",
      "Epoch 12/20, Iteration 8/303, Loss: 0.15026679635047913\n",
      "Epoch 12/20, Iteration 9/303, Loss: 0.28056249022483826\n",
      "Epoch 12/20, Iteration 10/303, Loss: 0.2965255379676819\n",
      "Epoch 12/20, Iteration 11/303, Loss: 0.24417264759540558\n",
      "Epoch 12/20, Iteration 12/303, Loss: 0.2899538576602936\n",
      "Epoch 12/20, Iteration 13/303, Loss: 0.10037675499916077\n",
      "Epoch 12/20, Iteration 14/303, Loss: 0.11681342124938965\n",
      "Epoch 12/20, Iteration 15/303, Loss: 0.09857826679944992\n",
      "Epoch 12/20, Iteration 16/303, Loss: 0.1730528622865677\n",
      "Epoch 12/20, Iteration 17/303, Loss: 0.36172208189964294\n",
      "Epoch 12/20, Iteration 18/303, Loss: 0.137770876288414\n",
      "Epoch 12/20, Iteration 19/303, Loss: 0.22176603972911835\n",
      "Epoch 12/20, Iteration 20/303, Loss: 0.21923333406448364\n",
      "Epoch 12/20, Iteration 21/303, Loss: 0.15038196742534637\n",
      "Epoch 12/20, Iteration 22/303, Loss: 0.20922914147377014\n",
      "Epoch 12/20, Iteration 23/303, Loss: 0.1276642084121704\n",
      "Epoch 12/20, Iteration 24/303, Loss: 0.18148674070835114\n",
      "Epoch 12/20, Iteration 25/303, Loss: 0.19576314091682434\n",
      "Epoch 12/20, Iteration 26/303, Loss: 0.28319498896598816\n",
      "Epoch 12/20, Iteration 27/303, Loss: 0.3042653203010559\n",
      "Epoch 12/20, Iteration 28/303, Loss: 0.2649427056312561\n",
      "Epoch 12/20, Iteration 29/303, Loss: 0.22352159023284912\n",
      "Epoch 12/20, Iteration 30/303, Loss: 0.16641883552074432\n",
      "Epoch 12/20, Iteration 31/303, Loss: 0.1495879888534546\n",
      "Epoch 12/20, Iteration 32/303, Loss: 0.08403362333774567\n",
      "Epoch 12/20, Iteration 33/303, Loss: 0.12880079448223114\n",
      "Epoch 12/20, Iteration 34/303, Loss: 0.20484670996665955\n",
      "Epoch 12/20, Iteration 35/303, Loss: 0.27279892563819885\n",
      "Epoch 12/20, Iteration 36/303, Loss: 0.208896666765213\n",
      "Epoch 12/20, Iteration 37/303, Loss: 0.22074738144874573\n",
      "Epoch 12/20, Iteration 38/303, Loss: 0.15131166577339172\n",
      "Epoch 12/20, Iteration 39/303, Loss: 0.20101356506347656\n",
      "Epoch 12/20, Iteration 40/303, Loss: 0.10088979452848434\n",
      "Epoch 12/20, Iteration 41/303, Loss: 0.1321086287498474\n",
      "Epoch 12/20, Iteration 42/303, Loss: 0.16092178225517273\n",
      "Epoch 12/20, Iteration 43/303, Loss: 0.2937202453613281\n",
      "Epoch 12/20, Iteration 44/303, Loss: 0.27269795536994934\n",
      "Epoch 12/20, Iteration 45/303, Loss: 0.17166011035442352\n",
      "Epoch 12/20, Iteration 46/303, Loss: 0.1423352062702179\n",
      "Epoch 12/20, Iteration 47/303, Loss: 0.18131212890148163\n",
      "Epoch 12/20, Iteration 48/303, Loss: 0.26154956221580505\n",
      "Epoch 12/20, Iteration 49/303, Loss: 0.11303682625293732\n",
      "Epoch 12/20, Iteration 50/303, Loss: 0.14644259214401245\n",
      "Epoch 12/20, Iteration 51/303, Loss: 0.07644899189472198\n",
      "Epoch 12/20, Iteration 52/303, Loss: 0.12233619391918182\n",
      "Epoch 12/20, Iteration 53/303, Loss: 0.10559767484664917\n",
      "Epoch 12/20, Iteration 54/303, Loss: 0.1589338332414627\n",
      "Epoch 12/20, Iteration 55/303, Loss: 0.16680960357189178\n",
      "Epoch 12/20, Iteration 56/303, Loss: 0.11516036093235016\n",
      "Epoch 12/20, Iteration 57/303, Loss: 0.031283728778362274\n",
      "Epoch 12/20, Iteration 58/303, Loss: 0.15805332362651825\n",
      "Epoch 12/20, Iteration 59/303, Loss: 0.2899989187717438\n",
      "Epoch 12/20, Iteration 60/303, Loss: 0.20039893686771393\n",
      "Epoch 12/20, Iteration 61/303, Loss: 0.14178727567195892\n",
      "Epoch 12/20, Iteration 62/303, Loss: 0.2086462527513504\n",
      "Epoch 12/20, Iteration 63/303, Loss: 0.09687209129333496\n",
      "Epoch 12/20, Iteration 64/303, Loss: 0.09118284285068512\n",
      "Epoch 12/20, Iteration 65/303, Loss: 0.2721155881881714\n",
      "Epoch 12/20, Iteration 66/303, Loss: 0.1187450960278511\n",
      "Epoch 12/20, Iteration 67/303, Loss: 0.1683996021747589\n",
      "Epoch 12/20, Iteration 68/303, Loss: 0.31544479727745056\n",
      "Epoch 12/20, Iteration 69/303, Loss: 0.24441300332546234\n",
      "Epoch 12/20, Iteration 70/303, Loss: 0.31075698137283325\n",
      "Epoch 12/20, Iteration 71/303, Loss: 0.23808148503303528\n",
      "Epoch 12/20, Iteration 72/303, Loss: 0.3752627968788147\n",
      "Epoch 12/20, Iteration 73/303, Loss: 0.0780426487326622\n",
      "Epoch 12/20, Iteration 74/303, Loss: 0.3357864320278168\n",
      "Epoch 12/20, Iteration 75/303, Loss: 0.252926766872406\n",
      "Epoch 12/20, Iteration 76/303, Loss: 0.0913224071264267\n",
      "Epoch 12/20, Iteration 77/303, Loss: 0.20248648524284363\n",
      "Epoch 12/20, Iteration 78/303, Loss: 0.151322141289711\n",
      "Epoch 12/20, Iteration 79/303, Loss: 0.16591766476631165\n",
      "Epoch 12/20, Iteration 80/303, Loss: 0.07434941828250885\n",
      "Epoch 12/20, Iteration 81/303, Loss: 0.08128765225410461\n",
      "Epoch 12/20, Iteration 82/303, Loss: 0.07325788587331772\n",
      "Epoch 12/20, Iteration 83/303, Loss: 0.1523030549287796\n",
      "Epoch 12/20, Iteration 84/303, Loss: 0.18977411091327667\n",
      "Epoch 12/20, Iteration 85/303, Loss: 0.19811633229255676\n",
      "Epoch 12/20, Iteration 86/303, Loss: 0.07903015613555908\n",
      "Epoch 12/20, Iteration 87/303, Loss: 0.1331629455089569\n",
      "Epoch 12/20, Iteration 88/303, Loss: 0.08993811905384064\n",
      "Epoch 12/20, Iteration 89/303, Loss: 0.15386927127838135\n",
      "Epoch 12/20, Iteration 90/303, Loss: 0.12852665781974792\n",
      "Epoch 12/20, Iteration 91/303, Loss: 0.056751713156700134\n",
      "Epoch 12/20, Iteration 92/303, Loss: 0.13698497414588928\n",
      "Epoch 12/20, Iteration 93/303, Loss: 0.14388631284236908\n",
      "Epoch 12/20, Iteration 94/303, Loss: 0.2208332121372223\n",
      "Epoch 12/20, Iteration 95/303, Loss: 0.10107793658971786\n",
      "Epoch 12/20, Iteration 96/303, Loss: 0.14579235017299652\n",
      "Epoch 12/20, Iteration 97/303, Loss: 0.06788073480129242\n",
      "Epoch 12/20, Iteration 98/303, Loss: 0.12077653408050537\n",
      "Epoch 12/20, Iteration 99/303, Loss: 0.09783190488815308\n",
      "Epoch 12/20, Iteration 100/303, Loss: 0.2253022938966751\n",
      "Epoch 12/20, Iteration 101/303, Loss: 0.16633282601833344\n",
      "Epoch 12/20, Iteration 102/303, Loss: 0.14791055023670197\n",
      "Epoch 12/20, Iteration 103/303, Loss: 0.22631332278251648\n",
      "Epoch 12/20, Iteration 104/303, Loss: 0.16000249981880188\n",
      "Epoch 12/20, Iteration 105/303, Loss: 0.1708855926990509\n",
      "Epoch 12/20, Iteration 106/303, Loss: 0.1314217448234558\n",
      "Epoch 12/20, Iteration 107/303, Loss: 0.13167864084243774\n",
      "Epoch 12/20, Iteration 108/303, Loss: 0.19565075635910034\n",
      "Epoch 12/20, Iteration 109/303, Loss: 0.15050578117370605\n",
      "Epoch 12/20, Iteration 110/303, Loss: 0.21396902203559875\n",
      "Epoch 12/20, Iteration 111/303, Loss: 0.24325433373451233\n",
      "Epoch 12/20, Iteration 112/303, Loss: 0.2621256411075592\n",
      "Epoch 12/20, Iteration 113/303, Loss: 0.13711678981781006\n",
      "Epoch 12/20, Iteration 114/303, Loss: 0.15384942293167114\n",
      "Epoch 12/20, Iteration 115/303, Loss: 0.09422318637371063\n",
      "Epoch 12/20, Iteration 116/303, Loss: 0.23430228233337402\n",
      "Epoch 12/20, Iteration 117/303, Loss: 0.16089291870594025\n",
      "Epoch 12/20, Iteration 118/303, Loss: 0.2605692148208618\n",
      "Epoch 12/20, Iteration 119/303, Loss: 0.17847122251987457\n",
      "Epoch 12/20, Iteration 120/303, Loss: 0.14577040076255798\n",
      "Epoch 12/20, Iteration 121/303, Loss: 0.12609830498695374\n",
      "Epoch 12/20, Iteration 122/303, Loss: 0.11948119103908539\n",
      "Epoch 12/20, Iteration 123/303, Loss: 0.09398499876260757\n",
      "Epoch 12/20, Iteration 124/303, Loss: 0.18739593029022217\n",
      "Epoch 12/20, Iteration 125/303, Loss: 0.21427658200263977\n",
      "Epoch 12/20, Iteration 126/303, Loss: 0.22544431686401367\n",
      "Epoch 12/20, Iteration 127/303, Loss: 0.2197740525007248\n",
      "Epoch 12/20, Iteration 128/303, Loss: 0.08981787413358688\n",
      "Epoch 12/20, Iteration 129/303, Loss: 0.14653252065181732\n",
      "Epoch 12/20, Iteration 130/303, Loss: 0.10794603824615479\n",
      "Epoch 12/20, Iteration 131/303, Loss: 0.0888291448354721\n",
      "Epoch 12/20, Iteration 132/303, Loss: 0.35301893949508667\n",
      "Epoch 12/20, Iteration 133/303, Loss: 0.5775890946388245\n",
      "Epoch 12/20, Iteration 134/303, Loss: 0.1893770694732666\n",
      "Epoch 12/20, Iteration 135/303, Loss: 0.23280727863311768\n",
      "Epoch 12/20, Iteration 136/303, Loss: 0.239179328083992\n",
      "Epoch 12/20, Iteration 137/303, Loss: 0.18550869822502136\n",
      "Epoch 12/20, Iteration 138/303, Loss: 0.11248661577701569\n",
      "Epoch 12/20, Iteration 139/303, Loss: 0.12520375847816467\n",
      "Epoch 12/20, Iteration 140/303, Loss: 0.311839759349823\n",
      "Epoch 12/20, Iteration 141/303, Loss: 0.10219273716211319\n",
      "Epoch 12/20, Iteration 142/303, Loss: 0.16702212393283844\n",
      "Epoch 12/20, Iteration 143/303, Loss: 0.1591147482395172\n",
      "Epoch 12/20, Iteration 144/303, Loss: 0.2915610074996948\n",
      "Epoch 12/20, Iteration 145/303, Loss: 0.20189408957958221\n",
      "Epoch 12/20, Iteration 146/303, Loss: 0.15563267469406128\n",
      "Epoch 12/20, Iteration 147/303, Loss: 0.10887783765792847\n",
      "Epoch 12/20, Iteration 148/303, Loss: 0.3224651515483856\n",
      "Epoch 12/20, Iteration 149/303, Loss: 0.23673269152641296\n",
      "Epoch 12/20, Iteration 150/303, Loss: 0.1868981271982193\n",
      "Epoch 12/20, Iteration 151/303, Loss: 0.1441865712404251\n",
      "Epoch 12/20, Iteration 152/303, Loss: 0.4758279323577881\n",
      "Epoch 12/20, Iteration 153/303, Loss: 0.3564949333667755\n",
      "Epoch 12/20, Iteration 154/303, Loss: 0.31596654653549194\n",
      "Epoch 12/20, Iteration 155/303, Loss: 0.15904656052589417\n",
      "Epoch 12/20, Iteration 156/303, Loss: 0.2750360071659088\n",
      "Epoch 12/20, Iteration 157/303, Loss: 0.13605180382728577\n",
      "Epoch 12/20, Iteration 158/303, Loss: 0.20755983889102936\n",
      "Epoch 12/20, Iteration 159/303, Loss: 0.12949644029140472\n",
      "Epoch 12/20, Iteration 160/303, Loss: 0.17020809650421143\n",
      "Epoch 12/20, Iteration 161/303, Loss: 0.16062727570533752\n",
      "Epoch 12/20, Iteration 162/303, Loss: 0.32176879048347473\n",
      "Epoch 12/20, Iteration 163/303, Loss: 0.255004346370697\n",
      "Epoch 12/20, Iteration 164/303, Loss: 0.10897829383611679\n",
      "Epoch 12/20, Iteration 165/303, Loss: 0.14927026629447937\n",
      "Epoch 12/20, Iteration 166/303, Loss: 0.2544509768486023\n",
      "Epoch 12/20, Iteration 167/303, Loss: 0.35509687662124634\n",
      "Epoch 12/20, Iteration 168/303, Loss: 0.07165728509426117\n",
      "Epoch 12/20, Iteration 169/303, Loss: 0.22045966982841492\n",
      "Epoch 12/20, Iteration 170/303, Loss: 0.17772793769836426\n",
      "Epoch 12/20, Iteration 171/303, Loss: 0.2391679733991623\n",
      "Epoch 12/20, Iteration 172/303, Loss: 0.11676198244094849\n",
      "Epoch 12/20, Iteration 173/303, Loss: 0.1354389190673828\n",
      "Epoch 12/20, Iteration 174/303, Loss: 0.11593227088451385\n",
      "Epoch 12/20, Iteration 175/303, Loss: 0.13634821772575378\n",
      "Epoch 12/20, Iteration 176/303, Loss: 0.07498191297054291\n",
      "Epoch 12/20, Iteration 177/303, Loss: 0.16887038946151733\n",
      "Epoch 12/20, Iteration 178/303, Loss: 0.22504882514476776\n",
      "Epoch 12/20, Iteration 179/303, Loss: 0.05573955550789833\n",
      "Epoch 12/20, Iteration 180/303, Loss: 0.21802963316440582\n",
      "Epoch 12/20, Iteration 181/303, Loss: 0.0801471471786499\n",
      "Epoch 12/20, Iteration 182/303, Loss: 0.07677923142910004\n",
      "Epoch 12/20, Iteration 183/303, Loss: 0.05571386218070984\n",
      "Epoch 12/20, Iteration 184/303, Loss: 0.04991675168275833\n",
      "Epoch 12/20, Iteration 185/303, Loss: 0.23676760494709015\n",
      "Epoch 12/20, Iteration 186/303, Loss: 0.05307473987340927\n",
      "Epoch 12/20, Iteration 187/303, Loss: 0.06488261371850967\n",
      "Epoch 12/20, Iteration 188/303, Loss: 0.23564699292182922\n",
      "Epoch 12/20, Iteration 189/303, Loss: 0.18418054282665253\n",
      "Epoch 12/20, Iteration 190/303, Loss: 0.137172132730484\n",
      "Epoch 12/20, Iteration 191/303, Loss: 0.19076737761497498\n",
      "Epoch 12/20, Iteration 192/303, Loss: 0.10833465307950974\n",
      "Epoch 12/20, Iteration 193/303, Loss: 0.28410810232162476\n",
      "Epoch 12/20, Iteration 194/303, Loss: 0.2798716425895691\n",
      "Epoch 12/20, Iteration 195/303, Loss: 0.2095504105091095\n",
      "Epoch 12/20, Iteration 196/303, Loss: 0.13555486500263214\n",
      "Epoch 12/20, Iteration 197/303, Loss: 0.18077868223190308\n",
      "Epoch 12/20, Iteration 198/303, Loss: 0.29342517256736755\n",
      "Epoch 12/20, Iteration 199/303, Loss: 0.07779841125011444\n",
      "Epoch 12/20, Iteration 200/303, Loss: 0.2883045971393585\n",
      "Epoch 12/20, Iteration 201/303, Loss: 0.3441427946090698\n",
      "Epoch 12/20, Iteration 202/303, Loss: 0.14610692858695984\n",
      "Epoch 12/20, Iteration 203/303, Loss: 0.2978677749633789\n",
      "Epoch 12/20, Iteration 204/303, Loss: 0.3227883577346802\n",
      "Epoch 12/20, Iteration 205/303, Loss: 0.33213546872138977\n",
      "Epoch 12/20, Iteration 206/303, Loss: 0.17110559344291687\n",
      "Epoch 12/20, Iteration 207/303, Loss: 0.36760520935058594\n",
      "Epoch 12/20, Iteration 208/303, Loss: 0.1852501779794693\n",
      "Epoch 12/20, Iteration 209/303, Loss: 0.13448470830917358\n",
      "Epoch 12/20, Iteration 210/303, Loss: 0.32491999864578247\n",
      "Epoch 12/20, Iteration 211/303, Loss: 0.27515822649002075\n",
      "Epoch 12/20, Iteration 212/303, Loss: 0.11324811726808548\n",
      "Epoch 12/20, Iteration 213/303, Loss: 0.13631772994995117\n",
      "Epoch 12/20, Iteration 214/303, Loss: 0.1198534369468689\n",
      "Epoch 12/20, Iteration 215/303, Loss: 0.09754838794469833\n",
      "Epoch 12/20, Iteration 216/303, Loss: 0.05393794924020767\n",
      "Epoch 12/20, Iteration 217/303, Loss: 0.1402444839477539\n",
      "Epoch 12/20, Iteration 218/303, Loss: 0.13353796303272247\n",
      "Epoch 12/20, Iteration 219/303, Loss: 0.15086276829242706\n",
      "Epoch 12/20, Iteration 220/303, Loss: 0.34473541378974915\n",
      "Epoch 12/20, Iteration 221/303, Loss: 0.43704092502593994\n",
      "Epoch 12/20, Iteration 222/303, Loss: 0.496163547039032\n",
      "Epoch 12/20, Iteration 223/303, Loss: 0.19863803684711456\n",
      "Epoch 12/20, Iteration 224/303, Loss: 0.24934500455856323\n",
      "Epoch 12/20, Iteration 225/303, Loss: 0.20391809940338135\n",
      "Epoch 12/20, Iteration 226/303, Loss: 0.14608950912952423\n",
      "Epoch 12/20, Iteration 227/303, Loss: 0.3243446350097656\n",
      "Epoch 12/20, Iteration 228/303, Loss: 0.062025703489780426\n",
      "Epoch 12/20, Iteration 229/303, Loss: 0.21821819245815277\n",
      "Epoch 12/20, Iteration 230/303, Loss: 0.41039156913757324\n",
      "Epoch 12/20, Iteration 231/303, Loss: 0.19997800886631012\n",
      "Epoch 12/20, Iteration 232/303, Loss: 0.21273589134216309\n",
      "Epoch 12/20, Iteration 233/303, Loss: 0.1884455680847168\n",
      "Epoch 12/20, Iteration 234/303, Loss: 0.13638794422149658\n",
      "Epoch 12/20, Iteration 235/303, Loss: 0.09965793043375015\n",
      "Epoch 12/20, Iteration 236/303, Loss: 0.1849275827407837\n",
      "Epoch 12/20, Iteration 237/303, Loss: 0.35641977190971375\n",
      "Epoch 12/20, Iteration 238/303, Loss: 0.24953016638755798\n",
      "Epoch 12/20, Iteration 239/303, Loss: 0.20522618293762207\n",
      "Epoch 12/20, Iteration 240/303, Loss: 0.18598692119121552\n",
      "Epoch 12/20, Iteration 241/303, Loss: 0.20857170224189758\n",
      "Epoch 12/20, Iteration 242/303, Loss: 0.18703313171863556\n",
      "Epoch 12/20, Iteration 243/303, Loss: 0.19755956530570984\n",
      "Epoch 12/20, Iteration 244/303, Loss: 0.2720082402229309\n",
      "Epoch 12/20, Iteration 245/303, Loss: 0.18865633010864258\n",
      "Epoch 12/20, Iteration 246/303, Loss: 0.2627662718296051\n",
      "Epoch 12/20, Iteration 247/303, Loss: 0.12094341218471527\n",
      "Epoch 12/20, Iteration 248/303, Loss: 0.4569607973098755\n",
      "Epoch 12/20, Iteration 249/303, Loss: 0.20927846431732178\n",
      "Epoch 12/20, Iteration 250/303, Loss: 0.1574263870716095\n",
      "Epoch 12/20, Iteration 251/303, Loss: 0.12354674190282822\n",
      "Epoch 12/20, Iteration 252/303, Loss: 0.29241645336151123\n",
      "Epoch 12/20, Iteration 253/303, Loss: 0.1299077272415161\n",
      "Epoch 12/20, Iteration 254/303, Loss: 0.1725834608078003\n",
      "Epoch 12/20, Iteration 255/303, Loss: 0.1661093533039093\n",
      "Epoch 12/20, Iteration 256/303, Loss: 0.08791520446538925\n",
      "Epoch 12/20, Iteration 257/303, Loss: 0.2823850214481354\n",
      "Epoch 12/20, Iteration 258/303, Loss: 0.30375733971595764\n",
      "Epoch 12/20, Iteration 259/303, Loss: 0.16720275580883026\n",
      "Epoch 12/20, Iteration 260/303, Loss: 0.062076084315776825\n",
      "Epoch 12/20, Iteration 261/303, Loss: 0.20011308789253235\n",
      "Epoch 12/20, Iteration 262/303, Loss: 0.2564208209514618\n",
      "Epoch 12/20, Iteration 263/303, Loss: 0.1533598005771637\n",
      "Epoch 12/20, Iteration 264/303, Loss: 0.2580147683620453\n",
      "Epoch 12/20, Iteration 265/303, Loss: 0.2091076374053955\n",
      "Epoch 12/20, Iteration 266/303, Loss: 0.2611691653728485\n",
      "Epoch 12/20, Iteration 267/303, Loss: 0.1701384335756302\n",
      "Epoch 12/20, Iteration 268/303, Loss: 0.16628460586071014\n",
      "Epoch 12/20, Iteration 269/303, Loss: 0.05845310539007187\n",
      "Epoch 12/20, Iteration 270/303, Loss: 0.3030758500099182\n",
      "Epoch 12/20, Iteration 271/303, Loss: 0.15430882573127747\n",
      "Epoch 12/20, Iteration 272/303, Loss: 0.11102021485567093\n",
      "Epoch 12/20, Iteration 273/303, Loss: 0.19420652091503143\n",
      "Epoch 12/20, Iteration 274/303, Loss: 0.24722538888454437\n",
      "Epoch 12/20, Iteration 275/303, Loss: 0.08566798269748688\n",
      "Epoch 12/20, Iteration 276/303, Loss: 0.18141867220401764\n",
      "Epoch 12/20, Iteration 277/303, Loss: 0.26447322964668274\n",
      "Epoch 12/20, Iteration 278/303, Loss: 0.1313057541847229\n",
      "Epoch 12/20, Iteration 279/303, Loss: 0.2021065503358841\n",
      "Epoch 12/20, Iteration 280/303, Loss: 0.2383090853691101\n",
      "Epoch 12/20, Iteration 281/303, Loss: 0.08455824851989746\n",
      "Epoch 12/20, Iteration 282/303, Loss: 0.17563167214393616\n",
      "Epoch 12/20, Iteration 283/303, Loss: 0.18252134323120117\n",
      "Epoch 12/20, Iteration 284/303, Loss: 0.2207665890455246\n",
      "Epoch 12/20, Iteration 285/303, Loss: 0.10860944539308548\n",
      "Epoch 12/20, Iteration 286/303, Loss: 0.10724915564060211\n",
      "Epoch 12/20, Iteration 287/303, Loss: 0.14445003867149353\n",
      "Epoch 12/20, Iteration 288/303, Loss: 0.12604694068431854\n",
      "Epoch 12/20, Iteration 289/303, Loss: 0.07123787701129913\n",
      "Epoch 12/20, Iteration 290/303, Loss: 0.12312681972980499\n",
      "Epoch 12/20, Iteration 291/303, Loss: 0.30751222372055054\n",
      "Epoch 12/20, Iteration 292/303, Loss: 0.1830505132675171\n",
      "Epoch 12/20, Iteration 293/303, Loss: 0.1183847039937973\n",
      "Epoch 12/20, Iteration 294/303, Loss: 0.12275003641843796\n",
      "Epoch 12/20, Iteration 295/303, Loss: 0.08302684873342514\n",
      "Epoch 12/20, Iteration 296/303, Loss: 0.2169651836156845\n",
      "Epoch 12/20, Iteration 297/303, Loss: 0.1088135689496994\n",
      "Epoch 12/20, Iteration 298/303, Loss: 0.08693672716617584\n",
      "Epoch 12/20, Iteration 299/303, Loss: 0.20505546033382416\n",
      "Epoch 12/20, Iteration 300/303, Loss: 0.18245282769203186\n",
      "Epoch 12/20, Iteration 301/303, Loss: 0.13373050093650818\n",
      "Epoch 12/20, Iteration 302/303, Loss: 0.15182022750377655\n",
      "Epoch 12/20, Iteration 303/303, Loss: 0.25269946455955505\n",
      "Epoch 13/20, Iteration 1/303, Loss: 0.23474246263504028\n",
      "Epoch 13/20, Iteration 2/303, Loss: 0.22517581284046173\n",
      "Epoch 13/20, Iteration 3/303, Loss: 0.18401610851287842\n",
      "Epoch 13/20, Iteration 4/303, Loss: 0.16244962811470032\n",
      "Epoch 13/20, Iteration 5/303, Loss: 0.1014714390039444\n",
      "Epoch 13/20, Iteration 6/303, Loss: 0.1022067591547966\n",
      "Epoch 13/20, Iteration 7/303, Loss: 0.08549808710813522\n",
      "Epoch 13/20, Iteration 8/303, Loss: 0.06879279017448425\n",
      "Epoch 13/20, Iteration 9/303, Loss: 0.13412898778915405\n",
      "Epoch 13/20, Iteration 10/303, Loss: 0.08556300401687622\n",
      "Epoch 13/20, Iteration 11/303, Loss: 0.06537961959838867\n",
      "Epoch 13/20, Iteration 12/303, Loss: 0.1163647249341011\n",
      "Epoch 13/20, Iteration 13/303, Loss: 0.1902005970478058\n",
      "Epoch 13/20, Iteration 14/303, Loss: 0.1226203590631485\n",
      "Epoch 13/20, Iteration 15/303, Loss: 0.19857725501060486\n",
      "Epoch 13/20, Iteration 16/303, Loss: 0.10945411771535873\n",
      "Epoch 13/20, Iteration 17/303, Loss: 0.08554629236459732\n",
      "Epoch 13/20, Iteration 18/303, Loss: 0.1621014028787613\n",
      "Epoch 13/20, Iteration 19/303, Loss: 0.040744759142398834\n",
      "Epoch 13/20, Iteration 20/303, Loss: 0.3133141100406647\n",
      "Epoch 13/20, Iteration 21/303, Loss: 0.10914229601621628\n",
      "Epoch 13/20, Iteration 22/303, Loss: 0.08525349199771881\n",
      "Epoch 13/20, Iteration 23/303, Loss: 0.14322757720947266\n",
      "Epoch 13/20, Iteration 24/303, Loss: 0.14838528633117676\n",
      "Epoch 13/20, Iteration 25/303, Loss: 0.31356990337371826\n",
      "Epoch 13/20, Iteration 26/303, Loss: 0.10128384083509445\n",
      "Epoch 13/20, Iteration 27/303, Loss: 0.10562669485807419\n",
      "Epoch 13/20, Iteration 28/303, Loss: 0.045002855360507965\n",
      "Epoch 13/20, Iteration 29/303, Loss: 0.1618424952030182\n",
      "Epoch 13/20, Iteration 30/303, Loss: 0.10880357027053833\n",
      "Epoch 13/20, Iteration 31/303, Loss: 0.21535788476467133\n",
      "Epoch 13/20, Iteration 32/303, Loss: 0.13518096506595612\n",
      "Epoch 13/20, Iteration 33/303, Loss: 0.11999773234128952\n",
      "Epoch 13/20, Iteration 34/303, Loss: 0.10112041980028152\n",
      "Epoch 13/20, Iteration 35/303, Loss: 0.10879266262054443\n",
      "Epoch 13/20, Iteration 36/303, Loss: 0.08338458836078644\n",
      "Epoch 13/20, Iteration 37/303, Loss: 0.0669243186712265\n",
      "Epoch 13/20, Iteration 38/303, Loss: 0.039165399968624115\n",
      "Epoch 13/20, Iteration 39/303, Loss: 0.04909418895840645\n",
      "Epoch 13/20, Iteration 40/303, Loss: 0.13785140216350555\n",
      "Epoch 13/20, Iteration 41/303, Loss: 0.21587055921554565\n",
      "Epoch 13/20, Iteration 42/303, Loss: 0.18789935111999512\n",
      "Epoch 13/20, Iteration 43/303, Loss: 0.11619696766138077\n",
      "Epoch 13/20, Iteration 44/303, Loss: 0.11733659356832504\n",
      "Epoch 13/20, Iteration 45/303, Loss: 0.12090083211660385\n",
      "Epoch 13/20, Iteration 46/303, Loss: 0.12340404838323593\n",
      "Epoch 13/20, Iteration 47/303, Loss: 0.14638414978981018\n",
      "Epoch 13/20, Iteration 48/303, Loss: 0.04275207966566086\n",
      "Epoch 13/20, Iteration 49/303, Loss: 0.2023032158613205\n",
      "Epoch 13/20, Iteration 50/303, Loss: 0.20326057076454163\n",
      "Epoch 13/20, Iteration 51/303, Loss: 0.12383049726486206\n",
      "Epoch 13/20, Iteration 52/303, Loss: 0.31244897842407227\n",
      "Epoch 13/20, Iteration 53/303, Loss: 0.3140639662742615\n",
      "Epoch 13/20, Iteration 54/303, Loss: 0.25272336602211\n",
      "Epoch 13/20, Iteration 55/303, Loss: 0.1198052391409874\n",
      "Epoch 13/20, Iteration 56/303, Loss: 0.08026149123907089\n",
      "Epoch 13/20, Iteration 57/303, Loss: 0.07615376263856888\n",
      "Epoch 13/20, Iteration 58/303, Loss: 0.08933252096176147\n",
      "Epoch 13/20, Iteration 59/303, Loss: 0.09776133298873901\n",
      "Epoch 13/20, Iteration 60/303, Loss: 0.14278976619243622\n",
      "Epoch 13/20, Iteration 61/303, Loss: 0.08993253111839294\n",
      "Epoch 13/20, Iteration 62/303, Loss: 0.056901197880506516\n",
      "Epoch 13/20, Iteration 63/303, Loss: 0.11161444336175919\n",
      "Epoch 13/20, Iteration 64/303, Loss: 0.26213881373405457\n",
      "Epoch 13/20, Iteration 65/303, Loss: 0.056031033396720886\n",
      "Epoch 13/20, Iteration 66/303, Loss: 0.13282491266727448\n",
      "Epoch 13/20, Iteration 67/303, Loss: 0.17509710788726807\n",
      "Epoch 13/20, Iteration 68/303, Loss: 0.14796552062034607\n",
      "Epoch 13/20, Iteration 69/303, Loss: 0.15514780580997467\n",
      "Epoch 13/20, Iteration 70/303, Loss: 0.1165066659450531\n",
      "Epoch 13/20, Iteration 71/303, Loss: 0.07915568351745605\n",
      "Epoch 13/20, Iteration 72/303, Loss: 0.10551810264587402\n",
      "Epoch 13/20, Iteration 73/303, Loss: 0.10175111889839172\n",
      "Epoch 13/20, Iteration 74/303, Loss: 0.11027852445840836\n",
      "Epoch 13/20, Iteration 75/303, Loss: 0.21982376277446747\n",
      "Epoch 13/20, Iteration 76/303, Loss: 0.12839540839195251\n",
      "Epoch 13/20, Iteration 77/303, Loss: 0.18761712312698364\n",
      "Epoch 13/20, Iteration 78/303, Loss: 0.2585729956626892\n",
      "Epoch 13/20, Iteration 79/303, Loss: 0.11226017773151398\n",
      "Epoch 13/20, Iteration 80/303, Loss: 0.04789339378476143\n",
      "Epoch 13/20, Iteration 81/303, Loss: 0.11137914657592773\n",
      "Epoch 13/20, Iteration 82/303, Loss: 0.3596363663673401\n",
      "Epoch 13/20, Iteration 83/303, Loss: 0.1015743836760521\n",
      "Epoch 13/20, Iteration 84/303, Loss: 0.0991615504026413\n",
      "Epoch 13/20, Iteration 85/303, Loss: 0.08731864392757416\n",
      "Epoch 13/20, Iteration 86/303, Loss: 0.08595789223909378\n",
      "Epoch 13/20, Iteration 87/303, Loss: 0.22862917184829712\n",
      "Epoch 13/20, Iteration 88/303, Loss: 0.2335529774427414\n",
      "Epoch 13/20, Iteration 89/303, Loss: 0.12341680377721786\n",
      "Epoch 13/20, Iteration 90/303, Loss: 0.1362817883491516\n",
      "Epoch 13/20, Iteration 91/303, Loss: 0.08501582592725754\n",
      "Epoch 13/20, Iteration 92/303, Loss: 0.22351673245429993\n",
      "Epoch 13/20, Iteration 93/303, Loss: 0.12971697747707367\n",
      "Epoch 13/20, Iteration 94/303, Loss: 0.16490833461284637\n",
      "Epoch 13/20, Iteration 95/303, Loss: 0.3984144628047943\n",
      "Epoch 13/20, Iteration 96/303, Loss: 0.15866391360759735\n",
      "Epoch 13/20, Iteration 97/303, Loss: 0.12729056179523468\n",
      "Epoch 13/20, Iteration 98/303, Loss: 0.12013737857341766\n",
      "Epoch 13/20, Iteration 99/303, Loss: 0.11280203610658646\n",
      "Epoch 13/20, Iteration 100/303, Loss: 0.14300647377967834\n",
      "Epoch 13/20, Iteration 101/303, Loss: 0.11805422604084015\n",
      "Epoch 13/20, Iteration 102/303, Loss: 0.13284017145633698\n",
      "Epoch 13/20, Iteration 103/303, Loss: 0.0719013586640358\n",
      "Epoch 13/20, Iteration 104/303, Loss: 0.22738322615623474\n",
      "Epoch 13/20, Iteration 105/303, Loss: 0.050805527716875076\n",
      "Epoch 13/20, Iteration 106/303, Loss: 0.25469252467155457\n",
      "Epoch 13/20, Iteration 107/303, Loss: 0.17743350565433502\n",
      "Epoch 13/20, Iteration 108/303, Loss: 0.11868651211261749\n",
      "Epoch 13/20, Iteration 109/303, Loss: 0.1201542541384697\n",
      "Epoch 13/20, Iteration 110/303, Loss: 0.1150626614689827\n",
      "Epoch 13/20, Iteration 111/303, Loss: 0.13622191548347473\n",
      "Epoch 13/20, Iteration 112/303, Loss: 0.16935758292675018\n",
      "Epoch 13/20, Iteration 113/303, Loss: 0.08663109689950943\n",
      "Epoch 13/20, Iteration 114/303, Loss: 0.19258783757686615\n",
      "Epoch 13/20, Iteration 115/303, Loss: 0.17746300995349884\n",
      "Epoch 13/20, Iteration 116/303, Loss: 0.041191406548023224\n",
      "Epoch 13/20, Iteration 117/303, Loss: 0.24052096903324127\n",
      "Epoch 13/20, Iteration 118/303, Loss: 0.21744930744171143\n",
      "Epoch 13/20, Iteration 119/303, Loss: 0.2001575082540512\n",
      "Epoch 13/20, Iteration 120/303, Loss: 0.09251578897237778\n",
      "Epoch 13/20, Iteration 121/303, Loss: 0.09683491289615631\n",
      "Epoch 13/20, Iteration 122/303, Loss: 0.1652570217847824\n",
      "Epoch 13/20, Iteration 123/303, Loss: 0.19434396922588348\n",
      "Epoch 13/20, Iteration 124/303, Loss: 0.18365943431854248\n",
      "Epoch 13/20, Iteration 125/303, Loss: 0.08193294703960419\n",
      "Epoch 13/20, Iteration 126/303, Loss: 0.22794859111309052\n",
      "Epoch 13/20, Iteration 127/303, Loss: 0.11900360137224197\n",
      "Epoch 13/20, Iteration 128/303, Loss: 0.07559095323085785\n",
      "Epoch 13/20, Iteration 129/303, Loss: 0.1302584707736969\n",
      "Epoch 13/20, Iteration 130/303, Loss: 0.06547921895980835\n",
      "Epoch 13/20, Iteration 131/303, Loss: 0.10863999277353287\n",
      "Epoch 13/20, Iteration 132/303, Loss: 0.2914260923862457\n",
      "Epoch 13/20, Iteration 133/303, Loss: 0.2111496925354004\n",
      "Epoch 13/20, Iteration 134/303, Loss: 0.3552112877368927\n",
      "Epoch 13/20, Iteration 135/303, Loss: 0.13922421634197235\n",
      "Epoch 13/20, Iteration 136/303, Loss: 0.1444501280784607\n",
      "Epoch 13/20, Iteration 137/303, Loss: 0.2322315126657486\n",
      "Epoch 13/20, Iteration 138/303, Loss: 0.12122639268636703\n",
      "Epoch 13/20, Iteration 139/303, Loss: 0.14859847724437714\n",
      "Epoch 13/20, Iteration 140/303, Loss: 0.09570717811584473\n",
      "Epoch 13/20, Iteration 141/303, Loss: 0.15918046236038208\n",
      "Epoch 13/20, Iteration 142/303, Loss: 0.08637842535972595\n",
      "Epoch 13/20, Iteration 143/303, Loss: 0.10188028216362\n",
      "Epoch 13/20, Iteration 144/303, Loss: 0.05158323049545288\n",
      "Epoch 13/20, Iteration 145/303, Loss: 0.16039595007896423\n",
      "Epoch 13/20, Iteration 146/303, Loss: 0.09648863971233368\n",
      "Epoch 13/20, Iteration 147/303, Loss: 0.1064891591668129\n",
      "Epoch 13/20, Iteration 148/303, Loss: 0.11055285483598709\n",
      "Epoch 13/20, Iteration 149/303, Loss: 0.07794224470853806\n",
      "Epoch 13/20, Iteration 150/303, Loss: 0.021033328026533127\n",
      "Epoch 13/20, Iteration 151/303, Loss: 0.11736859381198883\n",
      "Epoch 13/20, Iteration 152/303, Loss: 0.15883755683898926\n",
      "Epoch 13/20, Iteration 153/303, Loss: 0.09452974051237106\n",
      "Epoch 13/20, Iteration 154/303, Loss: 0.21452543139457703\n",
      "Epoch 13/20, Iteration 155/303, Loss: 0.4334215521812439\n",
      "Epoch 13/20, Iteration 156/303, Loss: 0.17036506533622742\n",
      "Epoch 13/20, Iteration 157/303, Loss: 0.11844039708375931\n",
      "Epoch 13/20, Iteration 158/303, Loss: 0.08694665133953094\n",
      "Epoch 13/20, Iteration 159/303, Loss: 0.049683794379234314\n",
      "Epoch 13/20, Iteration 160/303, Loss: 0.09161695837974548\n",
      "Epoch 13/20, Iteration 161/303, Loss: 0.09150947630405426\n",
      "Epoch 13/20, Iteration 162/303, Loss: 0.06336954236030579\n",
      "Epoch 13/20, Iteration 163/303, Loss: 0.27101194858551025\n",
      "Epoch 13/20, Iteration 164/303, Loss: 0.34576886892318726\n",
      "Epoch 13/20, Iteration 165/303, Loss: 0.08550890535116196\n",
      "Epoch 13/20, Iteration 166/303, Loss: 0.08647462725639343\n",
      "Epoch 13/20, Iteration 167/303, Loss: 0.27126410603523254\n",
      "Epoch 13/20, Iteration 168/303, Loss: 0.2804662883281708\n",
      "Epoch 13/20, Iteration 169/303, Loss: 0.23734258115291595\n",
      "Epoch 13/20, Iteration 170/303, Loss: 0.048419225960969925\n",
      "Epoch 13/20, Iteration 171/303, Loss: 0.20581163465976715\n",
      "Epoch 13/20, Iteration 172/303, Loss: 0.11244380474090576\n",
      "Epoch 13/20, Iteration 173/303, Loss: 0.19489926099777222\n",
      "Epoch 13/20, Iteration 174/303, Loss: 0.14687752723693848\n",
      "Epoch 13/20, Iteration 175/303, Loss: 0.12497840076684952\n",
      "Epoch 13/20, Iteration 176/303, Loss: 0.26265594363212585\n",
      "Epoch 13/20, Iteration 177/303, Loss: 0.30321916937828064\n",
      "Epoch 13/20, Iteration 178/303, Loss: 0.35934337973594666\n",
      "Epoch 13/20, Iteration 179/303, Loss: 0.5806322693824768\n",
      "Epoch 13/20, Iteration 180/303, Loss: 0.32011595368385315\n",
      "Epoch 13/20, Iteration 181/303, Loss: 0.13270355761051178\n",
      "Epoch 13/20, Iteration 182/303, Loss: 0.14814355969429016\n",
      "Epoch 13/20, Iteration 183/303, Loss: 0.14625950157642365\n",
      "Epoch 13/20, Iteration 184/303, Loss: 0.2332625687122345\n",
      "Epoch 13/20, Iteration 185/303, Loss: 0.2072124183177948\n",
      "Epoch 13/20, Iteration 186/303, Loss: 0.17776724696159363\n",
      "Epoch 13/20, Iteration 187/303, Loss: 0.19446784257888794\n",
      "Epoch 13/20, Iteration 188/303, Loss: 0.13279671967029572\n",
      "Epoch 13/20, Iteration 189/303, Loss: 0.26164743304252625\n",
      "Epoch 13/20, Iteration 190/303, Loss: 0.09749560058116913\n",
      "Epoch 13/20, Iteration 191/303, Loss: 0.0742424800992012\n",
      "Epoch 13/20, Iteration 192/303, Loss: 0.1139046847820282\n",
      "Epoch 13/20, Iteration 193/303, Loss: 0.14838747680187225\n",
      "Epoch 13/20, Iteration 194/303, Loss: 0.20639052987098694\n",
      "Epoch 13/20, Iteration 195/303, Loss: 0.1802719384431839\n",
      "Epoch 13/20, Iteration 196/303, Loss: 0.0982811376452446\n",
      "Epoch 13/20, Iteration 197/303, Loss: 0.12410496920347214\n",
      "Epoch 13/20, Iteration 198/303, Loss: 0.1394159495830536\n",
      "Epoch 13/20, Iteration 199/303, Loss: 0.08114241063594818\n",
      "Epoch 13/20, Iteration 200/303, Loss: 0.10901904851198196\n",
      "Epoch 13/20, Iteration 201/303, Loss: 0.09092580527067184\n",
      "Epoch 13/20, Iteration 202/303, Loss: 0.02310156635940075\n",
      "Epoch 13/20, Iteration 203/303, Loss: 0.07036316394805908\n",
      "Epoch 13/20, Iteration 204/303, Loss: 0.11555886268615723\n",
      "Epoch 13/20, Iteration 205/303, Loss: 0.28380605578422546\n",
      "Epoch 13/20, Iteration 206/303, Loss: 0.30753642320632935\n",
      "Epoch 13/20, Iteration 207/303, Loss: 0.17547917366027832\n",
      "Epoch 13/20, Iteration 208/303, Loss: 0.128631591796875\n",
      "Epoch 13/20, Iteration 209/303, Loss: 0.10099271684885025\n",
      "Epoch 13/20, Iteration 210/303, Loss: 0.137332946062088\n",
      "Epoch 13/20, Iteration 211/303, Loss: 0.11117123067378998\n",
      "Epoch 13/20, Iteration 212/303, Loss: 0.22881345450878143\n",
      "Epoch 13/20, Iteration 213/303, Loss: 0.08689557015895844\n",
      "Epoch 13/20, Iteration 214/303, Loss: 0.1966380774974823\n",
      "Epoch 13/20, Iteration 215/303, Loss: 0.10822062194347382\n",
      "Epoch 13/20, Iteration 216/303, Loss: 0.24589243531227112\n",
      "Epoch 13/20, Iteration 217/303, Loss: 0.18097728490829468\n",
      "Epoch 13/20, Iteration 218/303, Loss: 0.1724640130996704\n",
      "Epoch 13/20, Iteration 219/303, Loss: 0.19278734922409058\n",
      "Epoch 13/20, Iteration 220/303, Loss: 0.07554102689027786\n",
      "Epoch 13/20, Iteration 221/303, Loss: 0.14220689237117767\n",
      "Epoch 13/20, Iteration 222/303, Loss: 0.16118812561035156\n",
      "Epoch 13/20, Iteration 223/303, Loss: 0.11800069361925125\n",
      "Epoch 13/20, Iteration 224/303, Loss: 0.18908482789993286\n",
      "Epoch 13/20, Iteration 225/303, Loss: 0.1307278871536255\n",
      "Epoch 13/20, Iteration 226/303, Loss: 0.11692264676094055\n",
      "Epoch 13/20, Iteration 227/303, Loss: 0.17572692036628723\n",
      "Epoch 13/20, Iteration 228/303, Loss: 0.18196320533752441\n",
      "Epoch 13/20, Iteration 229/303, Loss: 0.17640280723571777\n",
      "Epoch 13/20, Iteration 230/303, Loss: 0.17084477841854095\n",
      "Epoch 13/20, Iteration 231/303, Loss: 0.14982259273529053\n",
      "Epoch 13/20, Iteration 232/303, Loss: 0.161733478307724\n",
      "Epoch 13/20, Iteration 233/303, Loss: 0.09557712078094482\n",
      "Epoch 13/20, Iteration 234/303, Loss: 0.1889658272266388\n",
      "Epoch 13/20, Iteration 235/303, Loss: 0.11140380054712296\n",
      "Epoch 13/20, Iteration 236/303, Loss: 0.09784680604934692\n",
      "Epoch 13/20, Iteration 237/303, Loss: 0.07354791462421417\n",
      "Epoch 13/20, Iteration 238/303, Loss: 0.2999257445335388\n",
      "Epoch 13/20, Iteration 239/303, Loss: 0.19428856670856476\n",
      "Epoch 13/20, Iteration 240/303, Loss: 0.05186830088496208\n",
      "Epoch 13/20, Iteration 241/303, Loss: 0.0755382850766182\n",
      "Epoch 13/20, Iteration 242/303, Loss: 0.09934630990028381\n",
      "Epoch 13/20, Iteration 243/303, Loss: 0.07334684580564499\n",
      "Epoch 13/20, Iteration 244/303, Loss: 0.16224196553230286\n",
      "Epoch 13/20, Iteration 245/303, Loss: 0.13629022240638733\n",
      "Epoch 13/20, Iteration 246/303, Loss: 0.3470079302787781\n",
      "Epoch 13/20, Iteration 247/303, Loss: 0.39030739665031433\n",
      "Epoch 13/20, Iteration 248/303, Loss: 0.3711860775947571\n",
      "Epoch 13/20, Iteration 249/303, Loss: 0.11209169030189514\n",
      "Epoch 13/20, Iteration 250/303, Loss: 0.1984333097934723\n",
      "Epoch 13/20, Iteration 251/303, Loss: 0.07407438009977341\n",
      "Epoch 13/20, Iteration 252/303, Loss: 0.17102764546871185\n",
      "Epoch 13/20, Iteration 253/303, Loss: 0.21917742490768433\n",
      "Epoch 13/20, Iteration 254/303, Loss: 0.144435316324234\n",
      "Epoch 13/20, Iteration 255/303, Loss: 0.13207170367240906\n",
      "Epoch 13/20, Iteration 256/303, Loss: 0.19049662351608276\n",
      "Epoch 13/20, Iteration 257/303, Loss: 0.11670619249343872\n",
      "Epoch 13/20, Iteration 258/303, Loss: 0.2776971161365509\n",
      "Epoch 13/20, Iteration 259/303, Loss: 0.09007822722196579\n",
      "Epoch 13/20, Iteration 260/303, Loss: 0.20492911338806152\n",
      "Epoch 13/20, Iteration 261/303, Loss: 0.33105239272117615\n",
      "Epoch 13/20, Iteration 262/303, Loss: 0.13063450157642365\n",
      "Epoch 13/20, Iteration 263/303, Loss: 0.20834794640541077\n",
      "Epoch 13/20, Iteration 264/303, Loss: 0.38228562474250793\n",
      "Epoch 13/20, Iteration 265/303, Loss: 0.1347232311964035\n",
      "Epoch 13/20, Iteration 266/303, Loss: 0.19092948734760284\n",
      "Epoch 13/20, Iteration 267/303, Loss: 0.1751241683959961\n",
      "Epoch 13/20, Iteration 268/303, Loss: 0.0846373438835144\n",
      "Epoch 13/20, Iteration 269/303, Loss: 0.04779716208577156\n",
      "Epoch 13/20, Iteration 270/303, Loss: 0.06351781636476517\n",
      "Epoch 13/20, Iteration 271/303, Loss: 0.17035053670406342\n",
      "Epoch 13/20, Iteration 272/303, Loss: 0.2355670928955078\n",
      "Epoch 13/20, Iteration 273/303, Loss: 0.23545879125595093\n",
      "Epoch 13/20, Iteration 274/303, Loss: 0.10904452204704285\n",
      "Epoch 13/20, Iteration 275/303, Loss: 0.25174179673194885\n",
      "Epoch 13/20, Iteration 276/303, Loss: 0.2935411036014557\n",
      "Epoch 13/20, Iteration 277/303, Loss: 0.17980647087097168\n",
      "Epoch 13/20, Iteration 278/303, Loss: 0.3638951778411865\n",
      "Epoch 13/20, Iteration 279/303, Loss: 0.06439337879419327\n",
      "Epoch 13/20, Iteration 280/303, Loss: 0.15908318758010864\n",
      "Epoch 13/20, Iteration 281/303, Loss: 0.1943974494934082\n",
      "Epoch 13/20, Iteration 282/303, Loss: 0.12720714509487152\n",
      "Epoch 13/20, Iteration 283/303, Loss: 0.16797460615634918\n",
      "Epoch 13/20, Iteration 284/303, Loss: 0.10844563692808151\n",
      "Epoch 13/20, Iteration 285/303, Loss: 0.2536175549030304\n",
      "Epoch 13/20, Iteration 286/303, Loss: 0.14951245486736298\n",
      "Epoch 13/20, Iteration 287/303, Loss: 0.0723167210817337\n",
      "Epoch 13/20, Iteration 288/303, Loss: 0.11538612097501755\n",
      "Epoch 13/20, Iteration 289/303, Loss: 0.09037874639034271\n",
      "Epoch 13/20, Iteration 290/303, Loss: 0.13070620596408844\n",
      "Epoch 13/20, Iteration 291/303, Loss: 0.18532221019268036\n",
      "Epoch 13/20, Iteration 292/303, Loss: 0.22890979051589966\n",
      "Epoch 13/20, Iteration 293/303, Loss: 0.049517687410116196\n",
      "Epoch 13/20, Iteration 294/303, Loss: 0.12627656757831573\n",
      "Epoch 13/20, Iteration 295/303, Loss: 0.12652000784873962\n",
      "Epoch 13/20, Iteration 296/303, Loss: 0.0647880882024765\n",
      "Epoch 13/20, Iteration 297/303, Loss: 0.2391732931137085\n",
      "Epoch 13/20, Iteration 298/303, Loss: 0.1400168240070343\n",
      "Epoch 13/20, Iteration 299/303, Loss: 0.12583038210868835\n",
      "Epoch 13/20, Iteration 300/303, Loss: 0.05614191293716431\n",
      "Epoch 13/20, Iteration 301/303, Loss: 0.270906925201416\n",
      "Epoch 13/20, Iteration 302/303, Loss: 0.20538347959518433\n",
      "Epoch 13/20, Iteration 303/303, Loss: 0.44360655546188354\n",
      "Epoch 14/20, Iteration 1/303, Loss: 0.17914602160453796\n",
      "Epoch 14/20, Iteration 2/303, Loss: 0.17792944610118866\n",
      "Epoch 14/20, Iteration 3/303, Loss: 0.13750818371772766\n",
      "Epoch 14/20, Iteration 4/303, Loss: 0.06816519796848297\n",
      "Epoch 14/20, Iteration 5/303, Loss: 0.05605241656303406\n",
      "Epoch 14/20, Iteration 6/303, Loss: 0.03718332201242447\n",
      "Epoch 14/20, Iteration 7/303, Loss: 0.0915493443608284\n",
      "Epoch 14/20, Iteration 8/303, Loss: 0.07952746748924255\n",
      "Epoch 14/20, Iteration 9/303, Loss: 0.12056264281272888\n",
      "Epoch 14/20, Iteration 10/303, Loss: 0.15325623750686646\n",
      "Epoch 14/20, Iteration 11/303, Loss: 0.09771907329559326\n",
      "Epoch 14/20, Iteration 12/303, Loss: 0.25206172466278076\n",
      "Epoch 14/20, Iteration 13/303, Loss: 0.11553896963596344\n",
      "Epoch 14/20, Iteration 14/303, Loss: 0.029514480382204056\n",
      "Epoch 14/20, Iteration 15/303, Loss: 0.07259935140609741\n",
      "Epoch 14/20, Iteration 16/303, Loss: 0.058852218091487885\n",
      "Epoch 14/20, Iteration 17/303, Loss: 0.056387774646282196\n",
      "Epoch 14/20, Iteration 18/303, Loss: 0.2611655592918396\n",
      "Epoch 14/20, Iteration 19/303, Loss: 0.12280362844467163\n",
      "Epoch 14/20, Iteration 20/303, Loss: 0.2550307512283325\n",
      "Epoch 14/20, Iteration 21/303, Loss: 0.1498270481824875\n",
      "Epoch 14/20, Iteration 22/303, Loss: 0.10057434439659119\n",
      "Epoch 14/20, Iteration 23/303, Loss: 0.11464112997055054\n",
      "Epoch 14/20, Iteration 24/303, Loss: 0.10847534239292145\n",
      "Epoch 14/20, Iteration 25/303, Loss: 0.059367306530475616\n",
      "Epoch 14/20, Iteration 26/303, Loss: 0.1090443953871727\n",
      "Epoch 14/20, Iteration 27/303, Loss: 0.36507341265678406\n",
      "Epoch 14/20, Iteration 28/303, Loss: 0.11336468160152435\n",
      "Epoch 14/20, Iteration 29/303, Loss: 0.09611567854881287\n",
      "Epoch 14/20, Iteration 30/303, Loss: 0.1261461079120636\n",
      "Epoch 14/20, Iteration 31/303, Loss: 0.09832935780286789\n",
      "Epoch 14/20, Iteration 32/303, Loss: 0.0707474797964096\n",
      "Epoch 14/20, Iteration 33/303, Loss: 0.09844943881034851\n",
      "Epoch 14/20, Iteration 34/303, Loss: 0.18948698043823242\n",
      "Epoch 14/20, Iteration 35/303, Loss: 0.08266294747591019\n",
      "Epoch 14/20, Iteration 36/303, Loss: 0.09935075789690018\n",
      "Epoch 14/20, Iteration 37/303, Loss: 0.07667110860347748\n",
      "Epoch 14/20, Iteration 38/303, Loss: 0.05271192640066147\n",
      "Epoch 14/20, Iteration 39/303, Loss: 0.08995331823825836\n",
      "Epoch 14/20, Iteration 40/303, Loss: 0.0957033634185791\n",
      "Epoch 14/20, Iteration 41/303, Loss: 0.11962367594242096\n",
      "Epoch 14/20, Iteration 42/303, Loss: 0.018987441435456276\n",
      "Epoch 14/20, Iteration 43/303, Loss: 0.07449573278427124\n",
      "Epoch 14/20, Iteration 44/303, Loss: 0.051951758563518524\n",
      "Epoch 14/20, Iteration 45/303, Loss: 0.029810361564159393\n",
      "Epoch 14/20, Iteration 46/303, Loss: 0.185486301779747\n",
      "Epoch 14/20, Iteration 47/303, Loss: 0.06931725144386292\n",
      "Epoch 14/20, Iteration 48/303, Loss: 0.07895655930042267\n",
      "Epoch 14/20, Iteration 49/303, Loss: 0.0977248027920723\n",
      "Epoch 14/20, Iteration 50/303, Loss: 0.06835860759019852\n",
      "Epoch 14/20, Iteration 51/303, Loss: 0.10632903128862381\n",
      "Epoch 14/20, Iteration 52/303, Loss: 0.09195031225681305\n",
      "Epoch 14/20, Iteration 53/303, Loss: 0.04553942009806633\n",
      "Epoch 14/20, Iteration 54/303, Loss: 0.05324212461709976\n",
      "Epoch 14/20, Iteration 55/303, Loss: 0.024164807051420212\n",
      "Epoch 14/20, Iteration 56/303, Loss: 0.027300627902150154\n",
      "Epoch 14/20, Iteration 57/303, Loss: 0.04887017607688904\n",
      "Epoch 14/20, Iteration 58/303, Loss: 0.0636570155620575\n",
      "Epoch 14/20, Iteration 59/303, Loss: 0.13225126266479492\n",
      "Epoch 14/20, Iteration 60/303, Loss: 0.04752540960907936\n",
      "Epoch 14/20, Iteration 61/303, Loss: 0.1524045169353485\n",
      "Epoch 14/20, Iteration 62/303, Loss: 0.18509742617607117\n",
      "Epoch 14/20, Iteration 63/303, Loss: 0.12598854303359985\n",
      "Epoch 14/20, Iteration 64/303, Loss: 0.2858593761920929\n",
      "Epoch 14/20, Iteration 65/303, Loss: 0.20760048925876617\n",
      "Epoch 14/20, Iteration 66/303, Loss: 0.05216613784432411\n",
      "Epoch 14/20, Iteration 67/303, Loss: 0.040886230766773224\n",
      "Epoch 14/20, Iteration 68/303, Loss: 0.09873529523611069\n",
      "Epoch 14/20, Iteration 69/303, Loss: 0.06891637295484543\n",
      "Epoch 14/20, Iteration 70/303, Loss: 0.11529572308063507\n",
      "Epoch 14/20, Iteration 71/303, Loss: 0.09346017241477966\n",
      "Epoch 14/20, Iteration 72/303, Loss: 0.02683592215180397\n",
      "Epoch 14/20, Iteration 73/303, Loss: 0.04522313177585602\n",
      "Epoch 14/20, Iteration 74/303, Loss: 0.27512356638908386\n",
      "Epoch 14/20, Iteration 75/303, Loss: 0.03697337582707405\n",
      "Epoch 14/20, Iteration 76/303, Loss: 0.1457807719707489\n",
      "Epoch 14/20, Iteration 77/303, Loss: 0.14648181200027466\n",
      "Epoch 14/20, Iteration 78/303, Loss: 0.08030440658330917\n",
      "Epoch 14/20, Iteration 79/303, Loss: 0.011172143742442131\n",
      "Epoch 14/20, Iteration 80/303, Loss: 0.0440024808049202\n",
      "Epoch 14/20, Iteration 81/303, Loss: 0.12187883257865906\n",
      "Epoch 14/20, Iteration 82/303, Loss: 0.12705302238464355\n",
      "Epoch 14/20, Iteration 83/303, Loss: 0.04226480796933174\n",
      "Epoch 14/20, Iteration 84/303, Loss: 0.155193492770195\n",
      "Epoch 14/20, Iteration 85/303, Loss: 0.14541883766651154\n",
      "Epoch 14/20, Iteration 86/303, Loss: 0.18616771697998047\n",
      "Epoch 14/20, Iteration 87/303, Loss: 0.02193431742489338\n",
      "Epoch 14/20, Iteration 88/303, Loss: 0.204558864235878\n",
      "Epoch 14/20, Iteration 89/303, Loss: 0.12822358310222626\n",
      "Epoch 14/20, Iteration 90/303, Loss: 0.10971143841743469\n",
      "Epoch 14/20, Iteration 91/303, Loss: 0.07393423467874527\n",
      "Epoch 14/20, Iteration 92/303, Loss: 0.044346075505018234\n",
      "Epoch 14/20, Iteration 93/303, Loss: 0.17264658212661743\n",
      "Epoch 14/20, Iteration 94/303, Loss: 0.24688467383384705\n",
      "Epoch 14/20, Iteration 95/303, Loss: 0.35179173946380615\n",
      "Epoch 14/20, Iteration 96/303, Loss: 0.07127328217029572\n",
      "Epoch 14/20, Iteration 97/303, Loss: 0.06838309019804001\n",
      "Epoch 14/20, Iteration 98/303, Loss: 0.1536821871995926\n",
      "Epoch 14/20, Iteration 99/303, Loss: 0.07561091333627701\n",
      "Epoch 14/20, Iteration 100/303, Loss: 0.09009894728660583\n",
      "Epoch 14/20, Iteration 101/303, Loss: 0.07191096246242523\n",
      "Epoch 14/20, Iteration 102/303, Loss: 0.07316041737794876\n",
      "Epoch 14/20, Iteration 103/303, Loss: 0.15495406091213226\n",
      "Epoch 14/20, Iteration 104/303, Loss: 0.13256120681762695\n",
      "Epoch 14/20, Iteration 105/303, Loss: 0.23884710669517517\n",
      "Epoch 14/20, Iteration 106/303, Loss: 0.22780145704746246\n",
      "Epoch 14/20, Iteration 107/303, Loss: 0.10435165464878082\n",
      "Epoch 14/20, Iteration 108/303, Loss: 0.09336123615503311\n",
      "Epoch 14/20, Iteration 109/303, Loss: 0.11799934506416321\n",
      "Epoch 14/20, Iteration 110/303, Loss: 0.35248443484306335\n",
      "Epoch 14/20, Iteration 111/303, Loss: 0.30775317549705505\n",
      "Epoch 14/20, Iteration 112/303, Loss: 0.08497261255979538\n",
      "Epoch 14/20, Iteration 113/303, Loss: 0.17721667885780334\n",
      "Epoch 14/20, Iteration 114/303, Loss: 0.05343690887093544\n",
      "Epoch 14/20, Iteration 115/303, Loss: 0.15625563263893127\n",
      "Epoch 14/20, Iteration 116/303, Loss: 0.13275857269763947\n",
      "Epoch 14/20, Iteration 117/303, Loss: 0.12197229266166687\n",
      "Epoch 14/20, Iteration 118/303, Loss: 0.043242525309324265\n",
      "Epoch 14/20, Iteration 119/303, Loss: 0.21234992146492004\n",
      "Epoch 14/20, Iteration 120/303, Loss: 0.21236523985862732\n",
      "Epoch 14/20, Iteration 121/303, Loss: 0.030745718628168106\n",
      "Epoch 14/20, Iteration 122/303, Loss: 0.02898171730339527\n",
      "Epoch 14/20, Iteration 123/303, Loss: 0.10977855324745178\n",
      "Epoch 14/20, Iteration 124/303, Loss: 0.0753910169005394\n",
      "Epoch 14/20, Iteration 125/303, Loss: 0.0805436372756958\n",
      "Epoch 14/20, Iteration 126/303, Loss: 0.11306719481945038\n",
      "Epoch 14/20, Iteration 127/303, Loss: 0.12971611320972443\n",
      "Epoch 14/20, Iteration 128/303, Loss: 0.17631275951862335\n",
      "Epoch 14/20, Iteration 129/303, Loss: 0.08608303964138031\n",
      "Epoch 14/20, Iteration 130/303, Loss: 0.06961933523416519\n",
      "Epoch 14/20, Iteration 131/303, Loss: 0.14909040927886963\n",
      "Epoch 14/20, Iteration 132/303, Loss: 0.16851766407489777\n",
      "Epoch 14/20, Iteration 133/303, Loss: 0.16090893745422363\n",
      "Epoch 14/20, Iteration 134/303, Loss: 0.16434592008590698\n",
      "Epoch 14/20, Iteration 135/303, Loss: 0.2618336081504822\n",
      "Epoch 14/20, Iteration 136/303, Loss: 0.11269618570804596\n",
      "Epoch 14/20, Iteration 137/303, Loss: 0.269547700881958\n",
      "Epoch 14/20, Iteration 138/303, Loss: 0.04687201976776123\n",
      "Epoch 14/20, Iteration 139/303, Loss: 0.06349056959152222\n",
      "Epoch 14/20, Iteration 140/303, Loss: 0.23744896054267883\n",
      "Epoch 14/20, Iteration 141/303, Loss: 0.12199407070875168\n",
      "Epoch 14/20, Iteration 142/303, Loss: 0.09534785896539688\n",
      "Epoch 14/20, Iteration 143/303, Loss: 0.12062765657901764\n",
      "Epoch 14/20, Iteration 144/303, Loss: 0.2454802244901657\n",
      "Epoch 14/20, Iteration 145/303, Loss: 0.07033638656139374\n",
      "Epoch 14/20, Iteration 146/303, Loss: 0.06272876262664795\n",
      "Epoch 14/20, Iteration 147/303, Loss: 0.08591417223215103\n",
      "Epoch 14/20, Iteration 148/303, Loss: 0.07897185534238815\n",
      "Epoch 14/20, Iteration 149/303, Loss: 0.17594411969184875\n",
      "Epoch 14/20, Iteration 150/303, Loss: 0.12029841542243958\n",
      "Epoch 14/20, Iteration 151/303, Loss: 0.04745357111096382\n",
      "Epoch 14/20, Iteration 152/303, Loss: 0.07041984796524048\n",
      "Epoch 14/20, Iteration 153/303, Loss: 0.07283078879117966\n",
      "Epoch 14/20, Iteration 154/303, Loss: 0.055385299026966095\n",
      "Epoch 14/20, Iteration 155/303, Loss: 0.035426199436187744\n",
      "Epoch 14/20, Iteration 156/303, Loss: 0.12326231598854065\n",
      "Epoch 14/20, Iteration 157/303, Loss: 0.030335403978824615\n",
      "Epoch 14/20, Iteration 158/303, Loss: 0.1209031417965889\n",
      "Epoch 14/20, Iteration 159/303, Loss: 0.055063143372535706\n",
      "Epoch 14/20, Iteration 160/303, Loss: 0.09552696347236633\n",
      "Epoch 14/20, Iteration 161/303, Loss: 0.12320443987846375\n",
      "Epoch 14/20, Iteration 162/303, Loss: 0.02790861949324608\n",
      "Epoch 14/20, Iteration 163/303, Loss: 0.09726738929748535\n",
      "Epoch 14/20, Iteration 164/303, Loss: 0.15078473091125488\n",
      "Epoch 14/20, Iteration 165/303, Loss: 0.18850219249725342\n",
      "Epoch 14/20, Iteration 166/303, Loss: 0.044188447296619415\n",
      "Epoch 14/20, Iteration 167/303, Loss: 0.1685265600681305\n",
      "Epoch 14/20, Iteration 168/303, Loss: 0.03392820805311203\n",
      "Epoch 14/20, Iteration 169/303, Loss: 0.11564581096172333\n",
      "Epoch 14/20, Iteration 170/303, Loss: 0.07764159142971039\n",
      "Epoch 14/20, Iteration 171/303, Loss: 0.06108728423714638\n",
      "Epoch 14/20, Iteration 172/303, Loss: 0.13765639066696167\n",
      "Epoch 14/20, Iteration 173/303, Loss: 0.18558093905448914\n",
      "Epoch 14/20, Iteration 174/303, Loss: 0.18047447502613068\n",
      "Epoch 14/20, Iteration 175/303, Loss: 0.2278580516576767\n",
      "Epoch 14/20, Iteration 176/303, Loss: 0.23644647002220154\n",
      "Epoch 14/20, Iteration 177/303, Loss: 0.15243904292583466\n",
      "Epoch 14/20, Iteration 178/303, Loss: 0.16664175689220428\n",
      "Epoch 14/20, Iteration 179/303, Loss: 0.339788556098938\n",
      "Epoch 14/20, Iteration 180/303, Loss: 0.2644664943218231\n",
      "Epoch 14/20, Iteration 181/303, Loss: 0.04538594186306\n",
      "Epoch 14/20, Iteration 182/303, Loss: 0.08217489719390869\n",
      "Epoch 14/20, Iteration 183/303, Loss: 0.11343546956777573\n",
      "Epoch 14/20, Iteration 184/303, Loss: 0.11864292621612549\n",
      "Epoch 14/20, Iteration 185/303, Loss: 0.06486330181360245\n",
      "Epoch 14/20, Iteration 186/303, Loss: 0.1505487859249115\n",
      "Epoch 14/20, Iteration 187/303, Loss: 0.13160377740859985\n",
      "Epoch 14/20, Iteration 188/303, Loss: 0.10870367288589478\n",
      "Epoch 14/20, Iteration 189/303, Loss: 0.1642727106809616\n",
      "Epoch 14/20, Iteration 190/303, Loss: 0.11689992994070053\n",
      "Epoch 14/20, Iteration 191/303, Loss: 0.052972495555877686\n",
      "Epoch 14/20, Iteration 192/303, Loss: 0.1885957270860672\n",
      "Epoch 14/20, Iteration 193/303, Loss: 0.05298823118209839\n",
      "Epoch 14/20, Iteration 194/303, Loss: 0.04003971815109253\n",
      "Epoch 14/20, Iteration 195/303, Loss: 0.13034121692180634\n",
      "Epoch 14/20, Iteration 196/303, Loss: 0.06385447829961777\n",
      "Epoch 14/20, Iteration 197/303, Loss: 0.09882084280252457\n",
      "Epoch 14/20, Iteration 198/303, Loss: 0.08216065913438797\n",
      "Epoch 14/20, Iteration 199/303, Loss: 0.013769603334367275\n",
      "Epoch 14/20, Iteration 200/303, Loss: 0.054840803146362305\n",
      "Epoch 14/20, Iteration 201/303, Loss: 0.13467064499855042\n",
      "Epoch 14/20, Iteration 202/303, Loss: 0.08158264309167862\n",
      "Epoch 14/20, Iteration 203/303, Loss: 0.1928805708885193\n",
      "Epoch 14/20, Iteration 204/303, Loss: 0.1471877098083496\n",
      "Epoch 14/20, Iteration 205/303, Loss: 0.2096063643693924\n",
      "Epoch 14/20, Iteration 206/303, Loss: 0.12163081765174866\n",
      "Epoch 14/20, Iteration 207/303, Loss: 0.10474507510662079\n",
      "Epoch 14/20, Iteration 208/303, Loss: 0.0518546998500824\n",
      "Epoch 14/20, Iteration 209/303, Loss: 0.2635936439037323\n",
      "Epoch 14/20, Iteration 210/303, Loss: 0.44922709465026855\n",
      "Epoch 14/20, Iteration 211/303, Loss: 0.3344888985157013\n",
      "Epoch 14/20, Iteration 212/303, Loss: 0.11314662545919418\n",
      "Epoch 14/20, Iteration 213/303, Loss: 0.1688229739665985\n",
      "Epoch 14/20, Iteration 214/303, Loss: 0.15784956514835358\n",
      "Epoch 14/20, Iteration 215/303, Loss: 0.1944473385810852\n",
      "Epoch 14/20, Iteration 216/303, Loss: 0.18880204856395721\n",
      "Epoch 14/20, Iteration 217/303, Loss: 0.14025582373142242\n",
      "Epoch 14/20, Iteration 218/303, Loss: 0.2329738736152649\n",
      "Epoch 14/20, Iteration 219/303, Loss: 0.07848083972930908\n",
      "Epoch 14/20, Iteration 220/303, Loss: 0.11516862362623215\n",
      "Epoch 14/20, Iteration 221/303, Loss: 0.06569001823663712\n",
      "Epoch 14/20, Iteration 222/303, Loss: 0.050345245748758316\n",
      "Epoch 14/20, Iteration 223/303, Loss: 0.1523159295320511\n",
      "Epoch 14/20, Iteration 224/303, Loss: 0.08628810942173004\n",
      "Epoch 14/20, Iteration 225/303, Loss: 0.14394445717334747\n",
      "Epoch 14/20, Iteration 226/303, Loss: 0.02031754143536091\n",
      "Epoch 14/20, Iteration 227/303, Loss: 0.2614075541496277\n",
      "Epoch 14/20, Iteration 228/303, Loss: 0.2368641048669815\n",
      "Epoch 14/20, Iteration 229/303, Loss: 0.24437695741653442\n",
      "Epoch 14/20, Iteration 230/303, Loss: 0.10848134756088257\n",
      "Epoch 14/20, Iteration 231/303, Loss: 0.08666698634624481\n",
      "Epoch 14/20, Iteration 232/303, Loss: 0.12597538530826569\n",
      "Epoch 14/20, Iteration 233/303, Loss: 0.10668475180864334\n",
      "Epoch 14/20, Iteration 234/303, Loss: 0.03427446261048317\n",
      "Epoch 14/20, Iteration 235/303, Loss: 0.04579530656337738\n",
      "Epoch 14/20, Iteration 236/303, Loss: 0.061841048300266266\n",
      "Epoch 14/20, Iteration 237/303, Loss: 0.07750158756971359\n",
      "Epoch 14/20, Iteration 238/303, Loss: 0.10789211094379425\n",
      "Epoch 14/20, Iteration 239/303, Loss: 0.04347256198525429\n",
      "Epoch 14/20, Iteration 240/303, Loss: 0.02614716626703739\n",
      "Epoch 14/20, Iteration 241/303, Loss: 0.026529815047979355\n",
      "Epoch 14/20, Iteration 242/303, Loss: 0.04060596972703934\n",
      "Epoch 14/20, Iteration 243/303, Loss: 0.023878244683146477\n",
      "Epoch 14/20, Iteration 244/303, Loss: 0.10326924175024033\n",
      "Epoch 14/20, Iteration 245/303, Loss: 0.15931031107902527\n",
      "Epoch 14/20, Iteration 246/303, Loss: 0.11239217966794968\n",
      "Epoch 14/20, Iteration 247/303, Loss: 0.20805524289608002\n",
      "Epoch 14/20, Iteration 248/303, Loss: 0.07707341760396957\n",
      "Epoch 14/20, Iteration 249/303, Loss: 0.12941262125968933\n",
      "Epoch 14/20, Iteration 250/303, Loss: 0.12610888481140137\n",
      "Epoch 14/20, Iteration 251/303, Loss: 0.18397189676761627\n",
      "Epoch 14/20, Iteration 252/303, Loss: 0.14643524587154388\n",
      "Epoch 14/20, Iteration 253/303, Loss: 0.03083057701587677\n",
      "Epoch 14/20, Iteration 254/303, Loss: 0.05328161641955376\n",
      "Epoch 14/20, Iteration 255/303, Loss: 0.05925667658448219\n",
      "Epoch 14/20, Iteration 256/303, Loss: 0.061677563935518265\n",
      "Epoch 14/20, Iteration 257/303, Loss: 0.19421251118183136\n",
      "Epoch 14/20, Iteration 258/303, Loss: 0.19302654266357422\n",
      "Epoch 14/20, Iteration 259/303, Loss: 0.32720762491226196\n",
      "Epoch 14/20, Iteration 260/303, Loss: 0.8382591605186462\n",
      "Epoch 14/20, Iteration 261/303, Loss: 0.5207169651985168\n",
      "Epoch 14/20, Iteration 262/303, Loss: 0.271637499332428\n",
      "Epoch 14/20, Iteration 263/303, Loss: 0.2590094208717346\n",
      "Epoch 14/20, Iteration 264/303, Loss: 0.13023556768894196\n",
      "Epoch 14/20, Iteration 265/303, Loss: 0.19417011737823486\n",
      "Epoch 14/20, Iteration 266/303, Loss: 0.12929844856262207\n",
      "Epoch 14/20, Iteration 267/303, Loss: 0.11378030478954315\n",
      "Epoch 14/20, Iteration 268/303, Loss: 0.17013591527938843\n",
      "Epoch 14/20, Iteration 269/303, Loss: 0.16530272364616394\n",
      "Epoch 14/20, Iteration 270/303, Loss: 0.1747978776693344\n",
      "Epoch 14/20, Iteration 271/303, Loss: 0.23050418496131897\n",
      "Epoch 14/20, Iteration 272/303, Loss: 0.15738698840141296\n",
      "Epoch 14/20, Iteration 273/303, Loss: 0.07387332618236542\n",
      "Epoch 14/20, Iteration 274/303, Loss: 0.08517830818891525\n",
      "Epoch 14/20, Iteration 275/303, Loss: 0.16417230665683746\n",
      "Epoch 14/20, Iteration 276/303, Loss: 0.10160106420516968\n",
      "Epoch 14/20, Iteration 277/303, Loss: 0.0785779282450676\n",
      "Epoch 14/20, Iteration 278/303, Loss: 0.06664931774139404\n",
      "Epoch 14/20, Iteration 279/303, Loss: 0.10705330967903137\n",
      "Epoch 14/20, Iteration 280/303, Loss: 0.056939639151096344\n",
      "Epoch 14/20, Iteration 281/303, Loss: 0.04095064476132393\n",
      "Epoch 14/20, Iteration 282/303, Loss: 0.3608991801738739\n",
      "Epoch 14/20, Iteration 283/303, Loss: 0.31481271982192993\n",
      "Epoch 14/20, Iteration 284/303, Loss: 0.32952988147735596\n",
      "Epoch 14/20, Iteration 285/303, Loss: 0.36384981870651245\n",
      "Epoch 14/20, Iteration 286/303, Loss: 0.320439875125885\n",
      "Epoch 14/20, Iteration 287/303, Loss: 0.24687816202640533\n",
      "Epoch 14/20, Iteration 288/303, Loss: 0.23598091304302216\n",
      "Epoch 14/20, Iteration 289/303, Loss: 0.26510724425315857\n",
      "Epoch 14/20, Iteration 290/303, Loss: 0.18774543702602386\n",
      "Epoch 14/20, Iteration 291/303, Loss: 0.10765191912651062\n",
      "Epoch 14/20, Iteration 292/303, Loss: 0.10589657723903656\n",
      "Epoch 14/20, Iteration 293/303, Loss: 0.1551397293806076\n",
      "Epoch 14/20, Iteration 294/303, Loss: 0.083889439702034\n",
      "Epoch 14/20, Iteration 295/303, Loss: 0.22200451791286469\n",
      "Epoch 14/20, Iteration 296/303, Loss: 0.06266520917415619\n",
      "Epoch 14/20, Iteration 297/303, Loss: 0.18343514204025269\n",
      "Epoch 14/20, Iteration 298/303, Loss: 0.15899620950222015\n",
      "Epoch 14/20, Iteration 299/303, Loss: 0.08762016892433167\n",
      "Epoch 14/20, Iteration 300/303, Loss: 0.138882115483284\n",
      "Epoch 14/20, Iteration 301/303, Loss: 0.1022859662771225\n",
      "Epoch 14/20, Iteration 302/303, Loss: 0.06788952648639679\n",
      "Epoch 14/20, Iteration 303/303, Loss: 0.0996105968952179\n",
      "Epoch 15/20, Iteration 1/303, Loss: 0.19917736947536469\n",
      "Epoch 15/20, Iteration 2/303, Loss: 0.0629689171910286\n",
      "Epoch 15/20, Iteration 3/303, Loss: 0.1387922763824463\n",
      "Epoch 15/20, Iteration 4/303, Loss: 0.022472554817795753\n",
      "Epoch 15/20, Iteration 5/303, Loss: 0.07269614934921265\n",
      "Epoch 15/20, Iteration 6/303, Loss: 0.051882416009902954\n",
      "Epoch 15/20, Iteration 7/303, Loss: 0.06483086943626404\n",
      "Epoch 15/20, Iteration 8/303, Loss: 0.038843199610710144\n",
      "Epoch 15/20, Iteration 9/303, Loss: 0.08206257969141006\n",
      "Epoch 15/20, Iteration 10/303, Loss: 0.058875542134046555\n",
      "Epoch 15/20, Iteration 11/303, Loss: 0.01573820598423481\n",
      "Epoch 15/20, Iteration 12/303, Loss: 0.12186990678310394\n",
      "Epoch 15/20, Iteration 13/303, Loss: 0.12187351286411285\n",
      "Epoch 15/20, Iteration 14/303, Loss: 0.0384049229323864\n",
      "Epoch 15/20, Iteration 15/303, Loss: 0.0544075146317482\n",
      "Epoch 15/20, Iteration 16/303, Loss: 0.06647273153066635\n",
      "Epoch 15/20, Iteration 17/303, Loss: 0.09054558724164963\n",
      "Epoch 15/20, Iteration 18/303, Loss: 0.07912392914295197\n",
      "Epoch 15/20, Iteration 19/303, Loss: 0.06767638027667999\n",
      "Epoch 15/20, Iteration 20/303, Loss: 0.07484394311904907\n",
      "Epoch 15/20, Iteration 21/303, Loss: 0.020021282136440277\n",
      "Epoch 15/20, Iteration 22/303, Loss: 0.021825255826115608\n",
      "Epoch 15/20, Iteration 23/303, Loss: 0.04007815942168236\n",
      "Epoch 15/20, Iteration 24/303, Loss: 0.0705447867512703\n",
      "Epoch 15/20, Iteration 25/303, Loss: 0.10414955019950867\n",
      "Epoch 15/20, Iteration 26/303, Loss: 0.054167747497558594\n",
      "Epoch 15/20, Iteration 27/303, Loss: 0.018808234483003616\n",
      "Epoch 15/20, Iteration 28/303, Loss: 0.03198276087641716\n",
      "Epoch 15/20, Iteration 29/303, Loss: 0.04958472400903702\n",
      "Epoch 15/20, Iteration 30/303, Loss: 0.11498598009347916\n",
      "Epoch 15/20, Iteration 31/303, Loss: 0.043771304190158844\n",
      "Epoch 15/20, Iteration 32/303, Loss: 0.029785675927996635\n",
      "Epoch 15/20, Iteration 33/303, Loss: 0.06676680594682693\n",
      "Epoch 15/20, Iteration 34/303, Loss: 0.0335683673620224\n",
      "Epoch 15/20, Iteration 35/303, Loss: 0.038412149995565414\n",
      "Epoch 15/20, Iteration 36/303, Loss: 0.11661970615386963\n",
      "Epoch 15/20, Iteration 37/303, Loss: 0.09282800555229187\n",
      "Epoch 15/20, Iteration 38/303, Loss: 0.05429941788315773\n",
      "Epoch 15/20, Iteration 39/303, Loss: 0.05933251231908798\n",
      "Epoch 15/20, Iteration 40/303, Loss: 0.03599419444799423\n",
      "Epoch 15/20, Iteration 41/303, Loss: 0.0190141461789608\n",
      "Epoch 15/20, Iteration 42/303, Loss: 0.039554696530103683\n",
      "Epoch 15/20, Iteration 43/303, Loss: 0.06283207982778549\n",
      "Epoch 15/20, Iteration 44/303, Loss: 0.1775413602590561\n",
      "Epoch 15/20, Iteration 45/303, Loss: 0.1398562639951706\n",
      "Epoch 15/20, Iteration 46/303, Loss: 0.056002479046583176\n",
      "Epoch 15/20, Iteration 47/303, Loss: 0.13916808366775513\n",
      "Epoch 15/20, Iteration 48/303, Loss: 0.11840273439884186\n",
      "Epoch 15/20, Iteration 49/303, Loss: 0.034922514110803604\n",
      "Epoch 15/20, Iteration 50/303, Loss: 0.08578158915042877\n",
      "Epoch 15/20, Iteration 51/303, Loss: 0.021533802151679993\n",
      "Epoch 15/20, Iteration 52/303, Loss: 0.1248631700873375\n",
      "Epoch 15/20, Iteration 53/303, Loss: 0.02494485303759575\n",
      "Epoch 15/20, Iteration 54/303, Loss: 0.20382514595985413\n",
      "Epoch 15/20, Iteration 55/303, Loss: 0.022585857659578323\n",
      "Epoch 15/20, Iteration 56/303, Loss: 0.03219187259674072\n",
      "Epoch 15/20, Iteration 57/303, Loss: 0.033954259008169174\n",
      "Epoch 15/20, Iteration 58/303, Loss: 0.03783787041902542\n",
      "Epoch 15/20, Iteration 59/303, Loss: 0.2233969271183014\n",
      "Epoch 15/20, Iteration 60/303, Loss: 0.056568730622529984\n",
      "Epoch 15/20, Iteration 61/303, Loss: 0.11354511231184006\n",
      "Epoch 15/20, Iteration 62/303, Loss: 0.10398369282484055\n",
      "Epoch 15/20, Iteration 63/303, Loss: 0.05045192688703537\n",
      "Epoch 15/20, Iteration 64/303, Loss: 0.02264638990163803\n",
      "Epoch 15/20, Iteration 65/303, Loss: 0.03932737186551094\n",
      "Epoch 15/20, Iteration 66/303, Loss: 0.042050525546073914\n",
      "Epoch 15/20, Iteration 67/303, Loss: 0.028620116412639618\n",
      "Epoch 15/20, Iteration 68/303, Loss: 0.03731337934732437\n",
      "Epoch 15/20, Iteration 69/303, Loss: 0.12671619653701782\n",
      "Epoch 15/20, Iteration 70/303, Loss: 0.09125998616218567\n",
      "Epoch 15/20, Iteration 71/303, Loss: 0.0347243957221508\n",
      "Epoch 15/20, Iteration 72/303, Loss: 0.11717749387025833\n",
      "Epoch 15/20, Iteration 73/303, Loss: 0.06718923151493073\n",
      "Epoch 15/20, Iteration 74/303, Loss: 0.031936779618263245\n",
      "Epoch 15/20, Iteration 75/303, Loss: 0.01736765168607235\n",
      "Epoch 15/20, Iteration 76/303, Loss: 0.03334648162126541\n",
      "Epoch 15/20, Iteration 77/303, Loss: 0.02845882438123226\n",
      "Epoch 15/20, Iteration 78/303, Loss: 0.08678223192691803\n",
      "Epoch 15/20, Iteration 79/303, Loss: 0.1854678988456726\n",
      "Epoch 15/20, Iteration 80/303, Loss: 0.03556439280509949\n",
      "Epoch 15/20, Iteration 81/303, Loss: 0.10193010419607162\n",
      "Epoch 15/20, Iteration 82/303, Loss: 0.07518254220485687\n",
      "Epoch 15/20, Iteration 83/303, Loss: 0.21144288778305054\n",
      "Epoch 15/20, Iteration 84/303, Loss: 0.023691661655902863\n",
      "Epoch 15/20, Iteration 85/303, Loss: 0.0680740550160408\n",
      "Epoch 15/20, Iteration 86/303, Loss: 0.08617938309907913\n",
      "Epoch 15/20, Iteration 87/303, Loss: 0.06578867882490158\n",
      "Epoch 15/20, Iteration 88/303, Loss: 0.07902369648218155\n",
      "Epoch 15/20, Iteration 89/303, Loss: 0.020476629957556725\n",
      "Epoch 15/20, Iteration 90/303, Loss: 0.007820140570402145\n",
      "Epoch 15/20, Iteration 91/303, Loss: 0.04691682010889053\n",
      "Epoch 15/20, Iteration 92/303, Loss: 0.09699603915214539\n",
      "Epoch 15/20, Iteration 93/303, Loss: 0.06996048986911774\n",
      "Epoch 15/20, Iteration 94/303, Loss: 0.03967403247952461\n",
      "Epoch 15/20, Iteration 95/303, Loss: 0.03869656100869179\n",
      "Epoch 15/20, Iteration 96/303, Loss: 0.04681171104311943\n",
      "Epoch 15/20, Iteration 97/303, Loss: 0.022432362660765648\n",
      "Epoch 15/20, Iteration 98/303, Loss: 0.22073234617710114\n",
      "Epoch 15/20, Iteration 99/303, Loss: 0.07578065246343613\n",
      "Epoch 15/20, Iteration 100/303, Loss: 0.09196650236845016\n",
      "Epoch 15/20, Iteration 101/303, Loss: 0.03427227586507797\n",
      "Epoch 15/20, Iteration 102/303, Loss: 0.03746826574206352\n",
      "Epoch 15/20, Iteration 103/303, Loss: 0.04454663023352623\n",
      "Epoch 15/20, Iteration 104/303, Loss: 0.03289761021733284\n",
      "Epoch 15/20, Iteration 105/303, Loss: 0.02110196277499199\n",
      "Epoch 15/20, Iteration 106/303, Loss: 0.09584857523441315\n",
      "Epoch 15/20, Iteration 107/303, Loss: 0.036745186895132065\n",
      "Epoch 15/20, Iteration 108/303, Loss: 0.06624215096235275\n",
      "Epoch 15/20, Iteration 109/303, Loss: 0.15819072723388672\n",
      "Epoch 15/20, Iteration 110/303, Loss: 0.23984116315841675\n",
      "Epoch 15/20, Iteration 111/303, Loss: 0.06299854815006256\n",
      "Epoch 15/20, Iteration 112/303, Loss: 0.1035904809832573\n",
      "Epoch 15/20, Iteration 113/303, Loss: 0.04607382416725159\n",
      "Epoch 15/20, Iteration 114/303, Loss: 0.06535808742046356\n",
      "Epoch 15/20, Iteration 115/303, Loss: 0.029977142810821533\n",
      "Epoch 15/20, Iteration 116/303, Loss: 0.07158729434013367\n",
      "Epoch 15/20, Iteration 117/303, Loss: 0.03571412339806557\n",
      "Epoch 15/20, Iteration 118/303, Loss: 0.022090967744588852\n",
      "Epoch 15/20, Iteration 119/303, Loss: 0.054895929992198944\n",
      "Epoch 15/20, Iteration 120/303, Loss: 0.05787312611937523\n",
      "Epoch 15/20, Iteration 121/303, Loss: 0.09632107615470886\n",
      "Epoch 15/20, Iteration 122/303, Loss: 0.023340243846178055\n",
      "Epoch 15/20, Iteration 123/303, Loss: 0.11091487854719162\n",
      "Epoch 15/20, Iteration 124/303, Loss: 0.17744474112987518\n",
      "Epoch 15/20, Iteration 125/303, Loss: 0.027166729792952538\n",
      "Epoch 15/20, Iteration 126/303, Loss: 0.11275249719619751\n",
      "Epoch 15/20, Iteration 127/303, Loss: 0.024896495044231415\n",
      "Epoch 15/20, Iteration 128/303, Loss: 0.026709459722042084\n",
      "Epoch 15/20, Iteration 129/303, Loss: 0.04727325960993767\n",
      "Epoch 15/20, Iteration 130/303, Loss: 0.09283112734556198\n",
      "Epoch 15/20, Iteration 131/303, Loss: 0.1606346219778061\n",
      "Epoch 15/20, Iteration 132/303, Loss: 0.0665072500705719\n",
      "Epoch 15/20, Iteration 133/303, Loss: 0.025586573407053947\n",
      "Epoch 15/20, Iteration 134/303, Loss: 0.04283391311764717\n",
      "Epoch 15/20, Iteration 135/303, Loss: 0.09952302277088165\n",
      "Epoch 15/20, Iteration 136/303, Loss: 0.021257737651467323\n",
      "Epoch 15/20, Iteration 137/303, Loss: 0.022627566009759903\n",
      "Epoch 15/20, Iteration 138/303, Loss: 0.08002505451440811\n",
      "Epoch 15/20, Iteration 139/303, Loss: 0.026004737243056297\n",
      "Epoch 15/20, Iteration 140/303, Loss: 0.10027027130126953\n",
      "Epoch 15/20, Iteration 141/303, Loss: 0.0358809158205986\n",
      "Epoch 15/20, Iteration 142/303, Loss: 0.014618529006838799\n",
      "Epoch 15/20, Iteration 143/303, Loss: 0.12872537970542908\n",
      "Epoch 15/20, Iteration 144/303, Loss: 0.06864455342292786\n",
      "Epoch 15/20, Iteration 145/303, Loss: 0.17184926569461823\n",
      "Epoch 15/20, Iteration 146/303, Loss: 0.024462763220071793\n",
      "Epoch 15/20, Iteration 147/303, Loss: 0.022111402824521065\n",
      "Epoch 15/20, Iteration 148/303, Loss: 0.12850847840309143\n",
      "Epoch 15/20, Iteration 149/303, Loss: 0.22839638590812683\n",
      "Epoch 15/20, Iteration 150/303, Loss: 0.09981182962656021\n",
      "Epoch 15/20, Iteration 151/303, Loss: 0.04645777866244316\n",
      "Epoch 15/20, Iteration 152/303, Loss: 0.028473665937781334\n",
      "Epoch 15/20, Iteration 153/303, Loss: 0.0598510280251503\n",
      "Epoch 15/20, Iteration 154/303, Loss: 0.16601698100566864\n",
      "Epoch 15/20, Iteration 155/303, Loss: 0.06218262389302254\n",
      "Epoch 15/20, Iteration 156/303, Loss: 0.03210612013936043\n",
      "Epoch 15/20, Iteration 157/303, Loss: 0.10375730693340302\n",
      "Epoch 15/20, Iteration 158/303, Loss: 0.08808843791484833\n",
      "Epoch 15/20, Iteration 159/303, Loss: 0.021406112238764763\n",
      "Epoch 15/20, Iteration 160/303, Loss: 0.09286321699619293\n",
      "Epoch 15/20, Iteration 161/303, Loss: 0.054654330015182495\n",
      "Epoch 15/20, Iteration 162/303, Loss: 0.02501147799193859\n",
      "Epoch 15/20, Iteration 163/303, Loss: 0.007858163677155972\n",
      "Epoch 15/20, Iteration 164/303, Loss: 0.09653852880001068\n",
      "Epoch 15/20, Iteration 165/303, Loss: 0.1435386687517166\n",
      "Epoch 15/20, Iteration 166/303, Loss: 0.05150970444083214\n",
      "Epoch 15/20, Iteration 167/303, Loss: 0.12229559570550919\n",
      "Epoch 15/20, Iteration 168/303, Loss: 0.035960759967565536\n",
      "Epoch 15/20, Iteration 169/303, Loss: 0.012159951031208038\n",
      "Epoch 15/20, Iteration 170/303, Loss: 0.03841300308704376\n",
      "Epoch 15/20, Iteration 171/303, Loss: 0.03774602711200714\n",
      "Epoch 15/20, Iteration 172/303, Loss: 0.015442555770277977\n",
      "Epoch 15/20, Iteration 173/303, Loss: 0.11598698794841766\n",
      "Epoch 15/20, Iteration 174/303, Loss: 0.1393316090106964\n",
      "Epoch 15/20, Iteration 175/303, Loss: 0.15789158642292023\n",
      "Epoch 15/20, Iteration 176/303, Loss: 0.2986356317996979\n",
      "Epoch 15/20, Iteration 177/303, Loss: 0.45659106969833374\n",
      "Epoch 15/20, Iteration 178/303, Loss: 0.6353654861450195\n",
      "Epoch 15/20, Iteration 179/303, Loss: 0.11779148876667023\n",
      "Epoch 15/20, Iteration 180/303, Loss: 0.12109342962503433\n",
      "Epoch 15/20, Iteration 181/303, Loss: 0.47650691866874695\n",
      "Epoch 15/20, Iteration 182/303, Loss: 0.5234177112579346\n",
      "Epoch 15/20, Iteration 183/303, Loss: 0.19327938556671143\n",
      "Epoch 15/20, Iteration 184/303, Loss: 0.0887937843799591\n",
      "Epoch 15/20, Iteration 185/303, Loss: 0.10231678187847137\n",
      "Epoch 15/20, Iteration 186/303, Loss: 0.11791114509105682\n",
      "Epoch 15/20, Iteration 187/303, Loss: 0.07694219052791595\n",
      "Epoch 15/20, Iteration 188/303, Loss: 0.05041046440601349\n",
      "Epoch 15/20, Iteration 189/303, Loss: 0.06882233917713165\n",
      "Epoch 15/20, Iteration 190/303, Loss: 0.10013903677463531\n",
      "Epoch 15/20, Iteration 191/303, Loss: 0.08819931745529175\n",
      "Epoch 15/20, Iteration 192/303, Loss: 0.06400810927152634\n",
      "Epoch 15/20, Iteration 193/303, Loss: 0.14205627143383026\n",
      "Epoch 15/20, Iteration 194/303, Loss: 0.08026216924190521\n",
      "Epoch 15/20, Iteration 195/303, Loss: 0.11420901119709015\n",
      "Epoch 15/20, Iteration 196/303, Loss: 0.13099175691604614\n",
      "Epoch 15/20, Iteration 197/303, Loss: 0.2062707245349884\n",
      "Epoch 15/20, Iteration 198/303, Loss: 0.06214038282632828\n",
      "Epoch 15/20, Iteration 199/303, Loss: 0.08665037900209427\n",
      "Epoch 15/20, Iteration 200/303, Loss: 0.0714690089225769\n",
      "Epoch 15/20, Iteration 201/303, Loss: 0.048837628215551376\n",
      "Epoch 15/20, Iteration 202/303, Loss: 0.18408800661563873\n",
      "Epoch 15/20, Iteration 203/303, Loss: 0.06758274883031845\n",
      "Epoch 15/20, Iteration 204/303, Loss: 0.0647297129034996\n",
      "Epoch 15/20, Iteration 205/303, Loss: 0.16842667758464813\n",
      "Epoch 15/20, Iteration 206/303, Loss: 0.24084976315498352\n",
      "Epoch 15/20, Iteration 207/303, Loss: 0.07849858701229095\n",
      "Epoch 15/20, Iteration 208/303, Loss: 0.051052600145339966\n",
      "Epoch 15/20, Iteration 209/303, Loss: 0.056565701961517334\n",
      "Epoch 15/20, Iteration 210/303, Loss: 0.09963157027959824\n",
      "Epoch 15/20, Iteration 211/303, Loss: 0.034205999225378036\n",
      "Epoch 15/20, Iteration 212/303, Loss: 0.15453645586967468\n",
      "Epoch 15/20, Iteration 213/303, Loss: 0.1405380666255951\n",
      "Epoch 15/20, Iteration 214/303, Loss: 0.01403533574193716\n",
      "Epoch 15/20, Iteration 215/303, Loss: 0.10948236286640167\n",
      "Epoch 15/20, Iteration 216/303, Loss: 0.05751672759652138\n",
      "Epoch 15/20, Iteration 217/303, Loss: 0.08200712502002716\n",
      "Epoch 15/20, Iteration 218/303, Loss: 0.2949869930744171\n",
      "Epoch 15/20, Iteration 219/303, Loss: 0.2677915394306183\n",
      "Epoch 15/20, Iteration 220/303, Loss: 0.2248331904411316\n",
      "Epoch 15/20, Iteration 221/303, Loss: 0.18091782927513123\n",
      "Epoch 15/20, Iteration 222/303, Loss: 0.12051843106746674\n",
      "Epoch 15/20, Iteration 223/303, Loss: 0.1330680549144745\n",
      "Epoch 15/20, Iteration 224/303, Loss: 0.21885812282562256\n",
      "Epoch 15/20, Iteration 225/303, Loss: 0.07292705029249191\n",
      "Epoch 15/20, Iteration 226/303, Loss: 0.06978295743465424\n",
      "Epoch 15/20, Iteration 227/303, Loss: 0.06078977882862091\n",
      "Epoch 15/20, Iteration 228/303, Loss: 0.10919776558876038\n",
      "Epoch 15/20, Iteration 229/303, Loss: 0.08496232330799103\n",
      "Epoch 15/20, Iteration 230/303, Loss: 0.08984781801700592\n",
      "Epoch 15/20, Iteration 231/303, Loss: 0.11894591897726059\n",
      "Epoch 15/20, Iteration 232/303, Loss: 0.06157665699720383\n",
      "Epoch 15/20, Iteration 233/303, Loss: 0.0675315260887146\n",
      "Epoch 15/20, Iteration 234/303, Loss: 0.03530091419816017\n",
      "Epoch 15/20, Iteration 235/303, Loss: 0.18796315789222717\n",
      "Epoch 15/20, Iteration 236/303, Loss: 0.14437353610992432\n",
      "Epoch 15/20, Iteration 237/303, Loss: 0.14985980093479156\n",
      "Epoch 15/20, Iteration 238/303, Loss: 0.4210629165172577\n",
      "Epoch 15/20, Iteration 239/303, Loss: 0.17005154490470886\n",
      "Epoch 15/20, Iteration 240/303, Loss: 0.059274666011333466\n",
      "Epoch 15/20, Iteration 241/303, Loss: 0.2382570505142212\n",
      "Epoch 15/20, Iteration 242/303, Loss: 0.2545212209224701\n",
      "Epoch 15/20, Iteration 243/303, Loss: 0.05360839143395424\n",
      "Epoch 15/20, Iteration 244/303, Loss: 0.060370925813913345\n",
      "Epoch 15/20, Iteration 245/303, Loss: 0.4021391272544861\n",
      "Epoch 15/20, Iteration 246/303, Loss: 0.22584521770477295\n",
      "Epoch 15/20, Iteration 247/303, Loss: 0.07542148977518082\n",
      "Epoch 15/20, Iteration 248/303, Loss: 0.06059960648417473\n",
      "Epoch 15/20, Iteration 249/303, Loss: 0.2688046991825104\n",
      "Epoch 15/20, Iteration 250/303, Loss: 0.04956645146012306\n",
      "Epoch 15/20, Iteration 251/303, Loss: 0.09104481339454651\n",
      "Epoch 15/20, Iteration 252/303, Loss: 0.029536008834838867\n",
      "Epoch 15/20, Iteration 253/303, Loss: 0.0622880756855011\n",
      "Epoch 15/20, Iteration 254/303, Loss: 0.04275402054190636\n",
      "Epoch 15/20, Iteration 255/303, Loss: 0.18228861689567566\n",
      "Epoch 15/20, Iteration 256/303, Loss: 0.06721321493387222\n",
      "Epoch 15/20, Iteration 257/303, Loss: 0.12843286991119385\n",
      "Epoch 15/20, Iteration 258/303, Loss: 0.07973966002464294\n",
      "Epoch 15/20, Iteration 259/303, Loss: 0.05503902584314346\n",
      "Epoch 15/20, Iteration 260/303, Loss: 0.13450175523757935\n",
      "Epoch 15/20, Iteration 261/303, Loss: 0.20528404414653778\n",
      "Epoch 15/20, Iteration 262/303, Loss: 0.06862419843673706\n",
      "Epoch 15/20, Iteration 263/303, Loss: 0.13729140162467957\n",
      "Epoch 15/20, Iteration 264/303, Loss: 0.00946034025400877\n",
      "Epoch 15/20, Iteration 265/303, Loss: 0.09301616996526718\n",
      "Epoch 15/20, Iteration 266/303, Loss: 0.20102918148040771\n",
      "Epoch 15/20, Iteration 267/303, Loss: 0.06373152136802673\n",
      "Epoch 15/20, Iteration 268/303, Loss: 0.16129818558692932\n",
      "Epoch 15/20, Iteration 269/303, Loss: 0.05823182314634323\n",
      "Epoch 15/20, Iteration 270/303, Loss: 0.18514399230480194\n",
      "Epoch 15/20, Iteration 271/303, Loss: 0.053498245775699615\n",
      "Epoch 15/20, Iteration 272/303, Loss: 0.09533598273992538\n",
      "Epoch 15/20, Iteration 273/303, Loss: 0.0389646552503109\n",
      "Epoch 15/20, Iteration 274/303, Loss: 0.07291577011346817\n",
      "Epoch 15/20, Iteration 275/303, Loss: 0.07158491760492325\n",
      "Epoch 15/20, Iteration 276/303, Loss: 0.09915591776371002\n",
      "Epoch 15/20, Iteration 277/303, Loss: 0.09893475472927094\n",
      "Epoch 15/20, Iteration 278/303, Loss: 0.03805511072278023\n",
      "Epoch 15/20, Iteration 279/303, Loss: 0.12310986965894699\n",
      "Epoch 15/20, Iteration 280/303, Loss: 0.058570533990859985\n",
      "Epoch 15/20, Iteration 281/303, Loss: 0.07539824396371841\n",
      "Epoch 15/20, Iteration 282/303, Loss: 0.05709920823574066\n",
      "Epoch 15/20, Iteration 283/303, Loss: 0.039532408118247986\n",
      "Epoch 15/20, Iteration 284/303, Loss: 0.07895919680595398\n",
      "Epoch 15/20, Iteration 285/303, Loss: 0.05337553843855858\n",
      "Epoch 15/20, Iteration 286/303, Loss: 0.15884730219841003\n",
      "Epoch 15/20, Iteration 287/303, Loss: 0.07304081320762634\n",
      "Epoch 15/20, Iteration 288/303, Loss: 0.02313658967614174\n",
      "Epoch 15/20, Iteration 289/303, Loss: 0.041398435831069946\n",
      "Epoch 15/20, Iteration 290/303, Loss: 0.056945234537124634\n",
      "Epoch 15/20, Iteration 291/303, Loss: 0.13047869503498077\n",
      "Epoch 15/20, Iteration 292/303, Loss: 0.12632788717746735\n",
      "Epoch 15/20, Iteration 293/303, Loss: 0.04461335763335228\n",
      "Epoch 15/20, Iteration 294/303, Loss: 0.0876377746462822\n",
      "Epoch 15/20, Iteration 295/303, Loss: 0.23695042729377747\n",
      "Epoch 15/20, Iteration 296/303, Loss: 0.12031496316194534\n",
      "Epoch 15/20, Iteration 297/303, Loss: 0.08924037218093872\n",
      "Epoch 15/20, Iteration 298/303, Loss: 0.12092193216085434\n",
      "Epoch 15/20, Iteration 299/303, Loss: 0.18069538474082947\n",
      "Epoch 15/20, Iteration 300/303, Loss: 0.024116624146699905\n",
      "Epoch 15/20, Iteration 301/303, Loss: 0.08227218687534332\n",
      "Epoch 15/20, Iteration 302/303, Loss: 0.0998811349272728\n",
      "Epoch 15/20, Iteration 303/303, Loss: 0.0795716941356659\n",
      "Epoch 16/20, Iteration 1/303, Loss: 0.029303723946213722\n",
      "Epoch 16/20, Iteration 2/303, Loss: 0.02407285012304783\n",
      "Epoch 16/20, Iteration 3/303, Loss: 0.09808380901813507\n",
      "Epoch 16/20, Iteration 4/303, Loss: 0.04609275981783867\n",
      "Epoch 16/20, Iteration 5/303, Loss: 0.06061077117919922\n",
      "Epoch 16/20, Iteration 6/303, Loss: 0.025711242109537125\n",
      "Epoch 16/20, Iteration 7/303, Loss: 0.03167525678873062\n",
      "Epoch 16/20, Iteration 8/303, Loss: 0.022144600749015808\n",
      "Epoch 16/20, Iteration 9/303, Loss: 0.011720921844244003\n",
      "Epoch 16/20, Iteration 10/303, Loss: 0.05987105146050453\n",
      "Epoch 16/20, Iteration 11/303, Loss: 0.04635879769921303\n",
      "Epoch 16/20, Iteration 12/303, Loss: 0.046318843960762024\n",
      "Epoch 16/20, Iteration 13/303, Loss: 0.02409694902598858\n",
      "Epoch 16/20, Iteration 14/303, Loss: 0.028929298743605614\n",
      "Epoch 16/20, Iteration 15/303, Loss: 0.00907862838357687\n",
      "Epoch 16/20, Iteration 16/303, Loss: 0.023396344855427742\n",
      "Epoch 16/20, Iteration 17/303, Loss: 0.03715023770928383\n",
      "Epoch 16/20, Iteration 18/303, Loss: 0.08908475935459137\n",
      "Epoch 16/20, Iteration 19/303, Loss: 0.01947902701795101\n",
      "Epoch 16/20, Iteration 20/303, Loss: 0.012658926658332348\n",
      "Epoch 16/20, Iteration 21/303, Loss: 0.06538937240839005\n",
      "Epoch 16/20, Iteration 22/303, Loss: 0.02346775494515896\n",
      "Epoch 16/20, Iteration 23/303, Loss: 0.036830924451351166\n",
      "Epoch 16/20, Iteration 24/303, Loss: 0.026907602325081825\n",
      "Epoch 16/20, Iteration 25/303, Loss: 0.011319424957036972\n",
      "Epoch 16/20, Iteration 26/303, Loss: 0.09730450809001923\n",
      "Epoch 16/20, Iteration 27/303, Loss: 0.033549487590789795\n",
      "Epoch 16/20, Iteration 28/303, Loss: 0.026207847520709038\n",
      "Epoch 16/20, Iteration 29/303, Loss: 0.03472336381673813\n",
      "Epoch 16/20, Iteration 30/303, Loss: 0.004253037739545107\n",
      "Epoch 16/20, Iteration 31/303, Loss: 0.028408542275428772\n",
      "Epoch 16/20, Iteration 32/303, Loss: 0.021140452474355698\n",
      "Epoch 16/20, Iteration 33/303, Loss: 0.053388811647892\n",
      "Epoch 16/20, Iteration 34/303, Loss: 0.005495978519320488\n",
      "Epoch 16/20, Iteration 35/303, Loss: 0.029121212661266327\n",
      "Epoch 16/20, Iteration 36/303, Loss: 0.029483681544661522\n",
      "Epoch 16/20, Iteration 37/303, Loss: 0.036129504442214966\n",
      "Epoch 16/20, Iteration 38/303, Loss: 0.03533612936735153\n",
      "Epoch 16/20, Iteration 39/303, Loss: 0.11688369512557983\n",
      "Epoch 16/20, Iteration 40/303, Loss: 0.1464928686618805\n",
      "Epoch 16/20, Iteration 41/303, Loss: 0.007867664098739624\n",
      "Epoch 16/20, Iteration 42/303, Loss: 0.015451991930603981\n",
      "Epoch 16/20, Iteration 43/303, Loss: 0.01904653012752533\n",
      "Epoch 16/20, Iteration 44/303, Loss: 0.010654078796505928\n",
      "Epoch 16/20, Iteration 45/303, Loss: 0.04914495721459389\n",
      "Epoch 16/20, Iteration 46/303, Loss: 0.017161613330245018\n",
      "Epoch 16/20, Iteration 47/303, Loss: 0.016750499606132507\n",
      "Epoch 16/20, Iteration 48/303, Loss: 0.006808368489146233\n",
      "Epoch 16/20, Iteration 49/303, Loss: 0.016410158947110176\n",
      "Epoch 16/20, Iteration 50/303, Loss: 0.021775612607598305\n",
      "Epoch 16/20, Iteration 51/303, Loss: 0.0123582249507308\n",
      "Epoch 16/20, Iteration 52/303, Loss: 0.0900345891714096\n",
      "Epoch 16/20, Iteration 53/303, Loss: 0.04528426751494408\n",
      "Epoch 16/20, Iteration 54/303, Loss: 0.07851859927177429\n",
      "Epoch 16/20, Iteration 55/303, Loss: 0.06671904772520065\n",
      "Epoch 16/20, Iteration 56/303, Loss: 0.005676953122019768\n",
      "Epoch 16/20, Iteration 57/303, Loss: 0.049070511013269424\n",
      "Epoch 16/20, Iteration 58/303, Loss: 0.014466214925050735\n",
      "Epoch 16/20, Iteration 59/303, Loss: 0.0196705162525177\n",
      "Epoch 16/20, Iteration 60/303, Loss: 0.03272087499499321\n",
      "Epoch 16/20, Iteration 61/303, Loss: 0.054212313145399094\n",
      "Epoch 16/20, Iteration 62/303, Loss: 0.03437460958957672\n",
      "Epoch 16/20, Iteration 63/303, Loss: 0.035371333360672\n",
      "Epoch 16/20, Iteration 64/303, Loss: 0.006110515911132097\n",
      "Epoch 16/20, Iteration 65/303, Loss: 0.037824973464012146\n",
      "Epoch 16/20, Iteration 66/303, Loss: 0.037951380014419556\n",
      "Epoch 16/20, Iteration 67/303, Loss: 0.07837420701980591\n",
      "Epoch 16/20, Iteration 68/303, Loss: 0.045659296214580536\n",
      "Epoch 16/20, Iteration 69/303, Loss: 0.024286983534693718\n",
      "Epoch 16/20, Iteration 70/303, Loss: 0.12186650931835175\n",
      "Epoch 16/20, Iteration 71/303, Loss: 0.04504819214344025\n",
      "Epoch 16/20, Iteration 72/303, Loss: 0.017908522859215736\n",
      "Epoch 16/20, Iteration 73/303, Loss: 0.011957214213907719\n",
      "Epoch 16/20, Iteration 74/303, Loss: 0.2057694047689438\n",
      "Epoch 16/20, Iteration 75/303, Loss: 0.03447897732257843\n",
      "Epoch 16/20, Iteration 76/303, Loss: 0.08719214051961899\n",
      "Epoch 16/20, Iteration 77/303, Loss: 0.027014639228582382\n",
      "Epoch 16/20, Iteration 78/303, Loss: 0.014329548925161362\n",
      "Epoch 16/20, Iteration 79/303, Loss: 0.04129250347614288\n",
      "Epoch 16/20, Iteration 80/303, Loss: 0.04357951134443283\n",
      "Epoch 16/20, Iteration 81/303, Loss: 0.020378464832901955\n",
      "Epoch 16/20, Iteration 82/303, Loss: 0.020055314525961876\n",
      "Epoch 16/20, Iteration 83/303, Loss: 0.02255273051559925\n",
      "Epoch 16/20, Iteration 84/303, Loss: 0.040067315101623535\n",
      "Epoch 16/20, Iteration 85/303, Loss: 0.08963152021169662\n",
      "Epoch 16/20, Iteration 86/303, Loss: 0.03780125826597214\n",
      "Epoch 16/20, Iteration 87/303, Loss: 0.05156387388706207\n",
      "Epoch 16/20, Iteration 88/303, Loss: 0.023877283558249474\n",
      "Epoch 16/20, Iteration 89/303, Loss: 0.023903731256723404\n",
      "Epoch 16/20, Iteration 90/303, Loss: 0.057596009224653244\n",
      "Epoch 16/20, Iteration 91/303, Loss: 0.04036353901028633\n",
      "Epoch 16/20, Iteration 92/303, Loss: 0.044618602842092514\n",
      "Epoch 16/20, Iteration 93/303, Loss: 0.08297085016965866\n",
      "Epoch 16/20, Iteration 94/303, Loss: 0.12319491803646088\n",
      "Epoch 16/20, Iteration 95/303, Loss: 0.2825433015823364\n",
      "Epoch 16/20, Iteration 96/303, Loss: 0.3017858564853668\n",
      "Epoch 16/20, Iteration 97/303, Loss: 0.16306953132152557\n",
      "Epoch 16/20, Iteration 98/303, Loss: 0.07977207750082016\n",
      "Epoch 16/20, Iteration 99/303, Loss: 0.12343385070562363\n",
      "Epoch 16/20, Iteration 100/303, Loss: 0.09605403244495392\n",
      "Epoch 16/20, Iteration 101/303, Loss: 0.04913271591067314\n",
      "Epoch 16/20, Iteration 102/303, Loss: 0.13238945603370667\n",
      "Epoch 16/20, Iteration 103/303, Loss: 0.07214703410863876\n",
      "Epoch 16/20, Iteration 104/303, Loss: 0.3256727159023285\n",
      "Epoch 16/20, Iteration 105/303, Loss: 0.033100154250860214\n",
      "Epoch 16/20, Iteration 106/303, Loss: 0.10994749516248703\n",
      "Epoch 16/20, Iteration 107/303, Loss: 0.09741345047950745\n",
      "Epoch 16/20, Iteration 108/303, Loss: 0.06105240806937218\n",
      "Epoch 16/20, Iteration 109/303, Loss: 0.05125194415450096\n",
      "Epoch 16/20, Iteration 110/303, Loss: 0.11896061897277832\n",
      "Epoch 16/20, Iteration 111/303, Loss: 0.094549760222435\n",
      "Epoch 16/20, Iteration 112/303, Loss: 0.03420422971248627\n",
      "Epoch 16/20, Iteration 113/303, Loss: 0.1629904806613922\n",
      "Epoch 16/20, Iteration 114/303, Loss: 0.06841446459293365\n",
      "Epoch 16/20, Iteration 115/303, Loss: 0.03553927317261696\n",
      "Epoch 16/20, Iteration 116/303, Loss: 0.02627052180469036\n",
      "Epoch 16/20, Iteration 117/303, Loss: 0.03829323872923851\n",
      "Epoch 16/20, Iteration 118/303, Loss: 0.05721788480877876\n",
      "Epoch 16/20, Iteration 119/303, Loss: 0.09334202855825424\n",
      "Epoch 16/20, Iteration 120/303, Loss: 0.009379222989082336\n",
      "Epoch 16/20, Iteration 121/303, Loss: 0.06020179018378258\n",
      "Epoch 16/20, Iteration 122/303, Loss: 0.2585676610469818\n",
      "Epoch 16/20, Iteration 123/303, Loss: 0.11371739208698273\n",
      "Epoch 16/20, Iteration 124/303, Loss: 0.09057275205850601\n",
      "Epoch 16/20, Iteration 125/303, Loss: 0.10245887190103531\n",
      "Epoch 16/20, Iteration 126/303, Loss: 0.04186934977769852\n",
      "Epoch 16/20, Iteration 127/303, Loss: 0.08870520442724228\n",
      "Epoch 16/20, Iteration 128/303, Loss: 0.042558856308460236\n",
      "Epoch 16/20, Iteration 129/303, Loss: 0.11509183794260025\n",
      "Epoch 16/20, Iteration 130/303, Loss: 0.08398252725601196\n",
      "Epoch 16/20, Iteration 131/303, Loss: 0.06415194272994995\n",
      "Epoch 16/20, Iteration 132/303, Loss: 0.04509929195046425\n",
      "Epoch 16/20, Iteration 133/303, Loss: 0.028417019173502922\n",
      "Epoch 16/20, Iteration 134/303, Loss: 0.01601935178041458\n",
      "Epoch 16/20, Iteration 135/303, Loss: 0.11616102606058121\n",
      "Epoch 16/20, Iteration 136/303, Loss: 0.004813401028513908\n",
      "Epoch 16/20, Iteration 137/303, Loss: 0.0261570792645216\n",
      "Epoch 16/20, Iteration 138/303, Loss: 0.028662461787462234\n",
      "Epoch 16/20, Iteration 139/303, Loss: 0.01578025333583355\n",
      "Epoch 16/20, Iteration 140/303, Loss: 0.027558134868741035\n",
      "Epoch 16/20, Iteration 141/303, Loss: 0.07345448434352875\n",
      "Epoch 16/20, Iteration 142/303, Loss: 0.06920292973518372\n",
      "Epoch 16/20, Iteration 143/303, Loss: 0.06715136021375656\n",
      "Epoch 16/20, Iteration 144/303, Loss: 0.06212795153260231\n",
      "Epoch 16/20, Iteration 145/303, Loss: 0.10986914485692978\n",
      "Epoch 16/20, Iteration 146/303, Loss: 0.1794055998325348\n",
      "Epoch 16/20, Iteration 147/303, Loss: 0.09701228886842728\n",
      "Epoch 16/20, Iteration 148/303, Loss: 0.07387657463550568\n",
      "Epoch 16/20, Iteration 149/303, Loss: 0.05447838082909584\n",
      "Epoch 16/20, Iteration 150/303, Loss: 0.05378786474466324\n",
      "Epoch 16/20, Iteration 151/303, Loss: 0.032532788813114166\n",
      "Epoch 16/20, Iteration 152/303, Loss: 0.011724663898348808\n",
      "Epoch 16/20, Iteration 153/303, Loss: 0.02162834443151951\n",
      "Epoch 16/20, Iteration 154/303, Loss: 0.03608469292521477\n",
      "Epoch 16/20, Iteration 155/303, Loss: 0.07617539167404175\n",
      "Epoch 16/20, Iteration 156/303, Loss: 0.08772311359643936\n",
      "Epoch 16/20, Iteration 157/303, Loss: 0.03662176802754402\n",
      "Epoch 16/20, Iteration 158/303, Loss: 0.04766415059566498\n",
      "Epoch 16/20, Iteration 159/303, Loss: 0.020282810553908348\n",
      "Epoch 16/20, Iteration 160/303, Loss: 0.021494600921869278\n",
      "Epoch 16/20, Iteration 161/303, Loss: 0.06834333389997482\n",
      "Epoch 16/20, Iteration 162/303, Loss: 0.024982230737805367\n",
      "Epoch 16/20, Iteration 163/303, Loss: 0.021998433396220207\n",
      "Epoch 16/20, Iteration 164/303, Loss: 0.03426630422472954\n",
      "Epoch 16/20, Iteration 165/303, Loss: 0.07964827865362167\n",
      "Epoch 16/20, Iteration 166/303, Loss: 0.03277185559272766\n",
      "Epoch 16/20, Iteration 167/303, Loss: 0.09981506317853928\n",
      "Epoch 16/20, Iteration 168/303, Loss: 0.1600525677204132\n",
      "Epoch 16/20, Iteration 169/303, Loss: 0.054238129407167435\n",
      "Epoch 16/20, Iteration 170/303, Loss: 0.10119831562042236\n",
      "Epoch 16/20, Iteration 171/303, Loss: 0.058771826326847076\n",
      "Epoch 16/20, Iteration 172/303, Loss: 0.05133570358157158\n",
      "Epoch 16/20, Iteration 173/303, Loss: 0.03138428553938866\n",
      "Epoch 16/20, Iteration 174/303, Loss: 0.04166316241025925\n",
      "Epoch 16/20, Iteration 175/303, Loss: 0.15655840933322906\n",
      "Epoch 16/20, Iteration 176/303, Loss: 0.009029647335410118\n",
      "Epoch 16/20, Iteration 177/303, Loss: 0.28243598341941833\n",
      "Epoch 16/20, Iteration 178/303, Loss: 0.6803350448608398\n",
      "Epoch 16/20, Iteration 179/303, Loss: 0.8238283395767212\n",
      "Epoch 16/20, Iteration 180/303, Loss: 0.1598241776227951\n",
      "Epoch 16/20, Iteration 181/303, Loss: 0.1040424183011055\n",
      "Epoch 16/20, Iteration 182/303, Loss: 0.09100377559661865\n",
      "Epoch 16/20, Iteration 183/303, Loss: 0.10391320288181305\n",
      "Epoch 16/20, Iteration 184/303, Loss: 0.1632368266582489\n",
      "Epoch 16/20, Iteration 185/303, Loss: 0.10982538014650345\n",
      "Epoch 16/20, Iteration 186/303, Loss: 0.1293310821056366\n",
      "Epoch 16/20, Iteration 187/303, Loss: 0.10122983902692795\n",
      "Epoch 16/20, Iteration 188/303, Loss: 0.0783069059252739\n",
      "Epoch 16/20, Iteration 189/303, Loss: 0.16033703088760376\n",
      "Epoch 16/20, Iteration 190/303, Loss: 0.10936106741428375\n",
      "Epoch 16/20, Iteration 191/303, Loss: 0.08876583725214005\n",
      "Epoch 16/20, Iteration 192/303, Loss: 0.02372545748949051\n",
      "Epoch 16/20, Iteration 193/303, Loss: 0.07793816179037094\n",
      "Epoch 16/20, Iteration 194/303, Loss: 0.0834154412150383\n",
      "Epoch 16/20, Iteration 195/303, Loss: 0.07208696007728577\n",
      "Epoch 16/20, Iteration 196/303, Loss: 0.13418792188167572\n",
      "Epoch 16/20, Iteration 197/303, Loss: 0.04398356378078461\n",
      "Epoch 16/20, Iteration 198/303, Loss: 0.04143715649843216\n",
      "Epoch 16/20, Iteration 199/303, Loss: 0.05731625482439995\n",
      "Epoch 16/20, Iteration 200/303, Loss: 0.1739593744277954\n",
      "Epoch 16/20, Iteration 201/303, Loss: 0.20172908902168274\n",
      "Epoch 16/20, Iteration 202/303, Loss: 0.08878530561923981\n",
      "Epoch 16/20, Iteration 203/303, Loss: 0.02127886191010475\n",
      "Epoch 16/20, Iteration 204/303, Loss: 0.057714447379112244\n",
      "Epoch 16/20, Iteration 205/303, Loss: 0.04869348555803299\n",
      "Epoch 16/20, Iteration 206/303, Loss: 0.07510379701852798\n",
      "Epoch 16/20, Iteration 207/303, Loss: 0.1130533441901207\n",
      "Epoch 16/20, Iteration 208/303, Loss: 0.0828317254781723\n",
      "Epoch 16/20, Iteration 209/303, Loss: 0.026043323799967766\n",
      "Epoch 16/20, Iteration 210/303, Loss: 0.011108143255114555\n",
      "Epoch 16/20, Iteration 211/303, Loss: 0.061606377363204956\n",
      "Epoch 16/20, Iteration 212/303, Loss: 0.07478971034288406\n",
      "Epoch 16/20, Iteration 213/303, Loss: 0.14706438779830933\n",
      "Epoch 16/20, Iteration 214/303, Loss: 0.02730872482061386\n",
      "Epoch 16/20, Iteration 215/303, Loss: 0.07877406477928162\n",
      "Epoch 16/20, Iteration 216/303, Loss: 0.0310659259557724\n",
      "Epoch 16/20, Iteration 217/303, Loss: 0.03323529660701752\n",
      "Epoch 16/20, Iteration 218/303, Loss: 0.16221988201141357\n",
      "Epoch 16/20, Iteration 219/303, Loss: 0.04690616577863693\n",
      "Epoch 16/20, Iteration 220/303, Loss: 0.09549543261528015\n",
      "Epoch 16/20, Iteration 221/303, Loss: 0.18585075438022614\n",
      "Epoch 16/20, Iteration 222/303, Loss: 0.14047762751579285\n",
      "Epoch 16/20, Iteration 223/303, Loss: 0.0766080915927887\n",
      "Epoch 16/20, Iteration 224/303, Loss: 0.18466994166374207\n",
      "Epoch 16/20, Iteration 225/303, Loss: 0.11835460364818573\n",
      "Epoch 16/20, Iteration 226/303, Loss: 0.14632342755794525\n",
      "Epoch 16/20, Iteration 227/303, Loss: 0.14301428198814392\n",
      "Epoch 16/20, Iteration 228/303, Loss: 0.048535075038671494\n",
      "Epoch 16/20, Iteration 229/303, Loss: 0.21078796684741974\n",
      "Epoch 16/20, Iteration 230/303, Loss: 0.052922334522008896\n",
      "Epoch 16/20, Iteration 231/303, Loss: 0.1381184607744217\n",
      "Epoch 16/20, Iteration 232/303, Loss: 0.0721818134188652\n",
      "Epoch 16/20, Iteration 233/303, Loss: 0.03555787727236748\n",
      "Epoch 16/20, Iteration 234/303, Loss: 0.08141974359750748\n",
      "Epoch 16/20, Iteration 235/303, Loss: 0.06499778479337692\n",
      "Epoch 16/20, Iteration 236/303, Loss: 0.059642285108566284\n",
      "Epoch 16/20, Iteration 237/303, Loss: 0.09605463594198227\n",
      "Epoch 16/20, Iteration 238/303, Loss: 0.03094039112329483\n",
      "Epoch 16/20, Iteration 239/303, Loss: 0.026041369885206223\n",
      "Epoch 16/20, Iteration 240/303, Loss: 0.27281907200813293\n",
      "Epoch 16/20, Iteration 241/303, Loss: 0.13916361331939697\n",
      "Epoch 16/20, Iteration 242/303, Loss: 0.020132433623075485\n",
      "Epoch 16/20, Iteration 243/303, Loss: 0.06525065749883652\n",
      "Epoch 16/20, Iteration 244/303, Loss: 0.15244972705841064\n",
      "Epoch 16/20, Iteration 245/303, Loss: 0.1275666356086731\n",
      "Epoch 16/20, Iteration 246/303, Loss: 0.06177733838558197\n",
      "Epoch 16/20, Iteration 247/303, Loss: 0.024956747889518738\n",
      "Epoch 16/20, Iteration 248/303, Loss: 0.07540468126535416\n",
      "Epoch 16/20, Iteration 249/303, Loss: 0.07564228028059006\n",
      "Epoch 16/20, Iteration 250/303, Loss: 0.04352422058582306\n",
      "Epoch 16/20, Iteration 251/303, Loss: 0.06917426735162735\n",
      "Epoch 16/20, Iteration 252/303, Loss: 0.05130678415298462\n",
      "Epoch 16/20, Iteration 253/303, Loss: 0.061114080250263214\n",
      "Epoch 16/20, Iteration 254/303, Loss: 0.06975718587636948\n",
      "Epoch 16/20, Iteration 255/303, Loss: 0.054314933717250824\n",
      "Epoch 16/20, Iteration 256/303, Loss: 0.04679834097623825\n",
      "Epoch 16/20, Iteration 257/303, Loss: 0.07083328068256378\n",
      "Epoch 16/20, Iteration 258/303, Loss: 0.031704131513834\n",
      "Epoch 16/20, Iteration 259/303, Loss: 0.12533453106880188\n",
      "Epoch 16/20, Iteration 260/303, Loss: 0.05038062483072281\n",
      "Epoch 16/20, Iteration 261/303, Loss: 0.11531223356723785\n",
      "Epoch 16/20, Iteration 262/303, Loss: 0.047814782708883286\n",
      "Epoch 16/20, Iteration 263/303, Loss: 0.1433008313179016\n",
      "Epoch 16/20, Iteration 264/303, Loss: 0.03502879664301872\n",
      "Epoch 16/20, Iteration 265/303, Loss: 0.08581800758838654\n",
      "Epoch 16/20, Iteration 266/303, Loss: 0.0821341946721077\n",
      "Epoch 16/20, Iteration 267/303, Loss: 0.14670278131961823\n",
      "Epoch 16/20, Iteration 268/303, Loss: 0.03409527614712715\n",
      "Epoch 16/20, Iteration 269/303, Loss: 0.034535665065050125\n",
      "Epoch 16/20, Iteration 270/303, Loss: 0.048657722771167755\n",
      "Epoch 16/20, Iteration 271/303, Loss: 0.0894879698753357\n",
      "Epoch 16/20, Iteration 272/303, Loss: 0.012903508730232716\n",
      "Epoch 16/20, Iteration 273/303, Loss: 0.09886172413825989\n",
      "Epoch 16/20, Iteration 274/303, Loss: 0.09215430170297623\n",
      "Epoch 16/20, Iteration 275/303, Loss: 0.06290074437856674\n",
      "Epoch 16/20, Iteration 276/303, Loss: 0.10544376075267792\n",
      "Epoch 16/20, Iteration 277/303, Loss: 0.022115789353847504\n",
      "Epoch 16/20, Iteration 278/303, Loss: 0.16694682836532593\n",
      "Epoch 16/20, Iteration 279/303, Loss: 0.28647685050964355\n",
      "Epoch 16/20, Iteration 280/303, Loss: 0.14521552622318268\n",
      "Epoch 16/20, Iteration 281/303, Loss: 0.09222640842199326\n",
      "Epoch 16/20, Iteration 282/303, Loss: 0.0660707876086235\n",
      "Epoch 16/20, Iteration 283/303, Loss: 0.04739893227815628\n",
      "Epoch 16/20, Iteration 284/303, Loss: 0.06135707348585129\n",
      "Epoch 16/20, Iteration 285/303, Loss: 0.007754561025649309\n",
      "Epoch 16/20, Iteration 286/303, Loss: 0.0686725527048111\n",
      "Epoch 16/20, Iteration 287/303, Loss: 0.020670801401138306\n",
      "Epoch 16/20, Iteration 288/303, Loss: 0.061372481286525726\n",
      "Epoch 16/20, Iteration 289/303, Loss: 0.05347524210810661\n",
      "Epoch 16/20, Iteration 290/303, Loss: 0.107401542365551\n",
      "Epoch 16/20, Iteration 291/303, Loss: 0.13154344260692596\n",
      "Epoch 16/20, Iteration 292/303, Loss: 0.3307608366012573\n",
      "Epoch 16/20, Iteration 293/303, Loss: 0.09297190606594086\n",
      "Epoch 16/20, Iteration 294/303, Loss: 0.04261530935764313\n",
      "Epoch 16/20, Iteration 295/303, Loss: 0.09678030014038086\n",
      "Epoch 16/20, Iteration 296/303, Loss: 0.13728423416614532\n",
      "Epoch 16/20, Iteration 297/303, Loss: 0.11524765193462372\n",
      "Epoch 16/20, Iteration 298/303, Loss: 0.10968529433012009\n",
      "Epoch 16/20, Iteration 299/303, Loss: 0.03137754648923874\n",
      "Epoch 16/20, Iteration 300/303, Loss: 0.04595086723566055\n",
      "Epoch 16/20, Iteration 301/303, Loss: 0.08409293740987778\n",
      "Epoch 16/20, Iteration 302/303, Loss: 0.04904177412390709\n",
      "Epoch 16/20, Iteration 303/303, Loss: 0.06332169473171234\n",
      "Epoch 17/20, Iteration 1/303, Loss: 0.014608930796384811\n",
      "Epoch 17/20, Iteration 2/303, Loss: 0.02483326382935047\n",
      "Epoch 17/20, Iteration 3/303, Loss: 0.004520724061876535\n",
      "Epoch 17/20, Iteration 4/303, Loss: 0.008008440025150776\n",
      "Epoch 17/20, Iteration 5/303, Loss: 0.05190000683069229\n",
      "Epoch 17/20, Iteration 6/303, Loss: 0.04229782521724701\n",
      "Epoch 17/20, Iteration 7/303, Loss: 0.0390094593167305\n",
      "Epoch 17/20, Iteration 8/303, Loss: 0.06643465906381607\n",
      "Epoch 17/20, Iteration 9/303, Loss: 0.05364823341369629\n",
      "Epoch 17/20, Iteration 10/303, Loss: 0.03158831596374512\n",
      "Epoch 17/20, Iteration 11/303, Loss: 0.017089413478970528\n",
      "Epoch 17/20, Iteration 12/303, Loss: 0.06370022892951965\n",
      "Epoch 17/20, Iteration 13/303, Loss: 0.023173652589321136\n",
      "Epoch 17/20, Iteration 14/303, Loss: 0.0586843378841877\n",
      "Epoch 17/20, Iteration 15/303, Loss: 0.061283230781555176\n",
      "Epoch 17/20, Iteration 16/303, Loss: 0.0342133566737175\n",
      "Epoch 17/20, Iteration 17/303, Loss: 0.025123314931988716\n",
      "Epoch 17/20, Iteration 18/303, Loss: 0.05205986276268959\n",
      "Epoch 17/20, Iteration 19/303, Loss: 0.02690449170768261\n",
      "Epoch 17/20, Iteration 20/303, Loss: 0.015577326528728008\n",
      "Epoch 17/20, Iteration 21/303, Loss: 0.04496772959828377\n",
      "Epoch 17/20, Iteration 22/303, Loss: 0.01940709725022316\n",
      "Epoch 17/20, Iteration 23/303, Loss: 0.04908698424696922\n",
      "Epoch 17/20, Iteration 24/303, Loss: 0.025776352733373642\n",
      "Epoch 17/20, Iteration 25/303, Loss: 0.02193632908165455\n",
      "Epoch 17/20, Iteration 26/303, Loss: 0.06408623605966568\n",
      "Epoch 17/20, Iteration 27/303, Loss: 0.022024542093276978\n",
      "Epoch 17/20, Iteration 28/303, Loss: 0.009498857893049717\n",
      "Epoch 17/20, Iteration 29/303, Loss: 0.003673332976177335\n",
      "Epoch 17/20, Iteration 30/303, Loss: 0.00762669974938035\n",
      "Epoch 17/20, Iteration 31/303, Loss: 0.1290540099143982\n",
      "Epoch 17/20, Iteration 32/303, Loss: 0.1980229914188385\n",
      "Epoch 17/20, Iteration 33/303, Loss: 0.14517858624458313\n",
      "Epoch 17/20, Iteration 34/303, Loss: 0.2687855064868927\n",
      "Epoch 17/20, Iteration 35/303, Loss: 0.24613729119300842\n",
      "Epoch 17/20, Iteration 36/303, Loss: 0.06561106443405151\n",
      "Epoch 17/20, Iteration 37/303, Loss: 0.12275378406047821\n",
      "Epoch 17/20, Iteration 38/303, Loss: 0.040823258459568024\n",
      "Epoch 17/20, Iteration 39/303, Loss: 0.033372651785612106\n",
      "Epoch 17/20, Iteration 40/303, Loss: 0.012363478541374207\n",
      "Epoch 17/20, Iteration 41/303, Loss: 0.02817234769463539\n",
      "Epoch 17/20, Iteration 42/303, Loss: 0.04221726208925247\n",
      "Epoch 17/20, Iteration 43/303, Loss: 0.07946739345788956\n",
      "Epoch 17/20, Iteration 44/303, Loss: 0.03328823670744896\n",
      "Epoch 17/20, Iteration 45/303, Loss: 0.009096344001591206\n",
      "Epoch 17/20, Iteration 46/303, Loss: 0.006599499378353357\n",
      "Epoch 17/20, Iteration 47/303, Loss: 0.04943113029003143\n",
      "Epoch 17/20, Iteration 48/303, Loss: 0.10278399288654327\n",
      "Epoch 17/20, Iteration 49/303, Loss: 0.025925956666469574\n",
      "Epoch 17/20, Iteration 50/303, Loss: 0.08260837197303772\n",
      "Epoch 17/20, Iteration 51/303, Loss: 0.028740504756569862\n",
      "Epoch 17/20, Iteration 52/303, Loss: 0.007052313070744276\n",
      "Epoch 17/20, Iteration 53/303, Loss: 0.0036390407476574183\n",
      "Epoch 17/20, Iteration 54/303, Loss: 0.011982843279838562\n",
      "Epoch 17/20, Iteration 55/303, Loss: 0.04258665442466736\n",
      "Epoch 17/20, Iteration 56/303, Loss: 0.07690414041280746\n",
      "Epoch 17/20, Iteration 57/303, Loss: 0.027294710278511047\n",
      "Epoch 17/20, Iteration 58/303, Loss: 0.09259302169084549\n",
      "Epoch 17/20, Iteration 59/303, Loss: 0.07974528521299362\n",
      "Epoch 17/20, Iteration 60/303, Loss: 0.018877077847719193\n",
      "Epoch 17/20, Iteration 61/303, Loss: 0.059093669056892395\n",
      "Epoch 17/20, Iteration 62/303, Loss: 0.01886463351547718\n",
      "Epoch 17/20, Iteration 63/303, Loss: 0.038902074098587036\n",
      "Epoch 17/20, Iteration 64/303, Loss: 0.03326592966914177\n",
      "Epoch 17/20, Iteration 65/303, Loss: 0.017242390662431717\n",
      "Epoch 17/20, Iteration 66/303, Loss: 0.04826879873871803\n",
      "Epoch 17/20, Iteration 67/303, Loss: 0.010888811200857162\n",
      "Epoch 17/20, Iteration 68/303, Loss: 0.015255303122103214\n",
      "Epoch 17/20, Iteration 69/303, Loss: 0.06599700450897217\n",
      "Epoch 17/20, Iteration 70/303, Loss: 0.054109618067741394\n",
      "Epoch 17/20, Iteration 71/303, Loss: 0.061234377324581146\n",
      "Epoch 17/20, Iteration 72/303, Loss: 0.02006111852824688\n",
      "Epoch 17/20, Iteration 73/303, Loss: 0.046335697174072266\n",
      "Epoch 17/20, Iteration 74/303, Loss: 0.04460028186440468\n",
      "Epoch 17/20, Iteration 75/303, Loss: 0.026721414178609848\n",
      "Epoch 17/20, Iteration 76/303, Loss: 0.018913373351097107\n",
      "Epoch 17/20, Iteration 77/303, Loss: 0.06338272988796234\n",
      "Epoch 17/20, Iteration 78/303, Loss: 0.029836498200893402\n",
      "Epoch 17/20, Iteration 79/303, Loss: 0.0026183966547250748\n",
      "Epoch 17/20, Iteration 80/303, Loss: 0.0026671113446354866\n",
      "Epoch 17/20, Iteration 81/303, Loss: 0.03903257101774216\n",
      "Epoch 17/20, Iteration 82/303, Loss: 0.015475879423320293\n",
      "Epoch 17/20, Iteration 83/303, Loss: 0.0572945773601532\n",
      "Epoch 17/20, Iteration 84/303, Loss: 0.011263467371463776\n",
      "Epoch 17/20, Iteration 85/303, Loss: 0.0037006970960646868\n",
      "Epoch 17/20, Iteration 86/303, Loss: 0.016301358118653297\n",
      "Epoch 17/20, Iteration 87/303, Loss: 0.03835545480251312\n",
      "Epoch 17/20, Iteration 88/303, Loss: 0.003753635799512267\n",
      "Epoch 17/20, Iteration 89/303, Loss: 0.019363446161150932\n",
      "Epoch 17/20, Iteration 90/303, Loss: 0.03933814913034439\n",
      "Epoch 17/20, Iteration 91/303, Loss: 0.02493199147284031\n",
      "Epoch 17/20, Iteration 92/303, Loss: 0.00714379595592618\n",
      "Epoch 17/20, Iteration 93/303, Loss: 0.007663423661142588\n",
      "Epoch 17/20, Iteration 94/303, Loss: 0.009824927896261215\n",
      "Epoch 17/20, Iteration 95/303, Loss: 0.016347981989383698\n",
      "Epoch 17/20, Iteration 96/303, Loss: 0.032216109335422516\n",
      "Epoch 17/20, Iteration 97/303, Loss: 0.032167673110961914\n",
      "Epoch 17/20, Iteration 98/303, Loss: 0.01852734573185444\n",
      "Epoch 17/20, Iteration 99/303, Loss: 0.004492652602493763\n",
      "Epoch 17/20, Iteration 100/303, Loss: 0.03151172772049904\n",
      "Epoch 17/20, Iteration 101/303, Loss: 0.012778067030012608\n",
      "Epoch 17/20, Iteration 102/303, Loss: 0.012827564030885696\n",
      "Epoch 17/20, Iteration 103/303, Loss: 0.001331348903477192\n",
      "Epoch 17/20, Iteration 104/303, Loss: 0.01733933575451374\n",
      "Epoch 17/20, Iteration 105/303, Loss: 0.056522734463214874\n",
      "Epoch 17/20, Iteration 106/303, Loss: 0.01701754331588745\n",
      "Epoch 17/20, Iteration 107/303, Loss: 0.042281247675418854\n",
      "Epoch 17/20, Iteration 108/303, Loss: 0.031099099665880203\n",
      "Epoch 17/20, Iteration 109/303, Loss: 0.017406711354851723\n",
      "Epoch 17/20, Iteration 110/303, Loss: 0.0022644668351858854\n",
      "Epoch 17/20, Iteration 111/303, Loss: 0.03982432559132576\n",
      "Epoch 17/20, Iteration 112/303, Loss: 0.02215874195098877\n",
      "Epoch 17/20, Iteration 113/303, Loss: 0.06505417823791504\n",
      "Epoch 17/20, Iteration 114/303, Loss: 0.02085467055439949\n",
      "Epoch 17/20, Iteration 115/303, Loss: 0.08496389538049698\n",
      "Epoch 17/20, Iteration 116/303, Loss: 0.014818740077316761\n",
      "Epoch 17/20, Iteration 117/303, Loss: 0.024700799956917763\n",
      "Epoch 17/20, Iteration 118/303, Loss: 0.015909524634480476\n",
      "Epoch 17/20, Iteration 119/303, Loss: 0.03282643109560013\n",
      "Epoch 17/20, Iteration 120/303, Loss: 0.016853971406817436\n",
      "Epoch 17/20, Iteration 121/303, Loss: 0.03774633631110191\n",
      "Epoch 17/20, Iteration 122/303, Loss: 0.013430150225758553\n",
      "Epoch 17/20, Iteration 123/303, Loss: 0.08029816299676895\n",
      "Epoch 17/20, Iteration 124/303, Loss: 0.12552618980407715\n",
      "Epoch 17/20, Iteration 125/303, Loss: 0.49169236421585083\n",
      "Epoch 17/20, Iteration 126/303, Loss: 0.31297802925109863\n",
      "Epoch 17/20, Iteration 127/303, Loss: 0.4084744453430176\n",
      "Epoch 17/20, Iteration 128/303, Loss: 0.18986788392066956\n",
      "Epoch 17/20, Iteration 129/303, Loss: 0.1449749618768692\n",
      "Epoch 17/20, Iteration 130/303, Loss: 0.24784931540489197\n",
      "Epoch 17/20, Iteration 131/303, Loss: 0.10174693912267685\n",
      "Epoch 17/20, Iteration 132/303, Loss: 0.09059615433216095\n",
      "Epoch 17/20, Iteration 133/303, Loss: 0.07723836600780487\n",
      "Epoch 17/20, Iteration 134/303, Loss: 0.05750302970409393\n",
      "Epoch 17/20, Iteration 135/303, Loss: 0.08202875405550003\n",
      "Epoch 17/20, Iteration 136/303, Loss: 0.0352591834962368\n",
      "Epoch 17/20, Iteration 137/303, Loss: 0.07020813971757889\n",
      "Epoch 17/20, Iteration 138/303, Loss: 0.10676935315132141\n",
      "Epoch 17/20, Iteration 139/303, Loss: 0.1090070977807045\n",
      "Epoch 17/20, Iteration 140/303, Loss: 0.07927413284778595\n",
      "Epoch 17/20, Iteration 141/303, Loss: 0.1232135221362114\n",
      "Epoch 17/20, Iteration 142/303, Loss: 0.07418079674243927\n",
      "Epoch 17/20, Iteration 143/303, Loss: 0.19963285326957703\n",
      "Epoch 17/20, Iteration 144/303, Loss: 0.05416253209114075\n",
      "Epoch 17/20, Iteration 145/303, Loss: 0.09788206219673157\n",
      "Epoch 17/20, Iteration 146/303, Loss: 0.16928264498710632\n",
      "Epoch 17/20, Iteration 147/303, Loss: 0.06864151358604431\n",
      "Epoch 17/20, Iteration 148/303, Loss: 0.07593613862991333\n",
      "Epoch 17/20, Iteration 149/303, Loss: 0.060467950999736786\n",
      "Epoch 17/20, Iteration 150/303, Loss: 0.05039762333035469\n",
      "Epoch 17/20, Iteration 151/303, Loss: 0.04699881002306938\n",
      "Epoch 17/20, Iteration 152/303, Loss: 0.04470229521393776\n",
      "Epoch 17/20, Iteration 153/303, Loss: 0.0597134530544281\n",
      "Epoch 17/20, Iteration 154/303, Loss: 0.09984123706817627\n",
      "Epoch 17/20, Iteration 155/303, Loss: 0.009097721427679062\n",
      "Epoch 17/20, Iteration 156/303, Loss: 0.055118001997470856\n",
      "Epoch 17/20, Iteration 157/303, Loss: 0.027054978534579277\n",
      "Epoch 17/20, Iteration 158/303, Loss: 0.03742864355444908\n",
      "Epoch 17/20, Iteration 159/303, Loss: 0.03416674584150314\n",
      "Epoch 17/20, Iteration 160/303, Loss: 0.07139036059379578\n",
      "Epoch 17/20, Iteration 161/303, Loss: 0.04080610349774361\n",
      "Epoch 17/20, Iteration 162/303, Loss: 0.015551143325865269\n",
      "Epoch 17/20, Iteration 163/303, Loss: 0.010514885187149048\n",
      "Epoch 17/20, Iteration 164/303, Loss: 0.12523917853832245\n",
      "Epoch 17/20, Iteration 165/303, Loss: 0.03713373467326164\n",
      "Epoch 17/20, Iteration 166/303, Loss: 0.06202501803636551\n",
      "Epoch 17/20, Iteration 167/303, Loss: 0.18322022259235382\n",
      "Epoch 17/20, Iteration 168/303, Loss: 0.10975279659032822\n",
      "Epoch 17/20, Iteration 169/303, Loss: 0.03467391058802605\n",
      "Epoch 17/20, Iteration 170/303, Loss: 0.06424754858016968\n",
      "Epoch 17/20, Iteration 171/303, Loss: 0.05965237691998482\n",
      "Epoch 17/20, Iteration 172/303, Loss: 0.015183690004050732\n",
      "Epoch 17/20, Iteration 173/303, Loss: 0.051667485386133194\n",
      "Epoch 17/20, Iteration 174/303, Loss: 0.01954938843846321\n",
      "Epoch 17/20, Iteration 175/303, Loss: 0.013765771873295307\n",
      "Epoch 17/20, Iteration 176/303, Loss: 0.04207487404346466\n",
      "Epoch 17/20, Iteration 177/303, Loss: 0.005252226255834103\n",
      "Epoch 17/20, Iteration 178/303, Loss: 0.010449851863086224\n",
      "Epoch 17/20, Iteration 179/303, Loss: 0.013999919407069683\n",
      "Epoch 17/20, Iteration 180/303, Loss: 0.05677603930234909\n",
      "Epoch 17/20, Iteration 181/303, Loss: 0.23492668569087982\n",
      "Epoch 17/20, Iteration 182/303, Loss: 0.035027045756578445\n",
      "Epoch 17/20, Iteration 183/303, Loss: 0.028642646968364716\n",
      "Epoch 17/20, Iteration 184/303, Loss: 0.08761829137802124\n",
      "Epoch 17/20, Iteration 185/303, Loss: 0.138267382979393\n",
      "Epoch 17/20, Iteration 186/303, Loss: 0.036198921501636505\n",
      "Epoch 17/20, Iteration 187/303, Loss: 0.047327492386102676\n",
      "Epoch 17/20, Iteration 188/303, Loss: 0.05726242437958717\n",
      "Epoch 17/20, Iteration 189/303, Loss: 0.1734597384929657\n",
      "Epoch 17/20, Iteration 190/303, Loss: 0.153151735663414\n",
      "Epoch 17/20, Iteration 191/303, Loss: 0.12497268617153168\n",
      "Epoch 17/20, Iteration 192/303, Loss: 0.1142355427145958\n",
      "Epoch 17/20, Iteration 193/303, Loss: 0.1288391500711441\n",
      "Epoch 17/20, Iteration 194/303, Loss: 0.05837950110435486\n",
      "Epoch 17/20, Iteration 195/303, Loss: 0.02680042013525963\n",
      "Epoch 17/20, Iteration 196/303, Loss: 0.046759624034166336\n",
      "Epoch 17/20, Iteration 197/303, Loss: 0.03839563950896263\n",
      "Epoch 17/20, Iteration 198/303, Loss: 0.12460878491401672\n",
      "Epoch 17/20, Iteration 199/303, Loss: 0.07124753296375275\n",
      "Epoch 17/20, Iteration 200/303, Loss: 0.09328661113977432\n",
      "Epoch 17/20, Iteration 201/303, Loss: 0.0642838180065155\n",
      "Epoch 17/20, Iteration 202/303, Loss: 0.0326104573905468\n",
      "Epoch 17/20, Iteration 203/303, Loss: 0.08374165743589401\n",
      "Epoch 17/20, Iteration 204/303, Loss: 0.02325674705207348\n",
      "Epoch 17/20, Iteration 205/303, Loss: 0.01623847521841526\n",
      "Epoch 17/20, Iteration 206/303, Loss: 0.03983064740896225\n",
      "Epoch 17/20, Iteration 207/303, Loss: 0.027505064383149147\n",
      "Epoch 17/20, Iteration 208/303, Loss: 0.013089293614029884\n",
      "Epoch 17/20, Iteration 209/303, Loss: 0.011956536211073399\n",
      "Epoch 17/20, Iteration 210/303, Loss: 0.03451796993613243\n",
      "Epoch 17/20, Iteration 211/303, Loss: 0.00414989935234189\n",
      "Epoch 17/20, Iteration 212/303, Loss: 0.01178046502172947\n",
      "Epoch 17/20, Iteration 213/303, Loss: 0.05073624104261398\n",
      "Epoch 17/20, Iteration 214/303, Loss: 0.01986398734152317\n",
      "Epoch 17/20, Iteration 215/303, Loss: 0.10110596567392349\n",
      "Epoch 17/20, Iteration 216/303, Loss: 0.023925086483359337\n",
      "Epoch 17/20, Iteration 217/303, Loss: 0.07082130014896393\n",
      "Epoch 17/20, Iteration 218/303, Loss: 0.0633561760187149\n",
      "Epoch 17/20, Iteration 219/303, Loss: 0.015891069546341896\n",
      "Epoch 17/20, Iteration 220/303, Loss: 0.19666947424411774\n",
      "Epoch 17/20, Iteration 221/303, Loss: 0.03338485583662987\n",
      "Epoch 17/20, Iteration 222/303, Loss: 0.030716635286808014\n",
      "Epoch 17/20, Iteration 223/303, Loss: 0.029524361714720726\n",
      "Epoch 17/20, Iteration 224/303, Loss: 0.00810878537595272\n",
      "Epoch 17/20, Iteration 225/303, Loss: 0.009597845375537872\n",
      "Epoch 17/20, Iteration 226/303, Loss: 0.009674306958913803\n",
      "Epoch 17/20, Iteration 227/303, Loss: 0.037421733140945435\n",
      "Epoch 17/20, Iteration 228/303, Loss: 0.09407450258731842\n",
      "Epoch 17/20, Iteration 229/303, Loss: 0.06356281787157059\n",
      "Epoch 17/20, Iteration 230/303, Loss: 0.04153740406036377\n",
      "Epoch 17/20, Iteration 231/303, Loss: 0.020012082532048225\n",
      "Epoch 17/20, Iteration 232/303, Loss: 0.032173801213502884\n",
      "Epoch 17/20, Iteration 233/303, Loss: 0.060665152966976166\n",
      "Epoch 17/20, Iteration 234/303, Loss: 0.09447788447141647\n",
      "Epoch 17/20, Iteration 235/303, Loss: 0.22093313932418823\n",
      "Epoch 17/20, Iteration 236/303, Loss: 0.24293866753578186\n",
      "Epoch 17/20, Iteration 237/303, Loss: 0.22497615218162537\n",
      "Epoch 17/20, Iteration 238/303, Loss: 0.22318993508815765\n",
      "Epoch 17/20, Iteration 239/303, Loss: 0.2913261353969574\n",
      "Epoch 17/20, Iteration 240/303, Loss: 0.07225027680397034\n",
      "Epoch 17/20, Iteration 241/303, Loss: 0.050904273986816406\n",
      "Epoch 17/20, Iteration 242/303, Loss: 0.11964509636163712\n",
      "Epoch 17/20, Iteration 243/303, Loss: 0.15698406100273132\n",
      "Epoch 17/20, Iteration 244/303, Loss: 0.07009366154670715\n",
      "Epoch 17/20, Iteration 245/303, Loss: 0.02617667429149151\n",
      "Epoch 17/20, Iteration 246/303, Loss: 0.04014250636100769\n",
      "Epoch 17/20, Iteration 247/303, Loss: 0.10430586338043213\n",
      "Epoch 17/20, Iteration 248/303, Loss: 0.024022499099373817\n",
      "Epoch 17/20, Iteration 249/303, Loss: 0.018804414197802544\n",
      "Epoch 17/20, Iteration 250/303, Loss: 0.17310644686222076\n",
      "Epoch 17/20, Iteration 251/303, Loss: 0.01128795649856329\n",
      "Epoch 17/20, Iteration 252/303, Loss: 0.07407130300998688\n",
      "Epoch 17/20, Iteration 253/303, Loss: 0.014750109054148197\n",
      "Epoch 17/20, Iteration 254/303, Loss: 0.01612670347094536\n",
      "Epoch 17/20, Iteration 255/303, Loss: 0.01700747013092041\n",
      "Epoch 17/20, Iteration 256/303, Loss: 0.04119635745882988\n",
      "Epoch 17/20, Iteration 257/303, Loss: 0.14052006602287292\n",
      "Epoch 17/20, Iteration 258/303, Loss: 0.04210662841796875\n",
      "Epoch 17/20, Iteration 259/303, Loss: 0.037759169936180115\n",
      "Epoch 17/20, Iteration 260/303, Loss: 0.042025126516819\n",
      "Epoch 17/20, Iteration 261/303, Loss: 0.05239928513765335\n",
      "Epoch 17/20, Iteration 262/303, Loss: 0.08705216646194458\n",
      "Epoch 17/20, Iteration 263/303, Loss: 0.11969267576932907\n",
      "Epoch 17/20, Iteration 264/303, Loss: 0.111863873898983\n",
      "Epoch 17/20, Iteration 265/303, Loss: 0.02327622100710869\n",
      "Epoch 17/20, Iteration 266/303, Loss: 0.023137835785746574\n",
      "Epoch 17/20, Iteration 267/303, Loss: 0.04076972231268883\n",
      "Epoch 17/20, Iteration 268/303, Loss: 0.020606111735105515\n",
      "Epoch 17/20, Iteration 269/303, Loss: 0.12088124454021454\n",
      "Epoch 17/20, Iteration 270/303, Loss: 0.012975161895155907\n",
      "Epoch 17/20, Iteration 271/303, Loss: 0.008190619759261608\n",
      "Epoch 17/20, Iteration 272/303, Loss: 0.14206717908382416\n",
      "Epoch 17/20, Iteration 273/303, Loss: 0.015779616311192513\n",
      "Epoch 17/20, Iteration 274/303, Loss: 0.017023427411913872\n",
      "Epoch 17/20, Iteration 275/303, Loss: 0.056244708597660065\n",
      "Epoch 17/20, Iteration 276/303, Loss: 0.012010738253593445\n",
      "Epoch 17/20, Iteration 277/303, Loss: 0.017046861350536346\n",
      "Epoch 17/20, Iteration 278/303, Loss: 0.048834819346666336\n",
      "Epoch 17/20, Iteration 279/303, Loss: 0.013457409106194973\n",
      "Epoch 17/20, Iteration 280/303, Loss: 0.02657613717019558\n",
      "Epoch 17/20, Iteration 281/303, Loss: 0.03795209154486656\n",
      "Epoch 17/20, Iteration 282/303, Loss: 0.024841120466589928\n",
      "Epoch 17/20, Iteration 283/303, Loss: 0.016236841678619385\n",
      "Epoch 17/20, Iteration 284/303, Loss: 0.030706044286489487\n",
      "Epoch 17/20, Iteration 285/303, Loss: 0.005091566126793623\n",
      "Epoch 17/20, Iteration 286/303, Loss: 0.004148157313466072\n",
      "Epoch 17/20, Iteration 287/303, Loss: 0.04006168618798256\n",
      "Epoch 17/20, Iteration 288/303, Loss: 0.006474880967289209\n",
      "Epoch 17/20, Iteration 289/303, Loss: 0.01158586610108614\n",
      "Epoch 17/20, Iteration 290/303, Loss: 0.013247561641037464\n",
      "Epoch 17/20, Iteration 291/303, Loss: 0.03956979140639305\n",
      "Epoch 17/20, Iteration 292/303, Loss: 0.08145637810230255\n",
      "Epoch 17/20, Iteration 293/303, Loss: 0.0008087542955763638\n",
      "Epoch 17/20, Iteration 294/303, Loss: 0.008481888100504875\n",
      "Epoch 17/20, Iteration 295/303, Loss: 0.0637366771697998\n",
      "Epoch 17/20, Iteration 296/303, Loss: 0.03689367696642876\n",
      "Epoch 17/20, Iteration 297/303, Loss: 0.059834979474544525\n",
      "Epoch 17/20, Iteration 298/303, Loss: 0.07566120475530624\n",
      "Epoch 17/20, Iteration 299/303, Loss: 0.06207788363099098\n",
      "Epoch 17/20, Iteration 300/303, Loss: 0.039960574358701706\n",
      "Epoch 17/20, Iteration 301/303, Loss: 0.06415990740060806\n",
      "Epoch 17/20, Iteration 302/303, Loss: 0.15366049110889435\n",
      "Epoch 17/20, Iteration 303/303, Loss: 0.1763133406639099\n",
      "Epoch 18/20, Iteration 1/303, Loss: 0.019785026088356972\n",
      "Epoch 18/20, Iteration 2/303, Loss: 0.046487197279930115\n",
      "Epoch 18/20, Iteration 3/303, Loss: 0.02908305637538433\n",
      "Epoch 18/20, Iteration 4/303, Loss: 0.05984625220298767\n",
      "Epoch 18/20, Iteration 5/303, Loss: 0.02298620529472828\n",
      "Epoch 18/20, Iteration 6/303, Loss: 0.07785652577877045\n",
      "Epoch 18/20, Iteration 7/303, Loss: 0.010040921159088612\n",
      "Epoch 18/20, Iteration 8/303, Loss: 0.008831683546304703\n",
      "Epoch 18/20, Iteration 9/303, Loss: 0.05211087316274643\n",
      "Epoch 18/20, Iteration 10/303, Loss: 0.030841123312711716\n",
      "Epoch 18/20, Iteration 11/303, Loss: 0.02983459085226059\n",
      "Epoch 18/20, Iteration 12/303, Loss: 0.013987119309604168\n",
      "Epoch 18/20, Iteration 13/303, Loss: 0.029066938906908035\n",
      "Epoch 18/20, Iteration 14/303, Loss: 0.016951221972703934\n",
      "Epoch 18/20, Iteration 15/303, Loss: 0.07720489799976349\n",
      "Epoch 18/20, Iteration 16/303, Loss: 0.0017660863231867552\n",
      "Epoch 18/20, Iteration 17/303, Loss: 0.03374078497290611\n",
      "Epoch 18/20, Iteration 18/303, Loss: 0.01279659103602171\n",
      "Epoch 18/20, Iteration 19/303, Loss: 0.019088270142674446\n",
      "Epoch 18/20, Iteration 20/303, Loss: 0.015267718583345413\n",
      "Epoch 18/20, Iteration 21/303, Loss: 0.051190704107284546\n",
      "Epoch 18/20, Iteration 22/303, Loss: 0.018621377646923065\n",
      "Epoch 18/20, Iteration 23/303, Loss: 0.011513004079461098\n",
      "Epoch 18/20, Iteration 24/303, Loss: 0.040475595742464066\n",
      "Epoch 18/20, Iteration 25/303, Loss: 0.056847214698791504\n",
      "Epoch 18/20, Iteration 26/303, Loss: 0.028167465701699257\n",
      "Epoch 18/20, Iteration 27/303, Loss: 0.03188632056117058\n",
      "Epoch 18/20, Iteration 28/303, Loss: 0.07382648438215256\n",
      "Epoch 18/20, Iteration 29/303, Loss: 0.008688139729201794\n",
      "Epoch 18/20, Iteration 30/303, Loss: 0.021773934364318848\n",
      "Epoch 18/20, Iteration 31/303, Loss: 0.03057211823761463\n",
      "Epoch 18/20, Iteration 32/303, Loss: 0.02527412585914135\n",
      "Epoch 18/20, Iteration 33/303, Loss: 0.010257773101329803\n",
      "Epoch 18/20, Iteration 34/303, Loss: 0.02024533599615097\n",
      "Epoch 18/20, Iteration 35/303, Loss: 0.01814912259578705\n",
      "Epoch 18/20, Iteration 36/303, Loss: 0.012386486865580082\n",
      "Epoch 18/20, Iteration 37/303, Loss: 0.01305851899087429\n",
      "Epoch 18/20, Iteration 38/303, Loss: 0.007542767096310854\n",
      "Epoch 18/20, Iteration 39/303, Loss: 0.005587297957390547\n",
      "Epoch 18/20, Iteration 40/303, Loss: 0.017179157584905624\n",
      "Epoch 18/20, Iteration 41/303, Loss: 0.012524991296231747\n",
      "Epoch 18/20, Iteration 42/303, Loss: 0.019191507250070572\n",
      "Epoch 18/20, Iteration 43/303, Loss: 0.0349557101726532\n",
      "Epoch 18/20, Iteration 44/303, Loss: 0.05003562197089195\n",
      "Epoch 18/20, Iteration 45/303, Loss: 0.008517159149050713\n",
      "Epoch 18/20, Iteration 46/303, Loss: 0.010850111022591591\n",
      "Epoch 18/20, Iteration 47/303, Loss: 0.013765356503427029\n",
      "Epoch 18/20, Iteration 48/303, Loss: 0.021498098969459534\n",
      "Epoch 18/20, Iteration 49/303, Loss: 0.0039751785807311535\n",
      "Epoch 18/20, Iteration 50/303, Loss: 0.006783684249967337\n",
      "Epoch 18/20, Iteration 51/303, Loss: 0.02039218507707119\n",
      "Epoch 18/20, Iteration 52/303, Loss: 0.005989050026983023\n",
      "Epoch 18/20, Iteration 53/303, Loss: 0.005659214220941067\n",
      "Epoch 18/20, Iteration 54/303, Loss: 0.003042081370949745\n",
      "Epoch 18/20, Iteration 55/303, Loss: 0.007893356494605541\n",
      "Epoch 18/20, Iteration 56/303, Loss: 0.03233141079545021\n",
      "Epoch 18/20, Iteration 57/303, Loss: 0.013972186483442783\n",
      "Epoch 18/20, Iteration 58/303, Loss: 0.006790664978325367\n",
      "Epoch 18/20, Iteration 59/303, Loss: 0.008563282899558544\n",
      "Epoch 18/20, Iteration 60/303, Loss: 0.004151827655732632\n",
      "Epoch 18/20, Iteration 61/303, Loss: 0.02509543113410473\n",
      "Epoch 18/20, Iteration 62/303, Loss: 0.005006516817957163\n",
      "Epoch 18/20, Iteration 63/303, Loss: 0.0227223951369524\n",
      "Epoch 18/20, Iteration 64/303, Loss: 0.008345980197191238\n",
      "Epoch 18/20, Iteration 65/303, Loss: 0.01585068553686142\n",
      "Epoch 18/20, Iteration 66/303, Loss: 0.013751882128417492\n",
      "Epoch 18/20, Iteration 67/303, Loss: 0.002782457275316119\n",
      "Epoch 18/20, Iteration 68/303, Loss: 0.00881711021065712\n",
      "Epoch 18/20, Iteration 69/303, Loss: 0.0059383222833275795\n",
      "Epoch 18/20, Iteration 70/303, Loss: 0.005036615766584873\n",
      "Epoch 18/20, Iteration 71/303, Loss: 0.02023695595562458\n",
      "Epoch 18/20, Iteration 72/303, Loss: 0.013245319947600365\n",
      "Epoch 18/20, Iteration 73/303, Loss: 0.018110550940036774\n",
      "Epoch 18/20, Iteration 74/303, Loss: 0.01066217478364706\n",
      "Epoch 18/20, Iteration 75/303, Loss: 0.004778468515723944\n",
      "Epoch 18/20, Iteration 76/303, Loss: 0.008741569705307484\n",
      "Epoch 18/20, Iteration 77/303, Loss: 0.017482001334428787\n",
      "Epoch 18/20, Iteration 78/303, Loss: 0.012740259990096092\n",
      "Epoch 18/20, Iteration 79/303, Loss: 0.017133459448814392\n",
      "Epoch 18/20, Iteration 80/303, Loss: 0.06236105039715767\n",
      "Epoch 18/20, Iteration 81/303, Loss: 0.010902025736868382\n",
      "Epoch 18/20, Iteration 82/303, Loss: 0.004285102244466543\n",
      "Epoch 18/20, Iteration 83/303, Loss: 0.025153031572699547\n",
      "Epoch 18/20, Iteration 84/303, Loss: 0.015974417328834534\n",
      "Epoch 18/20, Iteration 85/303, Loss: 0.00917988270521164\n",
      "Epoch 18/20, Iteration 86/303, Loss: 0.03909924253821373\n",
      "Epoch 18/20, Iteration 87/303, Loss: 0.019353004172444344\n",
      "Epoch 18/20, Iteration 88/303, Loss: 0.046261265873909\n",
      "Epoch 18/20, Iteration 89/303, Loss: 0.012099811807274818\n",
      "Epoch 18/20, Iteration 90/303, Loss: 0.00945520494133234\n",
      "Epoch 18/20, Iteration 91/303, Loss: 0.0012538912706077099\n",
      "Epoch 18/20, Iteration 92/303, Loss: 0.01166805811226368\n",
      "Epoch 18/20, Iteration 93/303, Loss: 0.013236449100077152\n",
      "Epoch 18/20, Iteration 94/303, Loss: 0.024560874328017235\n",
      "Epoch 18/20, Iteration 95/303, Loss: 0.0205699410289526\n",
      "Epoch 18/20, Iteration 96/303, Loss: 0.00588856590911746\n",
      "Epoch 18/20, Iteration 97/303, Loss: 0.0071012224070727825\n",
      "Epoch 18/20, Iteration 98/303, Loss: 0.017873603850603104\n",
      "Epoch 18/20, Iteration 99/303, Loss: 0.018084736540913582\n",
      "Epoch 18/20, Iteration 100/303, Loss: 0.05164189264178276\n",
      "Epoch 18/20, Iteration 101/303, Loss: 0.004548808094114065\n",
      "Epoch 18/20, Iteration 102/303, Loss: 0.005126588512212038\n",
      "Epoch 18/20, Iteration 103/303, Loss: 0.015857722610235214\n",
      "Epoch 18/20, Iteration 104/303, Loss: 0.025279834866523743\n",
      "Epoch 18/20, Iteration 105/303, Loss: 0.009491587057709694\n",
      "Epoch 18/20, Iteration 106/303, Loss: 0.006686685141175985\n",
      "Epoch 18/20, Iteration 107/303, Loss: 0.002025909721851349\n",
      "Epoch 18/20, Iteration 108/303, Loss: 0.03324393928050995\n",
      "Epoch 18/20, Iteration 109/303, Loss: 0.018333246931433678\n",
      "Epoch 18/20, Iteration 110/303, Loss: 0.011278052814304829\n",
      "Epoch 18/20, Iteration 111/303, Loss: 0.04063551127910614\n",
      "Epoch 18/20, Iteration 112/303, Loss: 0.008664794266223907\n",
      "Epoch 18/20, Iteration 113/303, Loss: 0.014022953808307648\n",
      "Epoch 18/20, Iteration 114/303, Loss: 0.0319451168179512\n",
      "Epoch 18/20, Iteration 115/303, Loss: 0.04477054998278618\n",
      "Epoch 18/20, Iteration 116/303, Loss: 0.004632173106074333\n",
      "Epoch 18/20, Iteration 117/303, Loss: 0.040098708122968674\n",
      "Epoch 18/20, Iteration 118/303, Loss: 0.003489062190055847\n",
      "Epoch 18/20, Iteration 119/303, Loss: 0.00559131009504199\n",
      "Epoch 18/20, Iteration 120/303, Loss: 0.011175460182130337\n",
      "Epoch 18/20, Iteration 121/303, Loss: 0.05309685692191124\n",
      "Epoch 18/20, Iteration 122/303, Loss: 0.0160711407661438\n",
      "Epoch 18/20, Iteration 123/303, Loss: 0.013336597010493279\n",
      "Epoch 18/20, Iteration 124/303, Loss: 0.01435272116214037\n",
      "Epoch 18/20, Iteration 125/303, Loss: 0.002275035483762622\n",
      "Epoch 18/20, Iteration 126/303, Loss: 0.004816683009266853\n",
      "Epoch 18/20, Iteration 127/303, Loss: 0.006354637444019318\n",
      "Epoch 18/20, Iteration 128/303, Loss: 0.002071601804345846\n",
      "Epoch 18/20, Iteration 129/303, Loss: 0.017096219584345818\n",
      "Epoch 18/20, Iteration 130/303, Loss: 0.017665214836597443\n",
      "Epoch 18/20, Iteration 131/303, Loss: 0.00836201012134552\n",
      "Epoch 18/20, Iteration 132/303, Loss: 0.16642238199710846\n",
      "Epoch 18/20, Iteration 133/303, Loss: 0.03479424864053726\n",
      "Epoch 18/20, Iteration 134/303, Loss: 0.0034643420949578285\n",
      "Epoch 18/20, Iteration 135/303, Loss: 0.007505080197006464\n",
      "Epoch 18/20, Iteration 136/303, Loss: 0.00982142798602581\n",
      "Epoch 18/20, Iteration 137/303, Loss: 0.0025405993219465017\n",
      "Epoch 18/20, Iteration 138/303, Loss: 0.03869391605257988\n",
      "Epoch 18/20, Iteration 139/303, Loss: 0.026568325236439705\n",
      "Epoch 18/20, Iteration 140/303, Loss: 0.04048303887248039\n",
      "Epoch 18/20, Iteration 141/303, Loss: 0.0029862448573112488\n",
      "Epoch 18/20, Iteration 142/303, Loss: 0.03702656179666519\n",
      "Epoch 18/20, Iteration 143/303, Loss: 0.04432421922683716\n",
      "Epoch 18/20, Iteration 144/303, Loss: 0.021234847605228424\n",
      "Epoch 18/20, Iteration 145/303, Loss: 0.007157019805163145\n",
      "Epoch 18/20, Iteration 146/303, Loss: 0.0211921576410532\n",
      "Epoch 18/20, Iteration 147/303, Loss: 0.03031778149306774\n",
      "Epoch 18/20, Iteration 148/303, Loss: 0.0020866221748292446\n",
      "Epoch 18/20, Iteration 149/303, Loss: 0.09064114838838577\n",
      "Epoch 18/20, Iteration 150/303, Loss: 0.019467370584607124\n",
      "Epoch 18/20, Iteration 151/303, Loss: 0.010876864194869995\n",
      "Epoch 18/20, Iteration 152/303, Loss: 0.03380819037556648\n",
      "Epoch 18/20, Iteration 153/303, Loss: 0.02652594819664955\n",
      "Epoch 18/20, Iteration 154/303, Loss: 0.053535088896751404\n",
      "Epoch 18/20, Iteration 155/303, Loss: 0.002661679871380329\n",
      "Epoch 18/20, Iteration 156/303, Loss: 0.003068629652261734\n",
      "Epoch 18/20, Iteration 157/303, Loss: 0.0032664865721017122\n",
      "Epoch 18/20, Iteration 158/303, Loss: 0.015306839719414711\n",
      "Epoch 18/20, Iteration 159/303, Loss: 0.003236894030123949\n",
      "Epoch 18/20, Iteration 160/303, Loss: 0.0685655027627945\n",
      "Epoch 18/20, Iteration 161/303, Loss: 0.006387453991919756\n",
      "Epoch 18/20, Iteration 162/303, Loss: 0.020357586443424225\n",
      "Epoch 18/20, Iteration 163/303, Loss: 0.052703388035297394\n",
      "Epoch 18/20, Iteration 164/303, Loss: 0.033715784549713135\n",
      "Epoch 18/20, Iteration 165/303, Loss: 0.039933547377586365\n",
      "Epoch 18/20, Iteration 166/303, Loss: 0.022407686337828636\n",
      "Epoch 18/20, Iteration 167/303, Loss: 0.032118819653987885\n",
      "Epoch 18/20, Iteration 168/303, Loss: 0.018583063036203384\n",
      "Epoch 18/20, Iteration 169/303, Loss: 0.008588612079620361\n",
      "Epoch 18/20, Iteration 170/303, Loss: 0.04136757552623749\n",
      "Epoch 18/20, Iteration 171/303, Loss: 0.013293377123773098\n",
      "Epoch 18/20, Iteration 172/303, Loss: 0.0012136250734329224\n",
      "Epoch 18/20, Iteration 173/303, Loss: 0.0021784398704767227\n",
      "Epoch 18/20, Iteration 174/303, Loss: 0.03221117705106735\n",
      "Epoch 18/20, Iteration 175/303, Loss: 0.004620871040970087\n",
      "Epoch 18/20, Iteration 176/303, Loss: 0.04502955824136734\n",
      "Epoch 18/20, Iteration 177/303, Loss: 0.008629504591226578\n",
      "Epoch 18/20, Iteration 178/303, Loss: 0.00877685472369194\n",
      "Epoch 18/20, Iteration 179/303, Loss: 0.0029183817096054554\n",
      "Epoch 18/20, Iteration 180/303, Loss: 0.004911004565656185\n",
      "Epoch 18/20, Iteration 181/303, Loss: 0.005894838832318783\n",
      "Epoch 18/20, Iteration 182/303, Loss: 0.037321604788303375\n",
      "Epoch 18/20, Iteration 183/303, Loss: 0.012806275859475136\n",
      "Epoch 18/20, Iteration 184/303, Loss: 0.019207404926419258\n",
      "Epoch 18/20, Iteration 185/303, Loss: 0.005482093896716833\n",
      "Epoch 18/20, Iteration 186/303, Loss: 0.0061373175121843815\n",
      "Epoch 18/20, Iteration 187/303, Loss: 0.010904302820563316\n",
      "Epoch 18/20, Iteration 188/303, Loss: 0.00426927674561739\n",
      "Epoch 18/20, Iteration 189/303, Loss: 0.00905774999409914\n",
      "Epoch 18/20, Iteration 190/303, Loss: 0.0046053314581513405\n",
      "Epoch 18/20, Iteration 191/303, Loss: 0.013080392964184284\n",
      "Epoch 18/20, Iteration 192/303, Loss: 0.011460821144282818\n",
      "Epoch 18/20, Iteration 193/303, Loss: 0.00844944454729557\n",
      "Epoch 18/20, Iteration 194/303, Loss: 0.032551877200603485\n",
      "Epoch 18/20, Iteration 195/303, Loss: 0.023423125967383385\n",
      "Epoch 18/20, Iteration 196/303, Loss: 0.025160271674394608\n",
      "Epoch 18/20, Iteration 197/303, Loss: 0.016202688217163086\n",
      "Epoch 18/20, Iteration 198/303, Loss: 0.025304319337010384\n",
      "Epoch 18/20, Iteration 199/303, Loss: 0.036284953355789185\n",
      "Epoch 18/20, Iteration 200/303, Loss: 0.00788520835340023\n",
      "Epoch 18/20, Iteration 201/303, Loss: 0.070161372423172\n",
      "Epoch 18/20, Iteration 202/303, Loss: 0.06089311093091965\n",
      "Epoch 18/20, Iteration 203/303, Loss: 0.026280272752046585\n",
      "Epoch 18/20, Iteration 204/303, Loss: 0.022467724978923798\n",
      "Epoch 18/20, Iteration 205/303, Loss: 0.0019094739109277725\n",
      "Epoch 18/20, Iteration 206/303, Loss: 0.05177689343690872\n",
      "Epoch 18/20, Iteration 207/303, Loss: 0.037684664130210876\n",
      "Epoch 18/20, Iteration 208/303, Loss: 0.05845527723431587\n",
      "Epoch 18/20, Iteration 209/303, Loss: 0.00543659832328558\n",
      "Epoch 18/20, Iteration 210/303, Loss: 0.03819349408149719\n",
      "Epoch 18/20, Iteration 211/303, Loss: 0.018751269206404686\n",
      "Epoch 18/20, Iteration 212/303, Loss: 0.014449326321482658\n",
      "Epoch 18/20, Iteration 213/303, Loss: 0.012411631643772125\n",
      "Epoch 18/20, Iteration 214/303, Loss: 0.020625026896595955\n",
      "Epoch 18/20, Iteration 215/303, Loss: 0.005126550793647766\n",
      "Epoch 18/20, Iteration 216/303, Loss: 0.00997278280556202\n",
      "Epoch 18/20, Iteration 217/303, Loss: 0.004696306772530079\n",
      "Epoch 18/20, Iteration 218/303, Loss: 0.04755441099405289\n",
      "Epoch 18/20, Iteration 219/303, Loss: 0.014162255451083183\n",
      "Epoch 18/20, Iteration 220/303, Loss: 0.0023836009204387665\n",
      "Epoch 18/20, Iteration 221/303, Loss: 0.03698970749974251\n",
      "Epoch 18/20, Iteration 222/303, Loss: 0.021067697554826736\n",
      "Epoch 18/20, Iteration 223/303, Loss: 0.0070593878626823425\n",
      "Epoch 18/20, Iteration 224/303, Loss: 0.015147620812058449\n",
      "Epoch 18/20, Iteration 225/303, Loss: 0.016295205801725388\n",
      "Epoch 18/20, Iteration 226/303, Loss: 0.023143300786614418\n",
      "Epoch 18/20, Iteration 227/303, Loss: 0.0038306452333927155\n",
      "Epoch 18/20, Iteration 228/303, Loss: 0.007391732186079025\n",
      "Epoch 18/20, Iteration 229/303, Loss: 0.024654118344187737\n",
      "Epoch 18/20, Iteration 230/303, Loss: 0.0252007395029068\n",
      "Epoch 18/20, Iteration 231/303, Loss: 0.07489997893571854\n",
      "Epoch 18/20, Iteration 232/303, Loss: 0.0342513732612133\n",
      "Epoch 18/20, Iteration 233/303, Loss: 0.034973517060279846\n",
      "Epoch 18/20, Iteration 234/303, Loss: 0.014074984937906265\n",
      "Epoch 18/20, Iteration 235/303, Loss: 0.03968355804681778\n",
      "Epoch 18/20, Iteration 236/303, Loss: 0.007968837395310402\n",
      "Epoch 18/20, Iteration 237/303, Loss: 0.019312841817736626\n",
      "Epoch 18/20, Iteration 238/303, Loss: 0.010093078017234802\n",
      "Epoch 18/20, Iteration 239/303, Loss: 0.019419170916080475\n",
      "Epoch 18/20, Iteration 240/303, Loss: 0.017063964158296585\n",
      "Epoch 18/20, Iteration 241/303, Loss: 0.006580675486475229\n",
      "Epoch 18/20, Iteration 242/303, Loss: 0.04662758857011795\n",
      "Epoch 18/20, Iteration 243/303, Loss: 0.015155255794525146\n",
      "Epoch 18/20, Iteration 244/303, Loss: 0.0002510871272534132\n",
      "Epoch 18/20, Iteration 245/303, Loss: 0.002705853432416916\n",
      "Epoch 18/20, Iteration 246/303, Loss: 0.006112425122410059\n",
      "Epoch 18/20, Iteration 247/303, Loss: 0.012786117382347584\n",
      "Epoch 18/20, Iteration 248/303, Loss: 0.018392879515886307\n",
      "Epoch 18/20, Iteration 249/303, Loss: 0.015324894338846207\n",
      "Epoch 18/20, Iteration 250/303, Loss: 0.0007080780924297869\n",
      "Epoch 18/20, Iteration 251/303, Loss: 0.00234081014059484\n",
      "Epoch 18/20, Iteration 252/303, Loss: 0.00896405428647995\n",
      "Epoch 18/20, Iteration 253/303, Loss: 0.004781973548233509\n",
      "Epoch 18/20, Iteration 254/303, Loss: 0.0030308146961033344\n",
      "Epoch 18/20, Iteration 255/303, Loss: 0.008726198226213455\n",
      "Epoch 18/20, Iteration 256/303, Loss: 0.01010329369455576\n",
      "Epoch 18/20, Iteration 257/303, Loss: 0.005316602066159248\n",
      "Epoch 18/20, Iteration 258/303, Loss: 0.0045354925096035\n",
      "Epoch 18/20, Iteration 259/303, Loss: 0.0014066840521991253\n",
      "Epoch 18/20, Iteration 260/303, Loss: 0.01819484494626522\n",
      "Epoch 18/20, Iteration 261/303, Loss: 0.008388102985918522\n",
      "Epoch 18/20, Iteration 262/303, Loss: 0.008449910208582878\n",
      "Epoch 18/20, Iteration 263/303, Loss: 0.04261181503534317\n",
      "Epoch 18/20, Iteration 264/303, Loss: 0.01368012186139822\n",
      "Epoch 18/20, Iteration 265/303, Loss: 0.0027517692651599646\n",
      "Epoch 18/20, Iteration 266/303, Loss: 0.001306316931731999\n",
      "Epoch 18/20, Iteration 267/303, Loss: 0.008507792837917805\n",
      "Epoch 18/20, Iteration 268/303, Loss: 0.0082402927801013\n",
      "Epoch 18/20, Iteration 269/303, Loss: 0.002870033960789442\n",
      "Epoch 18/20, Iteration 270/303, Loss: 0.015739908441901207\n",
      "Epoch 18/20, Iteration 271/303, Loss: 0.04522986710071564\n",
      "Epoch 18/20, Iteration 272/303, Loss: 0.0026579841505736113\n",
      "Epoch 18/20, Iteration 273/303, Loss: 0.0024655256420373917\n",
      "Epoch 18/20, Iteration 274/303, Loss: 0.020969653502106667\n",
      "Epoch 18/20, Iteration 275/303, Loss: 0.021301254630088806\n",
      "Epoch 18/20, Iteration 276/303, Loss: 0.013000794686377048\n",
      "Epoch 18/20, Iteration 277/303, Loss: 0.042814116925001144\n",
      "Epoch 18/20, Iteration 278/303, Loss: 0.009937291033565998\n",
      "Epoch 18/20, Iteration 279/303, Loss: 0.21006010472774506\n",
      "Epoch 18/20, Iteration 280/303, Loss: 0.4179157018661499\n",
      "Epoch 18/20, Iteration 281/303, Loss: 1.982370138168335\n",
      "Epoch 18/20, Iteration 282/303, Loss: 5.929629802703857\n",
      "Epoch 18/20, Iteration 283/303, Loss: 1.21230149269104\n",
      "Epoch 18/20, Iteration 284/303, Loss: 0.8277816772460938\n",
      "Epoch 18/20, Iteration 285/303, Loss: 0.6394971609115601\n",
      "Epoch 18/20, Iteration 286/303, Loss: 0.5814094543457031\n",
      "Epoch 18/20, Iteration 287/303, Loss: 0.47283005714416504\n",
      "Epoch 18/20, Iteration 288/303, Loss: 0.4217008650302887\n",
      "Epoch 18/20, Iteration 289/303, Loss: 0.4435458779335022\n",
      "Epoch 18/20, Iteration 290/303, Loss: 0.4052669107913971\n",
      "Epoch 18/20, Iteration 291/303, Loss: 0.19063284993171692\n",
      "Epoch 18/20, Iteration 292/303, Loss: 0.26114392280578613\n",
      "Epoch 18/20, Iteration 293/303, Loss: 0.2355976104736328\n",
      "Epoch 18/20, Iteration 294/303, Loss: 0.30736541748046875\n",
      "Epoch 18/20, Iteration 295/303, Loss: 0.46815669536590576\n",
      "Epoch 18/20, Iteration 296/303, Loss: 0.20687511563301086\n",
      "Epoch 18/20, Iteration 297/303, Loss: 0.3025417625904083\n",
      "Epoch 18/20, Iteration 298/303, Loss: 0.21710558235645294\n",
      "Epoch 18/20, Iteration 299/303, Loss: 0.22855046391487122\n",
      "Epoch 18/20, Iteration 300/303, Loss: 0.22134798765182495\n",
      "Epoch 18/20, Iteration 301/303, Loss: 0.2680473029613495\n",
      "Epoch 18/20, Iteration 302/303, Loss: 0.12138707935810089\n",
      "Epoch 18/20, Iteration 303/303, Loss: 0.05068913847208023\n",
      "Epoch 19/20, Iteration 1/303, Loss: 0.27459216117858887\n",
      "Epoch 19/20, Iteration 2/303, Loss: 0.2588173747062683\n",
      "Epoch 19/20, Iteration 3/303, Loss: 0.11237751692533493\n",
      "Epoch 19/20, Iteration 4/303, Loss: 0.16228525340557098\n",
      "Epoch 19/20, Iteration 5/303, Loss: 0.11590596288442612\n",
      "Epoch 19/20, Iteration 6/303, Loss: 0.07945211231708527\n",
      "Epoch 19/20, Iteration 7/303, Loss: 0.09687891602516174\n",
      "Epoch 19/20, Iteration 8/303, Loss: 0.1107877641916275\n",
      "Epoch 19/20, Iteration 9/303, Loss: 0.07006056606769562\n",
      "Epoch 19/20, Iteration 10/303, Loss: 0.15896548330783844\n",
      "Epoch 19/20, Iteration 11/303, Loss: 0.17138239741325378\n",
      "Epoch 19/20, Iteration 12/303, Loss: 0.12013647705316544\n",
      "Epoch 19/20, Iteration 13/303, Loss: 0.16597102582454681\n",
      "Epoch 19/20, Iteration 14/303, Loss: 0.21067549288272858\n",
      "Epoch 19/20, Iteration 15/303, Loss: 0.316402405500412\n",
      "Epoch 19/20, Iteration 16/303, Loss: 0.11244262754917145\n",
      "Epoch 19/20, Iteration 17/303, Loss: 0.114023357629776\n",
      "Epoch 19/20, Iteration 18/303, Loss: 0.13628290593624115\n",
      "Epoch 19/20, Iteration 19/303, Loss: 0.06012037768959999\n",
      "Epoch 19/20, Iteration 20/303, Loss: 0.07715269923210144\n",
      "Epoch 19/20, Iteration 21/303, Loss: 0.10279788076877594\n",
      "Epoch 19/20, Iteration 22/303, Loss: 0.06135311350226402\n",
      "Epoch 19/20, Iteration 23/303, Loss: 0.08727750182151794\n",
      "Epoch 19/20, Iteration 24/303, Loss: 0.09624718874692917\n",
      "Epoch 19/20, Iteration 25/303, Loss: 0.0650583952665329\n",
      "Epoch 19/20, Iteration 26/303, Loss: 0.23764759302139282\n",
      "Epoch 19/20, Iteration 27/303, Loss: 0.06007960066199303\n",
      "Epoch 19/20, Iteration 28/303, Loss: 0.16811694204807281\n",
      "Epoch 19/20, Iteration 29/303, Loss: 0.055510275065898895\n",
      "Epoch 19/20, Iteration 30/303, Loss: 0.10294551402330399\n",
      "Epoch 19/20, Iteration 31/303, Loss: 0.17224562168121338\n",
      "Epoch 19/20, Iteration 32/303, Loss: 0.28774386644363403\n",
      "Epoch 19/20, Iteration 33/303, Loss: 0.22292929887771606\n",
      "Epoch 19/20, Iteration 34/303, Loss: 0.09036770462989807\n",
      "Epoch 19/20, Iteration 35/303, Loss: 0.1548711061477661\n",
      "Epoch 19/20, Iteration 36/303, Loss: 0.13384945690631866\n",
      "Epoch 19/20, Iteration 37/303, Loss: 0.07722578197717667\n",
      "Epoch 19/20, Iteration 38/303, Loss: 0.06562753021717072\n",
      "Epoch 19/20, Iteration 39/303, Loss: 0.05629783123731613\n",
      "Epoch 19/20, Iteration 40/303, Loss: 0.17717638611793518\n",
      "Epoch 19/20, Iteration 41/303, Loss: 0.13356013596057892\n",
      "Epoch 19/20, Iteration 42/303, Loss: 0.1872887909412384\n",
      "Epoch 19/20, Iteration 43/303, Loss: 0.056848879903554916\n",
      "Epoch 19/20, Iteration 44/303, Loss: 0.012826526537537575\n",
      "Epoch 19/20, Iteration 45/303, Loss: 0.09254562109708786\n",
      "Epoch 19/20, Iteration 46/303, Loss: 0.08011220395565033\n",
      "Epoch 19/20, Iteration 47/303, Loss: 0.05815191939473152\n",
      "Epoch 19/20, Iteration 48/303, Loss: 0.07920413464307785\n",
      "Epoch 19/20, Iteration 49/303, Loss: 0.07353340834379196\n",
      "Epoch 19/20, Iteration 50/303, Loss: 0.02189396694302559\n",
      "Epoch 19/20, Iteration 51/303, Loss: 0.030173392966389656\n",
      "Epoch 19/20, Iteration 52/303, Loss: 0.030269527807831764\n",
      "Epoch 19/20, Iteration 53/303, Loss: 0.09680294990539551\n",
      "Epoch 19/20, Iteration 54/303, Loss: 0.03832254931330681\n",
      "Epoch 19/20, Iteration 55/303, Loss: 0.048382606357336044\n",
      "Epoch 19/20, Iteration 56/303, Loss: 0.015511760488152504\n",
      "Epoch 19/20, Iteration 57/303, Loss: 0.03734362870454788\n",
      "Epoch 19/20, Iteration 58/303, Loss: 0.08026450872421265\n",
      "Epoch 19/20, Iteration 59/303, Loss: 0.03807810693979263\n",
      "Epoch 19/20, Iteration 60/303, Loss: 0.08459937572479248\n",
      "Epoch 19/20, Iteration 61/303, Loss: 0.040697868913412094\n",
      "Epoch 19/20, Iteration 62/303, Loss: 0.021621525287628174\n",
      "Epoch 19/20, Iteration 63/303, Loss: 0.16722410917282104\n",
      "Epoch 19/20, Iteration 64/303, Loss: 0.08359257876873016\n",
      "Epoch 19/20, Iteration 65/303, Loss: 0.09908755123615265\n",
      "Epoch 19/20, Iteration 66/303, Loss: 0.006061832420527935\n",
      "Epoch 19/20, Iteration 67/303, Loss: 0.02877727523446083\n",
      "Epoch 19/20, Iteration 68/303, Loss: 0.2299908548593521\n",
      "Epoch 19/20, Iteration 69/303, Loss: 0.1001446470618248\n",
      "Epoch 19/20, Iteration 70/303, Loss: 0.0800953358411789\n",
      "Epoch 19/20, Iteration 71/303, Loss: 0.14485597610473633\n",
      "Epoch 19/20, Iteration 72/303, Loss: 0.10326443612575531\n",
      "Epoch 19/20, Iteration 73/303, Loss: 0.10327539592981339\n",
      "Epoch 19/20, Iteration 74/303, Loss: 0.05407817289233208\n",
      "Epoch 19/20, Iteration 75/303, Loss: 0.20247720181941986\n",
      "Epoch 19/20, Iteration 76/303, Loss: 0.11864618211984634\n",
      "Epoch 19/20, Iteration 77/303, Loss: 0.06099745258688927\n",
      "Epoch 19/20, Iteration 78/303, Loss: 0.01830892264842987\n",
      "Epoch 19/20, Iteration 79/303, Loss: 0.01266208291053772\n",
      "Epoch 19/20, Iteration 80/303, Loss: 0.10643250495195389\n",
      "Epoch 19/20, Iteration 81/303, Loss: 0.10423852503299713\n",
      "Epoch 19/20, Iteration 82/303, Loss: 0.08852853626012802\n",
      "Epoch 19/20, Iteration 83/303, Loss: 0.12471512705087662\n",
      "Epoch 19/20, Iteration 84/303, Loss: 0.058978065848350525\n",
      "Epoch 19/20, Iteration 85/303, Loss: 0.13225549459457397\n",
      "Epoch 19/20, Iteration 86/303, Loss: 0.04691182076931\n",
      "Epoch 19/20, Iteration 87/303, Loss: 0.07618970423936844\n",
      "Epoch 19/20, Iteration 88/303, Loss: 0.21992065012454987\n",
      "Epoch 19/20, Iteration 89/303, Loss: 0.1423041671514511\n",
      "Epoch 19/20, Iteration 90/303, Loss: 0.11873283982276917\n",
      "Epoch 19/20, Iteration 91/303, Loss: 0.16591233015060425\n",
      "Epoch 19/20, Iteration 92/303, Loss: 0.016124477609992027\n",
      "Epoch 19/20, Iteration 93/303, Loss: 0.09111952036619186\n",
      "Epoch 19/20, Iteration 94/303, Loss: 0.03566359728574753\n",
      "Epoch 19/20, Iteration 95/303, Loss: 0.030374089255928993\n",
      "Epoch 19/20, Iteration 96/303, Loss: 0.08680129796266556\n",
      "Epoch 19/20, Iteration 97/303, Loss: 0.10634500533342361\n",
      "Epoch 19/20, Iteration 98/303, Loss: 0.030710261315107346\n",
      "Epoch 19/20, Iteration 99/303, Loss: 0.03614911437034607\n",
      "Epoch 19/20, Iteration 100/303, Loss: 0.02993428148329258\n",
      "Epoch 19/20, Iteration 101/303, Loss: 0.0920858308672905\n",
      "Epoch 19/20, Iteration 102/303, Loss: 0.195135235786438\n",
      "Epoch 19/20, Iteration 103/303, Loss: 0.06773199141025543\n",
      "Epoch 19/20, Iteration 104/303, Loss: 0.024179300293326378\n",
      "Epoch 19/20, Iteration 105/303, Loss: 0.01540021225810051\n",
      "Epoch 19/20, Iteration 106/303, Loss: 0.025726858526468277\n",
      "Epoch 19/20, Iteration 107/303, Loss: 0.09607372432947159\n",
      "Epoch 19/20, Iteration 108/303, Loss: 0.04174397140741348\n",
      "Epoch 19/20, Iteration 109/303, Loss: 0.035739511251449585\n",
      "Epoch 19/20, Iteration 110/303, Loss: 0.1693890392780304\n",
      "Epoch 19/20, Iteration 111/303, Loss: 0.1735876500606537\n",
      "Epoch 19/20, Iteration 112/303, Loss: 0.16209948062896729\n",
      "Epoch 19/20, Iteration 113/303, Loss: 0.07446523010730743\n",
      "Epoch 19/20, Iteration 114/303, Loss: 0.13810180127620697\n",
      "Epoch 19/20, Iteration 115/303, Loss: 0.192319855093956\n",
      "Epoch 19/20, Iteration 116/303, Loss: 0.11392943561077118\n",
      "Epoch 19/20, Iteration 117/303, Loss: 0.017610998824238777\n",
      "Epoch 19/20, Iteration 118/303, Loss: 0.03427708521485329\n",
      "Epoch 19/20, Iteration 119/303, Loss: 0.02406305819749832\n",
      "Epoch 19/20, Iteration 120/303, Loss: 0.023475002497434616\n",
      "Epoch 19/20, Iteration 121/303, Loss: 0.07986795157194138\n",
      "Epoch 19/20, Iteration 122/303, Loss: 0.06391681730747223\n",
      "Epoch 19/20, Iteration 123/303, Loss: 0.07344662398099899\n",
      "Epoch 19/20, Iteration 124/303, Loss: 0.03778122738003731\n",
      "Epoch 19/20, Iteration 125/303, Loss: 0.06782688200473785\n",
      "Epoch 19/20, Iteration 126/303, Loss: 0.04350227117538452\n",
      "Epoch 19/20, Iteration 127/303, Loss: 0.023064935579895973\n",
      "Epoch 19/20, Iteration 128/303, Loss: 0.022086329758167267\n",
      "Epoch 19/20, Iteration 129/303, Loss: 0.059361983090639114\n",
      "Epoch 19/20, Iteration 130/303, Loss: 0.01581883616745472\n",
      "Epoch 19/20, Iteration 131/303, Loss: 0.07006967067718506\n",
      "Epoch 19/20, Iteration 132/303, Loss: 0.10034357756376266\n",
      "Epoch 19/20, Iteration 133/303, Loss: 0.01629706844687462\n",
      "Epoch 19/20, Iteration 134/303, Loss: 0.016374792903661728\n",
      "Epoch 19/20, Iteration 135/303, Loss: 0.027992550283670425\n",
      "Epoch 19/20, Iteration 136/303, Loss: 0.04994126409292221\n",
      "Epoch 19/20, Iteration 137/303, Loss: 0.01901511289179325\n",
      "Epoch 19/20, Iteration 138/303, Loss: 0.31815269589424133\n",
      "Epoch 19/20, Iteration 139/303, Loss: 1.0568982362747192\n",
      "Epoch 19/20, Iteration 140/303, Loss: 0.5375377535820007\n",
      "Epoch 19/20, Iteration 141/303, Loss: 0.32955485582351685\n",
      "Epoch 19/20, Iteration 142/303, Loss: 0.1876048892736435\n",
      "Epoch 19/20, Iteration 143/303, Loss: 0.14205774664878845\n",
      "Epoch 19/20, Iteration 144/303, Loss: 0.2162044495344162\n",
      "Epoch 19/20, Iteration 145/303, Loss: 0.04368676617741585\n",
      "Epoch 19/20, Iteration 146/303, Loss: 0.1210574358701706\n",
      "Epoch 19/20, Iteration 147/303, Loss: 0.0723981261253357\n",
      "Epoch 19/20, Iteration 148/303, Loss: 0.06908981502056122\n",
      "Epoch 19/20, Iteration 149/303, Loss: 0.08713880926370621\n",
      "Epoch 19/20, Iteration 150/303, Loss: 0.13155336678028107\n",
      "Epoch 19/20, Iteration 151/303, Loss: 0.12743723392486572\n",
      "Epoch 19/20, Iteration 152/303, Loss: 0.12458744645118713\n",
      "Epoch 19/20, Iteration 153/303, Loss: 0.09039951860904694\n",
      "Epoch 19/20, Iteration 154/303, Loss: 0.09956115484237671\n",
      "Epoch 19/20, Iteration 155/303, Loss: 0.040876083076000214\n",
      "Epoch 19/20, Iteration 156/303, Loss: 0.04797928035259247\n",
      "Epoch 19/20, Iteration 157/303, Loss: 0.038448985666036606\n",
      "Epoch 19/20, Iteration 158/303, Loss: 0.14658750593662262\n",
      "Epoch 19/20, Iteration 159/303, Loss: 0.1233304813504219\n",
      "Epoch 19/20, Iteration 160/303, Loss: 0.048679813742637634\n",
      "Epoch 19/20, Iteration 161/303, Loss: 0.02451198734343052\n",
      "Epoch 19/20, Iteration 162/303, Loss: 0.0977039784193039\n",
      "Epoch 19/20, Iteration 163/303, Loss: 0.05932505428791046\n",
      "Epoch 19/20, Iteration 164/303, Loss: 0.028280658647418022\n",
      "Epoch 19/20, Iteration 165/303, Loss: 0.04921529442071915\n",
      "Epoch 19/20, Iteration 166/303, Loss: 0.03572586551308632\n",
      "Epoch 19/20, Iteration 167/303, Loss: 0.029508108273148537\n",
      "Epoch 19/20, Iteration 168/303, Loss: 0.03323247656226158\n",
      "Epoch 19/20, Iteration 169/303, Loss: 0.05444149300456047\n",
      "Epoch 19/20, Iteration 170/303, Loss: 0.06481122225522995\n",
      "Epoch 19/20, Iteration 171/303, Loss: 0.05011342838406563\n",
      "Epoch 19/20, Iteration 172/303, Loss: 0.09060423076152802\n",
      "Epoch 19/20, Iteration 173/303, Loss: 0.11078979820013046\n",
      "Epoch 19/20, Iteration 174/303, Loss: 0.09918868541717529\n",
      "Epoch 19/20, Iteration 175/303, Loss: 0.04611395671963692\n",
      "Epoch 19/20, Iteration 176/303, Loss: 0.06423044204711914\n",
      "Epoch 19/20, Iteration 177/303, Loss: 0.04096059128642082\n",
      "Epoch 19/20, Iteration 178/303, Loss: 0.13007819652557373\n",
      "Epoch 19/20, Iteration 179/303, Loss: 0.021052023395895958\n",
      "Epoch 19/20, Iteration 180/303, Loss: 0.01895304210484028\n",
      "Epoch 19/20, Iteration 181/303, Loss: 0.04628443717956543\n",
      "Epoch 19/20, Iteration 182/303, Loss: 0.02846413478255272\n",
      "Epoch 19/20, Iteration 183/303, Loss: 0.0612909235060215\n",
      "Epoch 19/20, Iteration 184/303, Loss: 0.17686989903450012\n",
      "Epoch 19/20, Iteration 185/303, Loss: 0.05232083424925804\n",
      "Epoch 19/20, Iteration 186/303, Loss: 0.018334418535232544\n",
      "Epoch 19/20, Iteration 187/303, Loss: 0.03373333439230919\n",
      "Epoch 19/20, Iteration 188/303, Loss: 0.032183051109313965\n",
      "Epoch 19/20, Iteration 189/303, Loss: 0.05776811018586159\n",
      "Epoch 19/20, Iteration 190/303, Loss: 0.011562708765268326\n",
      "Epoch 19/20, Iteration 191/303, Loss: 0.04623713344335556\n",
      "Epoch 19/20, Iteration 192/303, Loss: 0.036137040704488754\n",
      "Epoch 19/20, Iteration 193/303, Loss: 0.10567685961723328\n",
      "Epoch 19/20, Iteration 194/303, Loss: 0.20488779246807098\n",
      "Epoch 19/20, Iteration 195/303, Loss: 0.06788314878940582\n",
      "Epoch 19/20, Iteration 196/303, Loss: 0.026796141639351845\n",
      "Epoch 19/20, Iteration 197/303, Loss: 0.07587318867444992\n",
      "Epoch 19/20, Iteration 198/303, Loss: 0.05679700896143913\n",
      "Epoch 19/20, Iteration 199/303, Loss: 0.01340850442647934\n",
      "Epoch 19/20, Iteration 200/303, Loss: 0.03979887813329697\n",
      "Epoch 19/20, Iteration 201/303, Loss: 0.044575035572052\n",
      "Epoch 19/20, Iteration 202/303, Loss: 0.09850594401359558\n",
      "Epoch 19/20, Iteration 203/303, Loss: 0.008794794790446758\n",
      "Epoch 19/20, Iteration 204/303, Loss: 0.011727793142199516\n",
      "Epoch 19/20, Iteration 205/303, Loss: 0.035455718636512756\n",
      "Epoch 19/20, Iteration 206/303, Loss: 0.025042157620191574\n",
      "Epoch 19/20, Iteration 207/303, Loss: 0.0872533768415451\n",
      "Epoch 19/20, Iteration 208/303, Loss: 0.021898377686738968\n",
      "Epoch 19/20, Iteration 209/303, Loss: 0.02041122317314148\n",
      "Epoch 19/20, Iteration 210/303, Loss: 0.045085761696100235\n",
      "Epoch 19/20, Iteration 211/303, Loss: 0.007821379229426384\n",
      "Epoch 19/20, Iteration 212/303, Loss: 0.13691593706607819\n",
      "Epoch 19/20, Iteration 213/303, Loss: 0.051884859800338745\n",
      "Epoch 19/20, Iteration 214/303, Loss: 0.158160001039505\n",
      "Epoch 19/20, Iteration 215/303, Loss: 0.07680362462997437\n",
      "Epoch 19/20, Iteration 216/303, Loss: 0.07177859544754028\n",
      "Epoch 19/20, Iteration 217/303, Loss: 0.04326912760734558\n",
      "Epoch 19/20, Iteration 218/303, Loss: 0.02135458216071129\n",
      "Epoch 19/20, Iteration 219/303, Loss: 0.06169694662094116\n",
      "Epoch 19/20, Iteration 220/303, Loss: 0.0348953977227211\n",
      "Epoch 19/20, Iteration 221/303, Loss: 0.13294963538646698\n",
      "Epoch 19/20, Iteration 222/303, Loss: 0.20819351077079773\n",
      "Epoch 19/20, Iteration 223/303, Loss: 0.0703563243150711\n",
      "Epoch 19/20, Iteration 224/303, Loss: 0.026765907183289528\n",
      "Epoch 19/20, Iteration 225/303, Loss: 0.1142987310886383\n",
      "Epoch 19/20, Iteration 226/303, Loss: 0.026093967258930206\n",
      "Epoch 19/20, Iteration 227/303, Loss: 0.0909283384680748\n",
      "Epoch 19/20, Iteration 228/303, Loss: 0.023361120373010635\n",
      "Epoch 19/20, Iteration 229/303, Loss: 0.12024091184139252\n",
      "Epoch 19/20, Iteration 230/303, Loss: 0.04821782186627388\n",
      "Epoch 19/20, Iteration 231/303, Loss: 0.02333233132958412\n",
      "Epoch 19/20, Iteration 232/303, Loss: 0.12110010534524918\n",
      "Epoch 19/20, Iteration 233/303, Loss: 0.21117164194583893\n",
      "Epoch 19/20, Iteration 234/303, Loss: 0.21183623373508453\n",
      "Epoch 19/20, Iteration 235/303, Loss: 0.03232235834002495\n",
      "Epoch 19/20, Iteration 236/303, Loss: 0.08590482920408249\n",
      "Epoch 19/20, Iteration 237/303, Loss: 0.0845230370759964\n",
      "Epoch 19/20, Iteration 238/303, Loss: 0.08946257829666138\n",
      "Epoch 19/20, Iteration 239/303, Loss: 0.04081158712506294\n",
      "Epoch 19/20, Iteration 240/303, Loss: 0.0476272776722908\n",
      "Epoch 19/20, Iteration 241/303, Loss: 0.08136863261461258\n",
      "Epoch 19/20, Iteration 242/303, Loss: 0.10317263752222061\n",
      "Epoch 19/20, Iteration 243/303, Loss: 0.031496647745370865\n",
      "Epoch 19/20, Iteration 244/303, Loss: 0.09514261037111282\n",
      "Epoch 19/20, Iteration 245/303, Loss: 0.0762709379196167\n",
      "Epoch 19/20, Iteration 246/303, Loss: 0.08653532713651657\n",
      "Epoch 19/20, Iteration 247/303, Loss: 0.05884353816509247\n",
      "Epoch 19/20, Iteration 248/303, Loss: 0.06441012024879456\n",
      "Epoch 19/20, Iteration 249/303, Loss: 0.018075216561555862\n",
      "Epoch 19/20, Iteration 250/303, Loss: 0.08218198269605637\n",
      "Epoch 19/20, Iteration 251/303, Loss: 0.15617962181568146\n",
      "Epoch 19/20, Iteration 252/303, Loss: 0.02072170190513134\n",
      "Epoch 19/20, Iteration 253/303, Loss: 0.1069517731666565\n",
      "Epoch 19/20, Iteration 254/303, Loss: 0.04503052681684494\n",
      "Epoch 19/20, Iteration 255/303, Loss: 0.013185281306505203\n",
      "Epoch 19/20, Iteration 256/303, Loss: 0.030700037255883217\n",
      "Epoch 19/20, Iteration 257/303, Loss: 0.056247301399707794\n",
      "Epoch 19/20, Iteration 258/303, Loss: 0.049302972853183746\n",
      "Epoch 19/20, Iteration 259/303, Loss: 0.031697407364845276\n",
      "Epoch 19/20, Iteration 260/303, Loss: 0.06714320182800293\n",
      "Epoch 19/20, Iteration 261/303, Loss: 0.02187957800924778\n",
      "Epoch 19/20, Iteration 262/303, Loss: 0.047684475779533386\n",
      "Epoch 19/20, Iteration 263/303, Loss: 0.0077598812058568\n",
      "Epoch 19/20, Iteration 264/303, Loss: 0.016315286979079247\n",
      "Epoch 19/20, Iteration 265/303, Loss: 0.021359935402870178\n",
      "Epoch 19/20, Iteration 266/303, Loss: 0.03564761206507683\n",
      "Epoch 19/20, Iteration 267/303, Loss: 0.029046889394521713\n",
      "Epoch 19/20, Iteration 268/303, Loss: 0.019098520278930664\n",
      "Epoch 19/20, Iteration 269/303, Loss: 0.040572747588157654\n",
      "Epoch 19/20, Iteration 270/303, Loss: 0.04362037405371666\n",
      "Epoch 19/20, Iteration 271/303, Loss: 0.023975826799869537\n",
      "Epoch 19/20, Iteration 272/303, Loss: 0.009053257293999195\n",
      "Epoch 19/20, Iteration 273/303, Loss: 0.02473064884543419\n",
      "Epoch 19/20, Iteration 274/303, Loss: 0.008752388879656792\n",
      "Epoch 19/20, Iteration 275/303, Loss: 0.025413185358047485\n",
      "Epoch 19/20, Iteration 276/303, Loss: 0.04810293763875961\n",
      "Epoch 19/20, Iteration 277/303, Loss: 0.0807001143693924\n",
      "Epoch 19/20, Iteration 278/303, Loss: 0.08842089027166367\n",
      "Epoch 19/20, Iteration 279/303, Loss: 0.022869177162647247\n",
      "Epoch 19/20, Iteration 280/303, Loss: 0.052438050508499146\n",
      "Epoch 19/20, Iteration 281/303, Loss: 0.00408295588567853\n",
      "Epoch 19/20, Iteration 282/303, Loss: 0.03567071631550789\n",
      "Epoch 19/20, Iteration 283/303, Loss: 0.05498688295483589\n",
      "Epoch 19/20, Iteration 284/303, Loss: 0.02486579306423664\n",
      "Epoch 19/20, Iteration 285/303, Loss: 0.017379488795995712\n",
      "Epoch 19/20, Iteration 286/303, Loss: 0.14117978513240814\n",
      "Epoch 19/20, Iteration 287/303, Loss: 0.08455131202936172\n",
      "Epoch 19/20, Iteration 288/303, Loss: 0.10110059380531311\n",
      "Epoch 19/20, Iteration 289/303, Loss: 0.01296877022832632\n",
      "Epoch 19/20, Iteration 290/303, Loss: 0.08689360320568085\n",
      "Epoch 19/20, Iteration 291/303, Loss: 0.06151662394404411\n",
      "Epoch 19/20, Iteration 292/303, Loss: 0.04190656542778015\n",
      "Epoch 19/20, Iteration 293/303, Loss: 0.015406318008899689\n",
      "Epoch 19/20, Iteration 294/303, Loss: 0.07426879554986954\n",
      "Epoch 19/20, Iteration 295/303, Loss: 0.06404289603233337\n",
      "Epoch 19/20, Iteration 296/303, Loss: 0.011170138604938984\n",
      "Epoch 19/20, Iteration 297/303, Loss: 0.006296645849943161\n",
      "Epoch 19/20, Iteration 298/303, Loss: 0.00837790872901678\n",
      "Epoch 19/20, Iteration 299/303, Loss: 0.03961526229977608\n",
      "Epoch 19/20, Iteration 300/303, Loss: 0.19376039505004883\n",
      "Epoch 19/20, Iteration 301/303, Loss: 0.018824413418769836\n",
      "Epoch 19/20, Iteration 302/303, Loss: 0.0042463368736207485\n",
      "Epoch 19/20, Iteration 303/303, Loss: 0.047630440443754196\n",
      "Epoch 20/20, Iteration 1/303, Loss: 0.11136742681264877\n",
      "Epoch 20/20, Iteration 2/303, Loss: 0.028584904968738556\n",
      "Epoch 20/20, Iteration 3/303, Loss: 0.03759269043803215\n",
      "Epoch 20/20, Iteration 4/303, Loss: 0.03295871615409851\n",
      "Epoch 20/20, Iteration 5/303, Loss: 0.019214335829019547\n",
      "Epoch 20/20, Iteration 6/303, Loss: 0.02421588823199272\n",
      "Epoch 20/20, Iteration 7/303, Loss: 0.019294463098049164\n",
      "Epoch 20/20, Iteration 8/303, Loss: 0.013228701427578926\n",
      "Epoch 20/20, Iteration 9/303, Loss: 0.007126507814973593\n",
      "Epoch 20/20, Iteration 10/303, Loss: 0.01689806394279003\n",
      "Epoch 20/20, Iteration 11/303, Loss: 0.060046494007110596\n",
      "Epoch 20/20, Iteration 12/303, Loss: 0.06038593500852585\n",
      "Epoch 20/20, Iteration 13/303, Loss: 0.03474236652255058\n",
      "Epoch 20/20, Iteration 14/303, Loss: 0.05292033031582832\n",
      "Epoch 20/20, Iteration 15/303, Loss: 0.08815712481737137\n",
      "Epoch 20/20, Iteration 16/303, Loss: 0.10344012081623077\n",
      "Epoch 20/20, Iteration 17/303, Loss: 0.14297616481781006\n",
      "Epoch 20/20, Iteration 18/303, Loss: 0.04527176544070244\n",
      "Epoch 20/20, Iteration 19/303, Loss: 0.024429889395833015\n",
      "Epoch 20/20, Iteration 20/303, Loss: 0.010163380764424801\n",
      "Epoch 20/20, Iteration 21/303, Loss: 0.029667256399989128\n",
      "Epoch 20/20, Iteration 22/303, Loss: 0.00975031964480877\n",
      "Epoch 20/20, Iteration 23/303, Loss: 0.010052761994302273\n",
      "Epoch 20/20, Iteration 24/303, Loss: 0.012433832511305809\n",
      "Epoch 20/20, Iteration 25/303, Loss: 0.05817371979355812\n",
      "Epoch 20/20, Iteration 26/303, Loss: 0.01999749429523945\n",
      "Epoch 20/20, Iteration 27/303, Loss: 0.057475898414850235\n",
      "Epoch 20/20, Iteration 28/303, Loss: 0.08449936658143997\n",
      "Epoch 20/20, Iteration 29/303, Loss: 0.009879033081233501\n",
      "Epoch 20/20, Iteration 30/303, Loss: 0.026621147990226746\n",
      "Epoch 20/20, Iteration 31/303, Loss: 0.09326542913913727\n",
      "Epoch 20/20, Iteration 32/303, Loss: 0.011372396722435951\n",
      "Epoch 20/20, Iteration 33/303, Loss: 0.046027783304452896\n",
      "Epoch 20/20, Iteration 34/303, Loss: 0.04654910787940025\n",
      "Epoch 20/20, Iteration 35/303, Loss: 0.07775671035051346\n",
      "Epoch 20/20, Iteration 36/303, Loss: 0.03315822035074234\n",
      "Epoch 20/20, Iteration 37/303, Loss: 0.036671917885541916\n",
      "Epoch 20/20, Iteration 38/303, Loss: 0.008375117555260658\n",
      "Epoch 20/20, Iteration 39/303, Loss: 0.0376843698322773\n",
      "Epoch 20/20, Iteration 40/303, Loss: 0.014540639705955982\n",
      "Epoch 20/20, Iteration 41/303, Loss: 0.031641922891139984\n",
      "Epoch 20/20, Iteration 42/303, Loss: 0.16474516689777374\n",
      "Epoch 20/20, Iteration 43/303, Loss: 0.05863107368350029\n",
      "Epoch 20/20, Iteration 44/303, Loss: 0.010306430980563164\n",
      "Epoch 20/20, Iteration 45/303, Loss: 0.020930271595716476\n",
      "Epoch 20/20, Iteration 46/303, Loss: 0.036696162074804306\n",
      "Epoch 20/20, Iteration 47/303, Loss: 0.020899711176753044\n",
      "Epoch 20/20, Iteration 48/303, Loss: 0.02550484612584114\n",
      "Epoch 20/20, Iteration 49/303, Loss: 0.033838219940662384\n",
      "Epoch 20/20, Iteration 50/303, Loss: 0.008613829500973225\n",
      "Epoch 20/20, Iteration 51/303, Loss: 0.004596484825015068\n",
      "Epoch 20/20, Iteration 52/303, Loss: 0.0038231622893363237\n",
      "Epoch 20/20, Iteration 53/303, Loss: 0.010639157146215439\n",
      "Epoch 20/20, Iteration 54/303, Loss: 0.03227249160408974\n",
      "Epoch 20/20, Iteration 55/303, Loss: 0.02868812158703804\n",
      "Epoch 20/20, Iteration 56/303, Loss: 0.13283345103263855\n",
      "Epoch 20/20, Iteration 57/303, Loss: 0.015689091756939888\n",
      "Epoch 20/20, Iteration 58/303, Loss: 0.08385757356882095\n",
      "Epoch 20/20, Iteration 59/303, Loss: 0.030164506286382675\n",
      "Epoch 20/20, Iteration 60/303, Loss: 0.017695261165499687\n",
      "Epoch 20/20, Iteration 61/303, Loss: 0.004340710584074259\n",
      "Epoch 20/20, Iteration 62/303, Loss: 0.025169143453240395\n",
      "Epoch 20/20, Iteration 63/303, Loss: 0.021387089043855667\n",
      "Epoch 20/20, Iteration 64/303, Loss: 0.02129202149808407\n",
      "Epoch 20/20, Iteration 65/303, Loss: 0.012492552399635315\n",
      "Epoch 20/20, Iteration 66/303, Loss: 0.03648725897073746\n",
      "Epoch 20/20, Iteration 67/303, Loss: 0.026969728991389275\n",
      "Epoch 20/20, Iteration 68/303, Loss: 0.05921164155006409\n",
      "Epoch 20/20, Iteration 69/303, Loss: 0.02122326008975506\n",
      "Epoch 20/20, Iteration 70/303, Loss: 0.046925585716962814\n",
      "Epoch 20/20, Iteration 71/303, Loss: 0.03165727108716965\n",
      "Epoch 20/20, Iteration 72/303, Loss: 0.09532663226127625\n",
      "Epoch 20/20, Iteration 73/303, Loss: 0.0482330247759819\n",
      "Epoch 20/20, Iteration 74/303, Loss: 0.0673796758055687\n",
      "Epoch 20/20, Iteration 75/303, Loss: 0.04626660421490669\n",
      "Epoch 20/20, Iteration 76/303, Loss: 0.03790779784321785\n",
      "Epoch 20/20, Iteration 77/303, Loss: 0.14177671074867249\n",
      "Epoch 20/20, Iteration 78/303, Loss: 0.08373088389635086\n",
      "Epoch 20/20, Iteration 79/303, Loss: 0.16526064276695251\n",
      "Epoch 20/20, Iteration 80/303, Loss: 0.10494168847799301\n",
      "Epoch 20/20, Iteration 81/303, Loss: 0.10381484031677246\n",
      "Epoch 20/20, Iteration 82/303, Loss: 0.010552925989031792\n",
      "Epoch 20/20, Iteration 83/303, Loss: 0.07230769842863083\n",
      "Epoch 20/20, Iteration 84/303, Loss: 0.03513703495264053\n",
      "Epoch 20/20, Iteration 85/303, Loss: 0.059145279228687286\n",
      "Epoch 20/20, Iteration 86/303, Loss: 0.015616070479154587\n",
      "Epoch 20/20, Iteration 87/303, Loss: 0.04615693911910057\n",
      "Epoch 20/20, Iteration 88/303, Loss: 0.07173476368188858\n",
      "Epoch 20/20, Iteration 89/303, Loss: 0.06062488630414009\n",
      "Epoch 20/20, Iteration 90/303, Loss: 0.006191791966557503\n",
      "Epoch 20/20, Iteration 91/303, Loss: 0.03635089844465256\n",
      "Epoch 20/20, Iteration 92/303, Loss: 0.050560660660266876\n",
      "Epoch 20/20, Iteration 93/303, Loss: 0.004137954208999872\n",
      "Epoch 20/20, Iteration 94/303, Loss: 0.012229392305016518\n",
      "Epoch 20/20, Iteration 95/303, Loss: 0.00828857347369194\n",
      "Epoch 20/20, Iteration 96/303, Loss: 0.005238934885710478\n",
      "Epoch 20/20, Iteration 97/303, Loss: 0.025978432968258858\n",
      "Epoch 20/20, Iteration 98/303, Loss: 0.016683295369148254\n",
      "Epoch 20/20, Iteration 99/303, Loss: 0.06847113370895386\n",
      "Epoch 20/20, Iteration 100/303, Loss: 0.2386498898267746\n",
      "Epoch 20/20, Iteration 101/303, Loss: 0.023729508742690086\n",
      "Epoch 20/20, Iteration 102/303, Loss: 0.014714319258928299\n",
      "Epoch 20/20, Iteration 103/303, Loss: 0.03909553214907646\n",
      "Epoch 20/20, Iteration 104/303, Loss: 0.009976360946893692\n",
      "Epoch 20/20, Iteration 105/303, Loss: 0.011293187737464905\n",
      "Epoch 20/20, Iteration 106/303, Loss: 0.02858201041817665\n",
      "Epoch 20/20, Iteration 107/303, Loss: 0.010464636608958244\n",
      "Epoch 20/20, Iteration 108/303, Loss: 0.008891246281564236\n",
      "Epoch 20/20, Iteration 109/303, Loss: 0.12233954668045044\n",
      "Epoch 20/20, Iteration 110/303, Loss: 0.03451087698340416\n",
      "Epoch 20/20, Iteration 111/303, Loss: 0.06235624849796295\n",
      "Epoch 20/20, Iteration 112/303, Loss: 0.08584451675415039\n",
      "Epoch 20/20, Iteration 113/303, Loss: 0.18376007676124573\n",
      "Epoch 20/20, Iteration 114/303, Loss: 0.16198551654815674\n",
      "Epoch 20/20, Iteration 115/303, Loss: 0.17465855181217194\n",
      "Epoch 20/20, Iteration 116/303, Loss: 0.28548431396484375\n",
      "Epoch 20/20, Iteration 117/303, Loss: 0.06021630018949509\n",
      "Epoch 20/20, Iteration 118/303, Loss: 0.0904538631439209\n",
      "Epoch 20/20, Iteration 119/303, Loss: 0.025500085204839706\n",
      "Epoch 20/20, Iteration 120/303, Loss: 0.06546160578727722\n",
      "Epoch 20/20, Iteration 121/303, Loss: 0.007034859154373407\n",
      "Epoch 20/20, Iteration 122/303, Loss: 0.10706610232591629\n",
      "Epoch 20/20, Iteration 123/303, Loss: 0.06717129796743393\n",
      "Epoch 20/20, Iteration 124/303, Loss: 0.02085912600159645\n",
      "Epoch 20/20, Iteration 125/303, Loss: 0.061376407742500305\n",
      "Epoch 20/20, Iteration 126/303, Loss: 0.00894265715032816\n",
      "Epoch 20/20, Iteration 127/303, Loss: 0.031916309148073196\n",
      "Epoch 20/20, Iteration 128/303, Loss: 0.06500104814767838\n",
      "Epoch 20/20, Iteration 129/303, Loss: 0.13692441582679749\n",
      "Epoch 20/20, Iteration 130/303, Loss: 0.031683482229709625\n",
      "Epoch 20/20, Iteration 131/303, Loss: 0.008673476055264473\n",
      "Epoch 20/20, Iteration 132/303, Loss: 0.019471704959869385\n",
      "Epoch 20/20, Iteration 133/303, Loss: 0.037000808864831924\n",
      "Epoch 20/20, Iteration 134/303, Loss: 0.055907465517520905\n",
      "Epoch 20/20, Iteration 135/303, Loss: 0.01822034642100334\n",
      "Epoch 20/20, Iteration 136/303, Loss: 0.02494747005403042\n",
      "Epoch 20/20, Iteration 137/303, Loss: 0.035965822637081146\n",
      "Epoch 20/20, Iteration 138/303, Loss: 0.012643115594983101\n",
      "Epoch 20/20, Iteration 139/303, Loss: 0.03624549135565758\n",
      "Epoch 20/20, Iteration 140/303, Loss: 0.0225856751203537\n",
      "Epoch 20/20, Iteration 141/303, Loss: 0.09130138158798218\n",
      "Epoch 20/20, Iteration 142/303, Loss: 0.20033927261829376\n",
      "Epoch 20/20, Iteration 143/303, Loss: 0.2278129905462265\n",
      "Epoch 20/20, Iteration 144/303, Loss: 0.01405628863722086\n",
      "Epoch 20/20, Iteration 145/303, Loss: 0.0337221585214138\n",
      "Epoch 20/20, Iteration 146/303, Loss: 0.044416643679142\n",
      "Epoch 20/20, Iteration 147/303, Loss: 0.14856202900409698\n",
      "Epoch 20/20, Iteration 148/303, Loss: 0.059020332992076874\n",
      "Epoch 20/20, Iteration 149/303, Loss: 0.02675134316086769\n",
      "Epoch 20/20, Iteration 150/303, Loss: 0.07542307674884796\n",
      "Epoch 20/20, Iteration 151/303, Loss: 0.026415973901748657\n",
      "Epoch 20/20, Iteration 152/303, Loss: 0.017174120992422104\n",
      "Epoch 20/20, Iteration 153/303, Loss: 0.010992089286446571\n",
      "Epoch 20/20, Iteration 154/303, Loss: 0.028711369261145592\n",
      "Epoch 20/20, Iteration 155/303, Loss: 0.05759675055742264\n",
      "Epoch 20/20, Iteration 156/303, Loss: 0.03480148687958717\n",
      "Epoch 20/20, Iteration 157/303, Loss: 0.0063627357594668865\n",
      "Epoch 20/20, Iteration 158/303, Loss: 0.009557337500154972\n",
      "Epoch 20/20, Iteration 159/303, Loss: 0.0059150406159460545\n",
      "Epoch 20/20, Iteration 160/303, Loss: 0.06647424399852753\n",
      "Epoch 20/20, Iteration 161/303, Loss: 0.061032168567180634\n",
      "Epoch 20/20, Iteration 162/303, Loss: 0.07946322113275528\n",
      "Epoch 20/20, Iteration 163/303, Loss: 0.015552443452179432\n",
      "Epoch 20/20, Iteration 164/303, Loss: 0.10146363079547882\n",
      "Epoch 20/20, Iteration 165/303, Loss: 0.10174087435007095\n",
      "Epoch 20/20, Iteration 166/303, Loss: 0.012558800168335438\n",
      "Epoch 20/20, Iteration 167/303, Loss: 0.1075490191578865\n",
      "Epoch 20/20, Iteration 168/303, Loss: 0.10027353465557098\n",
      "Epoch 20/20, Iteration 169/303, Loss: 0.017507875338196754\n",
      "Epoch 20/20, Iteration 170/303, Loss: 0.03581630438566208\n",
      "Epoch 20/20, Iteration 171/303, Loss: 0.013322196900844574\n",
      "Epoch 20/20, Iteration 172/303, Loss: 0.049857400357723236\n",
      "Epoch 20/20, Iteration 173/303, Loss: 0.007824773900210857\n",
      "Epoch 20/20, Iteration 174/303, Loss: 0.03339700400829315\n",
      "Epoch 20/20, Iteration 175/303, Loss: 0.02534145675599575\n",
      "Epoch 20/20, Iteration 176/303, Loss: 0.3033783733844757\n",
      "Epoch 20/20, Iteration 177/303, Loss: 0.19340954720973969\n",
      "Epoch 20/20, Iteration 178/303, Loss: 0.2331344187259674\n",
      "Epoch 20/20, Iteration 179/303, Loss: 0.008979769423604012\n",
      "Epoch 20/20, Iteration 180/303, Loss: 0.18064802885055542\n",
      "Epoch 20/20, Iteration 181/303, Loss: 0.06909935921430588\n",
      "Epoch 20/20, Iteration 182/303, Loss: 0.02004266157746315\n",
      "Epoch 20/20, Iteration 183/303, Loss: 0.09507882595062256\n",
      "Epoch 20/20, Iteration 184/303, Loss: 0.06122665852308273\n",
      "Epoch 20/20, Iteration 185/303, Loss: 0.027622032910585403\n",
      "Epoch 20/20, Iteration 186/303, Loss: 0.054469428956508636\n",
      "Epoch 20/20, Iteration 187/303, Loss: 0.07512679696083069\n",
      "Epoch 20/20, Iteration 188/303, Loss: 0.13954876363277435\n",
      "Epoch 20/20, Iteration 189/303, Loss: 0.029922176152467728\n",
      "Epoch 20/20, Iteration 190/303, Loss: 0.010893046855926514\n",
      "Epoch 20/20, Iteration 191/303, Loss: 0.011950870044529438\n",
      "Epoch 20/20, Iteration 192/303, Loss: 0.06050313636660576\n",
      "Epoch 20/20, Iteration 193/303, Loss: 0.030239954590797424\n",
      "Epoch 20/20, Iteration 194/303, Loss: 0.02431468851864338\n",
      "Epoch 20/20, Iteration 195/303, Loss: 0.015056472271680832\n",
      "Epoch 20/20, Iteration 196/303, Loss: 0.04609450697898865\n",
      "Epoch 20/20, Iteration 197/303, Loss: 0.03390784561634064\n",
      "Epoch 20/20, Iteration 198/303, Loss: 0.11631051450967789\n",
      "Epoch 20/20, Iteration 199/303, Loss: 0.035307835787534714\n",
      "Epoch 20/20, Iteration 200/303, Loss: 0.04622581601142883\n",
      "Epoch 20/20, Iteration 201/303, Loss: 0.010954429395496845\n",
      "Epoch 20/20, Iteration 202/303, Loss: 0.00681787496432662\n",
      "Epoch 20/20, Iteration 203/303, Loss: 0.03833621367812157\n",
      "Epoch 20/20, Iteration 204/303, Loss: 0.05314791202545166\n",
      "Epoch 20/20, Iteration 205/303, Loss: 0.03853270411491394\n",
      "Epoch 20/20, Iteration 206/303, Loss: 0.07236295193433762\n",
      "Epoch 20/20, Iteration 207/303, Loss: 0.01215478964149952\n",
      "Epoch 20/20, Iteration 208/303, Loss: 0.01338175218552351\n",
      "Epoch 20/20, Iteration 209/303, Loss: 0.013069743290543556\n",
      "Epoch 20/20, Iteration 210/303, Loss: 0.10329937934875488\n",
      "Epoch 20/20, Iteration 211/303, Loss: 0.18585172295570374\n",
      "Epoch 20/20, Iteration 212/303, Loss: 0.08698999136686325\n",
      "Epoch 20/20, Iteration 213/303, Loss: 0.02177623100578785\n",
      "Epoch 20/20, Iteration 214/303, Loss: 0.06491807848215103\n",
      "Epoch 20/20, Iteration 215/303, Loss: 0.016744187101721764\n",
      "Epoch 20/20, Iteration 216/303, Loss: 0.043521858751773834\n",
      "Epoch 20/20, Iteration 217/303, Loss: 0.010199280455708504\n",
      "Epoch 20/20, Iteration 218/303, Loss: 0.05500037968158722\n",
      "Epoch 20/20, Iteration 219/303, Loss: 0.022442825138568878\n",
      "Epoch 20/20, Iteration 220/303, Loss: 0.016983559355139732\n",
      "Epoch 20/20, Iteration 221/303, Loss: 0.06449975818395615\n",
      "Epoch 20/20, Iteration 222/303, Loss: 0.022628063336014748\n",
      "Epoch 20/20, Iteration 223/303, Loss: 0.035191427916288376\n",
      "Epoch 20/20, Iteration 224/303, Loss: 0.10090753436088562\n",
      "Epoch 20/20, Iteration 225/303, Loss: 0.06677290797233582\n",
      "Epoch 20/20, Iteration 226/303, Loss: 0.013448146171867847\n",
      "Epoch 20/20, Iteration 227/303, Loss: 0.0175776407122612\n",
      "Epoch 20/20, Iteration 228/303, Loss: 0.007254865951836109\n",
      "Epoch 20/20, Iteration 229/303, Loss: 0.033441197127103806\n",
      "Epoch 20/20, Iteration 230/303, Loss: 0.016564777120947838\n",
      "Epoch 20/20, Iteration 231/303, Loss: 0.02190500684082508\n",
      "Epoch 20/20, Iteration 232/303, Loss: 0.03709317371249199\n",
      "Epoch 20/20, Iteration 233/303, Loss: 0.050726745277643204\n",
      "Epoch 20/20, Iteration 234/303, Loss: 0.005754085723310709\n",
      "Epoch 20/20, Iteration 235/303, Loss: 0.06539286673069\n",
      "Epoch 20/20, Iteration 236/303, Loss: 0.035181690007448196\n",
      "Epoch 20/20, Iteration 237/303, Loss: 0.0568794310092926\n",
      "Epoch 20/20, Iteration 238/303, Loss: 0.0371488481760025\n",
      "Epoch 20/20, Iteration 239/303, Loss: 0.013212505728006363\n",
      "Epoch 20/20, Iteration 240/303, Loss: 0.0032823067158460617\n",
      "Epoch 20/20, Iteration 241/303, Loss: 0.006559248082339764\n",
      "Epoch 20/20, Iteration 242/303, Loss: 0.003888745792210102\n",
      "Epoch 20/20, Iteration 243/303, Loss: 0.009972328320145607\n",
      "Epoch 20/20, Iteration 244/303, Loss: 0.008730664849281311\n",
      "Epoch 20/20, Iteration 245/303, Loss: 0.0015389168402180076\n",
      "Epoch 20/20, Iteration 246/303, Loss: 0.0028294699732214212\n",
      "Epoch 20/20, Iteration 247/303, Loss: 0.03669079393148422\n",
      "Epoch 20/20, Iteration 248/303, Loss: 0.006143407896161079\n",
      "Epoch 20/20, Iteration 249/303, Loss: 0.007309072185307741\n",
      "Epoch 20/20, Iteration 250/303, Loss: 0.0050131394527852535\n",
      "Epoch 20/20, Iteration 251/303, Loss: 0.004274694249033928\n",
      "Epoch 20/20, Iteration 252/303, Loss: 0.0033641390036791563\n",
      "Epoch 20/20, Iteration 253/303, Loss: 0.018798010423779488\n",
      "Epoch 20/20, Iteration 254/303, Loss: 0.0032488233409821987\n",
      "Epoch 20/20, Iteration 255/303, Loss: 0.022066518664360046\n",
      "Epoch 20/20, Iteration 256/303, Loss: 0.009593605995178223\n",
      "Epoch 20/20, Iteration 257/303, Loss: 0.0066059427335858345\n",
      "Epoch 20/20, Iteration 258/303, Loss: 0.001549567561596632\n",
      "Epoch 20/20, Iteration 259/303, Loss: 0.016384916380047798\n",
      "Epoch 20/20, Iteration 260/303, Loss: 0.0036464277654886246\n",
      "Epoch 20/20, Iteration 261/303, Loss: 0.015997804701328278\n",
      "Epoch 20/20, Iteration 262/303, Loss: 0.03597934544086456\n",
      "Epoch 20/20, Iteration 263/303, Loss: 0.04381469637155533\n",
      "Epoch 20/20, Iteration 264/303, Loss: 0.005902454257011414\n",
      "Epoch 20/20, Iteration 265/303, Loss: 0.004306454211473465\n",
      "Epoch 20/20, Iteration 266/303, Loss: 0.015644824132323265\n",
      "Epoch 20/20, Iteration 267/303, Loss: 0.014147371985018253\n",
      "Epoch 20/20, Iteration 268/303, Loss: 0.03403313830494881\n",
      "Epoch 20/20, Iteration 269/303, Loss: 0.021375803276896477\n",
      "Epoch 20/20, Iteration 270/303, Loss: 0.007654507178813219\n",
      "Epoch 20/20, Iteration 271/303, Loss: 0.07631882280111313\n",
      "Epoch 20/20, Iteration 272/303, Loss: 0.0027018217369914055\n",
      "Epoch 20/20, Iteration 273/303, Loss: 0.009035068564116955\n",
      "Epoch 20/20, Iteration 274/303, Loss: 0.012422323226928711\n",
      "Epoch 20/20, Iteration 275/303, Loss: 0.01597200520336628\n",
      "Epoch 20/20, Iteration 276/303, Loss: 0.001996788661926985\n",
      "Epoch 20/20, Iteration 277/303, Loss: 0.011971277184784412\n",
      "Epoch 20/20, Iteration 278/303, Loss: 0.04691407456994057\n",
      "Epoch 20/20, Iteration 279/303, Loss: 0.009497304446995258\n",
      "Epoch 20/20, Iteration 280/303, Loss: 0.006196790374815464\n",
      "Epoch 20/20, Iteration 281/303, Loss: 0.021325284615159035\n",
      "Epoch 20/20, Iteration 282/303, Loss: 0.030505741015076637\n",
      "Epoch 20/20, Iteration 283/303, Loss: 0.00863427110016346\n",
      "Epoch 20/20, Iteration 284/303, Loss: 0.01860594004392624\n",
      "Epoch 20/20, Iteration 285/303, Loss: 0.13069306313991547\n",
      "Epoch 20/20, Iteration 286/303, Loss: 0.14394517242908478\n",
      "Epoch 20/20, Iteration 287/303, Loss: 0.0031748441979289055\n",
      "Epoch 20/20, Iteration 288/303, Loss: 0.006552524399012327\n",
      "Epoch 20/20, Iteration 289/303, Loss: 0.034024678170681\n",
      "Epoch 20/20, Iteration 290/303, Loss: 0.014290105551481247\n",
      "Epoch 20/20, Iteration 291/303, Loss: 0.05751189589500427\n",
      "Epoch 20/20, Iteration 292/303, Loss: 0.06385913491249084\n",
      "Epoch 20/20, Iteration 293/303, Loss: 0.027135809883475304\n",
      "Epoch 20/20, Iteration 294/303, Loss: 0.02576480619609356\n",
      "Epoch 20/20, Iteration 295/303, Loss: 0.05263499543070793\n",
      "Epoch 20/20, Iteration 296/303, Loss: 0.006684053689241409\n",
      "Epoch 20/20, Iteration 297/303, Loss: 0.009324559010565281\n",
      "Epoch 20/20, Iteration 298/303, Loss: 0.04300512373447418\n",
      "Epoch 20/20, Iteration 299/303, Loss: 0.04334716498851776\n",
      "Epoch 20/20, Iteration 300/303, Loss: 0.05002499371767044\n",
      "Epoch 20/20, Iteration 301/303, Loss: 0.0130309471860528\n",
      "Epoch 20/20, Iteration 302/303, Loss: 0.011828595772385597\n",
      "Epoch 20/20, Iteration 303/303, Loss: 0.005721324123442173\n",
      "CPU times: total: 1h 39min 5s\n",
      "Wall time: 25min 33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Iteration 268/303, Loss: 0.45317816734313965\n",
      "Epoch 3/100, Iteration 269/303, Loss: 0.4777294397354126\n",
      "Epoch 3/100, Iteration 270/303, Loss: 0.4163530766963959\n",
      "Epoch 3/100, Iteration 271/303, Loss: 0.7153400182723999\n",
      "Epoch 3/100, Iteration 272/303, Loss: 0.6770245432853699\n",
      "Epoch 3/100, Iteration 273/303, Loss: 0.5716456770896912\n",
      "Epoch 3/100, Iteration 274/303, Loss: 0.5258144736289978\n",
      "Epoch 3/100, Iteration 275/303, Loss: 0.4851508140563965\n",
      "Epoch 3/100, Iteration 276/303, Loss: 0.6296175718307495\n",
      "Epoch 3/100, Iteration 277/303, Loss: 0.531254231929779\n",
      "Epoch 3/100, Iteration 278/303, Loss: 0.5474787354469299\n",
      "Epoch 3/100, Iteration 279/303, Loss: 0.585878849029541\n",
      "Epoch 3/100, Iteration 280/303, Loss: 0.5920871496200562\n",
      "Epoch 3/100, Iteration 281/303, Loss: 0.5609568953514099\n",
      "Epoch 3/100, Iteration 282/303, Loss: 0.4901425242424011\n",
      "Epoch 3/100, Iteration 283/303, Loss: 0.4326670467853546\n",
      "Epoch 3/100, Iteration 284/303, Loss: 0.5437423586845398\n",
      "Epoch 3/100, Iteration 285/303, Loss: 0.4299101233482361\n",
      "Epoch 3/100, Iteration 286/303, Loss: 0.5346149802207947\n",
      "Epoch 3/100, Iteration 287/303, Loss: 0.6220468282699585\n",
      "Epoch 3/100, Iteration 288/303, Loss: 0.4534448981285095\n",
      "Epoch 3/100, Iteration 289/303, Loss: 0.5496975779533386\n",
      "Epoch 3/100, Iteration 290/303, Loss: 0.7174748182296753\n",
      "Epoch 3/100, Iteration 291/303, Loss: 0.4959315061569214\n",
      "Epoch 3/100, Iteration 292/303, Loss: 0.40969008207321167\n",
      "Epoch 3/100, Iteration 293/303, Loss: 0.43388858437538147\n",
      "Epoch 3/100, Iteration 294/303, Loss: 0.5096428394317627\n",
      "Epoch 3/100, Iteration 295/303, Loss: 0.6173958778381348\n",
      "Epoch 3/100, Iteration 296/303, Loss: 0.5316476225852966\n",
      "Epoch 3/100, Iteration 297/303, Loss: 0.6390591263771057\n",
      "Epoch 3/100, Iteration 298/303, Loss: 0.49545735120773315\n",
      "Epoch 3/100, Iteration 299/303, Loss: 0.5134669542312622\n",
      "Epoch 3/100, Iteration 300/303, Loss: 0.37902820110321045\n",
      "Epoch 3/100, Iteration 301/303, Loss: 0.44740140438079834\n",
      "Epoch 3/100, Iteration 302/303, Loss: 0.4995129108428955\n",
      "Epoch 3/100, Iteration 303/303, Loss: 0.8183082938194275\n",
      "Epoch 4/100, Iteration 1/303, Loss: 0.5673750042915344\n",
      "Epoch 4/100, Iteration 2/303, Loss: 0.5369578003883362\n",
      "Epoch 4/100, Iteration 3/303, Loss: 0.5193884968757629\n",
      "Epoch 4/100, Iteration 4/303, Loss: 0.49824059009552\n",
      "Epoch 4/100, Iteration 5/303, Loss: 0.39525356888771057\n",
      "Epoch 4/100, Iteration 6/303, Loss: 0.4843963384628296\n",
      "Epoch 4/100, Iteration 7/303, Loss: 0.5966929197311401\n",
      "Epoch 4/100, Iteration 8/303, Loss: 0.5494915246963501\n",
      "Epoch 4/100, Iteration 9/303, Loss: 0.5039833188056946\n",
      "Epoch 4/100, Iteration 10/303, Loss: 0.5707176327705383\n",
      "Epoch 4/100, Iteration 11/303, Loss: 0.4052462875843048\n",
      "Epoch 4/100, Iteration 12/303, Loss: 0.4749745726585388\n",
      "Epoch 4/100, Iteration 13/303, Loss: 0.4994938373565674\n",
      "Epoch 4/100, Iteration 14/303, Loss: 0.47588348388671875\n",
      "Epoch 4/100, Iteration 15/303, Loss: 0.3478577733039856\n",
      "Epoch 4/100, Iteration 16/303, Loss: 0.3237776756286621\n",
      "Epoch 4/100, Iteration 17/303, Loss: 0.41412264108657837\n",
      "Epoch 4/100, Iteration 18/303, Loss: 0.5825284719467163\n",
      "Epoch 4/100, Iteration 19/303, Loss: 0.4785066843032837\n",
      "Epoch 4/100, Iteration 20/303, Loss: 0.5159403085708618\n",
      "Epoch 4/100, Iteration 21/303, Loss: 0.4509042501449585\n",
      "Epoch 4/100, Iteration 22/303, Loss: 0.5250749588012695\n",
      "Epoch 4/100, Iteration 23/303, Loss: 0.46594300866127014\n",
      "Epoch 4/100, Iteration 24/303, Loss: 0.4257018268108368\n",
      "Epoch 4/100, Iteration 25/303, Loss: 0.3414086699485779\n",
      "Epoch 4/100, Iteration 26/303, Loss: 0.5427282452583313\n",
      "Epoch 4/100, Iteration 27/303, Loss: 0.5000893473625183\n",
      "Epoch 4/100, Iteration 28/303, Loss: 0.6224194169044495\n",
      "Epoch 4/100, Iteration 29/303, Loss: 0.3031466603279114\n",
      "Epoch 4/100, Iteration 30/303, Loss: 0.4584527611732483\n",
      "Epoch 4/100, Iteration 31/303, Loss: 0.48027193546295166\n",
      "Epoch 4/100, Iteration 32/303, Loss: 0.34484413266181946\n",
      "Epoch 4/100, Iteration 33/303, Loss: 0.4913244843482971\n",
      "Epoch 4/100, Iteration 34/303, Loss: 0.44463667273521423\n",
      "Epoch 4/100, Iteration 35/303, Loss: 0.5736819505691528\n",
      "Epoch 4/100, Iteration 36/303, Loss: 0.43678581714630127\n",
      "Epoch 4/100, Iteration 37/303, Loss: 0.6207433938980103\n",
      "Epoch 4/100, Iteration 38/303, Loss: 0.5677981376647949\n",
      "Epoch 4/100, Iteration 39/303, Loss: 0.5328519940376282\n",
      "Epoch 4/100, Iteration 40/303, Loss: 0.41713571548461914\n",
      "Epoch 4/100, Iteration 41/303, Loss: 0.4201972186565399\n",
      "Epoch 4/100, Iteration 42/303, Loss: 0.3550816476345062\n",
      "Epoch 4/100, Iteration 43/303, Loss: 0.5427024960517883\n",
      "Epoch 4/100, Iteration 44/303, Loss: 0.4967082440853119\n",
      "Epoch 4/100, Iteration 45/303, Loss: 0.468063622713089\n",
      "Epoch 4/100, Iteration 46/303, Loss: 0.4161125421524048\n",
      "Epoch 4/100, Iteration 47/303, Loss: 0.4670669734477997\n",
      "Epoch 4/100, Iteration 48/303, Loss: 0.3609444200992584\n",
      "Epoch 4/100, Iteration 49/303, Loss: 0.5152503848075867\n",
      "Epoch 4/100, Iteration 50/303, Loss: 0.4946386516094208\n",
      "Epoch 4/100, Iteration 51/303, Loss: 0.5501695275306702\n",
      "Epoch 4/100, Iteration 52/303, Loss: 0.4010484218597412\n",
      "Epoch 4/100, Iteration 53/303, Loss: 0.4179840683937073\n",
      "Epoch 4/100, Iteration 54/303, Loss: 0.5738207697868347\n",
      "Epoch 4/100, Iteration 55/303, Loss: 0.5432350635528564\n",
      "Epoch 4/100, Iteration 56/303, Loss: 0.47194597125053406\n",
      "Epoch 4/100, Iteration 57/303, Loss: 0.5120965838432312\n",
      "Epoch 4/100, Iteration 58/303, Loss: 0.3665534555912018\n",
      "Epoch 4/100, Iteration 59/303, Loss: 0.4165745973587036\n",
      "Epoch 4/100, Iteration 60/303, Loss: 0.551407516002655\n",
      "Epoch 4/100, Iteration 61/303, Loss: 0.435510516166687\n",
      "Epoch 4/100, Iteration 62/303, Loss: 0.6970582008361816\n",
      "Epoch 4/100, Iteration 63/303, Loss: 0.5576754808425903\n",
      "Epoch 4/100, Iteration 64/303, Loss: 0.49121543765068054\n",
      "Epoch 4/100, Iteration 65/303, Loss: 0.4553374648094177\n",
      "Epoch 4/100, Iteration 66/303, Loss: 0.32419461011886597\n",
      "Epoch 4/100, Iteration 67/303, Loss: 0.40502655506134033\n",
      "Epoch 4/100, Iteration 68/303, Loss: 0.2809295654296875\n",
      "Epoch 4/100, Iteration 69/303, Loss: 0.3539920747280121\n",
      "Epoch 4/100, Iteration 70/303, Loss: 0.615143895149231\n",
      "Epoch 4/100, Iteration 71/303, Loss: 0.7327240109443665\n",
      "Epoch 4/100, Iteration 72/303, Loss: 0.5987734794616699\n",
      "Epoch 4/100, Iteration 73/303, Loss: 0.5111491680145264\n",
      "Epoch 4/100, Iteration 74/303, Loss: 0.5403677225112915\n",
      "Epoch 4/100, Iteration 75/303, Loss: 0.5535461902618408\n",
      "Epoch 4/100, Iteration 76/303, Loss: 0.5904960036277771\n",
      "Epoch 4/100, Iteration 77/303, Loss: 0.5755311846733093\n",
      "Epoch 4/100, Iteration 78/303, Loss: 0.5208414793014526\n",
      "Epoch 4/100, Iteration 79/303, Loss: 0.4039786458015442\n",
      "Epoch 4/100, Iteration 80/303, Loss: 0.49340373277664185\n",
      "Epoch 4/100, Iteration 81/303, Loss: 0.5993544459342957\n",
      "Epoch 4/100, Iteration 82/303, Loss: 0.3748317360877991\n",
      "Epoch 4/100, Iteration 83/303, Loss: 0.3759734034538269\n",
      "Epoch 4/100, Iteration 84/303, Loss: 0.5663731098175049\n",
      "Epoch 4/100, Iteration 85/303, Loss: 0.5235564708709717\n",
      "Epoch 4/100, Iteration 86/303, Loss: 0.48033207654953003\n",
      "Epoch 4/100, Iteration 87/303, Loss: 0.3717783987522125\n",
      "Epoch 4/100, Iteration 88/303, Loss: 0.529191792011261\n",
      "Epoch 4/100, Iteration 89/303, Loss: 0.4353860020637512\n",
      "Epoch 4/100, Iteration 90/303, Loss: 0.29621341824531555\n",
      "Epoch 4/100, Iteration 91/303, Loss: 0.36696815490722656\n",
      "Epoch 4/100, Iteration 92/303, Loss: 0.30748188495635986\n",
      "Epoch 4/100, Iteration 93/303, Loss: 0.4868018627166748\n",
      "Epoch 4/100, Iteration 94/303, Loss: 0.5964032411575317\n",
      "Epoch 4/100, Iteration 95/303, Loss: 0.426519513130188\n",
      "Epoch 4/100, Iteration 96/303, Loss: 0.5479279160499573\n",
      "Epoch 4/100, Iteration 97/303, Loss: 0.47072282433509827\n",
      "Epoch 4/100, Iteration 98/303, Loss: 0.36844778060913086\n",
      "Epoch 4/100, Iteration 99/303, Loss: 0.5104132294654846\n",
      "Epoch 4/100, Iteration 100/303, Loss: 0.5755147933959961\n",
      "Epoch 4/100, Iteration 101/303, Loss: 0.38168615102767944\n",
      "Epoch 4/100, Iteration 102/303, Loss: 0.5225105881690979\n",
      "Epoch 4/100, Iteration 103/303, Loss: 0.47126439213752747\n",
      "Epoch 4/100, Iteration 104/303, Loss: 0.4919944703578949\n",
      "Epoch 4/100, Iteration 105/303, Loss: 0.5047957301139832\n",
      "Epoch 4/100, Iteration 106/303, Loss: 0.6897438168525696\n",
      "Epoch 4/100, Iteration 107/303, Loss: 0.5466465950012207\n",
      "Epoch 4/100, Iteration 108/303, Loss: 0.4063602387905121\n",
      "Epoch 4/100, Iteration 109/303, Loss: 0.4610176682472229\n",
      "Epoch 4/100, Iteration 110/303, Loss: 0.534964919090271\n",
      "Epoch 4/100, Iteration 111/303, Loss: 0.5384436845779419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Iteration 112/303, Loss: 0.2999551296234131\n",
      "Epoch 4/100, Iteration 113/303, Loss: 0.3902929127216339\n",
      "Epoch 4/100, Iteration 114/303, Loss: 0.48242467641830444\n",
      "Epoch 4/100, Iteration 115/303, Loss: 0.40803325176239014\n",
      "Epoch 4/100, Iteration 116/303, Loss: 0.5083125829696655\n",
      "Epoch 4/100, Iteration 117/303, Loss: 0.453347384929657\n",
      "Epoch 4/100, Iteration 118/303, Loss: 0.4908488392829895\n",
      "Epoch 4/100, Iteration 119/303, Loss: 0.45947301387786865\n",
      "Epoch 4/100, Iteration 120/303, Loss: 0.4993976652622223\n",
      "Epoch 4/100, Iteration 121/303, Loss: 0.45389407873153687\n",
      "Epoch 4/100, Iteration 122/303, Loss: 0.37068840861320496\n",
      "Epoch 4/100, Iteration 123/303, Loss: 0.40162932872772217\n",
      "Epoch 4/100, Iteration 124/303, Loss: 0.37212830781936646\n",
      "Epoch 4/100, Iteration 125/303, Loss: 0.5290371775627136\n",
      "Epoch 4/100, Iteration 126/303, Loss: 0.4888649880886078\n",
      "Epoch 4/100, Iteration 127/303, Loss: 0.5929295420646667\n",
      "Epoch 4/100, Iteration 128/303, Loss: 0.6042279601097107\n",
      "Epoch 4/100, Iteration 129/303, Loss: 0.5444303154945374\n",
      "Epoch 4/100, Iteration 130/303, Loss: 0.36187559366226196\n",
      "Epoch 4/100, Iteration 131/303, Loss: 0.4516344666481018\n",
      "Epoch 4/100, Iteration 132/303, Loss: 0.44798365235328674\n",
      "Epoch 4/100, Iteration 133/303, Loss: 0.425319105386734\n",
      "Epoch 4/100, Iteration 134/303, Loss: 0.42209592461586\n",
      "Epoch 4/100, Iteration 135/303, Loss: 0.39388135075569153\n",
      "Epoch 4/100, Iteration 136/303, Loss: 0.4226638674736023\n",
      "Epoch 4/100, Iteration 137/303, Loss: 0.5277662873268127\n",
      "Epoch 4/100, Iteration 138/303, Loss: 0.5140822529792786\n",
      "Epoch 4/100, Iteration 139/303, Loss: 0.41250622272491455\n",
      "Epoch 4/100, Iteration 140/303, Loss: 0.5177686810493469\n",
      "Epoch 4/100, Iteration 141/303, Loss: 0.40162694454193115\n",
      "Epoch 4/100, Iteration 142/303, Loss: 0.5089648962020874\n",
      "Epoch 4/100, Iteration 143/303, Loss: 0.49965521693229675\n",
      "Epoch 4/100, Iteration 144/303, Loss: 0.4129917025566101\n",
      "Epoch 4/100, Iteration 145/303, Loss: 0.42823266983032227\n",
      "Epoch 4/100, Iteration 146/303, Loss: 0.42083966732025146\n",
      "Epoch 4/100, Iteration 147/303, Loss: 0.42991769313812256\n",
      "Epoch 4/100, Iteration 148/303, Loss: 0.42174679040908813\n",
      "Epoch 4/100, Iteration 149/303, Loss: 0.4074243903160095\n",
      "Epoch 4/100, Iteration 150/303, Loss: 0.40007656812667847\n",
      "Epoch 4/100, Iteration 151/303, Loss: 0.6994625926017761\n",
      "Epoch 4/100, Iteration 152/303, Loss: 0.6155279278755188\n",
      "Epoch 4/100, Iteration 153/303, Loss: 0.47909826040267944\n",
      "Epoch 4/100, Iteration 154/303, Loss: 0.39999234676361084\n",
      "Epoch 4/100, Iteration 155/303, Loss: 0.46361079812049866\n",
      "Epoch 4/100, Iteration 156/303, Loss: 0.4049527645111084\n",
      "Epoch 4/100, Iteration 157/303, Loss: 0.30349549651145935\n",
      "Epoch 4/100, Iteration 158/303, Loss: 0.5104594230651855\n",
      "Epoch 4/100, Iteration 159/303, Loss: 0.5123985409736633\n",
      "Epoch 4/100, Iteration 160/303, Loss: 0.4811897277832031\n",
      "Epoch 4/100, Iteration 161/303, Loss: 0.45669519901275635\n",
      "Epoch 4/100, Iteration 162/303, Loss: 0.5367305278778076\n",
      "Epoch 4/100, Iteration 163/303, Loss: 0.5898199081420898\n",
      "Epoch 4/100, Iteration 164/303, Loss: 0.3781086206436157\n",
      "Epoch 4/100, Iteration 165/303, Loss: 0.42860808968544006\n",
      "Epoch 4/100, Iteration 166/303, Loss: 0.8825402855873108\n",
      "Epoch 4/100, Iteration 167/303, Loss: 0.6717031598091125\n",
      "Epoch 4/100, Iteration 168/303, Loss: 0.5043732523918152\n",
      "Epoch 4/100, Iteration 169/303, Loss: 0.5128127336502075\n",
      "Epoch 4/100, Iteration 170/303, Loss: 0.5086550712585449\n",
      "Epoch 4/100, Iteration 171/303, Loss: 0.4922369122505188\n",
      "Epoch 4/100, Iteration 172/303, Loss: 0.4719693660736084\n",
      "Epoch 4/100, Iteration 173/303, Loss: 0.3568721115589142\n",
      "Epoch 4/100, Iteration 174/303, Loss: 0.28403252363204956\n",
      "Epoch 4/100, Iteration 175/303, Loss: 0.4345420300960541\n",
      "Epoch 4/100, Iteration 176/303, Loss: 0.63991379737854\n",
      "Epoch 4/100, Iteration 177/303, Loss: 0.6472894549369812\n",
      "Epoch 4/100, Iteration 178/303, Loss: 0.36575013399124146\n",
      "Epoch 4/100, Iteration 179/303, Loss: 0.5458574891090393\n",
      "Epoch 4/100, Iteration 180/303, Loss: 0.6673724055290222\n",
      "Epoch 4/100, Iteration 181/303, Loss: 0.5524216890335083\n",
      "Epoch 4/100, Iteration 182/303, Loss: 0.47067195177078247\n",
      "Epoch 4/100, Iteration 183/303, Loss: 0.36508864164352417\n",
      "Epoch 4/100, Iteration 184/303, Loss: 0.45066481828689575\n",
      "Epoch 4/100, Iteration 185/303, Loss: 0.5201718807220459\n",
      "Epoch 4/100, Iteration 186/303, Loss: 0.5288259387016296\n",
      "Epoch 4/100, Iteration 187/303, Loss: 0.5018693804740906\n",
      "Epoch 4/100, Iteration 188/303, Loss: 0.586054801940918\n",
      "Epoch 4/100, Iteration 189/303, Loss: 0.6416885256767273\n",
      "Epoch 4/100, Iteration 190/303, Loss: 0.5856869220733643\n",
      "Epoch 4/100, Iteration 191/303, Loss: 0.5531607270240784\n",
      "Epoch 4/100, Iteration 192/303, Loss: 0.47764694690704346\n",
      "Epoch 4/100, Iteration 193/303, Loss: 0.39285552501678467\n",
      "Epoch 4/100, Iteration 194/303, Loss: 0.8775375485420227\n",
      "Epoch 4/100, Iteration 195/303, Loss: 0.5710311532020569\n",
      "Epoch 4/100, Iteration 196/303, Loss: 0.444439560174942\n",
      "Epoch 4/100, Iteration 197/303, Loss: 0.4779764711856842\n",
      "Epoch 4/100, Iteration 198/303, Loss: 0.49906763434410095\n",
      "Epoch 4/100, Iteration 199/303, Loss: 0.4536595344543457\n",
      "Epoch 4/100, Iteration 200/303, Loss: 0.4487092196941376\n",
      "Epoch 4/100, Iteration 201/303, Loss: 0.47920480370521545\n",
      "Epoch 4/100, Iteration 202/303, Loss: 0.45749321579933167\n",
      "Epoch 4/100, Iteration 203/303, Loss: 0.5428593754768372\n",
      "Epoch 4/100, Iteration 204/303, Loss: 0.3853120803833008\n",
      "Epoch 4/100, Iteration 205/303, Loss: 0.436926007270813\n",
      "Epoch 4/100, Iteration 206/303, Loss: 0.5550969243049622\n",
      "Epoch 4/100, Iteration 207/303, Loss: 0.4406575560569763\n",
      "Epoch 4/100, Iteration 208/303, Loss: 0.5063775777816772\n",
      "Epoch 4/100, Iteration 209/303, Loss: 0.35197848081588745\n",
      "Epoch 4/100, Iteration 210/303, Loss: 0.5460110902786255\n",
      "Epoch 4/100, Iteration 211/303, Loss: 0.5150089859962463\n",
      "Epoch 4/100, Iteration 212/303, Loss: 0.3869599997997284\n",
      "Epoch 4/100, Iteration 213/303, Loss: 0.38489142060279846\n",
      "Epoch 4/100, Iteration 214/303, Loss: 0.48997002840042114\n",
      "Epoch 4/100, Iteration 215/303, Loss: 0.4790215790271759\n",
      "Epoch 4/100, Iteration 216/303, Loss: 0.3905818462371826\n",
      "Epoch 4/100, Iteration 217/303, Loss: 0.43263405561447144\n",
      "Epoch 4/100, Iteration 218/303, Loss: 0.4909648895263672\n",
      "Epoch 4/100, Iteration 219/303, Loss: 0.40908095240592957\n",
      "Epoch 4/100, Iteration 220/303, Loss: 0.4441458582878113\n",
      "Epoch 4/100, Iteration 221/303, Loss: 0.5833547711372375\n",
      "Epoch 4/100, Iteration 222/303, Loss: 0.3738742172718048\n",
      "Epoch 4/100, Iteration 223/303, Loss: 0.4677931070327759\n",
      "Epoch 4/100, Iteration 224/303, Loss: 0.5743632316589355\n",
      "Epoch 4/100, Iteration 225/303, Loss: 0.5726662278175354\n",
      "Epoch 4/100, Iteration 226/303, Loss: 0.4497501850128174\n",
      "Epoch 4/100, Iteration 227/303, Loss: 0.4876953363418579\n",
      "Epoch 4/100, Iteration 228/303, Loss: 0.5625362396240234\n",
      "Epoch 4/100, Iteration 229/303, Loss: 0.5082792639732361\n",
      "Epoch 4/100, Iteration 230/303, Loss: 0.349769651889801\n",
      "Epoch 4/100, Iteration 231/303, Loss: 0.5313082337379456\n",
      "Epoch 4/100, Iteration 232/303, Loss: 0.5644063949584961\n",
      "Epoch 4/100, Iteration 233/303, Loss: 0.5138371586799622\n",
      "Epoch 4/100, Iteration 234/303, Loss: 0.4997052252292633\n",
      "Epoch 4/100, Iteration 235/303, Loss: 0.5771624445915222\n",
      "Epoch 4/100, Iteration 236/303, Loss: 0.494906485080719\n",
      "Epoch 4/100, Iteration 237/303, Loss: 0.5687040090560913\n",
      "Epoch 4/100, Iteration 238/303, Loss: 0.4783427119255066\n",
      "Epoch 4/100, Iteration 239/303, Loss: 0.6723302006721497\n",
      "Epoch 4/100, Iteration 240/303, Loss: 0.3962031304836273\n",
      "Epoch 4/100, Iteration 241/303, Loss: 0.39436301589012146\n",
      "Epoch 4/100, Iteration 242/303, Loss: 0.42885830998420715\n",
      "Epoch 4/100, Iteration 243/303, Loss: 0.21708746254444122\n",
      "Epoch 4/100, Iteration 244/303, Loss: 0.3145119547843933\n",
      "Epoch 4/100, Iteration 245/303, Loss: 0.5118072628974915\n",
      "Epoch 4/100, Iteration 246/303, Loss: 0.33642080426216125\n",
      "Epoch 4/100, Iteration 247/303, Loss: 0.34418153762817383\n",
      "Epoch 4/100, Iteration 248/303, Loss: 0.755352258682251\n",
      "Epoch 4/100, Iteration 249/303, Loss: 0.38680508732795715\n",
      "Epoch 4/100, Iteration 250/303, Loss: 0.47712472081184387\n",
      "Epoch 4/100, Iteration 251/303, Loss: 0.48814722895622253\n",
      "Epoch 4/100, Iteration 252/303, Loss: 0.47950366139411926\n",
      "Epoch 4/100, Iteration 253/303, Loss: 0.4216848611831665\n",
      "Epoch 4/100, Iteration 254/303, Loss: 0.7554899454116821\n",
      "Epoch 4/100, Iteration 255/303, Loss: 0.38146668672561646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Iteration 256/303, Loss: 0.4338597059249878\n",
      "Epoch 4/100, Iteration 257/303, Loss: 0.47031062841415405\n",
      "Epoch 4/100, Iteration 258/303, Loss: 0.4109383225440979\n",
      "Epoch 4/100, Iteration 259/303, Loss: 0.5774783492088318\n",
      "Epoch 4/100, Iteration 260/303, Loss: 0.6070187091827393\n",
      "Epoch 4/100, Iteration 261/303, Loss: 0.46297237277030945\n",
      "Epoch 4/100, Iteration 262/303, Loss: 0.4147648811340332\n",
      "Epoch 4/100, Iteration 263/303, Loss: 0.48870664834976196\n",
      "Epoch 4/100, Iteration 264/303, Loss: 0.4842190146446228\n",
      "Epoch 4/100, Iteration 265/303, Loss: 0.4553413391113281\n",
      "Epoch 4/100, Iteration 266/303, Loss: 0.40521007776260376\n",
      "Epoch 4/100, Iteration 267/303, Loss: 0.49776989221572876\n",
      "Epoch 4/100, Iteration 268/303, Loss: 0.38582733273506165\n",
      "Epoch 4/100, Iteration 269/303, Loss: 0.5974091291427612\n",
      "Epoch 4/100, Iteration 270/303, Loss: 0.4637390077114105\n",
      "Epoch 4/100, Iteration 271/303, Loss: 0.47238752245903015\n",
      "Epoch 4/100, Iteration 272/303, Loss: 0.41223418712615967\n",
      "Epoch 4/100, Iteration 273/303, Loss: 0.42315465211868286\n",
      "Epoch 4/100, Iteration 274/303, Loss: 0.5295505523681641\n",
      "Epoch 4/100, Iteration 275/303, Loss: 0.5050160884857178\n",
      "Epoch 4/100, Iteration 276/303, Loss: 0.5996130108833313\n",
      "Epoch 4/100, Iteration 277/303, Loss: 0.3362428843975067\n",
      "Epoch 4/100, Iteration 278/303, Loss: 0.4293290972709656\n",
      "Epoch 4/100, Iteration 279/303, Loss: 0.49982842803001404\n",
      "Epoch 4/100, Iteration 280/303, Loss: 0.36234718561172485\n",
      "Epoch 4/100, Iteration 281/303, Loss: 0.2780647873878479\n",
      "Epoch 4/100, Iteration 282/303, Loss: 0.5421832203865051\n",
      "Epoch 4/100, Iteration 283/303, Loss: 0.4458487629890442\n",
      "Epoch 4/100, Iteration 284/303, Loss: 0.5028325915336609\n",
      "Epoch 4/100, Iteration 285/303, Loss: 0.5009322166442871\n",
      "Epoch 4/100, Iteration 286/303, Loss: 0.6065443158149719\n",
      "Epoch 4/100, Iteration 287/303, Loss: 0.41975295543670654\n",
      "Epoch 4/100, Iteration 288/303, Loss: 0.4219561517238617\n",
      "Epoch 4/100, Iteration 289/303, Loss: 0.3854287564754486\n",
      "Epoch 4/100, Iteration 290/303, Loss: 0.43236005306243896\n",
      "Epoch 4/100, Iteration 291/303, Loss: 0.3958677649497986\n",
      "Epoch 4/100, Iteration 292/303, Loss: 0.4211620092391968\n",
      "Epoch 4/100, Iteration 293/303, Loss: 0.3218923509120941\n",
      "Epoch 4/100, Iteration 294/303, Loss: 0.5393675565719604\n",
      "Epoch 4/100, Iteration 295/303, Loss: 0.3167020082473755\n",
      "Epoch 4/100, Iteration 296/303, Loss: 0.46246442198753357\n",
      "Epoch 4/100, Iteration 297/303, Loss: 0.4341312646865845\n",
      "Epoch 4/100, Iteration 298/303, Loss: 0.4002198874950409\n",
      "Epoch 4/100, Iteration 299/303, Loss: 0.3723839223384857\n",
      "Epoch 4/100, Iteration 300/303, Loss: 0.6476961374282837\n",
      "Epoch 4/100, Iteration 301/303, Loss: 0.5567247271537781\n",
      "Epoch 4/100, Iteration 302/303, Loss: 0.5479719042778015\n",
      "Epoch 4/100, Iteration 303/303, Loss: 0.31343984603881836\n",
      "Epoch 5/100, Iteration 1/303, Loss: 0.4145129919052124\n",
      "Epoch 5/100, Iteration 2/303, Loss: 0.42484763264656067\n",
      "Epoch 5/100, Iteration 3/303, Loss: 0.38279417157173157\n",
      "Epoch 5/100, Iteration 4/303, Loss: 0.5088478922843933\n",
      "Epoch 5/100, Iteration 5/303, Loss: 0.4336518943309784\n",
      "Epoch 5/100, Iteration 6/303, Loss: 0.3059244155883789\n",
      "Epoch 5/100, Iteration 7/303, Loss: 0.5103735327720642\n",
      "Epoch 5/100, Iteration 8/303, Loss: 0.2997357249259949\n",
      "Epoch 5/100, Iteration 9/303, Loss: 0.4005957245826721\n",
      "Epoch 5/100, Iteration 10/303, Loss: 0.3827863931655884\n",
      "Epoch 5/100, Iteration 11/303, Loss: 0.44880467653274536\n",
      "Epoch 5/100, Iteration 12/303, Loss: 0.3665042221546173\n",
      "Epoch 5/100, Iteration 13/303, Loss: 0.5399621725082397\n",
      "Epoch 5/100, Iteration 14/303, Loss: 0.5571210384368896\n",
      "Epoch 5/100, Iteration 15/303, Loss: 0.2680453956127167\n",
      "Epoch 5/100, Iteration 16/303, Loss: 0.3962395489215851\n",
      "Epoch 5/100, Iteration 17/303, Loss: 0.3537996709346771\n",
      "Epoch 5/100, Iteration 18/303, Loss: 0.42444565892219543\n",
      "Epoch 5/100, Iteration 19/303, Loss: 0.47315382957458496\n",
      "Epoch 5/100, Iteration 20/303, Loss: 0.7049413919448853\n",
      "Epoch 5/100, Iteration 21/303, Loss: 0.5263153314590454\n",
      "Epoch 5/100, Iteration 22/303, Loss: 0.38463807106018066\n",
      "Epoch 5/100, Iteration 23/303, Loss: 0.5403259992599487\n",
      "Epoch 5/100, Iteration 24/303, Loss: 0.6153724789619446\n",
      "Epoch 5/100, Iteration 25/303, Loss: 0.4541734755039215\n",
      "Epoch 5/100, Iteration 26/303, Loss: 0.31218600273132324\n",
      "Epoch 5/100, Iteration 27/303, Loss: 0.43478283286094666\n",
      "Epoch 5/100, Iteration 28/303, Loss: 0.5230103731155396\n",
      "Epoch 5/100, Iteration 29/303, Loss: 0.4556272029876709\n",
      "Epoch 5/100, Iteration 30/303, Loss: 0.493150532245636\n",
      "Epoch 5/100, Iteration 31/303, Loss: 0.4627920091152191\n",
      "Epoch 5/100, Iteration 32/303, Loss: 0.3555472791194916\n",
      "Epoch 5/100, Iteration 33/303, Loss: 0.45804426074028015\n",
      "Epoch 5/100, Iteration 34/303, Loss: 0.47224295139312744\n",
      "Epoch 5/100, Iteration 35/303, Loss: 0.4125492572784424\n",
      "Epoch 5/100, Iteration 36/303, Loss: 0.27563712000846863\n",
      "Epoch 5/100, Iteration 37/303, Loss: 0.34783464670181274\n",
      "Epoch 5/100, Iteration 38/303, Loss: 0.25362032651901245\n",
      "Epoch 5/100, Iteration 39/303, Loss: 0.592157781124115\n",
      "Epoch 5/100, Iteration 40/303, Loss: 0.41726231575012207\n",
      "Epoch 5/100, Iteration 41/303, Loss: 0.5578538179397583\n",
      "Epoch 5/100, Iteration 42/303, Loss: 0.5706518292427063\n",
      "Epoch 5/100, Iteration 43/303, Loss: 0.6336261034011841\n",
      "Epoch 5/100, Iteration 44/303, Loss: 0.49657556414604187\n",
      "Epoch 5/100, Iteration 45/303, Loss: 0.5414637327194214\n",
      "Epoch 5/100, Iteration 46/303, Loss: 0.4249575734138489\n",
      "Epoch 5/100, Iteration 47/303, Loss: 0.2734871506690979\n",
      "Epoch 5/100, Iteration 48/303, Loss: 0.38998064398765564\n",
      "Epoch 5/100, Iteration 49/303, Loss: 0.3876073360443115\n",
      "Epoch 5/100, Iteration 50/303, Loss: 0.30832260847091675\n",
      "Epoch 5/100, Iteration 51/303, Loss: 0.6000217795372009\n",
      "Epoch 5/100, Iteration 52/303, Loss: 0.39746296405792236\n",
      "Epoch 5/100, Iteration 53/303, Loss: 0.39673805236816406\n",
      "Epoch 5/100, Iteration 54/303, Loss: 0.4062209725379944\n",
      "Epoch 5/100, Iteration 55/303, Loss: 0.3408723771572113\n",
      "Epoch 5/100, Iteration 56/303, Loss: 0.468607634305954\n",
      "Epoch 5/100, Iteration 57/303, Loss: 0.36418429017066956\n",
      "Epoch 5/100, Iteration 58/303, Loss: 0.2566719651222229\n",
      "Epoch 5/100, Iteration 59/303, Loss: 0.42542755603790283\n",
      "Epoch 5/100, Iteration 60/303, Loss: 0.5954204797744751\n",
      "Epoch 5/100, Iteration 61/303, Loss: 0.3722917437553406\n",
      "Epoch 5/100, Iteration 62/303, Loss: 0.362481951713562\n",
      "Epoch 5/100, Iteration 63/303, Loss: 0.47321704030036926\n",
      "Epoch 5/100, Iteration 64/303, Loss: 0.39047113060951233\n",
      "Epoch 5/100, Iteration 65/303, Loss: 0.3470744788646698\n",
      "Epoch 5/100, Iteration 66/303, Loss: 0.4079905152320862\n",
      "Epoch 5/100, Iteration 67/303, Loss: 0.3029820919036865\n",
      "Epoch 5/100, Iteration 68/303, Loss: 0.42547607421875\n",
      "Epoch 5/100, Iteration 69/303, Loss: 0.35209763050079346\n",
      "Epoch 5/100, Iteration 70/303, Loss: 0.45469385385513306\n",
      "Epoch 5/100, Iteration 71/303, Loss: 0.4666479527950287\n",
      "Epoch 5/100, Iteration 72/303, Loss: 0.42794615030288696\n",
      "Epoch 5/100, Iteration 73/303, Loss: 0.36053702235221863\n",
      "Epoch 5/100, Iteration 74/303, Loss: 0.25475960969924927\n",
      "Epoch 5/100, Iteration 75/303, Loss: 0.5656542778015137\n",
      "Epoch 5/100, Iteration 76/303, Loss: 0.5759350657463074\n",
      "Epoch 5/100, Iteration 77/303, Loss: 0.5046231150627136\n",
      "Epoch 5/100, Iteration 78/303, Loss: 0.4073011577129364\n",
      "Epoch 5/100, Iteration 79/303, Loss: 0.4290400445461273\n",
      "Epoch 5/100, Iteration 80/303, Loss: 0.474015474319458\n",
      "Epoch 5/100, Iteration 81/303, Loss: 0.3978959918022156\n",
      "Epoch 5/100, Iteration 82/303, Loss: 0.478080689907074\n",
      "Epoch 5/100, Iteration 83/303, Loss: 0.42084524035453796\n",
      "Epoch 5/100, Iteration 84/303, Loss: 0.3494252860546112\n",
      "Epoch 5/100, Iteration 85/303, Loss: 0.35711702704429626\n",
      "Epoch 5/100, Iteration 86/303, Loss: 0.390029639005661\n",
      "Epoch 5/100, Iteration 87/303, Loss: 0.5183851718902588\n",
      "Epoch 5/100, Iteration 88/303, Loss: 0.4791220724582672\n",
      "Epoch 5/100, Iteration 89/303, Loss: 0.36594724655151367\n",
      "Epoch 5/100, Iteration 90/303, Loss: 0.3342835307121277\n",
      "Epoch 5/100, Iteration 91/303, Loss: 0.47630950808525085\n",
      "Epoch 5/100, Iteration 92/303, Loss: 0.5772266387939453\n",
      "Epoch 5/100, Iteration 93/303, Loss: 0.4492708444595337\n",
      "Epoch 5/100, Iteration 94/303, Loss: 0.2997644543647766\n",
      "Epoch 5/100, Iteration 95/303, Loss: 0.360495924949646\n",
      "Epoch 5/100, Iteration 96/303, Loss: 0.3747081160545349\n",
      "Epoch 5/100, Iteration 97/303, Loss: 0.7392926812171936\n",
      "Epoch 5/100, Iteration 98/303, Loss: 0.5580926537513733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Iteration 99/303, Loss: 0.4152238667011261\n",
      "Epoch 5/100, Iteration 100/303, Loss: 0.5268416404724121\n",
      "Epoch 5/100, Iteration 101/303, Loss: 0.5816189050674438\n",
      "Epoch 5/100, Iteration 102/303, Loss: 0.4814714193344116\n",
      "Epoch 5/100, Iteration 103/303, Loss: 0.3698155879974365\n",
      "Epoch 5/100, Iteration 104/303, Loss: 0.5245689749717712\n",
      "Epoch 5/100, Iteration 105/303, Loss: 0.3843003809452057\n",
      "Epoch 5/100, Iteration 106/303, Loss: 0.5674599409103394\n",
      "Epoch 5/100, Iteration 107/303, Loss: 0.36427539587020874\n",
      "Epoch 5/100, Iteration 108/303, Loss: 0.43323126435279846\n",
      "Epoch 5/100, Iteration 109/303, Loss: 0.3894041180610657\n",
      "Epoch 5/100, Iteration 110/303, Loss: 0.5682709217071533\n",
      "Epoch 5/100, Iteration 111/303, Loss: 0.33498403429985046\n",
      "Epoch 5/100, Iteration 112/303, Loss: 0.43059447407722473\n",
      "Epoch 5/100, Iteration 113/303, Loss: 0.3960123062133789\n",
      "Epoch 5/100, Iteration 114/303, Loss: 0.4483646750450134\n",
      "Epoch 5/100, Iteration 115/303, Loss: 0.3151906728744507\n",
      "Epoch 5/100, Iteration 116/303, Loss: 0.3870174288749695\n",
      "Epoch 5/100, Iteration 117/303, Loss: 0.7744607329368591\n",
      "Epoch 5/100, Iteration 118/303, Loss: 0.6258025169372559\n",
      "Epoch 5/100, Iteration 119/303, Loss: 0.4934617877006531\n",
      "Epoch 5/100, Iteration 120/303, Loss: 0.5793321132659912\n",
      "Epoch 5/100, Iteration 121/303, Loss: 0.48696473240852356\n",
      "Epoch 5/100, Iteration 122/303, Loss: 0.4049999415874481\n",
      "Epoch 5/100, Iteration 123/303, Loss: 0.4773370623588562\n",
      "Epoch 5/100, Iteration 124/303, Loss: 0.4749886691570282\n",
      "Epoch 5/100, Iteration 125/303, Loss: 0.3890640139579773\n",
      "Epoch 5/100, Iteration 126/303, Loss: 0.48795661330223083\n",
      "Epoch 5/100, Iteration 127/303, Loss: 0.4770529270172119\n",
      "Epoch 5/100, Iteration 128/303, Loss: 0.3658677041530609\n",
      "Epoch 5/100, Iteration 129/303, Loss: 0.44270479679107666\n",
      "Epoch 5/100, Iteration 130/303, Loss: 0.5321459174156189\n",
      "Epoch 5/100, Iteration 131/303, Loss: 0.4786909222602844\n",
      "Epoch 5/100, Iteration 132/303, Loss: 0.4731349050998688\n",
      "Epoch 5/100, Iteration 133/303, Loss: 0.550578236579895\n",
      "Epoch 5/100, Iteration 134/303, Loss: 0.579870879650116\n",
      "Epoch 5/100, Iteration 135/303, Loss: 0.6153252124786377\n",
      "Epoch 5/100, Iteration 136/303, Loss: 0.4237865209579468\n",
      "Epoch 5/100, Iteration 137/303, Loss: 0.3402519226074219\n",
      "Epoch 5/100, Iteration 138/303, Loss: 0.3834269046783447\n",
      "Epoch 5/100, Iteration 139/303, Loss: 0.553002655506134\n",
      "Epoch 5/100, Iteration 140/303, Loss: 0.44335368275642395\n",
      "Epoch 5/100, Iteration 141/303, Loss: 0.4382684826850891\n",
      "Epoch 5/100, Iteration 142/303, Loss: 0.2715394198894501\n",
      "Epoch 5/100, Iteration 143/303, Loss: 0.22978687286376953\n",
      "Epoch 5/100, Iteration 144/303, Loss: 0.3550889790058136\n",
      "Epoch 5/100, Iteration 145/303, Loss: 0.4384711980819702\n",
      "Epoch 5/100, Iteration 146/303, Loss: 0.5294411778450012\n",
      "Epoch 5/100, Iteration 147/303, Loss: 0.44343945384025574\n",
      "Epoch 5/100, Iteration 148/303, Loss: 0.3110276162624359\n",
      "Epoch 5/100, Iteration 149/303, Loss: 0.2908839285373688\n",
      "Epoch 5/100, Iteration 150/303, Loss: 0.27721288800239563\n",
      "Epoch 5/100, Iteration 151/303, Loss: 0.49725109338760376\n",
      "Epoch 5/100, Iteration 152/303, Loss: 0.4336809515953064\n",
      "Epoch 5/100, Iteration 153/303, Loss: 0.3844568133354187\n",
      "Epoch 5/100, Iteration 154/303, Loss: 0.295001745223999\n",
      "Epoch 5/100, Iteration 155/303, Loss: 0.4253711700439453\n",
      "Epoch 5/100, Iteration 156/303, Loss: 0.41153740882873535\n",
      "Epoch 5/100, Iteration 157/303, Loss: 0.4361703395843506\n",
      "Epoch 5/100, Iteration 158/303, Loss: 0.3641970157623291\n",
      "Epoch 5/100, Iteration 159/303, Loss: 0.3458920121192932\n",
      "Epoch 5/100, Iteration 160/303, Loss: 0.42869845032691956\n",
      "Epoch 5/100, Iteration 161/303, Loss: 0.3836846947669983\n",
      "Epoch 5/100, Iteration 162/303, Loss: 0.3821999430656433\n",
      "Epoch 5/100, Iteration 163/303, Loss: 0.5304629802703857\n",
      "Epoch 5/100, Iteration 164/303, Loss: 0.4080817401409149\n",
      "Epoch 5/100, Iteration 165/303, Loss: 0.5375223159790039\n",
      "Epoch 5/100, Iteration 166/303, Loss: 0.5130506753921509\n",
      "Epoch 5/100, Iteration 167/303, Loss: 0.6389607191085815\n",
      "Epoch 5/100, Iteration 168/303, Loss: 0.5404661893844604\n",
      "Epoch 5/100, Iteration 169/303, Loss: 0.5037574768066406\n",
      "Epoch 5/100, Iteration 170/303, Loss: 0.44478678703308105\n",
      "Epoch 5/100, Iteration 171/303, Loss: 0.4638325273990631\n",
      "Epoch 5/100, Iteration 172/303, Loss: 0.4558979272842407\n",
      "Epoch 5/100, Iteration 173/303, Loss: 0.3664936125278473\n",
      "Epoch 5/100, Iteration 174/303, Loss: 0.5976179242134094\n",
      "Epoch 5/100, Iteration 175/303, Loss: 0.3899238109588623\n",
      "Epoch 5/100, Iteration 176/303, Loss: 0.5801495909690857\n",
      "Epoch 5/100, Iteration 177/303, Loss: 0.5693157911300659\n",
      "Epoch 5/100, Iteration 178/303, Loss: 0.30313560366630554\n",
      "Epoch 5/100, Iteration 179/303, Loss: 0.35493704676628113\n",
      "Epoch 5/100, Iteration 180/303, Loss: 0.3308531641960144\n",
      "Epoch 5/100, Iteration 181/303, Loss: 0.29508426785469055\n",
      "Epoch 5/100, Iteration 182/303, Loss: 0.39232274889945984\n",
      "Epoch 5/100, Iteration 183/303, Loss: 0.5412346720695496\n",
      "Epoch 5/100, Iteration 184/303, Loss: 0.3619139790534973\n",
      "Epoch 5/100, Iteration 185/303, Loss: 0.2914511263370514\n",
      "Epoch 5/100, Iteration 186/303, Loss: 0.3947826325893402\n",
      "Epoch 5/100, Iteration 187/303, Loss: 0.35464638471603394\n",
      "Epoch 5/100, Iteration 188/303, Loss: 0.49414244294166565\n",
      "Epoch 5/100, Iteration 189/303, Loss: 0.5543333888053894\n",
      "Epoch 5/100, Iteration 190/303, Loss: 0.4832329750061035\n",
      "Epoch 5/100, Iteration 191/303, Loss: 0.3304319977760315\n",
      "Epoch 5/100, Iteration 192/303, Loss: 0.46742624044418335\n",
      "Epoch 5/100, Iteration 193/303, Loss: 0.2374924123287201\n",
      "Epoch 5/100, Iteration 194/303, Loss: 0.41408392786979675\n",
      "Epoch 5/100, Iteration 195/303, Loss: 0.40020009875297546\n",
      "Epoch 5/100, Iteration 196/303, Loss: 0.38615262508392334\n",
      "Epoch 5/100, Iteration 197/303, Loss: 0.28593674302101135\n",
      "Epoch 5/100, Iteration 198/303, Loss: 0.33248674869537354\n",
      "Epoch 5/100, Iteration 199/303, Loss: 0.4091479480266571\n",
      "Epoch 5/100, Iteration 200/303, Loss: 0.27139395475387573\n",
      "Epoch 5/100, Iteration 201/303, Loss: 0.2890002727508545\n",
      "Epoch 5/100, Iteration 202/303, Loss: 0.44958579540252686\n",
      "Epoch 5/100, Iteration 203/303, Loss: 0.4691901206970215\n",
      "Epoch 5/100, Iteration 204/303, Loss: 0.4575483202934265\n",
      "Epoch 5/100, Iteration 205/303, Loss: 0.39108315110206604\n",
      "Epoch 5/100, Iteration 206/303, Loss: 0.43663111329078674\n",
      "Epoch 5/100, Iteration 207/303, Loss: 0.4329582750797272\n",
      "Epoch 5/100, Iteration 208/303, Loss: 0.38131237030029297\n",
      "Epoch 5/100, Iteration 209/303, Loss: 0.34717005491256714\n",
      "Epoch 5/100, Iteration 210/303, Loss: 0.4370326101779938\n",
      "Epoch 5/100, Iteration 211/303, Loss: 0.45013493299484253\n",
      "Epoch 5/100, Iteration 212/303, Loss: 0.2876330614089966\n",
      "Epoch 5/100, Iteration 213/303, Loss: 0.5513674020767212\n",
      "Epoch 5/100, Iteration 214/303, Loss: 0.35633739829063416\n",
      "Epoch 5/100, Iteration 215/303, Loss: 0.5454325675964355\n",
      "Epoch 5/100, Iteration 216/303, Loss: 0.42920881509780884\n",
      "Epoch 5/100, Iteration 217/303, Loss: 0.4569672644138336\n",
      "Epoch 5/100, Iteration 218/303, Loss: 0.5189424157142639\n",
      "Epoch 5/100, Iteration 219/303, Loss: 0.5003269910812378\n",
      "Epoch 5/100, Iteration 220/303, Loss: 0.6424298286437988\n",
      "Epoch 5/100, Iteration 221/303, Loss: 0.4013919234275818\n",
      "Epoch 5/100, Iteration 222/303, Loss: 0.3634556531906128\n",
      "Epoch 5/100, Iteration 223/303, Loss: 0.37335991859436035\n",
      "Epoch 5/100, Iteration 224/303, Loss: 0.6043300032615662\n",
      "Epoch 5/100, Iteration 225/303, Loss: 0.3107689619064331\n",
      "Epoch 5/100, Iteration 226/303, Loss: 0.36654916405677795\n",
      "Epoch 5/100, Iteration 227/303, Loss: 0.2867550849914551\n",
      "Epoch 5/100, Iteration 228/303, Loss: 0.4099688231945038\n",
      "Epoch 5/100, Iteration 229/303, Loss: 0.3790813684463501\n",
      "Epoch 5/100, Iteration 230/303, Loss: 0.4658172130584717\n",
      "Epoch 5/100, Iteration 231/303, Loss: 0.4259659945964813\n",
      "Epoch 5/100, Iteration 232/303, Loss: 0.4904699921607971\n",
      "Epoch 5/100, Iteration 233/303, Loss: 0.33145779371261597\n",
      "Epoch 5/100, Iteration 234/303, Loss: 0.6841686367988586\n",
      "Epoch 5/100, Iteration 235/303, Loss: 0.4378838539123535\n",
      "Epoch 5/100, Iteration 236/303, Loss: 0.5165907144546509\n",
      "Epoch 5/100, Iteration 237/303, Loss: 0.43902188539505005\n",
      "Epoch 5/100, Iteration 238/303, Loss: 0.5431753396987915\n",
      "Epoch 5/100, Iteration 239/303, Loss: 0.3134838044643402\n",
      "Epoch 5/100, Iteration 240/303, Loss: 0.3603099286556244\n",
      "Epoch 5/100, Iteration 241/303, Loss: 0.4173749089241028\n",
      "Epoch 5/100, Iteration 242/303, Loss: 0.3183032274246216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Iteration 243/303, Loss: 0.3562980592250824\n",
      "Epoch 5/100, Iteration 244/303, Loss: 0.5076432824134827\n",
      "Epoch 5/100, Iteration 245/303, Loss: 0.34141263365745544\n",
      "Epoch 5/100, Iteration 246/303, Loss: 0.3252997100353241\n",
      "Epoch 5/100, Iteration 247/303, Loss: 0.31881991028785706\n",
      "Epoch 5/100, Iteration 248/303, Loss: 0.3241159915924072\n",
      "Epoch 5/100, Iteration 249/303, Loss: 0.4923136532306671\n",
      "Epoch 5/100, Iteration 250/303, Loss: 0.47154760360717773\n",
      "Epoch 5/100, Iteration 251/303, Loss: 0.4781152606010437\n",
      "Epoch 5/100, Iteration 252/303, Loss: 0.6034704446792603\n",
      "Epoch 5/100, Iteration 253/303, Loss: 0.4774335026741028\n",
      "Epoch 5/100, Iteration 254/303, Loss: 0.3719828426837921\n",
      "Epoch 5/100, Iteration 255/303, Loss: 0.22650675475597382\n",
      "Epoch 5/100, Iteration 256/303, Loss: 0.5015940070152283\n",
      "Epoch 5/100, Iteration 257/303, Loss: 0.46157294511795044\n",
      "Epoch 5/100, Iteration 258/303, Loss: 0.36170274019241333\n",
      "Epoch 5/100, Iteration 259/303, Loss: 0.4067073464393616\n",
      "Epoch 5/100, Iteration 260/303, Loss: 0.32792237401008606\n",
      "Epoch 5/100, Iteration 261/303, Loss: 0.6246883273124695\n",
      "Epoch 5/100, Iteration 262/303, Loss: 0.44829440116882324\n",
      "Epoch 5/100, Iteration 263/303, Loss: 0.3741370439529419\n",
      "Epoch 5/100, Iteration 264/303, Loss: 0.4079408049583435\n",
      "Epoch 5/100, Iteration 265/303, Loss: 0.47419488430023193\n",
      "Epoch 5/100, Iteration 266/303, Loss: 0.2891409695148468\n",
      "Epoch 5/100, Iteration 267/303, Loss: 0.3852566182613373\n",
      "Epoch 5/100, Iteration 268/303, Loss: 0.26844438910484314\n",
      "Epoch 5/100, Iteration 269/303, Loss: 0.3548222482204437\n",
      "Epoch 5/100, Iteration 270/303, Loss: 0.27550020813941956\n",
      "Epoch 5/100, Iteration 271/303, Loss: 0.4469403922557831\n",
      "Epoch 5/100, Iteration 272/303, Loss: 0.49883607029914856\n",
      "Epoch 5/100, Iteration 273/303, Loss: 0.479441374540329\n",
      "Epoch 5/100, Iteration 274/303, Loss: 0.4367665946483612\n",
      "Epoch 5/100, Iteration 275/303, Loss: 0.45781686902046204\n",
      "Epoch 5/100, Iteration 276/303, Loss: 0.4337927997112274\n",
      "Epoch 5/100, Iteration 277/303, Loss: 0.4142915904521942\n",
      "Epoch 5/100, Iteration 278/303, Loss: 0.35154396295547485\n",
      "Epoch 5/100, Iteration 279/303, Loss: 0.44716891646385193\n",
      "Epoch 5/100, Iteration 280/303, Loss: 0.48522278666496277\n",
      "Epoch 5/100, Iteration 281/303, Loss: 0.5326598882675171\n",
      "Epoch 5/100, Iteration 282/303, Loss: 0.5108535885810852\n",
      "Epoch 5/100, Iteration 283/303, Loss: 0.33502739667892456\n",
      "Epoch 5/100, Iteration 284/303, Loss: 0.6917109489440918\n",
      "Epoch 5/100, Iteration 285/303, Loss: 0.2588675022125244\n",
      "Epoch 5/100, Iteration 286/303, Loss: 0.31239813566207886\n",
      "Epoch 5/100, Iteration 287/303, Loss: 0.24762625992298126\n",
      "Epoch 5/100, Iteration 288/303, Loss: 0.4626113474369049\n",
      "Epoch 5/100, Iteration 289/303, Loss: 0.3369404375553131\n",
      "Epoch 5/100, Iteration 290/303, Loss: 0.4232821464538574\n",
      "Epoch 5/100, Iteration 291/303, Loss: 0.3523278832435608\n",
      "Epoch 5/100, Iteration 292/303, Loss: 0.41529786586761475\n",
      "Epoch 5/100, Iteration 293/303, Loss: 0.33585166931152344\n",
      "Epoch 5/100, Iteration 294/303, Loss: 0.3038650155067444\n",
      "Epoch 5/100, Iteration 295/303, Loss: 0.3979770243167877\n",
      "Epoch 5/100, Iteration 296/303, Loss: 0.30466902256011963\n",
      "Epoch 5/100, Iteration 297/303, Loss: 0.4602016806602478\n",
      "Epoch 5/100, Iteration 298/303, Loss: 0.5134531259536743\n",
      "Epoch 5/100, Iteration 299/303, Loss: 0.43906697630882263\n",
      "Epoch 5/100, Iteration 300/303, Loss: 0.5131404399871826\n",
      "Epoch 5/100, Iteration 301/303, Loss: 0.4409126043319702\n",
      "Epoch 5/100, Iteration 302/303, Loss: 0.4474647641181946\n",
      "Epoch 5/100, Iteration 303/303, Loss: 0.3274490535259247\n",
      "Epoch 6/100, Iteration 1/303, Loss: 0.4061683416366577\n",
      "Epoch 6/100, Iteration 2/303, Loss: 0.3814988136291504\n",
      "Epoch 6/100, Iteration 3/303, Loss: 0.3012174963951111\n",
      "Epoch 6/100, Iteration 4/303, Loss: 0.30657294392585754\n",
      "Epoch 6/100, Iteration 5/303, Loss: 0.3265867233276367\n",
      "Epoch 6/100, Iteration 6/303, Loss: 0.28027454018592834\n",
      "Epoch 6/100, Iteration 7/303, Loss: 0.2591015100479126\n",
      "Epoch 6/100, Iteration 8/303, Loss: 0.30143100023269653\n",
      "Epoch 6/100, Iteration 9/303, Loss: 0.4146849513053894\n",
      "Epoch 6/100, Iteration 10/303, Loss: 0.22242046892642975\n",
      "Epoch 6/100, Iteration 11/303, Loss: 0.4625491499900818\n",
      "Epoch 6/100, Iteration 12/303, Loss: 0.6765482425689697\n",
      "Epoch 6/100, Iteration 13/303, Loss: 0.46076199412345886\n",
      "Epoch 6/100, Iteration 14/303, Loss: 0.3296499252319336\n",
      "Epoch 6/100, Iteration 15/303, Loss: 0.3277188539505005\n",
      "Epoch 6/100, Iteration 16/303, Loss: 0.3123968839645386\n",
      "Epoch 6/100, Iteration 17/303, Loss: 0.44180190563201904\n",
      "Epoch 6/100, Iteration 18/303, Loss: 0.48453348875045776\n",
      "Epoch 6/100, Iteration 19/303, Loss: 0.44574400782585144\n",
      "Epoch 6/100, Iteration 20/303, Loss: 0.4615606963634491\n",
      "Epoch 6/100, Iteration 21/303, Loss: 0.2465772181749344\n",
      "Epoch 6/100, Iteration 22/303, Loss: 0.2909776270389557\n",
      "Epoch 6/100, Iteration 23/303, Loss: 0.3490520119667053\n",
      "Epoch 6/100, Iteration 24/303, Loss: 0.3746051788330078\n",
      "Epoch 6/100, Iteration 25/303, Loss: 0.3980702757835388\n",
      "Epoch 6/100, Iteration 26/303, Loss: 0.4478294253349304\n",
      "Epoch 6/100, Iteration 27/303, Loss: 0.3783010244369507\n",
      "Epoch 6/100, Iteration 28/303, Loss: 0.31890326738357544\n",
      "Epoch 6/100, Iteration 29/303, Loss: 0.31574952602386475\n",
      "Epoch 6/100, Iteration 30/303, Loss: 0.539786159992218\n",
      "Epoch 6/100, Iteration 31/303, Loss: 0.36750486493110657\n",
      "Epoch 6/100, Iteration 32/303, Loss: 0.40958404541015625\n",
      "Epoch 6/100, Iteration 33/303, Loss: 0.24481868743896484\n",
      "Epoch 6/100, Iteration 34/303, Loss: 0.305614173412323\n",
      "Epoch 6/100, Iteration 35/303, Loss: 0.3515234589576721\n",
      "Epoch 6/100, Iteration 36/303, Loss: 0.30132803320884705\n",
      "Epoch 6/100, Iteration 37/303, Loss: 0.3230748474597931\n",
      "Epoch 6/100, Iteration 38/303, Loss: 0.40221139788627625\n",
      "Epoch 6/100, Iteration 39/303, Loss: 0.460139662027359\n",
      "Epoch 6/100, Iteration 40/303, Loss: 0.3487081229686737\n",
      "Epoch 6/100, Iteration 41/303, Loss: 0.3413870930671692\n",
      "Epoch 6/100, Iteration 42/303, Loss: 0.2595946490764618\n",
      "Epoch 6/100, Iteration 43/303, Loss: 0.5179204344749451\n",
      "Epoch 6/100, Iteration 44/303, Loss: 0.5020164251327515\n",
      "Epoch 6/100, Iteration 45/303, Loss: 0.24533654749393463\n",
      "Epoch 6/100, Iteration 46/303, Loss: 0.22162193059921265\n",
      "Epoch 6/100, Iteration 47/303, Loss: 0.36614593863487244\n",
      "Epoch 6/100, Iteration 48/303, Loss: 0.41892194747924805\n",
      "Epoch 6/100, Iteration 49/303, Loss: 0.4057854413986206\n",
      "Epoch 6/100, Iteration 50/303, Loss: 0.4051338732242584\n",
      "Epoch 6/100, Iteration 51/303, Loss: 0.3427533209323883\n",
      "Epoch 6/100, Iteration 52/303, Loss: 0.5227531790733337\n",
      "Epoch 6/100, Iteration 53/303, Loss: 0.4637545049190521\n",
      "Epoch 6/100, Iteration 54/303, Loss: 0.3877009153366089\n",
      "Epoch 6/100, Iteration 55/303, Loss: 0.4438129663467407\n",
      "Epoch 6/100, Iteration 56/303, Loss: 0.6309592723846436\n",
      "Epoch 6/100, Iteration 57/303, Loss: 0.4129609167575836\n",
      "Epoch 6/100, Iteration 58/303, Loss: 0.39535239338874817\n",
      "Epoch 6/100, Iteration 59/303, Loss: 0.3084867298603058\n",
      "Epoch 6/100, Iteration 60/303, Loss: 0.4934297204017639\n",
      "Epoch 6/100, Iteration 61/303, Loss: 0.3501908779144287\n",
      "Epoch 6/100, Iteration 62/303, Loss: 0.352029412984848\n",
      "Epoch 6/100, Iteration 63/303, Loss: 0.37776318192481995\n",
      "Epoch 6/100, Iteration 64/303, Loss: 0.38342538475990295\n",
      "Epoch 6/100, Iteration 65/303, Loss: 0.4154587388038635\n",
      "Epoch 6/100, Iteration 66/303, Loss: 0.4392954111099243\n",
      "Epoch 6/100, Iteration 67/303, Loss: 0.513494610786438\n",
      "Epoch 6/100, Iteration 68/303, Loss: 0.5186135172843933\n",
      "Epoch 6/100, Iteration 69/303, Loss: 0.4296876788139343\n",
      "Epoch 6/100, Iteration 70/303, Loss: 0.3739345967769623\n",
      "Epoch 6/100, Iteration 71/303, Loss: 0.38840967416763306\n",
      "Epoch 6/100, Iteration 72/303, Loss: 0.4188448488712311\n",
      "Epoch 6/100, Iteration 73/303, Loss: 0.35882213711738586\n",
      "Epoch 6/100, Iteration 74/303, Loss: 0.5396499037742615\n",
      "Epoch 6/100, Iteration 75/303, Loss: 0.40787842869758606\n",
      "Epoch 6/100, Iteration 76/303, Loss: 0.4964213967323303\n",
      "Epoch 6/100, Iteration 77/303, Loss: 0.45977216958999634\n",
      "Epoch 6/100, Iteration 78/303, Loss: 0.40321260690689087\n",
      "Epoch 6/100, Iteration 79/303, Loss: 0.35012468695640564\n",
      "Epoch 6/100, Iteration 80/303, Loss: 0.2683609426021576\n",
      "Epoch 6/100, Iteration 81/303, Loss: 0.34290117025375366\n",
      "Epoch 6/100, Iteration 82/303, Loss: 0.33132171630859375\n",
      "Epoch 6/100, Iteration 83/303, Loss: 0.30545303225517273\n",
      "Epoch 6/100, Iteration 84/303, Loss: 0.20846185088157654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Iteration 85/303, Loss: 0.5109819769859314\n",
      "Epoch 6/100, Iteration 86/303, Loss: 0.32472190260887146\n",
      "Epoch 6/100, Iteration 87/303, Loss: 0.5105720162391663\n",
      "Epoch 6/100, Iteration 88/303, Loss: 0.4381202161312103\n",
      "Epoch 6/100, Iteration 89/303, Loss: 0.5318964123725891\n",
      "Epoch 6/100, Iteration 90/303, Loss: 0.38404881954193115\n",
      "Epoch 6/100, Iteration 91/303, Loss: 0.285000741481781\n",
      "Epoch 6/100, Iteration 92/303, Loss: 0.33899012207984924\n",
      "Epoch 6/100, Iteration 93/303, Loss: 0.2893297076225281\n",
      "Epoch 6/100, Iteration 94/303, Loss: 0.2600529193878174\n",
      "Epoch 6/100, Iteration 95/303, Loss: 0.44201427698135376\n",
      "Epoch 6/100, Iteration 96/303, Loss: 0.38786664605140686\n",
      "Epoch 6/100, Iteration 97/303, Loss: 0.42797619104385376\n",
      "Epoch 6/100, Iteration 98/303, Loss: 0.35848313570022583\n",
      "Epoch 6/100, Iteration 99/303, Loss: 0.36648133397102356\n",
      "Epoch 6/100, Iteration 100/303, Loss: 0.27567315101623535\n",
      "Epoch 6/100, Iteration 101/303, Loss: 0.40953734517097473\n",
      "Epoch 6/100, Iteration 102/303, Loss: 0.24690653383731842\n",
      "Epoch 6/100, Iteration 103/303, Loss: 0.3383495509624481\n",
      "Epoch 6/100, Iteration 104/303, Loss: 0.3761923909187317\n",
      "Epoch 6/100, Iteration 105/303, Loss: 0.40155142545700073\n",
      "Epoch 6/100, Iteration 106/303, Loss: 0.36190664768218994\n",
      "Epoch 6/100, Iteration 107/303, Loss: 0.5347586274147034\n",
      "Epoch 6/100, Iteration 108/303, Loss: 0.34406134486198425\n",
      "Epoch 6/100, Iteration 109/303, Loss: 0.4481239318847656\n",
      "Epoch 6/100, Iteration 110/303, Loss: 0.3552289605140686\n",
      "Epoch 6/100, Iteration 111/303, Loss: 0.3974054753780365\n",
      "Epoch 6/100, Iteration 112/303, Loss: 0.3616511821746826\n",
      "Epoch 6/100, Iteration 113/303, Loss: 0.4355773329734802\n",
      "Epoch 6/100, Iteration 114/303, Loss: 0.49875450134277344\n",
      "Epoch 6/100, Iteration 115/303, Loss: 0.41575151681900024\n",
      "Epoch 6/100, Iteration 116/303, Loss: 0.7828075885772705\n",
      "Epoch 6/100, Iteration 117/303, Loss: 0.5429258942604065\n",
      "Epoch 6/100, Iteration 118/303, Loss: 0.3620942234992981\n",
      "Epoch 6/100, Iteration 119/303, Loss: 0.39499685168266296\n",
      "Epoch 6/100, Iteration 120/303, Loss: 0.5126539468765259\n",
      "Epoch 6/100, Iteration 121/303, Loss: 0.4574737846851349\n",
      "Epoch 6/100, Iteration 122/303, Loss: 0.37380582094192505\n",
      "Epoch 6/100, Iteration 123/303, Loss: 0.4862499237060547\n",
      "Epoch 6/100, Iteration 124/303, Loss: 0.4055759906768799\n",
      "Epoch 6/100, Iteration 125/303, Loss: 0.33707723021507263\n",
      "Epoch 6/100, Iteration 126/303, Loss: 0.510190486907959\n",
      "Epoch 6/100, Iteration 127/303, Loss: 0.38221293687820435\n",
      "Epoch 6/100, Iteration 128/303, Loss: 0.28828030824661255\n",
      "Epoch 6/100, Iteration 129/303, Loss: 0.45603489875793457\n",
      "Epoch 6/100, Iteration 130/303, Loss: 0.29790645837783813\n",
      "Epoch 6/100, Iteration 131/303, Loss: 0.30647748708724976\n",
      "Epoch 6/100, Iteration 132/303, Loss: 0.36992841958999634\n",
      "Epoch 6/100, Iteration 133/303, Loss: 0.3917175233364105\n",
      "Epoch 6/100, Iteration 134/303, Loss: 0.4404348134994507\n",
      "Epoch 6/100, Iteration 135/303, Loss: 0.5363463163375854\n",
      "Epoch 6/100, Iteration 136/303, Loss: 0.33944353461265564\n",
      "Epoch 6/100, Iteration 137/303, Loss: 0.4671474099159241\n",
      "Epoch 6/100, Iteration 138/303, Loss: 0.4666500687599182\n",
      "Epoch 6/100, Iteration 139/303, Loss: 0.4352256953716278\n",
      "Epoch 6/100, Iteration 140/303, Loss: 0.33463114500045776\n",
      "Epoch 6/100, Iteration 141/303, Loss: 0.37214627861976624\n",
      "Epoch 6/100, Iteration 142/303, Loss: 0.3470821678638458\n",
      "Epoch 6/100, Iteration 143/303, Loss: 0.42111605405807495\n",
      "Epoch 6/100, Iteration 144/303, Loss: 0.45098841190338135\n",
      "Epoch 6/100, Iteration 145/303, Loss: 0.5058476328849792\n",
      "Epoch 6/100, Iteration 146/303, Loss: 0.4503066837787628\n",
      "Epoch 6/100, Iteration 147/303, Loss: 0.28159192204475403\n",
      "Epoch 6/100, Iteration 148/303, Loss: 0.4481748342514038\n",
      "Epoch 6/100, Iteration 149/303, Loss: 0.519264817237854\n",
      "Epoch 6/100, Iteration 150/303, Loss: 0.41397276520729065\n",
      "Epoch 6/100, Iteration 151/303, Loss: 0.32692447304725647\n",
      "Epoch 6/100, Iteration 152/303, Loss: 0.5017952919006348\n",
      "Epoch 6/100, Iteration 153/303, Loss: 0.27047231793403625\n",
      "Epoch 6/100, Iteration 154/303, Loss: 0.4111456871032715\n",
      "Epoch 6/100, Iteration 155/303, Loss: 0.2878960967063904\n",
      "Epoch 6/100, Iteration 156/303, Loss: 0.3235069215297699\n",
      "Epoch 6/100, Iteration 157/303, Loss: 0.33322393894195557\n",
      "Epoch 6/100, Iteration 158/303, Loss: 0.31024882197380066\n",
      "Epoch 6/100, Iteration 159/303, Loss: 0.4384113848209381\n",
      "Epoch 6/100, Iteration 160/303, Loss: 0.2872859239578247\n",
      "Epoch 6/100, Iteration 161/303, Loss: 0.4082925319671631\n",
      "Epoch 6/100, Iteration 162/303, Loss: 0.40051183104515076\n",
      "Epoch 6/100, Iteration 163/303, Loss: 0.2759391963481903\n",
      "Epoch 6/100, Iteration 164/303, Loss: 0.4067959785461426\n",
      "Epoch 6/100, Iteration 165/303, Loss: 0.442806214094162\n",
      "Epoch 6/100, Iteration 166/303, Loss: 0.4364461898803711\n",
      "Epoch 6/100, Iteration 167/303, Loss: 0.4040554165840149\n",
      "Epoch 6/100, Iteration 168/303, Loss: 0.37356504797935486\n",
      "Epoch 6/100, Iteration 169/303, Loss: 0.3716195523738861\n",
      "Epoch 6/100, Iteration 170/303, Loss: 0.3718622922897339\n",
      "Epoch 6/100, Iteration 171/303, Loss: 0.24754878878593445\n",
      "Epoch 6/100, Iteration 172/303, Loss: 0.4336777329444885\n",
      "Epoch 6/100, Iteration 173/303, Loss: 0.7164222598075867\n",
      "Epoch 6/100, Iteration 174/303, Loss: 0.43874064087867737\n",
      "Epoch 6/100, Iteration 175/303, Loss: 0.22026321291923523\n",
      "Epoch 6/100, Iteration 176/303, Loss: 0.462624728679657\n",
      "Epoch 6/100, Iteration 177/303, Loss: 0.42109453678131104\n",
      "Epoch 6/100, Iteration 178/303, Loss: 0.2974100708961487\n",
      "Epoch 6/100, Iteration 179/303, Loss: 0.3423849046230316\n",
      "Epoch 6/100, Iteration 180/303, Loss: 0.6308110356330872\n",
      "Epoch 6/100, Iteration 181/303, Loss: 0.5307444334030151\n",
      "Epoch 6/100, Iteration 182/303, Loss: 0.29641813039779663\n",
      "Epoch 6/100, Iteration 183/303, Loss: 0.28222888708114624\n",
      "Epoch 6/100, Iteration 184/303, Loss: 0.5390183329582214\n",
      "Epoch 6/100, Iteration 185/303, Loss: 0.30010882019996643\n",
      "Epoch 6/100, Iteration 186/303, Loss: 0.4489859640598297\n",
      "Epoch 6/100, Iteration 187/303, Loss: 0.30515921115875244\n",
      "Epoch 6/100, Iteration 188/303, Loss: 0.4055785834789276\n",
      "Epoch 6/100, Iteration 189/303, Loss: 0.3840080797672272\n",
      "Epoch 6/100, Iteration 190/303, Loss: 0.37995651364326477\n",
      "Epoch 6/100, Iteration 191/303, Loss: 0.6730601787567139\n",
      "Epoch 6/100, Iteration 192/303, Loss: 0.36720770597457886\n",
      "Epoch 6/100, Iteration 193/303, Loss: 0.3866592049598694\n",
      "Epoch 6/100, Iteration 194/303, Loss: 0.32186609506607056\n",
      "Epoch 6/100, Iteration 195/303, Loss: 0.24615226686000824\n",
      "Epoch 6/100, Iteration 196/303, Loss: 0.23964329063892365\n",
      "Epoch 6/100, Iteration 197/303, Loss: 0.2185036838054657\n",
      "Epoch 6/100, Iteration 198/303, Loss: 0.20781098306179047\n",
      "Epoch 6/100, Iteration 199/303, Loss: 0.3770488500595093\n",
      "Epoch 6/100, Iteration 200/303, Loss: 0.467714786529541\n",
      "Epoch 6/100, Iteration 201/303, Loss: 0.4206085205078125\n",
      "Epoch 6/100, Iteration 202/303, Loss: 0.4521696865558624\n",
      "Epoch 6/100, Iteration 203/303, Loss: 0.3481824994087219\n",
      "Epoch 6/100, Iteration 204/303, Loss: 0.35126516222953796\n",
      "Epoch 6/100, Iteration 205/303, Loss: 0.3036172389984131\n",
      "Epoch 6/100, Iteration 206/303, Loss: 0.38703569769859314\n",
      "Epoch 6/100, Iteration 207/303, Loss: 0.309220552444458\n",
      "Epoch 6/100, Iteration 208/303, Loss: 0.2875317931175232\n",
      "Epoch 6/100, Iteration 209/303, Loss: 0.42064517736434937\n",
      "Epoch 6/100, Iteration 210/303, Loss: 0.2888585031032562\n",
      "Epoch 6/100, Iteration 211/303, Loss: 0.4082123935222626\n",
      "Epoch 6/100, Iteration 212/303, Loss: 0.4253048300743103\n",
      "Epoch 6/100, Iteration 213/303, Loss: 0.5264313817024231\n",
      "Epoch 6/100, Iteration 214/303, Loss: 0.4156716465950012\n",
      "Epoch 6/100, Iteration 215/303, Loss: 0.2974281907081604\n",
      "Epoch 6/100, Iteration 216/303, Loss: 0.48555314540863037\n",
      "Epoch 6/100, Iteration 217/303, Loss: 0.4028962254524231\n",
      "Epoch 6/100, Iteration 218/303, Loss: 0.3396800458431244\n",
      "Epoch 6/100, Iteration 219/303, Loss: 0.2615218162536621\n",
      "Epoch 6/100, Iteration 220/303, Loss: 0.42846742272377014\n",
      "Epoch 6/100, Iteration 221/303, Loss: 0.333437442779541\n",
      "Epoch 6/100, Iteration 222/303, Loss: 0.5347573757171631\n",
      "Epoch 6/100, Iteration 223/303, Loss: 0.3156488537788391\n",
      "Epoch 6/100, Iteration 224/303, Loss: 0.3297697901725769\n",
      "Epoch 6/100, Iteration 225/303, Loss: 0.34109336137771606\n",
      "Epoch 6/100, Iteration 226/303, Loss: 0.4438304603099823\n",
      "Epoch 6/100, Iteration 227/303, Loss: 0.34343019127845764\n",
      "Epoch 6/100, Iteration 228/303, Loss: 0.3367856740951538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Iteration 229/303, Loss: 0.47836941480636597\n",
      "Epoch 6/100, Iteration 230/303, Loss: 0.3162664473056793\n",
      "Epoch 6/100, Iteration 231/303, Loss: 0.3882555365562439\n",
      "Epoch 6/100, Iteration 232/303, Loss: 0.37833210825920105\n",
      "Epoch 6/100, Iteration 233/303, Loss: 0.3968183994293213\n",
      "Epoch 6/100, Iteration 234/303, Loss: 0.23476886749267578\n",
      "Epoch 6/100, Iteration 235/303, Loss: 0.17977052927017212\n",
      "Epoch 6/100, Iteration 236/303, Loss: 0.3235241770744324\n",
      "Epoch 6/100, Iteration 237/303, Loss: 0.3042212426662445\n",
      "Epoch 6/100, Iteration 238/303, Loss: 0.30845361948013306\n",
      "Epoch 6/100, Iteration 239/303, Loss: 0.5381038784980774\n",
      "Epoch 6/100, Iteration 240/303, Loss: 0.39147165417671204\n",
      "Epoch 6/100, Iteration 241/303, Loss: 0.34751269221305847\n",
      "Epoch 6/100, Iteration 242/303, Loss: 0.3299848437309265\n",
      "Epoch 6/100, Iteration 243/303, Loss: 0.4686719477176666\n",
      "Epoch 6/100, Iteration 244/303, Loss: 0.23602792620658875\n",
      "Epoch 6/100, Iteration 245/303, Loss: 0.3339669406414032\n",
      "Epoch 6/100, Iteration 246/303, Loss: 0.36254289746284485\n",
      "Epoch 6/100, Iteration 247/303, Loss: 0.34131771326065063\n",
      "Epoch 6/100, Iteration 248/303, Loss: 0.32807573676109314\n",
      "Epoch 6/100, Iteration 249/303, Loss: 0.1933601200580597\n",
      "Epoch 6/100, Iteration 250/303, Loss: 0.48773127794265747\n",
      "Epoch 6/100, Iteration 251/303, Loss: 0.16914086043834686\n",
      "Epoch 6/100, Iteration 252/303, Loss: 0.5694697499275208\n",
      "Epoch 6/100, Iteration 253/303, Loss: 0.4954325258731842\n",
      "Epoch 6/100, Iteration 254/303, Loss: 0.31905433535575867\n",
      "Epoch 6/100, Iteration 255/303, Loss: 0.3697548508644104\n",
      "Epoch 6/100, Iteration 256/303, Loss: 0.5325671434402466\n",
      "Epoch 6/100, Iteration 257/303, Loss: 0.43492189049720764\n",
      "Epoch 6/100, Iteration 258/303, Loss: 0.4726810157299042\n",
      "Epoch 6/100, Iteration 259/303, Loss: 0.31498095393180847\n",
      "Epoch 6/100, Iteration 260/303, Loss: 0.31404048204421997\n",
      "Epoch 6/100, Iteration 261/303, Loss: 0.34161925315856934\n",
      "Epoch 6/100, Iteration 262/303, Loss: 0.31171032786369324\n",
      "Epoch 6/100, Iteration 263/303, Loss: 0.20443195104599\n",
      "Epoch 6/100, Iteration 264/303, Loss: 0.4275209605693817\n",
      "Epoch 6/100, Iteration 265/303, Loss: 0.24829912185668945\n",
      "Epoch 6/100, Iteration 266/303, Loss: 0.26914355158805847\n",
      "Epoch 6/100, Iteration 267/303, Loss: 0.4983964264392853\n",
      "Epoch 6/100, Iteration 268/303, Loss: 0.39934512972831726\n",
      "Epoch 6/100, Iteration 269/303, Loss: 0.3760644495487213\n",
      "Epoch 6/100, Iteration 270/303, Loss: 0.3590720295906067\n",
      "Epoch 6/100, Iteration 271/303, Loss: 0.7226041555404663\n",
      "Epoch 6/100, Iteration 272/303, Loss: 0.4430576264858246\n",
      "Epoch 6/100, Iteration 273/303, Loss: 0.3092976212501526\n",
      "Epoch 6/100, Iteration 274/303, Loss: 0.4082717001438141\n",
      "Epoch 6/100, Iteration 275/303, Loss: 0.4155569076538086\n",
      "Epoch 6/100, Iteration 276/303, Loss: 0.5225309133529663\n",
      "Epoch 6/100, Iteration 277/303, Loss: 0.4678262770175934\n",
      "Epoch 6/100, Iteration 278/303, Loss: 0.31344231963157654\n",
      "Epoch 6/100, Iteration 279/303, Loss: 0.23834402859210968\n",
      "Epoch 6/100, Iteration 280/303, Loss: 0.43041330575942993\n",
      "Epoch 6/100, Iteration 281/303, Loss: 0.48721176385879517\n",
      "Epoch 6/100, Iteration 282/303, Loss: 0.4339737296104431\n",
      "Epoch 6/100, Iteration 283/303, Loss: 0.3463974893093109\n",
      "Epoch 6/100, Iteration 284/303, Loss: 0.28084036707878113\n",
      "Epoch 6/100, Iteration 285/303, Loss: 0.48107367753982544\n",
      "Epoch 6/100, Iteration 286/303, Loss: 0.30425605177879333\n",
      "Epoch 6/100, Iteration 287/303, Loss: 0.3455236554145813\n",
      "Epoch 6/100, Iteration 288/303, Loss: 0.2426452934741974\n",
      "Epoch 6/100, Iteration 289/303, Loss: 0.29451534152030945\n",
      "Epoch 6/100, Iteration 290/303, Loss: 0.36538320779800415\n",
      "Epoch 6/100, Iteration 291/303, Loss: 0.3963715732097626\n",
      "Epoch 6/100, Iteration 292/303, Loss: 0.4059884548187256\n",
      "Epoch 6/100, Iteration 293/303, Loss: 0.27721717953681946\n",
      "Epoch 6/100, Iteration 294/303, Loss: 0.568042516708374\n",
      "Epoch 6/100, Iteration 295/303, Loss: 0.33364343643188477\n",
      "Epoch 6/100, Iteration 296/303, Loss: 0.22281670570373535\n",
      "Epoch 6/100, Iteration 297/303, Loss: 0.23737841844558716\n",
      "Epoch 6/100, Iteration 298/303, Loss: 0.311679482460022\n",
      "Epoch 6/100, Iteration 299/303, Loss: 0.3799160122871399\n",
      "Epoch 6/100, Iteration 300/303, Loss: 0.3138390779495239\n",
      "Epoch 6/100, Iteration 301/303, Loss: 0.45752909779548645\n",
      "Epoch 6/100, Iteration 302/303, Loss: 0.26643720269203186\n",
      "Epoch 6/100, Iteration 303/303, Loss: 0.3612537086009979\n",
      "Epoch 7/100, Iteration 1/303, Loss: 0.4245139956474304\n",
      "Epoch 7/100, Iteration 2/303, Loss: 0.2856858968734741\n",
      "Epoch 7/100, Iteration 3/303, Loss: 0.7794232964515686\n",
      "Epoch 7/100, Iteration 4/303, Loss: 0.36726972460746765\n",
      "Epoch 7/100, Iteration 5/303, Loss: 0.30849775671958923\n",
      "Epoch 7/100, Iteration 6/303, Loss: 0.2931210994720459\n",
      "Epoch 7/100, Iteration 7/303, Loss: 0.47177907824516296\n",
      "Epoch 7/100, Iteration 8/303, Loss: 0.24912214279174805\n",
      "Epoch 7/100, Iteration 9/303, Loss: 0.3788122534751892\n",
      "Epoch 7/100, Iteration 10/303, Loss: 0.35074055194854736\n",
      "Epoch 7/100, Iteration 11/303, Loss: 0.4859865605831146\n",
      "Epoch 7/100, Iteration 12/303, Loss: 0.28585678339004517\n",
      "Epoch 7/100, Iteration 13/303, Loss: 0.39232775568962097\n",
      "Epoch 7/100, Iteration 14/303, Loss: 0.3440675437450409\n",
      "Epoch 7/100, Iteration 15/303, Loss: 0.3083198666572571\n",
      "Epoch 7/100, Iteration 16/303, Loss: 0.3213023245334625\n",
      "Epoch 7/100, Iteration 17/303, Loss: 0.29624640941619873\n",
      "Epoch 7/100, Iteration 18/303, Loss: 0.3983288109302521\n",
      "Epoch 7/100, Iteration 19/303, Loss: 0.34556055068969727\n",
      "Epoch 7/100, Iteration 20/303, Loss: 0.3717440068721771\n",
      "Epoch 7/100, Iteration 21/303, Loss: 0.3826426863670349\n",
      "Epoch 7/100, Iteration 22/303, Loss: 0.38322198390960693\n",
      "Epoch 7/100, Iteration 23/303, Loss: 0.24269609153270721\n",
      "Epoch 7/100, Iteration 24/303, Loss: 0.2194075584411621\n",
      "Epoch 7/100, Iteration 25/303, Loss: 0.2955264747142792\n",
      "Epoch 7/100, Iteration 26/303, Loss: 0.20504848659038544\n",
      "Epoch 7/100, Iteration 27/303, Loss: 0.2776949107646942\n",
      "Epoch 7/100, Iteration 28/303, Loss: 0.4104790687561035\n",
      "Epoch 7/100, Iteration 29/303, Loss: 0.3507694602012634\n",
      "Epoch 7/100, Iteration 30/303, Loss: 0.3434804677963257\n",
      "Epoch 7/100, Iteration 31/303, Loss: 0.4217239320278168\n",
      "Epoch 7/100, Iteration 32/303, Loss: 0.35776305198669434\n",
      "Epoch 7/100, Iteration 33/303, Loss: 0.3615019619464874\n",
      "Epoch 7/100, Iteration 34/303, Loss: 0.4951789379119873\n",
      "Epoch 7/100, Iteration 35/303, Loss: 0.29723814129829407\n",
      "Epoch 7/100, Iteration 36/303, Loss: 0.26911845803260803\n",
      "Epoch 7/100, Iteration 37/303, Loss: 0.2770974636077881\n",
      "Epoch 7/100, Iteration 38/303, Loss: 0.2036820352077484\n",
      "Epoch 7/100, Iteration 39/303, Loss: 0.41451412439346313\n",
      "Epoch 7/100, Iteration 40/303, Loss: 0.35139307379722595\n",
      "Epoch 7/100, Iteration 41/303, Loss: 0.4646901488304138\n",
      "Epoch 7/100, Iteration 42/303, Loss: 0.17981398105621338\n",
      "Epoch 7/100, Iteration 43/303, Loss: 0.31525859236717224\n",
      "Epoch 7/100, Iteration 44/303, Loss: 0.2656954526901245\n",
      "Epoch 7/100, Iteration 45/303, Loss: 0.2282000035047531\n",
      "Epoch 7/100, Iteration 46/303, Loss: 0.08544241636991501\n",
      "Epoch 7/100, Iteration 47/303, Loss: 0.45615965127944946\n",
      "Epoch 7/100, Iteration 48/303, Loss: 0.21131041646003723\n",
      "Epoch 7/100, Iteration 49/303, Loss: 0.36074098944664\n",
      "Epoch 7/100, Iteration 50/303, Loss: 0.3459223508834839\n",
      "Epoch 7/100, Iteration 51/303, Loss: 0.5357241034507751\n",
      "Epoch 7/100, Iteration 52/303, Loss: 0.35067132115364075\n",
      "Epoch 7/100, Iteration 53/303, Loss: 0.35575318336486816\n",
      "Epoch 7/100, Iteration 54/303, Loss: 0.3374755084514618\n",
      "Epoch 7/100, Iteration 55/303, Loss: 0.4077685475349426\n",
      "Epoch 7/100, Iteration 56/303, Loss: 0.18925398588180542\n",
      "Epoch 7/100, Iteration 57/303, Loss: 0.5321994423866272\n",
      "Epoch 7/100, Iteration 58/303, Loss: 0.4148305654525757\n",
      "Epoch 7/100, Iteration 59/303, Loss: 0.2913356423377991\n",
      "Epoch 7/100, Iteration 60/303, Loss: 0.20576058328151703\n",
      "Epoch 7/100, Iteration 61/303, Loss: 0.44666340947151184\n",
      "Epoch 7/100, Iteration 62/303, Loss: 0.30934566259384155\n",
      "Epoch 7/100, Iteration 63/303, Loss: 0.40688541531562805\n",
      "Epoch 7/100, Iteration 64/303, Loss: 0.5108892917633057\n",
      "Epoch 7/100, Iteration 65/303, Loss: 0.44180554151535034\n",
      "Epoch 7/100, Iteration 66/303, Loss: 0.3939599394798279\n",
      "Epoch 7/100, Iteration 67/303, Loss: 0.4468376934528351\n",
      "Epoch 7/100, Iteration 68/303, Loss: 0.2971121370792389\n",
      "Epoch 7/100, Iteration 69/303, Loss: 0.2980174422264099\n",
      "Epoch 7/100, Iteration 70/303, Loss: 0.43873849511146545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Iteration 71/303, Loss: 0.2540517747402191\n",
      "Epoch 7/100, Iteration 72/303, Loss: 0.3937702476978302\n",
      "Epoch 7/100, Iteration 73/303, Loss: 0.3311103582382202\n",
      "Epoch 7/100, Iteration 74/303, Loss: 0.24235525727272034\n",
      "Epoch 7/100, Iteration 75/303, Loss: 0.3337278366088867\n",
      "Epoch 7/100, Iteration 76/303, Loss: 0.3251509368419647\n",
      "Epoch 7/100, Iteration 77/303, Loss: 0.5882314443588257\n",
      "Epoch 7/100, Iteration 78/303, Loss: 0.3954012989997864\n",
      "Epoch 7/100, Iteration 79/303, Loss: 0.42559683322906494\n",
      "Epoch 7/100, Iteration 80/303, Loss: 0.39676591753959656\n",
      "Epoch 7/100, Iteration 81/303, Loss: 0.31138527393341064\n",
      "Epoch 7/100, Iteration 82/303, Loss: 0.17516489326953888\n",
      "Epoch 7/100, Iteration 83/303, Loss: 0.3131508529186249\n",
      "Epoch 7/100, Iteration 84/303, Loss: 0.3893415331840515\n",
      "Epoch 7/100, Iteration 85/303, Loss: 0.33166754245758057\n",
      "Epoch 7/100, Iteration 86/303, Loss: 0.3448416590690613\n",
      "Epoch 7/100, Iteration 87/303, Loss: 0.20330490171909332\n",
      "Epoch 7/100, Iteration 88/303, Loss: 0.21747183799743652\n",
      "Epoch 7/100, Iteration 89/303, Loss: 0.24779410660266876\n",
      "Epoch 7/100, Iteration 90/303, Loss: 0.4133446514606476\n",
      "Epoch 7/100, Iteration 91/303, Loss: 0.2552114725112915\n",
      "Epoch 7/100, Iteration 92/303, Loss: 0.2669272720813751\n",
      "Epoch 7/100, Iteration 93/303, Loss: 0.3726757764816284\n",
      "Epoch 7/100, Iteration 94/303, Loss: 0.4086311459541321\n",
      "Epoch 7/100, Iteration 95/303, Loss: 0.2542741596698761\n",
      "Epoch 7/100, Iteration 96/303, Loss: 0.4446656405925751\n",
      "Epoch 7/100, Iteration 97/303, Loss: 0.30266648530960083\n",
      "Epoch 7/100, Iteration 98/303, Loss: 0.23389847576618195\n",
      "Epoch 7/100, Iteration 99/303, Loss: 0.28183314204216003\n",
      "Epoch 7/100, Iteration 100/303, Loss: 0.5065395832061768\n",
      "Epoch 7/100, Iteration 101/303, Loss: 0.33188721537590027\n",
      "Epoch 7/100, Iteration 102/303, Loss: 0.5612543225288391\n",
      "Epoch 7/100, Iteration 103/303, Loss: 0.2517463266849518\n",
      "Epoch 7/100, Iteration 104/303, Loss: 0.3014060854911804\n",
      "Epoch 7/100, Iteration 105/303, Loss: 0.45910006761550903\n",
      "Epoch 7/100, Iteration 106/303, Loss: 0.25114092230796814\n",
      "Epoch 7/100, Iteration 107/303, Loss: 0.21645914018154144\n",
      "Epoch 7/100, Iteration 108/303, Loss: 0.4245295226573944\n",
      "Epoch 7/100, Iteration 109/303, Loss: 0.3920312523841858\n",
      "Epoch 7/100, Iteration 110/303, Loss: 0.4894832968711853\n",
      "Epoch 7/100, Iteration 111/303, Loss: 0.3337830603122711\n",
      "Epoch 7/100, Iteration 112/303, Loss: 0.3357604444026947\n",
      "Epoch 7/100, Iteration 113/303, Loss: 0.38997185230255127\n",
      "Epoch 7/100, Iteration 114/303, Loss: 0.23317797482013702\n",
      "Epoch 7/100, Iteration 115/303, Loss: 0.29463991522789\n",
      "Epoch 7/100, Iteration 116/303, Loss: 0.4725160002708435\n",
      "Epoch 7/100, Iteration 117/303, Loss: 0.6187318563461304\n",
      "Epoch 7/100, Iteration 118/303, Loss: 0.3883034288883209\n",
      "Epoch 7/100, Iteration 119/303, Loss: 0.35747939348220825\n",
      "Epoch 7/100, Iteration 120/303, Loss: 0.2953166961669922\n",
      "Epoch 7/100, Iteration 121/303, Loss: 0.3946418762207031\n",
      "Epoch 7/100, Iteration 122/303, Loss: 0.24314148724079132\n",
      "Epoch 7/100, Iteration 123/303, Loss: 0.24469459056854248\n",
      "Epoch 7/100, Iteration 124/303, Loss: 0.25895798206329346\n",
      "Epoch 7/100, Iteration 125/303, Loss: 0.2794732451438904\n",
      "Epoch 7/100, Iteration 126/303, Loss: 0.4288383722305298\n",
      "Epoch 7/100, Iteration 127/303, Loss: 0.37294885516166687\n",
      "Epoch 7/100, Iteration 128/303, Loss: 0.2647680342197418\n",
      "Epoch 7/100, Iteration 129/303, Loss: 0.3941963315010071\n",
      "Epoch 7/100, Iteration 130/303, Loss: 0.5828908681869507\n",
      "Epoch 7/100, Iteration 131/303, Loss: 0.22805288434028625\n",
      "Epoch 7/100, Iteration 132/303, Loss: 0.7032850980758667\n",
      "Epoch 7/100, Iteration 133/303, Loss: 0.3406907320022583\n",
      "Epoch 7/100, Iteration 134/303, Loss: 0.2734742760658264\n",
      "Epoch 7/100, Iteration 135/303, Loss: 0.4348130226135254\n",
      "Epoch 7/100, Iteration 136/303, Loss: 0.3078782558441162\n",
      "Epoch 7/100, Iteration 137/303, Loss: 0.28574687242507935\n",
      "Epoch 7/100, Iteration 138/303, Loss: 0.2782357335090637\n",
      "Epoch 7/100, Iteration 139/303, Loss: 0.3388647437095642\n",
      "Epoch 7/100, Iteration 140/303, Loss: 0.24346217513084412\n",
      "Epoch 7/100, Iteration 141/303, Loss: 0.28378820419311523\n",
      "Epoch 7/100, Iteration 142/303, Loss: 0.23429876565933228\n",
      "Epoch 7/100, Iteration 143/303, Loss: 0.2909069359302521\n",
      "Epoch 7/100, Iteration 144/303, Loss: 0.36960527300834656\n",
      "Epoch 7/100, Iteration 145/303, Loss: 0.3592221140861511\n",
      "Epoch 7/100, Iteration 146/303, Loss: 0.2841797173023224\n",
      "Epoch 7/100, Iteration 147/303, Loss: 0.3520048260688782\n",
      "Epoch 7/100, Iteration 148/303, Loss: 0.5600082874298096\n",
      "Epoch 7/100, Iteration 149/303, Loss: 0.2287583202123642\n",
      "Epoch 7/100, Iteration 150/303, Loss: 0.5259857177734375\n",
      "Epoch 7/100, Iteration 151/303, Loss: 0.4214683771133423\n",
      "Epoch 7/100, Iteration 152/303, Loss: 0.3160375952720642\n",
      "Epoch 7/100, Iteration 153/303, Loss: 0.3069327771663666\n",
      "Epoch 7/100, Iteration 154/303, Loss: 0.3345487713813782\n",
      "Epoch 7/100, Iteration 155/303, Loss: 0.2712288796901703\n",
      "Epoch 7/100, Iteration 156/303, Loss: 0.4127236604690552\n",
      "Epoch 7/100, Iteration 157/303, Loss: 0.1983281672000885\n",
      "Epoch 7/100, Iteration 158/303, Loss: 0.2200920581817627\n",
      "Epoch 7/100, Iteration 159/303, Loss: 0.14961613714694977\n",
      "Epoch 7/100, Iteration 160/303, Loss: 0.36197781562805176\n",
      "Epoch 7/100, Iteration 161/303, Loss: 0.36430415511131287\n",
      "Epoch 7/100, Iteration 162/303, Loss: 0.5921826958656311\n",
      "Epoch 7/100, Iteration 163/303, Loss: 0.3158873915672302\n",
      "Epoch 7/100, Iteration 164/303, Loss: 0.3146009147167206\n",
      "Epoch 7/100, Iteration 165/303, Loss: 0.21129319071769714\n",
      "Epoch 7/100, Iteration 166/303, Loss: 0.2989220917224884\n",
      "Epoch 7/100, Iteration 167/303, Loss: 0.802311897277832\n",
      "Epoch 7/100, Iteration 168/303, Loss: 0.4181677997112274\n",
      "Epoch 7/100, Iteration 169/303, Loss: 0.412594735622406\n",
      "Epoch 7/100, Iteration 170/303, Loss: 0.26769161224365234\n",
      "Epoch 7/100, Iteration 171/303, Loss: 0.24831265211105347\n",
      "Epoch 7/100, Iteration 172/303, Loss: 0.2549409866333008\n",
      "Epoch 7/100, Iteration 173/303, Loss: 0.3528990149497986\n",
      "Epoch 7/100, Iteration 174/303, Loss: 0.2741050124168396\n",
      "Epoch 7/100, Iteration 175/303, Loss: 0.247559055685997\n",
      "Epoch 7/100, Iteration 176/303, Loss: 0.22415733337402344\n",
      "Epoch 7/100, Iteration 177/303, Loss: 0.451219379901886\n",
      "Epoch 7/100, Iteration 178/303, Loss: 0.38218265771865845\n",
      "Epoch 7/100, Iteration 179/303, Loss: 0.39596647024154663\n",
      "Epoch 7/100, Iteration 180/303, Loss: 0.21205824613571167\n",
      "Epoch 7/100, Iteration 181/303, Loss: 0.3826729655265808\n",
      "Epoch 7/100, Iteration 182/303, Loss: 0.25161898136138916\n",
      "Epoch 7/100, Iteration 183/303, Loss: 0.39253824949264526\n",
      "Epoch 7/100, Iteration 184/303, Loss: 0.3717140853404999\n",
      "Epoch 7/100, Iteration 185/303, Loss: 0.3438371419906616\n",
      "Epoch 7/100, Iteration 186/303, Loss: 0.24460090696811676\n",
      "Epoch 7/100, Iteration 187/303, Loss: 0.23714831471443176\n",
      "Epoch 7/100, Iteration 188/303, Loss: 0.25057893991470337\n",
      "Epoch 7/100, Iteration 189/303, Loss: 0.3523949980735779\n",
      "Epoch 7/100, Iteration 190/303, Loss: 0.25470659136772156\n",
      "Epoch 7/100, Iteration 191/303, Loss: 0.3359664976596832\n",
      "Epoch 7/100, Iteration 192/303, Loss: 0.2814505398273468\n",
      "Epoch 7/100, Iteration 193/303, Loss: 0.30039680004119873\n",
      "Epoch 7/100, Iteration 194/303, Loss: 0.2735329568386078\n",
      "Epoch 7/100, Iteration 195/303, Loss: 0.6309757232666016\n",
      "Epoch 7/100, Iteration 196/303, Loss: 0.37765249609947205\n",
      "Epoch 7/100, Iteration 197/303, Loss: 0.3526967465877533\n",
      "Epoch 7/100, Iteration 198/303, Loss: 0.3937763571739197\n",
      "Epoch 7/100, Iteration 199/303, Loss: 0.3854571580886841\n",
      "Epoch 7/100, Iteration 200/303, Loss: 0.4831632077693939\n",
      "Epoch 7/100, Iteration 201/303, Loss: 0.3783458173274994\n",
      "Epoch 7/100, Iteration 202/303, Loss: 0.2816240191459656\n",
      "Epoch 7/100, Iteration 203/303, Loss: 0.32513126730918884\n",
      "Epoch 7/100, Iteration 204/303, Loss: 0.34998002648353577\n",
      "Epoch 7/100, Iteration 205/303, Loss: 0.1927611529827118\n",
      "Epoch 7/100, Iteration 206/303, Loss: 0.28266406059265137\n",
      "Epoch 7/100, Iteration 207/303, Loss: 0.4164595603942871\n",
      "Epoch 7/100, Iteration 208/303, Loss: 0.3018534481525421\n",
      "Epoch 7/100, Iteration 209/303, Loss: 0.3355487287044525\n",
      "Epoch 7/100, Iteration 210/303, Loss: 0.3030310571193695\n",
      "Epoch 7/100, Iteration 211/303, Loss: 0.6970541477203369\n",
      "Epoch 7/100, Iteration 212/303, Loss: 0.6267538666725159\n",
      "Epoch 7/100, Iteration 213/303, Loss: 0.28186094760894775\n",
      "Epoch 7/100, Iteration 214/303, Loss: 0.38452842831611633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Iteration 215/303, Loss: 0.26763132214546204\n",
      "Epoch 7/100, Iteration 216/303, Loss: 0.3686026632785797\n",
      "Epoch 7/100, Iteration 217/303, Loss: 0.3656667172908783\n",
      "Epoch 7/100, Iteration 218/303, Loss: 0.4092199504375458\n",
      "Epoch 7/100, Iteration 219/303, Loss: 0.36425310373306274\n",
      "Epoch 7/100, Iteration 220/303, Loss: 0.43498021364212036\n",
      "Epoch 7/100, Iteration 221/303, Loss: 0.18409870564937592\n",
      "Epoch 7/100, Iteration 222/303, Loss: 0.31583675742149353\n",
      "Epoch 7/100, Iteration 223/303, Loss: 0.25876471400260925\n",
      "Epoch 7/100, Iteration 224/303, Loss: 0.3821200132369995\n",
      "Epoch 7/100, Iteration 225/303, Loss: 0.34312912821769714\n",
      "Epoch 7/100, Iteration 226/303, Loss: 0.1672942191362381\n",
      "Epoch 7/100, Iteration 227/303, Loss: 0.44427672028541565\n",
      "Epoch 7/100, Iteration 228/303, Loss: 0.6315540075302124\n",
      "Epoch 7/100, Iteration 229/303, Loss: 0.33309435844421387\n",
      "Epoch 7/100, Iteration 230/303, Loss: 0.25765618681907654\n",
      "Epoch 7/100, Iteration 231/303, Loss: 0.22708682715892792\n",
      "Epoch 7/100, Iteration 232/303, Loss: 0.3724510073661804\n",
      "Epoch 7/100, Iteration 233/303, Loss: 0.4468086063861847\n",
      "Epoch 7/100, Iteration 234/303, Loss: 0.4277344346046448\n",
      "Epoch 7/100, Iteration 235/303, Loss: 0.32345354557037354\n",
      "Epoch 7/100, Iteration 236/303, Loss: 0.20510827004909515\n",
      "Epoch 7/100, Iteration 237/303, Loss: 0.40226519107818604\n",
      "Epoch 7/100, Iteration 238/303, Loss: 0.33318227529525757\n",
      "Epoch 7/100, Iteration 239/303, Loss: 0.40693414211273193\n",
      "Epoch 7/100, Iteration 240/303, Loss: 0.43339309096336365\n",
      "Epoch 7/100, Iteration 241/303, Loss: 0.28543704748153687\n",
      "Epoch 7/100, Iteration 242/303, Loss: 0.318390816450119\n",
      "Epoch 7/100, Iteration 243/303, Loss: 0.30946823954582214\n",
      "Epoch 7/100, Iteration 244/303, Loss: 0.4044134020805359\n",
      "Epoch 7/100, Iteration 245/303, Loss: 0.28899213671684265\n",
      "Epoch 7/100, Iteration 246/303, Loss: 0.33495211601257324\n",
      "Epoch 7/100, Iteration 247/303, Loss: 0.37291762232780457\n",
      "Epoch 7/100, Iteration 248/303, Loss: 0.34411054849624634\n",
      "Epoch 7/100, Iteration 249/303, Loss: 0.34399381279945374\n",
      "Epoch 7/100, Iteration 250/303, Loss: 0.27202996611595154\n",
      "Epoch 7/100, Iteration 251/303, Loss: 0.3413870334625244\n",
      "Epoch 7/100, Iteration 252/303, Loss: 0.29609400033950806\n",
      "Epoch 7/100, Iteration 253/303, Loss: 0.31973880529403687\n",
      "Epoch 7/100, Iteration 254/303, Loss: 0.27938100695610046\n",
      "Epoch 7/100, Iteration 255/303, Loss: 0.2988220751285553\n",
      "Epoch 7/100, Iteration 256/303, Loss: 0.26101869344711304\n",
      "Epoch 7/100, Iteration 257/303, Loss: 0.31576767563819885\n",
      "Epoch 7/100, Iteration 258/303, Loss: 0.25754842162132263\n",
      "Epoch 7/100, Iteration 259/303, Loss: 0.28594088554382324\n",
      "Epoch 7/100, Iteration 260/303, Loss: 0.25371286273002625\n",
      "Epoch 7/100, Iteration 261/303, Loss: 0.24582698941230774\n",
      "Epoch 7/100, Iteration 262/303, Loss: 0.5430604815483093\n",
      "Epoch 7/100, Iteration 263/303, Loss: 0.4071611166000366\n",
      "Epoch 7/100, Iteration 264/303, Loss: 0.3593270182609558\n",
      "Epoch 7/100, Iteration 265/303, Loss: 0.35948503017425537\n",
      "Epoch 7/100, Iteration 266/303, Loss: 0.3166165351867676\n",
      "Epoch 7/100, Iteration 267/303, Loss: 0.32491734623908997\n",
      "Epoch 7/100, Iteration 268/303, Loss: 0.21966838836669922\n",
      "Epoch 7/100, Iteration 269/303, Loss: 0.19058118760585785\n",
      "Epoch 7/100, Iteration 270/303, Loss: 0.26069578528404236\n",
      "Epoch 7/100, Iteration 271/303, Loss: 0.34471595287323\n",
      "Epoch 7/100, Iteration 272/303, Loss: 0.21342481672763824\n",
      "Epoch 7/100, Iteration 273/303, Loss: 0.26337090134620667\n",
      "Epoch 7/100, Iteration 274/303, Loss: 0.43638089299201965\n",
      "Epoch 7/100, Iteration 275/303, Loss: 0.31135720014572144\n",
      "Epoch 7/100, Iteration 276/303, Loss: 0.3417194187641144\n",
      "Epoch 7/100, Iteration 277/303, Loss: 0.3269593119621277\n",
      "Epoch 7/100, Iteration 278/303, Loss: 0.3952524960041046\n",
      "Epoch 7/100, Iteration 279/303, Loss: 0.3871743083000183\n",
      "Epoch 7/100, Iteration 280/303, Loss: 0.23559708893299103\n",
      "Epoch 7/100, Iteration 281/303, Loss: 0.5339034795761108\n",
      "Epoch 7/100, Iteration 282/303, Loss: 0.48833587765693665\n",
      "Epoch 7/100, Iteration 283/303, Loss: 0.43673574924468994\n",
      "Epoch 7/100, Iteration 284/303, Loss: 0.41898441314697266\n",
      "Epoch 7/100, Iteration 285/303, Loss: 0.2365218698978424\n",
      "Epoch 7/100, Iteration 286/303, Loss: 0.3508034348487854\n",
      "Epoch 7/100, Iteration 287/303, Loss: 0.2598530054092407\n",
      "Epoch 7/100, Iteration 288/303, Loss: 0.300173819065094\n",
      "Epoch 7/100, Iteration 289/303, Loss: 0.33549582958221436\n",
      "Epoch 7/100, Iteration 290/303, Loss: 0.33549633622169495\n",
      "Epoch 7/100, Iteration 291/303, Loss: 0.6171308755874634\n",
      "Epoch 7/100, Iteration 292/303, Loss: 0.4394263029098511\n",
      "Epoch 7/100, Iteration 293/303, Loss: 0.33628401160240173\n",
      "Epoch 7/100, Iteration 294/303, Loss: 0.21098633110523224\n",
      "Epoch 7/100, Iteration 295/303, Loss: 0.31285297870635986\n",
      "Epoch 7/100, Iteration 296/303, Loss: 0.28452959656715393\n",
      "Epoch 7/100, Iteration 297/303, Loss: 0.42572659254074097\n",
      "Epoch 7/100, Iteration 298/303, Loss: 0.1691984236240387\n",
      "Epoch 7/100, Iteration 299/303, Loss: 0.2788744270801544\n",
      "Epoch 7/100, Iteration 300/303, Loss: 0.3930688202381134\n",
      "Epoch 7/100, Iteration 301/303, Loss: 0.44975346326828003\n",
      "Epoch 7/100, Iteration 302/303, Loss: 0.2007785141468048\n",
      "Epoch 7/100, Iteration 303/303, Loss: 0.4319955110549927\n",
      "Epoch 8/100, Iteration 1/303, Loss: 0.4214683175086975\n",
      "Epoch 8/100, Iteration 2/303, Loss: 0.34901782870292664\n",
      "Epoch 8/100, Iteration 3/303, Loss: 0.18513181805610657\n",
      "Epoch 8/100, Iteration 4/303, Loss: 0.2588338255882263\n",
      "Epoch 8/100, Iteration 5/303, Loss: 0.17818793654441833\n",
      "Epoch 8/100, Iteration 6/303, Loss: 0.27362117171287537\n",
      "Epoch 8/100, Iteration 7/303, Loss: 0.2832387387752533\n",
      "Epoch 8/100, Iteration 8/303, Loss: 0.25741666555404663\n",
      "Epoch 8/100, Iteration 9/303, Loss: 0.511227011680603\n",
      "Epoch 8/100, Iteration 10/303, Loss: 0.2442496418952942\n",
      "Epoch 8/100, Iteration 11/303, Loss: 0.19194622337818146\n",
      "Epoch 8/100, Iteration 12/303, Loss: 0.3038267493247986\n",
      "Epoch 8/100, Iteration 13/303, Loss: 0.544434666633606\n",
      "Epoch 8/100, Iteration 14/303, Loss: 0.3081033229827881\n",
      "Epoch 8/100, Iteration 15/303, Loss: 0.418087899684906\n",
      "Epoch 8/100, Iteration 16/303, Loss: 0.4764467179775238\n",
      "Epoch 8/100, Iteration 17/303, Loss: 0.22537292540073395\n",
      "Epoch 8/100, Iteration 18/303, Loss: 0.3550756275653839\n",
      "Epoch 8/100, Iteration 19/303, Loss: 0.28027570247650146\n",
      "Epoch 8/100, Iteration 20/303, Loss: 0.19340091943740845\n",
      "Epoch 8/100, Iteration 21/303, Loss: 0.3228782117366791\n",
      "Epoch 8/100, Iteration 22/303, Loss: 0.20902076363563538\n",
      "Epoch 8/100, Iteration 23/303, Loss: 0.1392931044101715\n",
      "Epoch 8/100, Iteration 24/303, Loss: 0.2572211027145386\n",
      "Epoch 8/100, Iteration 25/303, Loss: 0.17146123945713043\n",
      "Epoch 8/100, Iteration 26/303, Loss: 0.452424019575119\n",
      "Epoch 8/100, Iteration 27/303, Loss: 0.2359948605298996\n",
      "Epoch 8/100, Iteration 28/303, Loss: 0.4411163926124573\n",
      "Epoch 8/100, Iteration 29/303, Loss: 0.3651932179927826\n",
      "Epoch 8/100, Iteration 30/303, Loss: 0.36010223627090454\n",
      "Epoch 8/100, Iteration 31/303, Loss: 0.1809266358613968\n",
      "Epoch 8/100, Iteration 32/303, Loss: 0.2809026837348938\n",
      "Epoch 8/100, Iteration 33/303, Loss: 0.28264015913009644\n",
      "Epoch 8/100, Iteration 34/303, Loss: 0.26967936754226685\n",
      "Epoch 8/100, Iteration 35/303, Loss: 0.35570451617240906\n",
      "Epoch 8/100, Iteration 36/303, Loss: 0.12816540896892548\n",
      "Epoch 8/100, Iteration 37/303, Loss: 0.363735556602478\n",
      "Epoch 8/100, Iteration 38/303, Loss: 0.36516937613487244\n",
      "Epoch 8/100, Iteration 39/303, Loss: 0.3224824368953705\n",
      "Epoch 8/100, Iteration 40/303, Loss: 0.26789212226867676\n",
      "Epoch 8/100, Iteration 41/303, Loss: 0.2491707056760788\n",
      "Epoch 8/100, Iteration 42/303, Loss: 0.6512067914009094\n",
      "Epoch 8/100, Iteration 43/303, Loss: 0.31348997354507446\n",
      "Epoch 8/100, Iteration 44/303, Loss: 0.31246495246887207\n",
      "Epoch 8/100, Iteration 45/303, Loss: 0.7623342275619507\n",
      "Epoch 8/100, Iteration 46/303, Loss: 0.4058871269226074\n",
      "Epoch 8/100, Iteration 47/303, Loss: 0.17488324642181396\n",
      "Epoch 8/100, Iteration 48/303, Loss: 0.26338693499565125\n",
      "Epoch 8/100, Iteration 49/303, Loss: 0.19608841836452484\n",
      "Epoch 8/100, Iteration 50/303, Loss: 0.32199904322624207\n",
      "Epoch 8/100, Iteration 51/303, Loss: 0.23052412271499634\n",
      "Epoch 8/100, Iteration 52/303, Loss: 0.24477124214172363\n",
      "Epoch 8/100, Iteration 53/303, Loss: 0.3086719214916229\n",
      "Epoch 8/100, Iteration 54/303, Loss: 0.341094046831131\n",
      "Epoch 8/100, Iteration 55/303, Loss: 0.25124332308769226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Iteration 56/303, Loss: 0.28935590386390686\n",
      "Epoch 8/100, Iteration 57/303, Loss: 0.27756381034851074\n",
      "Epoch 8/100, Iteration 58/303, Loss: 0.3399820327758789\n",
      "Epoch 8/100, Iteration 59/303, Loss: 0.5660662651062012\n",
      "Epoch 8/100, Iteration 60/303, Loss: 0.2292822152376175\n",
      "Epoch 8/100, Iteration 61/303, Loss: 0.4340226948261261\n",
      "Epoch 8/100, Iteration 62/303, Loss: 0.4448907971382141\n",
      "Epoch 8/100, Iteration 63/303, Loss: 0.2945774495601654\n",
      "Epoch 8/100, Iteration 64/303, Loss: 0.2516244053840637\n",
      "Epoch 8/100, Iteration 65/303, Loss: 0.35594427585601807\n",
      "Epoch 8/100, Iteration 66/303, Loss: 0.29290103912353516\n",
      "Epoch 8/100, Iteration 67/303, Loss: 0.25785353779792786\n",
      "Epoch 8/100, Iteration 68/303, Loss: 0.18647268414497375\n",
      "Epoch 8/100, Iteration 69/303, Loss: 0.19162194430828094\n",
      "Epoch 8/100, Iteration 70/303, Loss: 0.41836977005004883\n",
      "Epoch 8/100, Iteration 71/303, Loss: 0.2903064787387848\n",
      "Epoch 8/100, Iteration 72/303, Loss: 0.37558817863464355\n",
      "Epoch 8/100, Iteration 73/303, Loss: 0.35068100690841675\n",
      "Epoch 8/100, Iteration 74/303, Loss: 0.3144213557243347\n",
      "Epoch 8/100, Iteration 75/303, Loss: 0.4372890889644623\n",
      "Epoch 8/100, Iteration 76/303, Loss: 0.27214276790618896\n",
      "Epoch 8/100, Iteration 77/303, Loss: 0.24131013453006744\n",
      "Epoch 8/100, Iteration 78/303, Loss: 0.28058210015296936\n",
      "Epoch 8/100, Iteration 79/303, Loss: 0.3040432929992676\n",
      "Epoch 8/100, Iteration 80/303, Loss: 0.23840630054473877\n",
      "Epoch 8/100, Iteration 81/303, Loss: 0.4166693687438965\n",
      "Epoch 8/100, Iteration 82/303, Loss: 0.4923221468925476\n",
      "Epoch 8/100, Iteration 83/303, Loss: 0.3353275656700134\n",
      "Epoch 8/100, Iteration 84/303, Loss: 0.27945083379745483\n",
      "Epoch 8/100, Iteration 85/303, Loss: 0.4015349745750427\n",
      "Epoch 8/100, Iteration 86/303, Loss: 0.4519784450531006\n",
      "Epoch 8/100, Iteration 87/303, Loss: 0.3116077184677124\n",
      "Epoch 8/100, Iteration 88/303, Loss: 0.25948429107666016\n",
      "Epoch 8/100, Iteration 89/303, Loss: 0.3168882727622986\n",
      "Epoch 8/100, Iteration 90/303, Loss: 0.3954182267189026\n",
      "Epoch 8/100, Iteration 91/303, Loss: 0.3682123124599457\n",
      "Epoch 8/100, Iteration 92/303, Loss: 0.3103289306163788\n",
      "Epoch 8/100, Iteration 93/303, Loss: 0.24098052084445953\n",
      "Epoch 8/100, Iteration 94/303, Loss: 0.21274518966674805\n",
      "Epoch 8/100, Iteration 95/303, Loss: 0.18535664677619934\n",
      "Epoch 8/100, Iteration 96/303, Loss: 0.11488989740610123\n",
      "Epoch 8/100, Iteration 97/303, Loss: 0.16776499152183533\n",
      "Epoch 8/100, Iteration 98/303, Loss: 0.31732019782066345\n",
      "Epoch 8/100, Iteration 99/303, Loss: 0.2636956572532654\n",
      "Epoch 8/100, Iteration 100/303, Loss: 0.17914538085460663\n",
      "Epoch 8/100, Iteration 101/303, Loss: 0.2332116663455963\n",
      "Epoch 8/100, Iteration 102/303, Loss: 0.3164423108100891\n",
      "Epoch 8/100, Iteration 103/303, Loss: 0.27038663625717163\n",
      "Epoch 8/100, Iteration 104/303, Loss: 0.2544359266757965\n",
      "Epoch 8/100, Iteration 105/303, Loss: 0.22423869371414185\n",
      "Epoch 8/100, Iteration 106/303, Loss: 0.24605485796928406\n",
      "Epoch 8/100, Iteration 107/303, Loss: 0.20998044312000275\n",
      "Epoch 8/100, Iteration 108/303, Loss: 0.3296056389808655\n",
      "Epoch 8/100, Iteration 109/303, Loss: 0.18373699486255646\n",
      "Epoch 8/100, Iteration 110/303, Loss: 0.1348629891872406\n",
      "Epoch 8/100, Iteration 111/303, Loss: 0.5171530842781067\n",
      "Epoch 8/100, Iteration 112/303, Loss: 0.2077578902244568\n",
      "Epoch 8/100, Iteration 113/303, Loss: 0.31886228919029236\n",
      "Epoch 8/100, Iteration 114/303, Loss: 0.23850852251052856\n",
      "Epoch 8/100, Iteration 115/303, Loss: 0.3258081078529358\n",
      "Epoch 8/100, Iteration 116/303, Loss: 0.22656866908073425\n",
      "Epoch 8/100, Iteration 117/303, Loss: 0.2407108098268509\n",
      "Epoch 8/100, Iteration 118/303, Loss: 0.5379209518432617\n",
      "Epoch 8/100, Iteration 119/303, Loss: 0.3388136029243469\n",
      "Epoch 8/100, Iteration 120/303, Loss: 0.45161426067352295\n",
      "Epoch 8/100, Iteration 121/303, Loss: 0.36383676528930664\n",
      "Epoch 8/100, Iteration 122/303, Loss: 0.23821105062961578\n",
      "Epoch 8/100, Iteration 123/303, Loss: 0.5198265314102173\n",
      "Epoch 8/100, Iteration 124/303, Loss: 0.364831805229187\n",
      "Epoch 8/100, Iteration 125/303, Loss: 0.4167764484882355\n",
      "Epoch 8/100, Iteration 126/303, Loss: 0.13098619878292084\n",
      "Epoch 8/100, Iteration 127/303, Loss: 0.37320956587791443\n",
      "Epoch 8/100, Iteration 128/303, Loss: 0.3254210352897644\n",
      "Epoch 8/100, Iteration 129/303, Loss: 0.2651854455471039\n",
      "Epoch 8/100, Iteration 130/303, Loss: 0.20473060011863708\n",
      "Epoch 8/100, Iteration 131/303, Loss: 0.2728102505207062\n",
      "Epoch 8/100, Iteration 132/303, Loss: 0.4171947240829468\n",
      "Epoch 8/100, Iteration 133/303, Loss: 0.2273988276720047\n",
      "Epoch 8/100, Iteration 134/303, Loss: 0.526160478591919\n",
      "Epoch 8/100, Iteration 135/303, Loss: 0.5180632472038269\n",
      "Epoch 8/100, Iteration 136/303, Loss: 0.2568556070327759\n",
      "Epoch 8/100, Iteration 137/303, Loss: 0.27017825841903687\n",
      "Epoch 8/100, Iteration 138/303, Loss: 0.2142278403043747\n",
      "Epoch 8/100, Iteration 139/303, Loss: 0.4439217448234558\n",
      "Epoch 8/100, Iteration 140/303, Loss: 0.33718299865722656\n",
      "Epoch 8/100, Iteration 141/303, Loss: 0.3343663811683655\n",
      "Epoch 8/100, Iteration 142/303, Loss: 0.36913445591926575\n",
      "Epoch 8/100, Iteration 143/303, Loss: 0.2984991669654846\n",
      "Epoch 8/100, Iteration 144/303, Loss: 0.26467007398605347\n",
      "Epoch 8/100, Iteration 145/303, Loss: 0.14955945312976837\n",
      "Epoch 8/100, Iteration 146/303, Loss: 0.2978511154651642\n",
      "Epoch 8/100, Iteration 147/303, Loss: 0.14827749133110046\n",
      "Epoch 8/100, Iteration 148/303, Loss: 0.187893807888031\n",
      "Epoch 8/100, Iteration 149/303, Loss: 0.3020273745059967\n",
      "Epoch 8/100, Iteration 150/303, Loss: 0.17363959550857544\n",
      "Epoch 8/100, Iteration 151/303, Loss: 0.23647987842559814\n",
      "Epoch 8/100, Iteration 152/303, Loss: 0.5077887773513794\n",
      "Epoch 8/100, Iteration 153/303, Loss: 0.33319616317749023\n",
      "Epoch 8/100, Iteration 154/303, Loss: 0.210224449634552\n",
      "Epoch 8/100, Iteration 155/303, Loss: 0.22075402736663818\n",
      "Epoch 8/100, Iteration 156/303, Loss: 0.2714020609855652\n",
      "Epoch 8/100, Iteration 157/303, Loss: 0.20842881500720978\n",
      "Epoch 8/100, Iteration 158/303, Loss: 0.31089091300964355\n",
      "Epoch 8/100, Iteration 159/303, Loss: 0.45263612270355225\n",
      "Epoch 8/100, Iteration 160/303, Loss: 0.14635585248470306\n",
      "Epoch 8/100, Iteration 161/303, Loss: 0.15105070173740387\n",
      "Epoch 8/100, Iteration 162/303, Loss: 0.2290017008781433\n",
      "Epoch 8/100, Iteration 163/303, Loss: 0.4417649507522583\n",
      "Epoch 8/100, Iteration 164/303, Loss: 0.15662488341331482\n",
      "Epoch 8/100, Iteration 165/303, Loss: 0.19368362426757812\n",
      "Epoch 8/100, Iteration 166/303, Loss: 0.32951658964157104\n",
      "Epoch 8/100, Iteration 167/303, Loss: 0.27297165989875793\n",
      "Epoch 8/100, Iteration 168/303, Loss: 0.2589153051376343\n",
      "Epoch 8/100, Iteration 169/303, Loss: 0.3168100118637085\n",
      "Epoch 8/100, Iteration 170/303, Loss: 0.5119820237159729\n",
      "Epoch 8/100, Iteration 171/303, Loss: 0.28397002816200256\n",
      "Epoch 8/100, Iteration 172/303, Loss: 0.3179413676261902\n",
      "Epoch 8/100, Iteration 173/303, Loss: 0.314866840839386\n",
      "Epoch 8/100, Iteration 174/303, Loss: 0.21430185437202454\n",
      "Epoch 8/100, Iteration 175/303, Loss: 0.45132511854171753\n",
      "Epoch 8/100, Iteration 176/303, Loss: 0.2789102792739868\n",
      "Epoch 8/100, Iteration 177/303, Loss: 0.18590767681598663\n",
      "Epoch 8/100, Iteration 178/303, Loss: 0.1860586553812027\n",
      "Epoch 8/100, Iteration 179/303, Loss: 0.3474932312965393\n",
      "Epoch 8/100, Iteration 180/303, Loss: 0.2439243346452713\n",
      "Epoch 8/100, Iteration 181/303, Loss: 0.25759628415107727\n",
      "Epoch 8/100, Iteration 182/303, Loss: 0.31311309337615967\n",
      "Epoch 8/100, Iteration 183/303, Loss: 0.29827407002449036\n",
      "Epoch 8/100, Iteration 184/303, Loss: 0.41186782717704773\n",
      "Epoch 8/100, Iteration 185/303, Loss: 0.26935523748397827\n",
      "Epoch 8/100, Iteration 186/303, Loss: 0.3117626905441284\n",
      "Epoch 8/100, Iteration 187/303, Loss: 0.362310528755188\n",
      "Epoch 8/100, Iteration 188/303, Loss: 0.4697846472263336\n",
      "Epoch 8/100, Iteration 189/303, Loss: 0.23692700266838074\n",
      "Epoch 8/100, Iteration 190/303, Loss: 0.21004341542720795\n",
      "Epoch 8/100, Iteration 191/303, Loss: 0.289404958486557\n",
      "Epoch 8/100, Iteration 192/303, Loss: 0.36737027764320374\n",
      "Epoch 8/100, Iteration 193/303, Loss: 0.4044191241264343\n",
      "Epoch 8/100, Iteration 194/303, Loss: 0.2361874282360077\n",
      "Epoch 8/100, Iteration 195/303, Loss: 0.3067770004272461\n",
      "Epoch 8/100, Iteration 196/303, Loss: 0.1822090446949005\n",
      "Epoch 8/100, Iteration 197/303, Loss: 0.1827552318572998\n",
      "Epoch 8/100, Iteration 198/303, Loss: 0.4905763268470764\n",
      "Epoch 8/100, Iteration 199/303, Loss: 0.3990878164768219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Iteration 200/303, Loss: 0.2784959077835083\n",
      "Epoch 8/100, Iteration 201/303, Loss: 0.17678846418857574\n",
      "Epoch 8/100, Iteration 202/303, Loss: 0.2005428671836853\n",
      "Epoch 8/100, Iteration 203/303, Loss: 0.2623157799243927\n",
      "Epoch 8/100, Iteration 204/303, Loss: 0.2703816890716553\n",
      "Epoch 8/100, Iteration 205/303, Loss: 0.28665924072265625\n",
      "Epoch 8/100, Iteration 206/303, Loss: 0.1808892786502838\n",
      "Epoch 8/100, Iteration 207/303, Loss: 0.46501535177230835\n",
      "Epoch 8/100, Iteration 208/303, Loss: 0.12482251226902008\n",
      "Epoch 8/100, Iteration 209/303, Loss: 0.43163982033729553\n",
      "Epoch 8/100, Iteration 210/303, Loss: 0.19616509974002838\n",
      "Epoch 8/100, Iteration 211/303, Loss: 0.2789793014526367\n",
      "Epoch 8/100, Iteration 212/303, Loss: 0.1676137000322342\n",
      "Epoch 8/100, Iteration 213/303, Loss: 0.23210376501083374\n",
      "Epoch 8/100, Iteration 214/303, Loss: 0.4697216749191284\n",
      "Epoch 8/100, Iteration 215/303, Loss: 0.44470253586769104\n",
      "Epoch 8/100, Iteration 216/303, Loss: 0.33142316341400146\n",
      "Epoch 8/100, Iteration 217/303, Loss: 0.20094367861747742\n",
      "Epoch 8/100, Iteration 218/303, Loss: 0.3062508702278137\n",
      "Epoch 8/100, Iteration 219/303, Loss: 0.37618958950042725\n",
      "Epoch 8/100, Iteration 220/303, Loss: 0.22992970049381256\n",
      "Epoch 8/100, Iteration 221/303, Loss: 0.3255275785923004\n",
      "Epoch 8/100, Iteration 222/303, Loss: 0.2800458073616028\n",
      "Epoch 8/100, Iteration 223/303, Loss: 0.3147496283054352\n",
      "Epoch 8/100, Iteration 224/303, Loss: 0.3985598385334015\n",
      "Epoch 8/100, Iteration 225/303, Loss: 0.1787920892238617\n",
      "Epoch 8/100, Iteration 226/303, Loss: 0.16327016055583954\n",
      "Epoch 8/100, Iteration 227/303, Loss: 0.3512769341468811\n",
      "Epoch 8/100, Iteration 228/303, Loss: 0.17546966671943665\n",
      "Epoch 8/100, Iteration 229/303, Loss: 0.4735286831855774\n",
      "Epoch 8/100, Iteration 230/303, Loss: 0.2965724468231201\n",
      "Epoch 8/100, Iteration 231/303, Loss: 0.18273024260997772\n",
      "Epoch 8/100, Iteration 232/303, Loss: 0.36020204424858093\n",
      "Epoch 8/100, Iteration 233/303, Loss: 0.42278486490249634\n",
      "Epoch 8/100, Iteration 234/303, Loss: 0.3957468271255493\n",
      "Epoch 8/100, Iteration 235/303, Loss: 0.22034883499145508\n",
      "Epoch 8/100, Iteration 236/303, Loss: 0.37661948800086975\n",
      "Epoch 8/100, Iteration 237/303, Loss: 0.1631801575422287\n",
      "Epoch 8/100, Iteration 238/303, Loss: 0.18271256983280182\n",
      "Epoch 8/100, Iteration 239/303, Loss: 0.4498284161090851\n",
      "Epoch 8/100, Iteration 240/303, Loss: 0.17678296566009521\n",
      "Epoch 8/100, Iteration 241/303, Loss: 0.24549460411071777\n",
      "Epoch 8/100, Iteration 242/303, Loss: 0.3572796881198883\n",
      "Epoch 8/100, Iteration 243/303, Loss: 0.20628125965595245\n",
      "Epoch 8/100, Iteration 244/303, Loss: 0.24987941980361938\n",
      "Epoch 8/100, Iteration 245/303, Loss: 0.49217140674591064\n",
      "Epoch 8/100, Iteration 246/303, Loss: 0.35237592458724976\n",
      "Epoch 8/100, Iteration 247/303, Loss: 0.5116844177246094\n",
      "Epoch 8/100, Iteration 248/303, Loss: 0.1641334742307663\n",
      "Epoch 8/100, Iteration 249/303, Loss: 0.334389328956604\n",
      "Epoch 8/100, Iteration 250/303, Loss: 0.4281495213508606\n",
      "Epoch 8/100, Iteration 251/303, Loss: 0.35248130559921265\n",
      "Epoch 8/100, Iteration 252/303, Loss: 0.2871457636356354\n",
      "Epoch 8/100, Iteration 253/303, Loss: 0.35652413964271545\n",
      "Epoch 8/100, Iteration 254/303, Loss: 0.7314103841781616\n",
      "Epoch 8/100, Iteration 255/303, Loss: 0.42084914445877075\n",
      "Epoch 8/100, Iteration 256/303, Loss: 0.37796175479888916\n",
      "Epoch 8/100, Iteration 257/303, Loss: 0.2616249918937683\n",
      "Epoch 8/100, Iteration 258/303, Loss: 0.35552170872688293\n",
      "Epoch 8/100, Iteration 259/303, Loss: 0.34207573533058167\n",
      "Epoch 8/100, Iteration 260/303, Loss: 0.25862088799476624\n",
      "Epoch 8/100, Iteration 261/303, Loss: 0.17156046628952026\n",
      "Epoch 8/100, Iteration 262/303, Loss: 0.2439795583486557\n",
      "Epoch 8/100, Iteration 263/303, Loss: 0.25959235429763794\n",
      "Epoch 8/100, Iteration 264/303, Loss: 0.3737431466579437\n",
      "Epoch 8/100, Iteration 265/303, Loss: 0.2533722221851349\n",
      "Epoch 8/100, Iteration 266/303, Loss: 0.2921510338783264\n",
      "Epoch 8/100, Iteration 267/303, Loss: 0.3384897708892822\n",
      "Epoch 8/100, Iteration 268/303, Loss: 0.1769993007183075\n",
      "Epoch 8/100, Iteration 269/303, Loss: 0.26727765798568726\n",
      "Epoch 8/100, Iteration 270/303, Loss: 0.27182736992836\n",
      "Epoch 8/100, Iteration 271/303, Loss: 0.16774362325668335\n",
      "Epoch 8/100, Iteration 272/303, Loss: 0.1869315803050995\n",
      "Epoch 8/100, Iteration 273/303, Loss: 0.2202000617980957\n",
      "Epoch 8/100, Iteration 274/303, Loss: 0.2344113141298294\n",
      "Epoch 8/100, Iteration 275/303, Loss: 0.49736058712005615\n",
      "Epoch 8/100, Iteration 276/303, Loss: 0.1747768521308899\n",
      "Epoch 8/100, Iteration 277/303, Loss: 0.6155611276626587\n",
      "Epoch 8/100, Iteration 278/303, Loss: 0.4108053147792816\n",
      "Epoch 8/100, Iteration 279/303, Loss: 0.14553923904895782\n",
      "Epoch 8/100, Iteration 280/303, Loss: 0.1979711353778839\n",
      "Epoch 8/100, Iteration 281/303, Loss: 0.2600614130496979\n",
      "Epoch 8/100, Iteration 282/303, Loss: 0.5484945774078369\n",
      "Epoch 8/100, Iteration 283/303, Loss: 0.24373412132263184\n",
      "Epoch 8/100, Iteration 284/303, Loss: 0.2798251509666443\n",
      "Epoch 8/100, Iteration 285/303, Loss: 0.2803913950920105\n",
      "Epoch 8/100, Iteration 286/303, Loss: 0.2729140520095825\n",
      "Epoch 8/100, Iteration 287/303, Loss: 0.24148762226104736\n",
      "Epoch 8/100, Iteration 288/303, Loss: 0.4335955083370209\n",
      "Epoch 8/100, Iteration 289/303, Loss: 0.6776503324508667\n",
      "Epoch 8/100, Iteration 290/303, Loss: 0.23006783425807953\n",
      "Epoch 8/100, Iteration 291/303, Loss: 0.20887233316898346\n",
      "Epoch 8/100, Iteration 292/303, Loss: 0.24017180502414703\n",
      "Epoch 8/100, Iteration 293/303, Loss: 0.3269674777984619\n",
      "Epoch 8/100, Iteration 294/303, Loss: 0.3874930739402771\n",
      "Epoch 8/100, Iteration 295/303, Loss: 0.3516320288181305\n",
      "Epoch 8/100, Iteration 296/303, Loss: 0.34356099367141724\n",
      "Epoch 8/100, Iteration 297/303, Loss: 0.40009188652038574\n",
      "Epoch 8/100, Iteration 298/303, Loss: 0.24133583903312683\n",
      "Epoch 8/100, Iteration 299/303, Loss: 0.35258376598358154\n",
      "Epoch 8/100, Iteration 300/303, Loss: 0.300134539604187\n",
      "Epoch 8/100, Iteration 301/303, Loss: 0.30939289927482605\n",
      "Epoch 8/100, Iteration 302/303, Loss: 0.2985324561595917\n",
      "Epoch 8/100, Iteration 303/303, Loss: 0.32696259021759033\n",
      "Epoch 9/100, Iteration 1/303, Loss: 0.20667095482349396\n",
      "Epoch 9/100, Iteration 2/303, Loss: 0.2826823592185974\n",
      "Epoch 9/100, Iteration 3/303, Loss: 0.35612136125564575\n",
      "Epoch 9/100, Iteration 4/303, Loss: 0.2220418006181717\n",
      "Epoch 9/100, Iteration 5/303, Loss: 0.28912225365638733\n",
      "Epoch 9/100, Iteration 6/303, Loss: 0.2589462101459503\n",
      "Epoch 9/100, Iteration 7/303, Loss: 0.33918216824531555\n",
      "Epoch 9/100, Iteration 8/303, Loss: 0.49293264746665955\n",
      "Epoch 9/100, Iteration 9/303, Loss: 0.3703400194644928\n",
      "Epoch 9/100, Iteration 10/303, Loss: 0.2227996587753296\n",
      "Epoch 9/100, Iteration 11/303, Loss: 0.20781217515468597\n",
      "Epoch 9/100, Iteration 12/303, Loss: 0.22649791836738586\n",
      "Epoch 9/100, Iteration 13/303, Loss: 0.14357517659664154\n",
      "Epoch 9/100, Iteration 14/303, Loss: 0.40442758798599243\n",
      "Epoch 9/100, Iteration 15/303, Loss: 0.313965767621994\n",
      "Epoch 9/100, Iteration 16/303, Loss: 0.2080109715461731\n",
      "Epoch 9/100, Iteration 17/303, Loss: 0.1874789595603943\n",
      "Epoch 9/100, Iteration 18/303, Loss: 0.269060343503952\n",
      "Epoch 9/100, Iteration 19/303, Loss: 0.11625781655311584\n",
      "Epoch 9/100, Iteration 20/303, Loss: 0.25612351298332214\n",
      "Epoch 9/100, Iteration 21/303, Loss: 0.15403078496456146\n",
      "Epoch 9/100, Iteration 22/303, Loss: 0.23578542470932007\n",
      "Epoch 9/100, Iteration 23/303, Loss: 0.3119558095932007\n",
      "Epoch 9/100, Iteration 24/303, Loss: 0.2665039300918579\n",
      "Epoch 9/100, Iteration 25/303, Loss: 0.1792268007993698\n",
      "Epoch 9/100, Iteration 26/303, Loss: 0.2444736659526825\n",
      "Epoch 9/100, Iteration 27/303, Loss: 0.1621738225221634\n",
      "Epoch 9/100, Iteration 28/303, Loss: 0.19067969918251038\n",
      "Epoch 9/100, Iteration 29/303, Loss: 0.3683117628097534\n",
      "Epoch 9/100, Iteration 30/303, Loss: 0.12076020240783691\n",
      "Epoch 9/100, Iteration 31/303, Loss: 0.406697541475296\n",
      "Epoch 9/100, Iteration 32/303, Loss: 0.27384984493255615\n",
      "Epoch 9/100, Iteration 33/303, Loss: 0.27635541558265686\n",
      "Epoch 9/100, Iteration 34/303, Loss: 0.4971652626991272\n",
      "Epoch 9/100, Iteration 35/303, Loss: 0.2944658100605011\n",
      "Epoch 9/100, Iteration 36/303, Loss: 0.23802804946899414\n",
      "Epoch 9/100, Iteration 37/303, Loss: 0.46541959047317505\n",
      "Epoch 9/100, Iteration 38/303, Loss: 0.17342567443847656\n",
      "Epoch 9/100, Iteration 39/303, Loss: 0.20742307603359222\n",
      "Epoch 9/100, Iteration 40/303, Loss: 0.4136976897716522\n",
      "Epoch 9/100, Iteration 41/303, Loss: 0.16201893985271454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Iteration 42/303, Loss: 0.14726975560188293\n",
      "Epoch 9/100, Iteration 43/303, Loss: 0.2406192272901535\n",
      "Epoch 9/100, Iteration 44/303, Loss: 0.5944820046424866\n",
      "Epoch 9/100, Iteration 45/303, Loss: 0.3127453923225403\n",
      "Epoch 9/100, Iteration 46/303, Loss: 0.20476597547531128\n",
      "Epoch 9/100, Iteration 47/303, Loss: 0.20402196049690247\n",
      "Epoch 9/100, Iteration 48/303, Loss: 0.2538444697856903\n",
      "Epoch 9/100, Iteration 49/303, Loss: 0.3371761441230774\n",
      "Epoch 9/100, Iteration 50/303, Loss: 0.3123800456523895\n",
      "Epoch 9/100, Iteration 51/303, Loss: 0.14316071569919586\n",
      "Epoch 9/100, Iteration 52/303, Loss: 0.20527859032154083\n",
      "Epoch 9/100, Iteration 53/303, Loss: 0.23703010380268097\n",
      "Epoch 9/100, Iteration 54/303, Loss: 0.17370173335075378\n",
      "Epoch 9/100, Iteration 55/303, Loss: 0.3151203989982605\n",
      "Epoch 9/100, Iteration 56/303, Loss: 0.366852730512619\n",
      "Epoch 9/100, Iteration 57/303, Loss: 0.17323964834213257\n",
      "Epoch 9/100, Iteration 58/303, Loss: 0.23532871901988983\n",
      "Epoch 9/100, Iteration 59/303, Loss: 0.2463013380765915\n",
      "Epoch 9/100, Iteration 60/303, Loss: 0.42566075921058655\n",
      "Epoch 9/100, Iteration 61/303, Loss: 0.3536916971206665\n",
      "Epoch 9/100, Iteration 62/303, Loss: 0.40638428926467896\n",
      "Epoch 9/100, Iteration 63/303, Loss: 0.33529308438301086\n",
      "Epoch 9/100, Iteration 64/303, Loss: 0.20242153108119965\n",
      "Epoch 9/100, Iteration 65/303, Loss: 0.27654752135276794\n",
      "Epoch 9/100, Iteration 66/303, Loss: 0.17858128249645233\n",
      "Epoch 9/100, Iteration 67/303, Loss: 0.19969113171100616\n",
      "Epoch 9/100, Iteration 68/303, Loss: 0.2621689438819885\n",
      "Epoch 9/100, Iteration 69/303, Loss: 0.2650807201862335\n",
      "Epoch 9/100, Iteration 70/303, Loss: 0.24530936777591705\n",
      "Epoch 9/100, Iteration 71/303, Loss: 0.16590693593025208\n",
      "Epoch 9/100, Iteration 72/303, Loss: 0.19143855571746826\n",
      "Epoch 9/100, Iteration 73/303, Loss: 0.17132459580898285\n",
      "Epoch 9/100, Iteration 74/303, Loss: 0.31491729617118835\n",
      "Epoch 9/100, Iteration 75/303, Loss: 0.35151317715644836\n",
      "Epoch 9/100, Iteration 76/303, Loss: 0.19857628643512726\n",
      "Epoch 9/100, Iteration 77/303, Loss: 0.25838014483451843\n",
      "Epoch 9/100, Iteration 78/303, Loss: 0.2972424030303955\n",
      "Epoch 9/100, Iteration 79/303, Loss: 0.47885626554489136\n",
      "Epoch 9/100, Iteration 80/303, Loss: 0.3139817714691162\n",
      "Epoch 9/100, Iteration 81/303, Loss: 0.28612789511680603\n",
      "Epoch 9/100, Iteration 82/303, Loss: 0.14483600854873657\n",
      "Epoch 9/100, Iteration 83/303, Loss: 0.19834372401237488\n",
      "Epoch 9/100, Iteration 84/303, Loss: 0.3449033498764038\n",
      "Epoch 9/100, Iteration 85/303, Loss: 0.5002267360687256\n",
      "Epoch 9/100, Iteration 86/303, Loss: 0.17625702917575836\n",
      "Epoch 9/100, Iteration 87/303, Loss: 0.17555592954158783\n",
      "Epoch 9/100, Iteration 88/303, Loss: 0.33905625343322754\n",
      "Epoch 9/100, Iteration 89/303, Loss: 0.3389486074447632\n",
      "Epoch 9/100, Iteration 90/303, Loss: 0.3199222981929779\n",
      "Epoch 9/100, Iteration 91/303, Loss: 0.14519894123077393\n",
      "Epoch 9/100, Iteration 92/303, Loss: 0.29139572381973267\n",
      "Epoch 9/100, Iteration 93/303, Loss: 0.24903017282485962\n",
      "Epoch 9/100, Iteration 94/303, Loss: 0.252871036529541\n",
      "Epoch 9/100, Iteration 95/303, Loss: 0.24268192052841187\n",
      "Epoch 9/100, Iteration 96/303, Loss: 0.06538019329309464\n",
      "Epoch 9/100, Iteration 97/303, Loss: 0.258035808801651\n",
      "Epoch 9/100, Iteration 98/303, Loss: 0.24784047901630402\n",
      "Epoch 9/100, Iteration 99/303, Loss: 0.26855921745300293\n",
      "Epoch 9/100, Iteration 100/303, Loss: 0.16331875324249268\n",
      "Epoch 9/100, Iteration 101/303, Loss: 0.22227375209331512\n",
      "Epoch 9/100, Iteration 102/303, Loss: 0.23163075745105743\n",
      "Epoch 9/100, Iteration 103/303, Loss: 0.23864887654781342\n",
      "Epoch 9/100, Iteration 104/303, Loss: 0.3250424861907959\n",
      "Epoch 9/100, Iteration 105/303, Loss: 0.2692626118659973\n",
      "Epoch 9/100, Iteration 106/303, Loss: 0.25205275416374207\n",
      "Epoch 9/100, Iteration 107/303, Loss: 0.4801238775253296\n",
      "Epoch 9/100, Iteration 108/303, Loss: 0.21435818076133728\n",
      "Epoch 9/100, Iteration 109/303, Loss: 0.21458977460861206\n",
      "Epoch 9/100, Iteration 110/303, Loss: 0.23584167659282684\n",
      "Epoch 9/100, Iteration 111/303, Loss: 0.46620750427246094\n",
      "Epoch 9/100, Iteration 112/303, Loss: 0.39878469705581665\n",
      "Epoch 9/100, Iteration 113/303, Loss: 0.39220404624938965\n",
      "Epoch 9/100, Iteration 114/303, Loss: 0.4304639995098114\n",
      "Epoch 9/100, Iteration 115/303, Loss: 0.266506552696228\n",
      "Epoch 9/100, Iteration 116/303, Loss: 0.2358725368976593\n",
      "Epoch 9/100, Iteration 117/303, Loss: 0.16772708296775818\n",
      "Epoch 9/100, Iteration 118/303, Loss: 0.3517545759677887\n",
      "Epoch 9/100, Iteration 119/303, Loss: 0.2066918909549713\n",
      "Epoch 9/100, Iteration 120/303, Loss: 0.31360921263694763\n",
      "Epoch 9/100, Iteration 121/303, Loss: 0.19235265254974365\n",
      "Epoch 9/100, Iteration 122/303, Loss: 0.24858972430229187\n",
      "Epoch 9/100, Iteration 123/303, Loss: 0.29652518033981323\n",
      "Epoch 9/100, Iteration 124/303, Loss: 0.48711130023002625\n",
      "Epoch 9/100, Iteration 125/303, Loss: 0.24764783680438995\n",
      "Epoch 9/100, Iteration 126/303, Loss: 0.4368447959423065\n",
      "Epoch 9/100, Iteration 127/303, Loss: 0.3502492308616638\n",
      "Epoch 9/100, Iteration 128/303, Loss: 0.33552980422973633\n",
      "Epoch 9/100, Iteration 129/303, Loss: 0.29182976484298706\n",
      "Epoch 9/100, Iteration 130/303, Loss: 0.22630296647548676\n",
      "Epoch 9/100, Iteration 131/303, Loss: 0.20393946766853333\n",
      "Epoch 9/100, Iteration 132/303, Loss: 0.24899134039878845\n",
      "Epoch 9/100, Iteration 133/303, Loss: 0.5900804996490479\n",
      "Epoch 9/100, Iteration 134/303, Loss: 0.45534077286720276\n",
      "Epoch 9/100, Iteration 135/303, Loss: 0.17412622272968292\n",
      "Epoch 9/100, Iteration 136/303, Loss: 0.18747195601463318\n",
      "Epoch 9/100, Iteration 137/303, Loss: 0.1511351466178894\n",
      "Epoch 9/100, Iteration 138/303, Loss: 0.4295696020126343\n",
      "Epoch 9/100, Iteration 139/303, Loss: 0.25279584527015686\n",
      "Epoch 9/100, Iteration 140/303, Loss: 0.2053961157798767\n",
      "Epoch 9/100, Iteration 141/303, Loss: 0.1808873862028122\n",
      "Epoch 9/100, Iteration 142/303, Loss: 0.16718971729278564\n",
      "Epoch 9/100, Iteration 143/303, Loss: 0.18986305594444275\n",
      "Epoch 9/100, Iteration 144/303, Loss: 0.247582346200943\n",
      "Epoch 9/100, Iteration 145/303, Loss: 0.29423248767852783\n",
      "Epoch 9/100, Iteration 146/303, Loss: 0.32516998052597046\n",
      "Epoch 9/100, Iteration 147/303, Loss: 0.2920163571834564\n",
      "Epoch 9/100, Iteration 148/303, Loss: 0.4906732738018036\n",
      "Epoch 9/100, Iteration 149/303, Loss: 0.19705256819725037\n",
      "Epoch 9/100, Iteration 150/303, Loss: 0.17045345902442932\n",
      "Epoch 9/100, Iteration 151/303, Loss: 0.17837432026863098\n",
      "Epoch 9/100, Iteration 152/303, Loss: 0.15106667578220367\n",
      "Epoch 9/100, Iteration 153/303, Loss: 0.4290594458580017\n",
      "Epoch 9/100, Iteration 154/303, Loss: 0.34872737526893616\n",
      "Epoch 9/100, Iteration 155/303, Loss: 0.3232421278953552\n",
      "Epoch 9/100, Iteration 156/303, Loss: 0.3123771548271179\n",
      "Epoch 9/100, Iteration 157/303, Loss: 0.46186739206314087\n",
      "Epoch 9/100, Iteration 158/303, Loss: 0.3003115952014923\n",
      "Epoch 9/100, Iteration 159/303, Loss: 0.3226156234741211\n",
      "Epoch 9/100, Iteration 160/303, Loss: 0.3311452865600586\n",
      "Epoch 9/100, Iteration 161/303, Loss: 0.3658097982406616\n",
      "Epoch 9/100, Iteration 162/303, Loss: 0.3418627679347992\n",
      "Epoch 9/100, Iteration 163/303, Loss: 0.17134599387645721\n",
      "Epoch 9/100, Iteration 164/303, Loss: 0.3427949547767639\n",
      "Epoch 9/100, Iteration 165/303, Loss: 0.22394897043704987\n",
      "Epoch 9/100, Iteration 166/303, Loss: 0.341701865196228\n",
      "Epoch 9/100, Iteration 167/303, Loss: 0.17012310028076172\n",
      "Epoch 9/100, Iteration 168/303, Loss: 0.20041689276695251\n",
      "Epoch 9/100, Iteration 169/303, Loss: 0.22803950309753418\n",
      "Epoch 9/100, Iteration 170/303, Loss: 0.3143448829650879\n",
      "Epoch 9/100, Iteration 171/303, Loss: 0.20090675354003906\n",
      "Epoch 9/100, Iteration 172/303, Loss: 0.31669533252716064\n",
      "Epoch 9/100, Iteration 173/303, Loss: 0.2904839515686035\n",
      "Epoch 9/100, Iteration 174/303, Loss: 0.2718520760536194\n",
      "Epoch 9/100, Iteration 175/303, Loss: 0.2972210943698883\n",
      "Epoch 9/100, Iteration 176/303, Loss: 0.16066397726535797\n",
      "Epoch 9/100, Iteration 177/303, Loss: 0.2799808084964752\n",
      "Epoch 9/100, Iteration 178/303, Loss: 0.2563798427581787\n",
      "Epoch 9/100, Iteration 179/303, Loss: 0.27540117502212524\n",
      "Epoch 9/100, Iteration 180/303, Loss: 0.3920130729675293\n",
      "Epoch 9/100, Iteration 181/303, Loss: 0.16433537006378174\n",
      "Epoch 9/100, Iteration 182/303, Loss: 0.342497318983078\n",
      "Epoch 9/100, Iteration 183/303, Loss: 0.3448833227157593\n",
      "Epoch 9/100, Iteration 184/303, Loss: 0.16359467804431915\n",
      "Epoch 9/100, Iteration 185/303, Loss: 0.28520724177360535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Iteration 186/303, Loss: 0.3085290491580963\n",
      "Epoch 9/100, Iteration 187/303, Loss: 0.17704130709171295\n",
      "Epoch 9/100, Iteration 188/303, Loss: 0.07877790927886963\n",
      "Epoch 9/100, Iteration 189/303, Loss: 0.2856239676475525\n",
      "Epoch 9/100, Iteration 190/303, Loss: 0.2668469548225403\n",
      "Epoch 9/100, Iteration 191/303, Loss: 0.28787118196487427\n",
      "Epoch 9/100, Iteration 192/303, Loss: 0.1357324719429016\n",
      "Epoch 9/100, Iteration 193/303, Loss: 0.3225660026073456\n",
      "Epoch 9/100, Iteration 194/303, Loss: 0.2985858619213104\n",
      "Epoch 9/100, Iteration 195/303, Loss: 0.25257211923599243\n",
      "Epoch 9/100, Iteration 196/303, Loss: 0.4352225065231323\n",
      "Epoch 9/100, Iteration 197/303, Loss: 0.3378274440765381\n",
      "Epoch 9/100, Iteration 198/303, Loss: 0.43947333097457886\n",
      "Epoch 9/100, Iteration 199/303, Loss: 0.35279226303100586\n",
      "Epoch 9/100, Iteration 200/303, Loss: 0.08756353706121445\n",
      "Epoch 9/100, Iteration 201/303, Loss: 0.2037692666053772\n",
      "Epoch 9/100, Iteration 202/303, Loss: 0.2012515664100647\n",
      "Epoch 9/100, Iteration 203/303, Loss: 0.396252304315567\n",
      "Epoch 9/100, Iteration 204/303, Loss: 0.26036790013313293\n",
      "Epoch 9/100, Iteration 205/303, Loss: 0.17603133618831635\n",
      "Epoch 9/100, Iteration 206/303, Loss: 0.4219941198825836\n",
      "Epoch 9/100, Iteration 207/303, Loss: 0.3350866436958313\n",
      "Epoch 9/100, Iteration 208/303, Loss: 0.1098991185426712\n",
      "Epoch 9/100, Iteration 209/303, Loss: 0.24573568999767303\n",
      "Epoch 9/100, Iteration 210/303, Loss: 0.339623361825943\n",
      "Epoch 9/100, Iteration 211/303, Loss: 0.14118821918964386\n",
      "Epoch 9/100, Iteration 212/303, Loss: 0.25468534231185913\n",
      "Epoch 9/100, Iteration 213/303, Loss: 0.2654429078102112\n",
      "Epoch 9/100, Iteration 214/303, Loss: 0.3001205325126648\n",
      "Epoch 9/100, Iteration 215/303, Loss: 0.26880693435668945\n",
      "Epoch 9/100, Iteration 216/303, Loss: 0.31558117270469666\n",
      "Epoch 9/100, Iteration 217/303, Loss: 0.4562649130821228\n",
      "Epoch 9/100, Iteration 218/303, Loss: 0.25168466567993164\n",
      "Epoch 9/100, Iteration 219/303, Loss: 0.3459080457687378\n",
      "Epoch 9/100, Iteration 220/303, Loss: 0.1921764761209488\n",
      "Epoch 9/100, Iteration 221/303, Loss: 0.2094009816646576\n",
      "Epoch 9/100, Iteration 222/303, Loss: 0.38319551944732666\n",
      "Epoch 9/100, Iteration 223/303, Loss: 0.2384897917509079\n",
      "Epoch 9/100, Iteration 224/303, Loss: 0.225350022315979\n",
      "Epoch 9/100, Iteration 225/303, Loss: 0.14790260791778564\n",
      "Epoch 9/100, Iteration 226/303, Loss: 0.30206233263015747\n",
      "Epoch 9/100, Iteration 227/303, Loss: 0.5047794580459595\n",
      "Epoch 9/100, Iteration 228/303, Loss: 0.2250906229019165\n",
      "Epoch 9/100, Iteration 229/303, Loss: 0.27548378705978394\n",
      "Epoch 9/100, Iteration 230/303, Loss: 0.2841007113456726\n",
      "Epoch 9/100, Iteration 231/303, Loss: 0.3185533583164215\n",
      "Epoch 9/100, Iteration 232/303, Loss: 0.15679247677326202\n",
      "Epoch 9/100, Iteration 233/303, Loss: 0.14043763279914856\n",
      "Epoch 9/100, Iteration 234/303, Loss: 0.3124030530452728\n",
      "Epoch 9/100, Iteration 235/303, Loss: 0.2798745334148407\n",
      "Epoch 9/100, Iteration 236/303, Loss: 0.20892111957073212\n",
      "Epoch 9/100, Iteration 237/303, Loss: 0.2861311137676239\n",
      "Epoch 9/100, Iteration 238/303, Loss: 0.1910402476787567\n",
      "Epoch 9/100, Iteration 239/303, Loss: 0.28657957911491394\n",
      "Epoch 9/100, Iteration 240/303, Loss: 0.35008567571640015\n",
      "Epoch 9/100, Iteration 241/303, Loss: 0.5379423499107361\n",
      "Epoch 9/100, Iteration 242/303, Loss: 0.24886703491210938\n",
      "Epoch 9/100, Iteration 243/303, Loss: 0.1410880833864212\n",
      "Epoch 9/100, Iteration 244/303, Loss: 0.4000670909881592\n",
      "Epoch 9/100, Iteration 245/303, Loss: 0.2503510117530823\n",
      "Epoch 9/100, Iteration 246/303, Loss: 0.33477580547332764\n",
      "Epoch 9/100, Iteration 247/303, Loss: 0.2127232402563095\n",
      "Epoch 9/100, Iteration 248/303, Loss: 0.22117584943771362\n",
      "Epoch 9/100, Iteration 249/303, Loss: 0.3684830069541931\n",
      "Epoch 9/100, Iteration 250/303, Loss: 0.2499687522649765\n",
      "Epoch 9/100, Iteration 251/303, Loss: 0.1585363894701004\n",
      "Epoch 9/100, Iteration 252/303, Loss: 0.19402579963207245\n",
      "Epoch 9/100, Iteration 253/303, Loss: 0.30306944251060486\n",
      "Epoch 9/100, Iteration 254/303, Loss: 0.2828540802001953\n",
      "Epoch 9/100, Iteration 255/303, Loss: 0.16989392042160034\n",
      "Epoch 9/100, Iteration 256/303, Loss: 0.2404799461364746\n",
      "Epoch 9/100, Iteration 257/303, Loss: 0.3262447714805603\n",
      "Epoch 9/100, Iteration 258/303, Loss: 0.27910807728767395\n",
      "Epoch 9/100, Iteration 259/303, Loss: 0.2106594294309616\n",
      "Epoch 9/100, Iteration 260/303, Loss: 0.34618139266967773\n",
      "Epoch 9/100, Iteration 261/303, Loss: 0.31554538011550903\n",
      "Epoch 9/100, Iteration 262/303, Loss: 0.2681218087673187\n",
      "Epoch 9/100, Iteration 263/303, Loss: 0.3807750940322876\n",
      "Epoch 9/100, Iteration 264/303, Loss: 0.3705126941204071\n",
      "Epoch 9/100, Iteration 265/303, Loss: 0.4088059067726135\n",
      "Epoch 9/100, Iteration 266/303, Loss: 0.322954922914505\n",
      "Epoch 9/100, Iteration 267/303, Loss: 0.24856463074684143\n",
      "Epoch 9/100, Iteration 268/303, Loss: 0.31908661127090454\n",
      "Epoch 9/100, Iteration 269/303, Loss: 0.1830568164587021\n",
      "Epoch 9/100, Iteration 270/303, Loss: 0.12849725782871246\n",
      "Epoch 9/100, Iteration 271/303, Loss: 0.16454148292541504\n",
      "Epoch 9/100, Iteration 272/303, Loss: 0.5483465194702148\n",
      "Epoch 9/100, Iteration 273/303, Loss: 0.2273118942975998\n",
      "Epoch 9/100, Iteration 274/303, Loss: 0.2107277810573578\n",
      "Epoch 9/100, Iteration 275/303, Loss: 0.32494860887527466\n",
      "Epoch 9/100, Iteration 276/303, Loss: 0.07981903851032257\n",
      "Epoch 9/100, Iteration 277/303, Loss: 0.30617594718933105\n",
      "Epoch 9/100, Iteration 278/303, Loss: 0.21662358939647675\n",
      "Epoch 9/100, Iteration 279/303, Loss: 0.35845866799354553\n",
      "Epoch 9/100, Iteration 280/303, Loss: 0.35185760259628296\n",
      "Epoch 9/100, Iteration 281/303, Loss: 0.21644848585128784\n",
      "Epoch 9/100, Iteration 282/303, Loss: 0.16091474890708923\n",
      "Epoch 9/100, Iteration 283/303, Loss: 0.3272276818752289\n",
      "Epoch 9/100, Iteration 284/303, Loss: 0.19692721962928772\n",
      "Epoch 9/100, Iteration 285/303, Loss: 0.3317624628543854\n",
      "Epoch 9/100, Iteration 286/303, Loss: 0.2690579295158386\n",
      "Epoch 9/100, Iteration 287/303, Loss: 0.17669877409934998\n",
      "Epoch 9/100, Iteration 288/303, Loss: 0.3113846182823181\n",
      "Epoch 9/100, Iteration 289/303, Loss: 0.25259897112846375\n",
      "Epoch 9/100, Iteration 290/303, Loss: 0.2941206991672516\n",
      "Epoch 9/100, Iteration 291/303, Loss: 0.46040332317352295\n",
      "Epoch 9/100, Iteration 292/303, Loss: 0.19784888625144958\n",
      "Epoch 9/100, Iteration 293/303, Loss: 0.29196131229400635\n",
      "Epoch 9/100, Iteration 294/303, Loss: 0.1543046236038208\n",
      "Epoch 9/100, Iteration 295/303, Loss: 0.3694484829902649\n",
      "Epoch 9/100, Iteration 296/303, Loss: 0.38652947545051575\n",
      "Epoch 9/100, Iteration 297/303, Loss: 0.10880622267723083\n",
      "Epoch 9/100, Iteration 298/303, Loss: 0.44939011335372925\n",
      "Epoch 9/100, Iteration 299/303, Loss: 0.33541518449783325\n",
      "Epoch 9/100, Iteration 300/303, Loss: 0.32554733753204346\n",
      "Epoch 9/100, Iteration 301/303, Loss: 0.3344363272190094\n",
      "Epoch 9/100, Iteration 302/303, Loss: 0.22627495229244232\n",
      "Epoch 9/100, Iteration 303/303, Loss: 0.20570741593837738\n",
      "Epoch 10/100, Iteration 1/303, Loss: 0.28265881538391113\n",
      "Epoch 10/100, Iteration 2/303, Loss: 0.17941057682037354\n",
      "Epoch 10/100, Iteration 3/303, Loss: 0.28063973784446716\n",
      "Epoch 10/100, Iteration 4/303, Loss: 0.28660595417022705\n",
      "Epoch 10/100, Iteration 5/303, Loss: 0.12730522453784943\n",
      "Epoch 10/100, Iteration 6/303, Loss: 0.2549017071723938\n",
      "Epoch 10/100, Iteration 7/303, Loss: 0.18519404530525208\n",
      "Epoch 10/100, Iteration 8/303, Loss: 0.1444503664970398\n",
      "Epoch 10/100, Iteration 9/303, Loss: 0.047480110079050064\n",
      "Epoch 10/100, Iteration 10/303, Loss: 0.5615471601486206\n",
      "Epoch 10/100, Iteration 11/303, Loss: 0.40074121952056885\n",
      "Epoch 10/100, Iteration 12/303, Loss: 0.2363811880350113\n",
      "Epoch 10/100, Iteration 13/303, Loss: 0.1544908732175827\n",
      "Epoch 10/100, Iteration 14/303, Loss: 0.2778116464614868\n",
      "Epoch 10/100, Iteration 15/303, Loss: 0.21074500679969788\n",
      "Epoch 10/100, Iteration 16/303, Loss: 0.1063913106918335\n",
      "Epoch 10/100, Iteration 17/303, Loss: 0.09411591291427612\n",
      "Epoch 10/100, Iteration 18/303, Loss: 0.18161937594413757\n",
      "Epoch 10/100, Iteration 19/303, Loss: 0.10377249121665955\n",
      "Epoch 10/100, Iteration 20/303, Loss: 0.28092870116233826\n",
      "Epoch 10/100, Iteration 21/303, Loss: 0.17387786507606506\n",
      "Epoch 10/100, Iteration 22/303, Loss: 0.09392766654491425\n",
      "Epoch 10/100, Iteration 23/303, Loss: 0.12622876465320587\n",
      "Epoch 10/100, Iteration 24/303, Loss: 0.14343595504760742\n",
      "Epoch 10/100, Iteration 25/303, Loss: 0.262406587600708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Iteration 26/303, Loss: 0.2276173233985901\n",
      "Epoch 10/100, Iteration 27/303, Loss: 0.18167829513549805\n",
      "Epoch 10/100, Iteration 28/303, Loss: 0.07579445093870163\n",
      "Epoch 10/100, Iteration 29/303, Loss: 0.19993174076080322\n",
      "Epoch 10/100, Iteration 30/303, Loss: 0.32839083671569824\n",
      "Epoch 10/100, Iteration 31/303, Loss: 0.22464847564697266\n",
      "Epoch 10/100, Iteration 32/303, Loss: 0.12038737535476685\n",
      "Epoch 10/100, Iteration 33/303, Loss: 0.22659143805503845\n",
      "Epoch 10/100, Iteration 34/303, Loss: 0.19662880897521973\n",
      "Epoch 10/100, Iteration 35/303, Loss: 0.4122430682182312\n",
      "Epoch 10/100, Iteration 36/303, Loss: 0.5001237988471985\n",
      "Epoch 10/100, Iteration 37/303, Loss: 0.39687758684158325\n",
      "Epoch 10/100, Iteration 38/303, Loss: 0.2301076203584671\n",
      "Epoch 10/100, Iteration 39/303, Loss: 0.14924800395965576\n",
      "Epoch 10/100, Iteration 40/303, Loss: 0.2981572449207306\n",
      "Epoch 10/100, Iteration 41/303, Loss: 0.17385762929916382\n",
      "Epoch 10/100, Iteration 42/303, Loss: 0.21318475902080536\n",
      "Epoch 10/100, Iteration 43/303, Loss: 0.2932744324207306\n",
      "Epoch 10/100, Iteration 44/303, Loss: 0.11241061985492706\n",
      "Epoch 10/100, Iteration 45/303, Loss: 0.20104533433914185\n",
      "Epoch 10/100, Iteration 46/303, Loss: 0.17046871781349182\n",
      "Epoch 10/100, Iteration 47/303, Loss: 0.07782629877328873\n",
      "Epoch 10/100, Iteration 48/303, Loss: 0.2902672290802002\n",
      "Epoch 10/100, Iteration 49/303, Loss: 0.20148997008800507\n",
      "Epoch 10/100, Iteration 50/303, Loss: 0.17532294988632202\n",
      "Epoch 10/100, Iteration 51/303, Loss: 0.23358215391635895\n",
      "Epoch 10/100, Iteration 52/303, Loss: 0.24431489408016205\n",
      "Epoch 10/100, Iteration 53/303, Loss: 0.22697080671787262\n",
      "Epoch 10/100, Iteration 54/303, Loss: 0.2926101088523865\n",
      "Epoch 10/100, Iteration 55/303, Loss: 0.20058435201644897\n",
      "Epoch 10/100, Iteration 56/303, Loss: 0.304177463054657\n",
      "Epoch 10/100, Iteration 57/303, Loss: 0.45966455340385437\n",
      "Epoch 10/100, Iteration 58/303, Loss: 0.26027020812034607\n",
      "Epoch 10/100, Iteration 59/303, Loss: 0.22101624310016632\n",
      "Epoch 10/100, Iteration 60/303, Loss: 0.2204764187335968\n",
      "Epoch 10/100, Iteration 61/303, Loss: 0.17062810063362122\n",
      "Epoch 10/100, Iteration 62/303, Loss: 0.14885643124580383\n",
      "Epoch 10/100, Iteration 63/303, Loss: 0.16700321435928345\n",
      "Epoch 10/100, Iteration 64/303, Loss: 0.20710121095180511\n",
      "Epoch 10/100, Iteration 65/303, Loss: 0.09378835558891296\n",
      "Epoch 10/100, Iteration 66/303, Loss: 0.2195398360490799\n",
      "Epoch 10/100, Iteration 67/303, Loss: 0.2815802991390228\n",
      "Epoch 10/100, Iteration 68/303, Loss: 0.419845312833786\n",
      "Epoch 10/100, Iteration 69/303, Loss: 0.4573858082294464\n",
      "Epoch 10/100, Iteration 70/303, Loss: 0.26354578137397766\n",
      "Epoch 10/100, Iteration 71/303, Loss: 0.22690145671367645\n",
      "Epoch 10/100, Iteration 72/303, Loss: 0.2649611830711365\n",
      "Epoch 10/100, Iteration 73/303, Loss: 0.08994901925325394\n",
      "Epoch 10/100, Iteration 74/303, Loss: 0.15409058332443237\n",
      "Epoch 10/100, Iteration 75/303, Loss: 0.24175645411014557\n",
      "Epoch 10/100, Iteration 76/303, Loss: 0.10886682569980621\n",
      "Epoch 10/100, Iteration 77/303, Loss: 0.1451960951089859\n",
      "Epoch 10/100, Iteration 78/303, Loss: 0.32190582156181335\n",
      "Epoch 10/100, Iteration 79/303, Loss: 0.3012794852256775\n",
      "Epoch 10/100, Iteration 80/303, Loss: 0.24281297624111176\n",
      "Epoch 10/100, Iteration 81/303, Loss: 0.2102140486240387\n",
      "Epoch 10/100, Iteration 82/303, Loss: 0.12148918956518173\n",
      "Epoch 10/100, Iteration 83/303, Loss: 0.1432756781578064\n",
      "Epoch 10/100, Iteration 84/303, Loss: 0.47071337699890137\n",
      "Epoch 10/100, Iteration 85/303, Loss: 0.17171736061573029\n",
      "Epoch 10/100, Iteration 86/303, Loss: 0.5650798678398132\n",
      "Epoch 10/100, Iteration 87/303, Loss: 0.15865111351013184\n",
      "Epoch 10/100, Iteration 88/303, Loss: 0.08576039969921112\n",
      "Epoch 10/100, Iteration 89/303, Loss: 0.20605364441871643\n",
      "Epoch 10/100, Iteration 90/303, Loss: 0.19629524648189545\n",
      "Epoch 10/100, Iteration 91/303, Loss: 0.23911955952644348\n",
      "Epoch 10/100, Iteration 92/303, Loss: 0.14143948256969452\n",
      "Epoch 10/100, Iteration 93/303, Loss: 0.15256884694099426\n",
      "Epoch 10/100, Iteration 94/303, Loss: 0.1731114387512207\n",
      "Epoch 10/100, Iteration 95/303, Loss: 0.28361523151397705\n",
      "Epoch 10/100, Iteration 96/303, Loss: 0.1114037036895752\n",
      "Epoch 10/100, Iteration 97/303, Loss: 0.1773378700017929\n",
      "Epoch 10/100, Iteration 98/303, Loss: 0.22994376718997955\n",
      "Epoch 10/100, Iteration 99/303, Loss: 0.2395617663860321\n",
      "Epoch 10/100, Iteration 100/303, Loss: 0.19994813203811646\n",
      "Epoch 10/100, Iteration 101/303, Loss: 0.37907785177230835\n",
      "Epoch 10/100, Iteration 102/303, Loss: 0.17983755469322205\n",
      "Epoch 10/100, Iteration 103/303, Loss: 0.3443247675895691\n",
      "Epoch 10/100, Iteration 104/303, Loss: 0.2857430875301361\n",
      "Epoch 10/100, Iteration 105/303, Loss: 0.18985339999198914\n",
      "Epoch 10/100, Iteration 106/303, Loss: 0.1146809533238411\n",
      "Epoch 10/100, Iteration 107/303, Loss: 0.10455568879842758\n",
      "Epoch 10/100, Iteration 108/303, Loss: 0.17506374418735504\n",
      "Epoch 10/100, Iteration 109/303, Loss: 0.19137750566005707\n",
      "Epoch 10/100, Iteration 110/303, Loss: 0.5063928365707397\n",
      "Epoch 10/100, Iteration 111/303, Loss: 0.25929009914398193\n",
      "Epoch 10/100, Iteration 112/303, Loss: 0.3462679982185364\n",
      "Epoch 10/100, Iteration 113/303, Loss: 0.20964981615543365\n",
      "Epoch 10/100, Iteration 114/303, Loss: 0.3833194971084595\n",
      "Epoch 10/100, Iteration 115/303, Loss: 0.544899046421051\n",
      "Epoch 10/100, Iteration 116/303, Loss: 0.37703025341033936\n",
      "Epoch 10/100, Iteration 117/303, Loss: 0.31962186098098755\n",
      "Epoch 10/100, Iteration 118/303, Loss: 0.27977192401885986\n",
      "Epoch 10/100, Iteration 119/303, Loss: 0.35125216841697693\n",
      "Epoch 10/100, Iteration 120/303, Loss: 0.14079883694648743\n",
      "Epoch 10/100, Iteration 121/303, Loss: 0.30980750918388367\n",
      "Epoch 10/100, Iteration 122/303, Loss: 0.3433707356452942\n",
      "Epoch 10/100, Iteration 123/303, Loss: 0.3592831790447235\n",
      "Epoch 10/100, Iteration 124/303, Loss: 0.20017486810684204\n",
      "Epoch 10/100, Iteration 125/303, Loss: 0.11899999529123306\n",
      "Epoch 10/100, Iteration 126/303, Loss: 0.1733260452747345\n",
      "Epoch 10/100, Iteration 127/303, Loss: 0.25141820311546326\n",
      "Epoch 10/100, Iteration 128/303, Loss: 0.05816654860973358\n",
      "Epoch 10/100, Iteration 129/303, Loss: 0.13425661623477936\n",
      "Epoch 10/100, Iteration 130/303, Loss: 0.3197840452194214\n",
      "Epoch 10/100, Iteration 131/303, Loss: 0.3059946894645691\n",
      "Epoch 10/100, Iteration 132/303, Loss: 0.26453328132629395\n",
      "Epoch 10/100, Iteration 133/303, Loss: 0.1199062243103981\n",
      "Epoch 10/100, Iteration 134/303, Loss: 0.19181188941001892\n",
      "Epoch 10/100, Iteration 135/303, Loss: 0.24907240271568298\n",
      "Epoch 10/100, Iteration 136/303, Loss: 0.25836312770843506\n",
      "Epoch 10/100, Iteration 137/303, Loss: 0.1676960438489914\n",
      "Epoch 10/100, Iteration 138/303, Loss: 0.28528285026550293\n",
      "Epoch 10/100, Iteration 139/303, Loss: 0.26691538095474243\n",
      "Epoch 10/100, Iteration 140/303, Loss: 0.1343250274658203\n",
      "Epoch 10/100, Iteration 141/303, Loss: 0.2509155869483948\n",
      "Epoch 10/100, Iteration 142/303, Loss: 0.2986708879470825\n",
      "Epoch 10/100, Iteration 143/303, Loss: 0.3347228169441223\n",
      "Epoch 10/100, Iteration 144/303, Loss: 0.2143600881099701\n",
      "Epoch 10/100, Iteration 145/303, Loss: 0.6116941571235657\n",
      "Epoch 10/100, Iteration 146/303, Loss: 0.1919892579317093\n",
      "Epoch 10/100, Iteration 147/303, Loss: 0.1271306276321411\n",
      "Epoch 10/100, Iteration 148/303, Loss: 0.11900705844163895\n",
      "Epoch 10/100, Iteration 149/303, Loss: 0.25756463408470154\n",
      "Epoch 10/100, Iteration 150/303, Loss: 0.22460465133190155\n",
      "Epoch 10/100, Iteration 151/303, Loss: 0.1786978393793106\n",
      "Epoch 10/100, Iteration 152/303, Loss: 0.28754687309265137\n",
      "Epoch 10/100, Iteration 153/303, Loss: 0.33510667085647583\n",
      "Epoch 10/100, Iteration 154/303, Loss: 0.30544573068618774\n",
      "Epoch 10/100, Iteration 155/303, Loss: 0.2783008813858032\n",
      "Epoch 10/100, Iteration 156/303, Loss: 0.23360377550125122\n",
      "Epoch 10/100, Iteration 157/303, Loss: 0.05068166181445122\n",
      "Epoch 10/100, Iteration 158/303, Loss: 0.22184212505817413\n",
      "Epoch 10/100, Iteration 159/303, Loss: 0.206350177526474\n",
      "Epoch 10/100, Iteration 160/303, Loss: 0.1614665687084198\n",
      "Epoch 10/100, Iteration 161/303, Loss: 0.16846054792404175\n",
      "Epoch 10/100, Iteration 162/303, Loss: 0.18545418977737427\n",
      "Epoch 10/100, Iteration 163/303, Loss: 0.3078416883945465\n",
      "Epoch 10/100, Iteration 164/303, Loss: 0.28562477231025696\n",
      "Epoch 10/100, Iteration 165/303, Loss: 0.3104338049888611\n",
      "Epoch 10/100, Iteration 166/303, Loss: 0.32360729575157166\n",
      "Epoch 10/100, Iteration 167/303, Loss: 0.25811976194381714\n",
      "Epoch 10/100, Iteration 168/303, Loss: 0.20359429717063904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Iteration 169/303, Loss: 0.36798781156539917\n",
      "Epoch 10/100, Iteration 170/303, Loss: 0.1877036690711975\n",
      "Epoch 10/100, Iteration 171/303, Loss: 0.18133756518363953\n",
      "Epoch 10/100, Iteration 172/303, Loss: 0.1874372661113739\n",
      "Epoch 10/100, Iteration 173/303, Loss: 0.2299380600452423\n",
      "Epoch 10/100, Iteration 174/303, Loss: 0.08729883283376694\n",
      "Epoch 10/100, Iteration 175/303, Loss: 0.318970263004303\n",
      "Epoch 10/100, Iteration 176/303, Loss: 0.19055640697479248\n",
      "Epoch 10/100, Iteration 177/303, Loss: 0.22881342470645905\n",
      "Epoch 10/100, Iteration 178/303, Loss: 0.2810472548007965\n",
      "Epoch 10/100, Iteration 179/303, Loss: 0.18048138916492462\n",
      "Epoch 10/100, Iteration 180/303, Loss: 0.2290312647819519\n",
      "Epoch 10/100, Iteration 181/303, Loss: 0.09448277205228806\n",
      "Epoch 10/100, Iteration 182/303, Loss: 0.277959942817688\n",
      "Epoch 10/100, Iteration 183/303, Loss: 0.17016983032226562\n",
      "Epoch 10/100, Iteration 184/303, Loss: 0.2015252560377121\n",
      "Epoch 10/100, Iteration 185/303, Loss: 0.2073054015636444\n",
      "Epoch 10/100, Iteration 186/303, Loss: 0.21717539429664612\n",
      "Epoch 10/100, Iteration 187/303, Loss: 0.2361920326948166\n",
      "Epoch 10/100, Iteration 188/303, Loss: 0.24662643671035767\n",
      "Epoch 10/100, Iteration 189/303, Loss: 0.15814350545406342\n",
      "Epoch 10/100, Iteration 190/303, Loss: 0.20835837721824646\n",
      "Epoch 10/100, Iteration 191/303, Loss: 0.21248118579387665\n",
      "Epoch 10/100, Iteration 192/303, Loss: 0.2197209894657135\n",
      "Epoch 10/100, Iteration 193/303, Loss: 0.3887842297554016\n",
      "Epoch 10/100, Iteration 194/303, Loss: 0.2057436853647232\n",
      "Epoch 10/100, Iteration 195/303, Loss: 0.24300989508628845\n",
      "Epoch 10/100, Iteration 196/303, Loss: 0.269715815782547\n",
      "Epoch 10/100, Iteration 197/303, Loss: 0.12396197021007538\n",
      "Epoch 10/100, Iteration 198/303, Loss: 0.16264863312244415\n",
      "Epoch 10/100, Iteration 199/303, Loss: 0.2511986196041107\n",
      "Epoch 10/100, Iteration 200/303, Loss: 0.2148667722940445\n",
      "Epoch 10/100, Iteration 201/303, Loss: 0.21528254449367523\n",
      "Epoch 10/100, Iteration 202/303, Loss: 0.3145703375339508\n",
      "Epoch 10/100, Iteration 203/303, Loss: 0.14646799862384796\n",
      "Epoch 10/100, Iteration 204/303, Loss: 0.22337764501571655\n",
      "Epoch 10/100, Iteration 205/303, Loss: 0.17652755975723267\n",
      "Epoch 10/100, Iteration 206/303, Loss: 0.1872919201850891\n",
      "Epoch 10/100, Iteration 207/303, Loss: 0.2710350751876831\n",
      "Epoch 10/100, Iteration 208/303, Loss: 0.1506759226322174\n",
      "Epoch 10/100, Iteration 209/303, Loss: 0.13234540820121765\n",
      "Epoch 10/100, Iteration 210/303, Loss: 0.19415678083896637\n",
      "Epoch 10/100, Iteration 211/303, Loss: 0.4215318262577057\n",
      "Epoch 10/100, Iteration 212/303, Loss: 0.10578390210866928\n",
      "Epoch 10/100, Iteration 213/303, Loss: 0.12537643313407898\n",
      "Epoch 10/100, Iteration 214/303, Loss: 0.17896167933940887\n",
      "Epoch 10/100, Iteration 215/303, Loss: 0.4900035262107849\n",
      "Epoch 10/100, Iteration 216/303, Loss: 0.41841480135917664\n",
      "Epoch 10/100, Iteration 217/303, Loss: 0.12030334025621414\n",
      "Epoch 10/100, Iteration 218/303, Loss: 0.18230187892913818\n",
      "Epoch 10/100, Iteration 219/303, Loss: 0.23948217928409576\n",
      "Epoch 10/100, Iteration 220/303, Loss: 0.39973145723342896\n",
      "Epoch 10/100, Iteration 221/303, Loss: 0.1642305701971054\n",
      "Epoch 10/100, Iteration 222/303, Loss: 0.24983181059360504\n",
      "Epoch 10/100, Iteration 223/303, Loss: 0.11161810904741287\n",
      "Epoch 10/100, Iteration 224/303, Loss: 0.27797266840934753\n",
      "Epoch 10/100, Iteration 225/303, Loss: 0.2703063488006592\n",
      "Epoch 10/100, Iteration 226/303, Loss: 0.16116219758987427\n",
      "Epoch 10/100, Iteration 227/303, Loss: 0.23531746864318848\n",
      "Epoch 10/100, Iteration 228/303, Loss: 0.17480891942977905\n",
      "Epoch 10/100, Iteration 229/303, Loss: 0.13195766508579254\n",
      "Epoch 10/100, Iteration 230/303, Loss: 0.10105147957801819\n",
      "Epoch 10/100, Iteration 231/303, Loss: 0.21939674019813538\n",
      "Epoch 10/100, Iteration 232/303, Loss: 0.14181306958198547\n",
      "Epoch 10/100, Iteration 233/303, Loss: 0.19360516965389252\n",
      "Epoch 10/100, Iteration 234/303, Loss: 0.41290709376335144\n",
      "Epoch 10/100, Iteration 235/303, Loss: 0.09809774905443192\n",
      "Epoch 10/100, Iteration 236/303, Loss: 0.13070766627788544\n",
      "Epoch 10/100, Iteration 237/303, Loss: 0.24463796615600586\n",
      "Epoch 10/100, Iteration 238/303, Loss: 0.1727711409330368\n",
      "Epoch 10/100, Iteration 239/303, Loss: 0.2907326817512512\n",
      "Epoch 10/100, Iteration 240/303, Loss: 0.4103025496006012\n",
      "Epoch 10/100, Iteration 241/303, Loss: 0.45116472244262695\n",
      "Epoch 10/100, Iteration 242/303, Loss: 0.33532610535621643\n",
      "Epoch 10/100, Iteration 243/303, Loss: 0.32986336946487427\n",
      "Epoch 10/100, Iteration 244/303, Loss: 0.46618184447288513\n",
      "Epoch 10/100, Iteration 245/303, Loss: 0.41574543714523315\n",
      "Epoch 10/100, Iteration 246/303, Loss: 0.21666330099105835\n",
      "Epoch 10/100, Iteration 247/303, Loss: 0.3533934950828552\n",
      "Epoch 10/100, Iteration 248/303, Loss: 0.22092583775520325\n",
      "Epoch 10/100, Iteration 249/303, Loss: 0.22284705936908722\n",
      "Epoch 10/100, Iteration 250/303, Loss: 0.17652666568756104\n",
      "Epoch 10/100, Iteration 251/303, Loss: 0.2326618731021881\n",
      "Epoch 10/100, Iteration 252/303, Loss: 0.1897469013929367\n",
      "Epoch 10/100, Iteration 253/303, Loss: 0.28379735350608826\n",
      "Epoch 10/100, Iteration 254/303, Loss: 0.26188382506370544\n",
      "Epoch 10/100, Iteration 255/303, Loss: 0.23185521364212036\n",
      "Epoch 10/100, Iteration 256/303, Loss: 0.29542282223701477\n",
      "Epoch 10/100, Iteration 257/303, Loss: 0.20438842475414276\n",
      "Epoch 10/100, Iteration 258/303, Loss: 0.2135588675737381\n",
      "Epoch 10/100, Iteration 259/303, Loss: 0.4182981848716736\n",
      "Epoch 10/100, Iteration 260/303, Loss: 0.33635058999061584\n",
      "Epoch 10/100, Iteration 261/303, Loss: 0.3006656765937805\n",
      "Epoch 10/100, Iteration 262/303, Loss: 0.2597677409648895\n",
      "Epoch 10/100, Iteration 263/303, Loss: 0.25984475016593933\n",
      "Epoch 10/100, Iteration 264/303, Loss: 0.2086142897605896\n",
      "Epoch 10/100, Iteration 265/303, Loss: 0.18910925090312958\n",
      "Epoch 10/100, Iteration 266/303, Loss: 0.29607897996902466\n",
      "Epoch 10/100, Iteration 267/303, Loss: 0.3286362290382385\n",
      "Epoch 10/100, Iteration 268/303, Loss: 0.23075547814369202\n",
      "Epoch 10/100, Iteration 269/303, Loss: 0.16036655008792877\n",
      "Epoch 10/100, Iteration 270/303, Loss: 0.26146048307418823\n",
      "Epoch 10/100, Iteration 271/303, Loss: 0.26258766651153564\n",
      "Epoch 10/100, Iteration 272/303, Loss: 0.24747887253761292\n",
      "Epoch 10/100, Iteration 273/303, Loss: 0.13116805255413055\n",
      "Epoch 10/100, Iteration 274/303, Loss: 0.12087082862854004\n",
      "Epoch 10/100, Iteration 275/303, Loss: 0.5663363933563232\n",
      "Epoch 10/100, Iteration 276/303, Loss: 0.3248284161090851\n",
      "Epoch 10/100, Iteration 277/303, Loss: 0.3572787940502167\n",
      "Epoch 10/100, Iteration 278/303, Loss: 0.5368186831474304\n",
      "Epoch 10/100, Iteration 279/303, Loss: 0.21476803719997406\n",
      "Epoch 10/100, Iteration 280/303, Loss: 0.18257443606853485\n",
      "Epoch 10/100, Iteration 281/303, Loss: 0.23300135135650635\n",
      "Epoch 10/100, Iteration 282/303, Loss: 0.5186499953269958\n",
      "Epoch 10/100, Iteration 283/303, Loss: 0.11860867589712143\n",
      "Epoch 10/100, Iteration 284/303, Loss: 0.1981865018606186\n",
      "Epoch 10/100, Iteration 285/303, Loss: 0.3286517858505249\n",
      "Epoch 10/100, Iteration 286/303, Loss: 0.2037370502948761\n",
      "Epoch 10/100, Iteration 287/303, Loss: 0.26622462272644043\n",
      "Epoch 10/100, Iteration 288/303, Loss: 0.40462175011634827\n",
      "Epoch 10/100, Iteration 289/303, Loss: 0.25684210658073425\n",
      "Epoch 10/100, Iteration 290/303, Loss: 0.17067864537239075\n",
      "Epoch 10/100, Iteration 291/303, Loss: 0.2587084472179413\n",
      "Epoch 10/100, Iteration 292/303, Loss: 0.2542382478713989\n",
      "Epoch 10/100, Iteration 293/303, Loss: 0.18332476913928986\n",
      "Epoch 10/100, Iteration 294/303, Loss: 0.14142517745494843\n",
      "Epoch 10/100, Iteration 295/303, Loss: 0.28419798612594604\n",
      "Epoch 10/100, Iteration 296/303, Loss: 0.3113323748111725\n",
      "Epoch 10/100, Iteration 297/303, Loss: 0.1642976999282837\n",
      "Epoch 10/100, Iteration 298/303, Loss: 0.1977396458387375\n",
      "Epoch 10/100, Iteration 299/303, Loss: 0.2696530818939209\n",
      "Epoch 10/100, Iteration 300/303, Loss: 0.2287876307964325\n",
      "Epoch 10/100, Iteration 301/303, Loss: 0.3046468198299408\n",
      "Epoch 10/100, Iteration 302/303, Loss: 0.2664681375026703\n",
      "Epoch 10/100, Iteration 303/303, Loss: 0.16629987955093384\n",
      "Epoch 11/100, Iteration 1/303, Loss: 0.04225410148501396\n",
      "Epoch 11/100, Iteration 2/303, Loss: 0.17187586426734924\n",
      "Epoch 11/100, Iteration 3/303, Loss: 0.22497743368148804\n",
      "Epoch 11/100, Iteration 4/303, Loss: 0.1990819126367569\n",
      "Epoch 11/100, Iteration 5/303, Loss: 0.16333714127540588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Iteration 6/303, Loss: 0.22140109539031982\n",
      "Epoch 11/100, Iteration 7/303, Loss: 0.2879282236099243\n",
      "Epoch 11/100, Iteration 8/303, Loss: 0.15615589916706085\n",
      "Epoch 11/100, Iteration 9/303, Loss: 0.23597539961338043\n",
      "Epoch 11/100, Iteration 10/303, Loss: 0.28805476427078247\n",
      "Epoch 11/100, Iteration 11/303, Loss: 0.22732645273208618\n",
      "Epoch 11/100, Iteration 12/303, Loss: 0.19970904290676117\n",
      "Epoch 11/100, Iteration 13/303, Loss: 0.13242913782596588\n",
      "Epoch 11/100, Iteration 14/303, Loss: 0.1019364446401596\n",
      "Epoch 11/100, Iteration 15/303, Loss: 0.12482032179832458\n",
      "Epoch 11/100, Iteration 16/303, Loss: 0.10570037364959717\n",
      "Epoch 11/100, Iteration 17/303, Loss: 0.18280580639839172\n",
      "Epoch 11/100, Iteration 18/303, Loss: 0.13541525602340698\n",
      "Epoch 11/100, Iteration 19/303, Loss: 0.36599865555763245\n",
      "Epoch 11/100, Iteration 20/303, Loss: 0.15537956357002258\n",
      "Epoch 11/100, Iteration 21/303, Loss: 0.1674119532108307\n",
      "Epoch 11/100, Iteration 22/303, Loss: 0.18846383690834045\n",
      "Epoch 11/100, Iteration 23/303, Loss: 0.2606230676174164\n",
      "Epoch 11/100, Iteration 24/303, Loss: 0.11678551882505417\n",
      "Epoch 11/100, Iteration 25/303, Loss: 0.2562078833580017\n",
      "Epoch 11/100, Iteration 26/303, Loss: 0.13175612688064575\n",
      "Epoch 11/100, Iteration 27/303, Loss: 0.2502009868621826\n",
      "Epoch 11/100, Iteration 28/303, Loss: 0.0931323915719986\n",
      "Epoch 11/100, Iteration 29/303, Loss: 0.24829289317131042\n",
      "Epoch 11/100, Iteration 30/303, Loss: 0.1888193041086197\n",
      "Epoch 11/100, Iteration 31/303, Loss: 0.2614412307739258\n",
      "Epoch 11/100, Iteration 32/303, Loss: 0.13265396654605865\n",
      "Epoch 11/100, Iteration 33/303, Loss: 0.15653476119041443\n",
      "Epoch 11/100, Iteration 34/303, Loss: 0.08368327468633652\n",
      "Epoch 11/100, Iteration 35/303, Loss: 0.18385878205299377\n",
      "Epoch 11/100, Iteration 36/303, Loss: 0.13521572947502136\n",
      "Epoch 11/100, Iteration 37/303, Loss: 0.1254536360502243\n",
      "Epoch 11/100, Iteration 38/303, Loss: 0.2300368845462799\n",
      "Epoch 11/100, Iteration 39/303, Loss: 0.21707554161548615\n",
      "Epoch 11/100, Iteration 40/303, Loss: 0.2442535161972046\n",
      "Epoch 11/100, Iteration 41/303, Loss: 0.0852530300617218\n",
      "Epoch 11/100, Iteration 42/303, Loss: 0.04314727708697319\n",
      "Epoch 11/100, Iteration 43/303, Loss: 0.13653689622879028\n",
      "Epoch 11/100, Iteration 44/303, Loss: 0.17957723140716553\n",
      "Epoch 11/100, Iteration 45/303, Loss: 0.20666107535362244\n",
      "Epoch 11/100, Iteration 46/303, Loss: 0.12150260806083679\n",
      "Epoch 11/100, Iteration 47/303, Loss: 0.11304879933595657\n",
      "Epoch 11/100, Iteration 48/303, Loss: 0.161702960729599\n",
      "Epoch 11/100, Iteration 49/303, Loss: 0.1715492606163025\n",
      "Epoch 11/100, Iteration 50/303, Loss: 0.09235820919275284\n",
      "Epoch 11/100, Iteration 51/303, Loss: 0.15648692846298218\n",
      "Epoch 11/100, Iteration 52/303, Loss: 0.15682357549667358\n",
      "Epoch 11/100, Iteration 53/303, Loss: 0.07638756930828094\n",
      "Epoch 11/100, Iteration 54/303, Loss: 0.0883045420050621\n",
      "Epoch 11/100, Iteration 55/303, Loss: 0.5281801819801331\n",
      "Epoch 11/100, Iteration 56/303, Loss: 0.10151086002588272\n",
      "Epoch 11/100, Iteration 57/303, Loss: 0.26575756072998047\n",
      "Epoch 11/100, Iteration 58/303, Loss: 0.4413469135761261\n",
      "Epoch 11/100, Iteration 59/303, Loss: 0.1971638798713684\n",
      "Epoch 11/100, Iteration 60/303, Loss: 0.37499040365219116\n",
      "Epoch 11/100, Iteration 61/303, Loss: 0.16095900535583496\n",
      "Epoch 11/100, Iteration 62/303, Loss: 0.19723737239837646\n",
      "Epoch 11/100, Iteration 63/303, Loss: 0.43073731660842896\n",
      "Epoch 11/100, Iteration 64/303, Loss: 0.28615087270736694\n",
      "Epoch 11/100, Iteration 65/303, Loss: 0.32952889800071716\n",
      "Epoch 11/100, Iteration 66/303, Loss: 0.10705345124006271\n",
      "Epoch 11/100, Iteration 67/303, Loss: 0.2647973299026489\n",
      "Epoch 11/100, Iteration 68/303, Loss: 0.27009162306785583\n",
      "Epoch 11/100, Iteration 69/303, Loss: 0.17093360424041748\n",
      "Epoch 11/100, Iteration 70/303, Loss: 0.17117415368556976\n",
      "Epoch 11/100, Iteration 71/303, Loss: 0.11917880177497864\n",
      "Epoch 11/100, Iteration 72/303, Loss: 0.16555264592170715\n",
      "Epoch 11/100, Iteration 73/303, Loss: 0.37193337082862854\n",
      "Epoch 11/100, Iteration 74/303, Loss: 0.07884662598371506\n",
      "Epoch 11/100, Iteration 75/303, Loss: 0.3082406520843506\n",
      "Epoch 11/100, Iteration 76/303, Loss: 0.20204117894172668\n",
      "Epoch 11/100, Iteration 77/303, Loss: 0.2514295279979706\n",
      "Epoch 11/100, Iteration 78/303, Loss: 0.24793843924999237\n",
      "Epoch 11/100, Iteration 79/303, Loss: 0.32867345213890076\n",
      "Epoch 11/100, Iteration 80/303, Loss: 0.1487296223640442\n",
      "Epoch 11/100, Iteration 81/303, Loss: 0.1207946240901947\n",
      "Epoch 11/100, Iteration 82/303, Loss: 0.110813669860363\n",
      "Epoch 11/100, Iteration 83/303, Loss: 0.23279969394207\n",
      "Epoch 11/100, Iteration 84/303, Loss: 0.08983024954795837\n",
      "Epoch 11/100, Iteration 85/303, Loss: 0.3444199860095978\n",
      "Epoch 11/100, Iteration 86/303, Loss: 0.11092495173215866\n",
      "Epoch 11/100, Iteration 87/303, Loss: 0.20848383009433746\n",
      "Epoch 11/100, Iteration 88/303, Loss: 0.12053576111793518\n",
      "Epoch 11/100, Iteration 89/303, Loss: 0.35149693489074707\n",
      "Epoch 11/100, Iteration 90/303, Loss: 0.1039891242980957\n",
      "Epoch 11/100, Iteration 91/303, Loss: 0.06572382152080536\n",
      "Epoch 11/100, Iteration 92/303, Loss: 0.23956553637981415\n",
      "Epoch 11/100, Iteration 93/303, Loss: 0.19735722243785858\n",
      "Epoch 11/100, Iteration 94/303, Loss: 0.22055315971374512\n",
      "Epoch 11/100, Iteration 95/303, Loss: 0.14858874678611755\n",
      "Epoch 11/100, Iteration 96/303, Loss: 0.1421080082654953\n",
      "Epoch 11/100, Iteration 97/303, Loss: 0.13295702636241913\n",
      "Epoch 11/100, Iteration 98/303, Loss: 0.22902809083461761\n",
      "Epoch 11/100, Iteration 99/303, Loss: 0.181865856051445\n",
      "Epoch 11/100, Iteration 100/303, Loss: 0.16926968097686768\n",
      "Epoch 11/100, Iteration 101/303, Loss: 0.08776998519897461\n",
      "Epoch 11/100, Iteration 102/303, Loss: 0.14040839672088623\n",
      "Epoch 11/100, Iteration 103/303, Loss: 0.3999382555484772\n",
      "Epoch 11/100, Iteration 104/303, Loss: 0.388091117143631\n",
      "Epoch 11/100, Iteration 105/303, Loss: 0.2180919349193573\n",
      "Epoch 11/100, Iteration 106/303, Loss: 0.2418341040611267\n",
      "Epoch 11/100, Iteration 107/303, Loss: 0.4649764895439148\n",
      "Epoch 11/100, Iteration 108/303, Loss: 0.2703690528869629\n",
      "Epoch 11/100, Iteration 109/303, Loss: 0.18955260515213013\n",
      "Epoch 11/100, Iteration 110/303, Loss: 0.07919047027826309\n",
      "Epoch 11/100, Iteration 111/303, Loss: 0.1867137849330902\n",
      "Epoch 11/100, Iteration 112/303, Loss: 0.21924778819084167\n",
      "Epoch 11/100, Iteration 113/303, Loss: 0.2356865406036377\n",
      "Epoch 11/100, Iteration 114/303, Loss: 0.14267611503601074\n",
      "Epoch 11/100, Iteration 115/303, Loss: 0.23255082964897156\n",
      "Epoch 11/100, Iteration 116/303, Loss: 0.21639405190944672\n",
      "Epoch 11/100, Iteration 117/303, Loss: 0.20169976353645325\n",
      "Epoch 11/100, Iteration 118/303, Loss: 0.2414727658033371\n",
      "Epoch 11/100, Iteration 119/303, Loss: 0.19989584386348724\n",
      "Epoch 11/100, Iteration 120/303, Loss: 0.2069866955280304\n",
      "Epoch 11/100, Iteration 121/303, Loss: 0.13107557594776154\n",
      "Epoch 11/100, Iteration 122/303, Loss: 0.11141733080148697\n",
      "Epoch 11/100, Iteration 123/303, Loss: 0.15083760023117065\n",
      "Epoch 11/100, Iteration 124/303, Loss: 0.08527697622776031\n",
      "Epoch 11/100, Iteration 125/303, Loss: 0.3532601296901703\n",
      "Epoch 11/100, Iteration 126/303, Loss: 0.2159300148487091\n",
      "Epoch 11/100, Iteration 127/303, Loss: 0.07717645913362503\n",
      "Epoch 11/100, Iteration 128/303, Loss: 0.21869783103466034\n",
      "Epoch 11/100, Iteration 129/303, Loss: 0.27195701003074646\n",
      "Epoch 11/100, Iteration 130/303, Loss: 0.3194691836833954\n",
      "Epoch 11/100, Iteration 131/303, Loss: 0.13723887503147125\n",
      "Epoch 11/100, Iteration 132/303, Loss: 0.1902875006198883\n",
      "Epoch 11/100, Iteration 133/303, Loss: 0.1966528594493866\n",
      "Epoch 11/100, Iteration 134/303, Loss: 0.2850833833217621\n",
      "Epoch 11/100, Iteration 135/303, Loss: 0.1039581298828125\n",
      "Epoch 11/100, Iteration 136/303, Loss: 0.12171689420938492\n",
      "Epoch 11/100, Iteration 137/303, Loss: 0.15766188502311707\n",
      "Epoch 11/100, Iteration 138/303, Loss: 0.1198243573307991\n",
      "Epoch 11/100, Iteration 139/303, Loss: 0.23871049284934998\n",
      "Epoch 11/100, Iteration 140/303, Loss: 0.11253724247217178\n",
      "Epoch 11/100, Iteration 141/303, Loss: 0.22798548638820648\n",
      "Epoch 11/100, Iteration 142/303, Loss: 0.2431207001209259\n",
      "Epoch 11/100, Iteration 143/303, Loss: 0.11266463249921799\n",
      "Epoch 11/100, Iteration 144/303, Loss: 0.30832138657569885\n",
      "Epoch 11/100, Iteration 145/303, Loss: 0.4068656861782074\n",
      "Epoch 11/100, Iteration 146/303, Loss: 0.0653061792254448\n",
      "Epoch 11/100, Iteration 147/303, Loss: 0.15406391024589539\n",
      "Epoch 11/100, Iteration 148/303, Loss: 0.4573410451412201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Iteration 149/303, Loss: 0.07590623944997787\n",
      "Epoch 11/100, Iteration 150/303, Loss: 0.29193899035453796\n",
      "Epoch 11/100, Iteration 151/303, Loss: 0.17119960486888885\n",
      "Epoch 11/100, Iteration 152/303, Loss: 0.19380676746368408\n",
      "Epoch 11/100, Iteration 153/303, Loss: 0.15241380035877228\n",
      "Epoch 11/100, Iteration 154/303, Loss: 0.2287188023328781\n",
      "Epoch 11/100, Iteration 155/303, Loss: 0.1319923847913742\n",
      "Epoch 11/100, Iteration 156/303, Loss: 0.1581232249736786\n",
      "Epoch 11/100, Iteration 157/303, Loss: 0.14121763408184052\n",
      "Epoch 11/100, Iteration 158/303, Loss: 0.24414797127246857\n",
      "Epoch 11/100, Iteration 159/303, Loss: 0.2061225026845932\n",
      "Epoch 11/100, Iteration 160/303, Loss: 0.2063131183385849\n",
      "Epoch 11/100, Iteration 161/303, Loss: 0.210857093334198\n",
      "Epoch 11/100, Iteration 162/303, Loss: 0.15806818008422852\n",
      "Epoch 11/100, Iteration 163/303, Loss: 0.1580839455127716\n",
      "Epoch 11/100, Iteration 164/303, Loss: 0.2555827796459198\n",
      "Epoch 11/100, Iteration 165/303, Loss: 0.0990656316280365\n",
      "Epoch 11/100, Iteration 166/303, Loss: 0.20271970331668854\n",
      "Epoch 11/100, Iteration 167/303, Loss: 0.25395432114601135\n",
      "Epoch 11/100, Iteration 168/303, Loss: 0.14460787177085876\n",
      "Epoch 11/100, Iteration 169/303, Loss: 0.09397727996110916\n",
      "Epoch 11/100, Iteration 170/303, Loss: 0.12096691876649857\n",
      "Epoch 11/100, Iteration 171/303, Loss: 0.16837817430496216\n",
      "Epoch 11/100, Iteration 172/303, Loss: 0.40560469031333923\n",
      "Epoch 11/100, Iteration 173/303, Loss: 0.12158139050006866\n",
      "Epoch 11/100, Iteration 174/303, Loss: 0.1785700023174286\n",
      "Epoch 11/100, Iteration 175/303, Loss: 0.13587556779384613\n",
      "Epoch 11/100, Iteration 176/303, Loss: 0.13616947829723358\n",
      "Epoch 11/100, Iteration 177/303, Loss: 0.21169419586658478\n",
      "Epoch 11/100, Iteration 178/303, Loss: 0.26181089878082275\n",
      "Epoch 11/100, Iteration 179/303, Loss: 0.07950261235237122\n",
      "Epoch 11/100, Iteration 180/303, Loss: 0.05368150398135185\n",
      "Epoch 11/100, Iteration 181/303, Loss: 0.19266864657402039\n",
      "Epoch 11/100, Iteration 182/303, Loss: 0.0704231783747673\n",
      "Epoch 11/100, Iteration 183/303, Loss: 0.1999911218881607\n",
      "Epoch 11/100, Iteration 184/303, Loss: 0.21932175755500793\n",
      "Epoch 11/100, Iteration 185/303, Loss: 0.15089192986488342\n",
      "Epoch 11/100, Iteration 186/303, Loss: 0.26861295104026794\n",
      "Epoch 11/100, Iteration 187/303, Loss: 0.7848178148269653\n",
      "Epoch 11/100, Iteration 188/303, Loss: 0.15805409848690033\n",
      "Epoch 11/100, Iteration 189/303, Loss: 0.11866579204797745\n",
      "Epoch 11/100, Iteration 190/303, Loss: 0.1446560025215149\n",
      "Epoch 11/100, Iteration 191/303, Loss: 0.1313188523054123\n",
      "Epoch 11/100, Iteration 192/303, Loss: 0.4951411187648773\n",
      "Epoch 11/100, Iteration 193/303, Loss: 0.21846319735050201\n",
      "Epoch 11/100, Iteration 194/303, Loss: 0.2303188443183899\n",
      "Epoch 11/100, Iteration 195/303, Loss: 0.2040509730577469\n",
      "Epoch 11/100, Iteration 196/303, Loss: 0.18939311802387238\n",
      "Epoch 11/100, Iteration 197/303, Loss: 0.18618828058242798\n",
      "Epoch 11/100, Iteration 198/303, Loss: 0.27192503213882446\n",
      "Epoch 11/100, Iteration 199/303, Loss: 0.24648213386535645\n",
      "Epoch 11/100, Iteration 200/303, Loss: 0.2774662375450134\n",
      "Epoch 11/100, Iteration 201/303, Loss: 0.3437994718551636\n",
      "Epoch 11/100, Iteration 202/303, Loss: 0.1729709357023239\n",
      "Epoch 11/100, Iteration 203/303, Loss: 0.21587029099464417\n",
      "Epoch 11/100, Iteration 204/303, Loss: 0.18637603521347046\n",
      "Epoch 11/100, Iteration 205/303, Loss: 0.18367059528827667\n",
      "Epoch 11/100, Iteration 206/303, Loss: 0.15691626071929932\n",
      "Epoch 11/100, Iteration 207/303, Loss: 0.13776704668998718\n",
      "Epoch 11/100, Iteration 208/303, Loss: 0.14518460631370544\n",
      "Epoch 11/100, Iteration 209/303, Loss: 0.18767373263835907\n",
      "Epoch 11/100, Iteration 210/303, Loss: 0.21080993115901947\n",
      "Epoch 11/100, Iteration 211/303, Loss: 0.2635978162288666\n",
      "Epoch 11/100, Iteration 212/303, Loss: 0.10957778990268707\n",
      "Epoch 11/100, Iteration 213/303, Loss: 0.2900812029838562\n",
      "Epoch 11/100, Iteration 214/303, Loss: 0.2949557900428772\n",
      "Epoch 11/100, Iteration 215/303, Loss: 0.29256680607795715\n",
      "Epoch 11/100, Iteration 216/303, Loss: 0.23339566588401794\n",
      "Epoch 11/100, Iteration 217/303, Loss: 0.13346439599990845\n",
      "Epoch 11/100, Iteration 218/303, Loss: 0.23280562460422516\n",
      "Epoch 11/100, Iteration 219/303, Loss: 0.13227762281894684\n",
      "Epoch 11/100, Iteration 220/303, Loss: 0.1965782344341278\n",
      "Epoch 11/100, Iteration 221/303, Loss: 0.12704437971115112\n",
      "Epoch 11/100, Iteration 222/303, Loss: 0.14566724002361298\n",
      "Epoch 11/100, Iteration 223/303, Loss: 0.31704357266426086\n",
      "Epoch 11/100, Iteration 224/303, Loss: 0.3039146065711975\n",
      "Epoch 11/100, Iteration 225/303, Loss: 0.17539015412330627\n",
      "Epoch 11/100, Iteration 226/303, Loss: 0.38769838213920593\n",
      "Epoch 11/100, Iteration 227/303, Loss: 0.17226293683052063\n",
      "Epoch 11/100, Iteration 228/303, Loss: 0.4430365264415741\n",
      "Epoch 11/100, Iteration 229/303, Loss: 0.16655699908733368\n",
      "Epoch 11/100, Iteration 230/303, Loss: 0.1340600848197937\n",
      "Epoch 11/100, Iteration 231/303, Loss: 0.4284372925758362\n",
      "Epoch 11/100, Iteration 232/303, Loss: 0.2164367437362671\n",
      "Epoch 11/100, Iteration 233/303, Loss: 0.2503521144390106\n",
      "Epoch 11/100, Iteration 234/303, Loss: 0.09467374533414841\n",
      "Epoch 11/100, Iteration 235/303, Loss: 0.09472888708114624\n",
      "Epoch 11/100, Iteration 236/303, Loss: 0.3638191819190979\n",
      "Epoch 11/100, Iteration 237/303, Loss: 0.12499339878559113\n",
      "Epoch 11/100, Iteration 238/303, Loss: 0.13829024136066437\n",
      "Epoch 11/100, Iteration 239/303, Loss: 0.2620266377925873\n",
      "Epoch 11/100, Iteration 240/303, Loss: 0.14506354928016663\n",
      "Epoch 11/100, Iteration 241/303, Loss: 0.1308608502149582\n",
      "Epoch 11/100, Iteration 242/303, Loss: 0.1358068883419037\n",
      "Epoch 11/100, Iteration 243/303, Loss: 0.16538599133491516\n",
      "Epoch 11/100, Iteration 244/303, Loss: 0.1593557745218277\n",
      "Epoch 11/100, Iteration 245/303, Loss: 0.1891794353723526\n",
      "Epoch 11/100, Iteration 246/303, Loss: 0.10781476646661758\n",
      "Epoch 11/100, Iteration 247/303, Loss: 0.17643247544765472\n",
      "Epoch 11/100, Iteration 248/303, Loss: 0.15745802223682404\n",
      "Epoch 11/100, Iteration 249/303, Loss: 0.2989879250526428\n",
      "Epoch 11/100, Iteration 250/303, Loss: 0.19083471596240997\n",
      "Epoch 11/100, Iteration 251/303, Loss: 0.23296530544757843\n",
      "Epoch 11/100, Iteration 252/303, Loss: 0.23828168213367462\n",
      "Epoch 11/100, Iteration 253/303, Loss: 0.1775529831647873\n",
      "Epoch 11/100, Iteration 254/303, Loss: 0.18381908535957336\n",
      "Epoch 11/100, Iteration 255/303, Loss: 0.19178012013435364\n",
      "Epoch 11/100, Iteration 256/303, Loss: 0.18757429718971252\n",
      "Epoch 11/100, Iteration 257/303, Loss: 0.08821011334657669\n",
      "Epoch 11/100, Iteration 258/303, Loss: 0.15489575266838074\n",
      "Epoch 11/100, Iteration 259/303, Loss: 0.3047897517681122\n",
      "Epoch 11/100, Iteration 260/303, Loss: 0.3717186450958252\n",
      "Epoch 11/100, Iteration 261/303, Loss: 0.299245685338974\n",
      "Epoch 11/100, Iteration 262/303, Loss: 0.14255391061306\n",
      "Epoch 11/100, Iteration 263/303, Loss: 0.09171261638402939\n",
      "Epoch 11/100, Iteration 264/303, Loss: 0.13777533173561096\n",
      "Epoch 11/100, Iteration 265/303, Loss: 0.2766025960445404\n",
      "Epoch 11/100, Iteration 266/303, Loss: 0.11294038593769073\n",
      "Epoch 11/100, Iteration 267/303, Loss: 0.46198582649230957\n",
      "Epoch 11/100, Iteration 268/303, Loss: 0.25913357734680176\n",
      "Epoch 11/100, Iteration 269/303, Loss: 0.16674767434597015\n",
      "Epoch 11/100, Iteration 270/303, Loss: 0.18974508345127106\n",
      "Epoch 11/100, Iteration 271/303, Loss: 0.06616650521755219\n",
      "Epoch 11/100, Iteration 272/303, Loss: 0.39883148670196533\n",
      "Epoch 11/100, Iteration 273/303, Loss: 0.22517582774162292\n",
      "Epoch 11/100, Iteration 274/303, Loss: 0.2277490347623825\n",
      "Epoch 11/100, Iteration 275/303, Loss: 0.21816490590572357\n",
      "Epoch 11/100, Iteration 276/303, Loss: 0.09112387150526047\n",
      "Epoch 11/100, Iteration 277/303, Loss: 0.2987460196018219\n",
      "Epoch 11/100, Iteration 278/303, Loss: 0.25848647952079773\n",
      "Epoch 11/100, Iteration 279/303, Loss: 0.26369988918304443\n",
      "Epoch 11/100, Iteration 280/303, Loss: 0.16432510316371918\n",
      "Epoch 11/100, Iteration 281/303, Loss: 0.0632232129573822\n",
      "Epoch 11/100, Iteration 282/303, Loss: 0.33142006397247314\n",
      "Epoch 11/100, Iteration 283/303, Loss: 0.12936648726463318\n",
      "Epoch 11/100, Iteration 284/303, Loss: 0.3208979666233063\n",
      "Epoch 11/100, Iteration 285/303, Loss: 0.5992285013198853\n",
      "Epoch 11/100, Iteration 286/303, Loss: 0.1871916949748993\n",
      "Epoch 11/100, Iteration 287/303, Loss: 0.20008139312267303\n",
      "Epoch 11/100, Iteration 288/303, Loss: 0.15749630331993103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Iteration 289/303, Loss: 0.2622694671154022\n",
      "Epoch 11/100, Iteration 290/303, Loss: 0.21893522143363953\n",
      "Epoch 11/100, Iteration 291/303, Loss: 0.2424069344997406\n",
      "Epoch 11/100, Iteration 292/303, Loss: 0.39937281608581543\n",
      "Epoch 11/100, Iteration 293/303, Loss: 0.18736787140369415\n",
      "Epoch 11/100, Iteration 294/303, Loss: 0.16261565685272217\n",
      "Epoch 11/100, Iteration 295/303, Loss: 0.335752934217453\n",
      "Epoch 11/100, Iteration 296/303, Loss: 0.5333117246627808\n",
      "Epoch 11/100, Iteration 297/303, Loss: 0.18712016940116882\n",
      "Epoch 11/100, Iteration 298/303, Loss: 0.19639015197753906\n",
      "Epoch 11/100, Iteration 299/303, Loss: 0.21074064075946808\n",
      "Epoch 11/100, Iteration 300/303, Loss: 0.10666028410196304\n",
      "Epoch 11/100, Iteration 301/303, Loss: 0.19131237268447876\n",
      "Epoch 11/100, Iteration 302/303, Loss: 0.16455811262130737\n",
      "Epoch 11/100, Iteration 303/303, Loss: 0.146781325340271\n",
      "Epoch 12/100, Iteration 1/303, Loss: 0.1700795590877533\n",
      "Epoch 12/100, Iteration 2/303, Loss: 0.11120828986167908\n",
      "Epoch 12/100, Iteration 3/303, Loss: 0.1741531640291214\n",
      "Epoch 12/100, Iteration 4/303, Loss: 0.12030179798603058\n",
      "Epoch 12/100, Iteration 5/303, Loss: 0.11507067829370499\n",
      "Epoch 12/100, Iteration 6/303, Loss: 0.15825839340686798\n",
      "Epoch 12/100, Iteration 7/303, Loss: 0.12211793661117554\n",
      "Epoch 12/100, Iteration 8/303, Loss: 0.10752549767494202\n",
      "Epoch 12/100, Iteration 9/303, Loss: 0.10728394240140915\n",
      "Epoch 12/100, Iteration 10/303, Loss: 0.11638849228620529\n",
      "Epoch 12/100, Iteration 11/303, Loss: 0.0638236328959465\n",
      "Epoch 12/100, Iteration 12/303, Loss: 0.12317764759063721\n",
      "Epoch 12/100, Iteration 13/303, Loss: 0.09611478447914124\n",
      "Epoch 12/100, Iteration 14/303, Loss: 0.08927282691001892\n",
      "Epoch 12/100, Iteration 15/303, Loss: 0.13335224986076355\n",
      "Epoch 12/100, Iteration 16/303, Loss: 0.24722689390182495\n",
      "Epoch 12/100, Iteration 17/303, Loss: 0.3600950241088867\n",
      "Epoch 12/100, Iteration 18/303, Loss: 0.15940885245800018\n",
      "Epoch 12/100, Iteration 19/303, Loss: 0.15512382984161377\n",
      "Epoch 12/100, Iteration 20/303, Loss: 0.10554976761341095\n",
      "Epoch 12/100, Iteration 21/303, Loss: 0.11896218359470367\n",
      "Epoch 12/100, Iteration 22/303, Loss: 0.11096116900444031\n",
      "Epoch 12/100, Iteration 23/303, Loss: 0.23593294620513916\n",
      "Epoch 12/100, Iteration 24/303, Loss: 0.11098694056272507\n",
      "Epoch 12/100, Iteration 25/303, Loss: 0.2732713222503662\n",
      "Epoch 12/100, Iteration 26/303, Loss: 0.3059976100921631\n",
      "Epoch 12/100, Iteration 27/303, Loss: 0.1451275795698166\n",
      "Epoch 12/100, Iteration 28/303, Loss: 0.09798083454370499\n",
      "Epoch 12/100, Iteration 29/303, Loss: 0.08549010008573532\n",
      "Epoch 12/100, Iteration 30/303, Loss: 0.1870136260986328\n",
      "Epoch 12/100, Iteration 31/303, Loss: 0.09209300577640533\n",
      "Epoch 12/100, Iteration 32/303, Loss: 0.0816662386059761\n",
      "Epoch 12/100, Iteration 33/303, Loss: 0.055419035255908966\n",
      "Epoch 12/100, Iteration 34/303, Loss: 0.11619064211845398\n",
      "Epoch 12/100, Iteration 35/303, Loss: 0.10102051496505737\n",
      "Epoch 12/100, Iteration 36/303, Loss: 0.1051998883485794\n",
      "Epoch 12/100, Iteration 37/303, Loss: 0.09492126852273941\n",
      "Epoch 12/100, Iteration 38/303, Loss: 0.13118499517440796\n",
      "Epoch 12/100, Iteration 39/303, Loss: 0.13378113508224487\n",
      "Epoch 12/100, Iteration 40/303, Loss: 0.193058580160141\n",
      "Epoch 12/100, Iteration 41/303, Loss: 0.07541194558143616\n",
      "Epoch 12/100, Iteration 42/303, Loss: 0.32238852977752686\n",
      "Epoch 12/100, Iteration 43/303, Loss: 0.12218861281871796\n",
      "Epoch 12/100, Iteration 44/303, Loss: 0.042226117104291916\n",
      "Epoch 12/100, Iteration 45/303, Loss: 0.06996194273233414\n",
      "Epoch 12/100, Iteration 46/303, Loss: 0.07335279136896133\n",
      "Epoch 12/100, Iteration 47/303, Loss: 0.1651327908039093\n",
      "Epoch 12/100, Iteration 48/303, Loss: 0.22903552651405334\n",
      "Epoch 12/100, Iteration 49/303, Loss: 0.0826515480875969\n",
      "Epoch 12/100, Iteration 50/303, Loss: 0.09596866369247437\n",
      "Epoch 12/100, Iteration 51/303, Loss: 0.17458979785442352\n",
      "Epoch 12/100, Iteration 52/303, Loss: 0.11274205148220062\n",
      "Epoch 12/100, Iteration 53/303, Loss: 0.07495100796222687\n",
      "Epoch 12/100, Iteration 54/303, Loss: 0.1283266544342041\n",
      "Epoch 12/100, Iteration 55/303, Loss: 0.06549488008022308\n",
      "Epoch 12/100, Iteration 56/303, Loss: 0.09244684875011444\n",
      "Epoch 12/100, Iteration 57/303, Loss: 0.11844652891159058\n",
      "Epoch 12/100, Iteration 58/303, Loss: 0.15522004663944244\n",
      "Epoch 12/100, Iteration 59/303, Loss: 0.14635224640369415\n",
      "Epoch 12/100, Iteration 60/303, Loss: 0.08134904503822327\n",
      "Epoch 12/100, Iteration 61/303, Loss: 0.1535298228263855\n",
      "Epoch 12/100, Iteration 62/303, Loss: 0.05648624897003174\n",
      "Epoch 12/100, Iteration 63/303, Loss: 0.10672703385353088\n",
      "Epoch 12/100, Iteration 64/303, Loss: 0.23131324350833893\n",
      "Epoch 12/100, Iteration 65/303, Loss: 0.43011710047721863\n",
      "Epoch 12/100, Iteration 66/303, Loss: 0.2665679454803467\n",
      "Epoch 12/100, Iteration 67/303, Loss: 0.18293273448944092\n",
      "Epoch 12/100, Iteration 68/303, Loss: 0.1759606897830963\n",
      "Epoch 12/100, Iteration 69/303, Loss: 0.2253987193107605\n",
      "Epoch 12/100, Iteration 70/303, Loss: 0.29530736804008484\n",
      "Epoch 12/100, Iteration 71/303, Loss: 0.19656001031398773\n",
      "Epoch 12/100, Iteration 72/303, Loss: 0.21051296591758728\n",
      "Epoch 12/100, Iteration 73/303, Loss: 0.2296057492494583\n",
      "Epoch 12/100, Iteration 74/303, Loss: 0.10661440342664719\n",
      "Epoch 12/100, Iteration 75/303, Loss: 0.17321431636810303\n",
      "Epoch 12/100, Iteration 76/303, Loss: 0.09540906548500061\n",
      "Epoch 12/100, Iteration 77/303, Loss: 0.17362137138843536\n",
      "Epoch 12/100, Iteration 78/303, Loss: 0.2100340723991394\n",
      "Epoch 12/100, Iteration 79/303, Loss: 0.18209277093410492\n",
      "Epoch 12/100, Iteration 80/303, Loss: 0.2720969319343567\n",
      "Epoch 12/100, Iteration 81/303, Loss: 0.5698419809341431\n",
      "Epoch 12/100, Iteration 82/303, Loss: 0.15287509560585022\n",
      "Epoch 12/100, Iteration 83/303, Loss: 0.12090946733951569\n",
      "Epoch 12/100, Iteration 84/303, Loss: 0.04733379930257797\n",
      "Epoch 12/100, Iteration 85/303, Loss: 0.13172534108161926\n",
      "Epoch 12/100, Iteration 86/303, Loss: 0.18290701508522034\n",
      "Epoch 12/100, Iteration 87/303, Loss: 0.29316410422325134\n",
      "Epoch 12/100, Iteration 88/303, Loss: 0.07341237366199493\n",
      "Epoch 12/100, Iteration 89/303, Loss: 0.09275209158658981\n",
      "Epoch 12/100, Iteration 90/303, Loss: 0.4293822646141052\n",
      "Epoch 12/100, Iteration 91/303, Loss: 0.2488897740840912\n",
      "Epoch 12/100, Iteration 92/303, Loss: 0.09082572162151337\n",
      "Epoch 12/100, Iteration 93/303, Loss: 0.16652964055538177\n",
      "Epoch 12/100, Iteration 94/303, Loss: 0.20837701857089996\n",
      "Epoch 12/100, Iteration 95/303, Loss: 0.26643991470336914\n",
      "Epoch 12/100, Iteration 96/303, Loss: 0.2485155612230301\n",
      "Epoch 12/100, Iteration 97/303, Loss: 0.15423594415187836\n",
      "Epoch 12/100, Iteration 98/303, Loss: 0.09716501832008362\n",
      "Epoch 12/100, Iteration 99/303, Loss: 0.2015697956085205\n",
      "Epoch 12/100, Iteration 100/303, Loss: 0.25285738706588745\n",
      "Epoch 12/100, Iteration 101/303, Loss: 0.1392032355070114\n",
      "Epoch 12/100, Iteration 102/303, Loss: 0.1570732295513153\n",
      "Epoch 12/100, Iteration 103/303, Loss: 0.3903205692768097\n",
      "Epoch 12/100, Iteration 104/303, Loss: 0.08311169594526291\n",
      "Epoch 12/100, Iteration 105/303, Loss: 0.18094682693481445\n",
      "Epoch 12/100, Iteration 106/303, Loss: 0.0781603679060936\n",
      "Epoch 12/100, Iteration 107/303, Loss: 0.20524244010448456\n",
      "Epoch 12/100, Iteration 108/303, Loss: 0.07457820326089859\n",
      "Epoch 12/100, Iteration 109/303, Loss: 0.15400712192058563\n",
      "Epoch 12/100, Iteration 110/303, Loss: 0.0731767863035202\n",
      "Epoch 12/100, Iteration 111/303, Loss: 0.13858278095722198\n",
      "Epoch 12/100, Iteration 112/303, Loss: 0.09183859825134277\n",
      "Epoch 12/100, Iteration 113/303, Loss: 0.19478608667850494\n",
      "Epoch 12/100, Iteration 114/303, Loss: 0.1562235951423645\n",
      "Epoch 12/100, Iteration 115/303, Loss: 0.12438888102769852\n",
      "Epoch 12/100, Iteration 116/303, Loss: 0.15097473561763763\n",
      "Epoch 12/100, Iteration 117/303, Loss: 0.12441739439964294\n",
      "Epoch 12/100, Iteration 118/303, Loss: 0.2748561203479767\n",
      "Epoch 12/100, Iteration 119/303, Loss: 0.27507853507995605\n",
      "Epoch 12/100, Iteration 120/303, Loss: 0.1569148600101471\n",
      "Epoch 12/100, Iteration 121/303, Loss: 0.15093955397605896\n",
      "Epoch 12/100, Iteration 122/303, Loss: 0.07816582918167114\n",
      "Epoch 12/100, Iteration 123/303, Loss: 0.2191222608089447\n",
      "Epoch 12/100, Iteration 124/303, Loss: 0.17531320452690125\n",
      "Epoch 12/100, Iteration 125/303, Loss: 0.15547651052474976\n",
      "Epoch 12/100, Iteration 126/303, Loss: 0.15057295560836792\n",
      "Epoch 12/100, Iteration 127/303, Loss: 0.11074171960353851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Iteration 128/303, Loss: 0.19125598669052124\n",
      "Epoch 12/100, Iteration 129/303, Loss: 0.07737307995557785\n",
      "Epoch 12/100, Iteration 130/303, Loss: 0.2594899535179138\n",
      "Epoch 12/100, Iteration 131/303, Loss: 0.1685756891965866\n",
      "Epoch 12/100, Iteration 132/303, Loss: 0.26020798087120056\n",
      "Epoch 12/100, Iteration 133/303, Loss: 0.11568066477775574\n",
      "Epoch 12/100, Iteration 134/303, Loss: 0.1887163668870926\n",
      "Epoch 12/100, Iteration 135/303, Loss: 0.17329123616218567\n",
      "Epoch 12/100, Iteration 136/303, Loss: 0.06914839893579483\n",
      "Epoch 12/100, Iteration 137/303, Loss: 0.1975310742855072\n",
      "Epoch 12/100, Iteration 138/303, Loss: 0.10934582352638245\n",
      "Epoch 12/100, Iteration 139/303, Loss: 0.09182053804397583\n",
      "Epoch 12/100, Iteration 140/303, Loss: 0.07540915906429291\n",
      "Epoch 12/100, Iteration 141/303, Loss: 0.042244866490364075\n",
      "Epoch 12/100, Iteration 142/303, Loss: 0.07374371588230133\n",
      "Epoch 12/100, Iteration 143/303, Loss: 0.03699565306305885\n",
      "Epoch 12/100, Iteration 144/303, Loss: 0.15512269735336304\n",
      "Epoch 12/100, Iteration 145/303, Loss: 0.19571487605571747\n",
      "Epoch 12/100, Iteration 146/303, Loss: 0.08691181242465973\n",
      "Epoch 12/100, Iteration 147/303, Loss: 0.04018364101648331\n",
      "Epoch 12/100, Iteration 148/303, Loss: 0.08008235692977905\n",
      "Epoch 12/100, Iteration 149/303, Loss: 0.3579709827899933\n",
      "Epoch 12/100, Iteration 150/303, Loss: 0.5783793330192566\n",
      "Epoch 12/100, Iteration 151/303, Loss: 0.2539982497692108\n",
      "Epoch 12/100, Iteration 152/303, Loss: 0.14466068148612976\n",
      "Epoch 12/100, Iteration 153/303, Loss: 0.1767674833536148\n",
      "Epoch 12/100, Iteration 154/303, Loss: 0.1815117597579956\n",
      "Epoch 12/100, Iteration 155/303, Loss: 0.12189202010631561\n",
      "Epoch 12/100, Iteration 156/303, Loss: 0.14268721640110016\n",
      "Epoch 12/100, Iteration 157/303, Loss: 0.21618926525115967\n",
      "Epoch 12/100, Iteration 158/303, Loss: 0.1652984321117401\n",
      "Epoch 12/100, Iteration 159/303, Loss: 0.3060424327850342\n",
      "Epoch 12/100, Iteration 160/303, Loss: 0.09387612342834473\n",
      "Epoch 12/100, Iteration 161/303, Loss: 0.07022266834974289\n",
      "Epoch 12/100, Iteration 162/303, Loss: 0.4347018599510193\n",
      "Epoch 12/100, Iteration 163/303, Loss: 0.17866626381874084\n",
      "Epoch 12/100, Iteration 164/303, Loss: 0.10058404505252838\n",
      "Epoch 12/100, Iteration 165/303, Loss: 0.23775029182434082\n",
      "Epoch 12/100, Iteration 166/303, Loss: 0.13681760430335999\n",
      "Epoch 12/100, Iteration 167/303, Loss: 0.18042287230491638\n",
      "Epoch 12/100, Iteration 168/303, Loss: 0.1533743441104889\n",
      "Epoch 12/100, Iteration 169/303, Loss: 0.24601493775844574\n",
      "Epoch 12/100, Iteration 170/303, Loss: 0.1297728419303894\n",
      "Epoch 12/100, Iteration 171/303, Loss: 0.21485304832458496\n",
      "Epoch 12/100, Iteration 172/303, Loss: 0.10916756093502045\n",
      "Epoch 12/100, Iteration 173/303, Loss: 0.2661683261394501\n",
      "Epoch 12/100, Iteration 174/303, Loss: 0.08021537959575653\n",
      "Epoch 12/100, Iteration 175/303, Loss: 0.1620039939880371\n",
      "Epoch 12/100, Iteration 176/303, Loss: 0.19464251399040222\n",
      "Epoch 12/100, Iteration 177/303, Loss: 0.16776300966739655\n",
      "Epoch 12/100, Iteration 178/303, Loss: 0.09929798543453217\n",
      "Epoch 12/100, Iteration 179/303, Loss: 0.3197295367717743\n",
      "Epoch 12/100, Iteration 180/303, Loss: 0.42910560965538025\n",
      "Epoch 12/100, Iteration 181/303, Loss: 0.1365174651145935\n",
      "Epoch 12/100, Iteration 182/303, Loss: 0.3010633587837219\n",
      "Epoch 12/100, Iteration 183/303, Loss: 0.17690208554267883\n",
      "Epoch 12/100, Iteration 184/303, Loss: 0.2232389748096466\n",
      "Epoch 12/100, Iteration 185/303, Loss: 0.18790453672409058\n",
      "Epoch 12/100, Iteration 186/303, Loss: 0.12690716981887817\n",
      "Epoch 12/100, Iteration 187/303, Loss: 0.18562032282352448\n",
      "Epoch 12/100, Iteration 188/303, Loss: 0.26494142413139343\n",
      "Epoch 12/100, Iteration 189/303, Loss: 0.07219211757183075\n",
      "Epoch 12/100, Iteration 190/303, Loss: 0.20474344491958618\n",
      "Epoch 12/100, Iteration 191/303, Loss: 0.1112281084060669\n",
      "Epoch 12/100, Iteration 192/303, Loss: 0.1273566633462906\n",
      "Epoch 12/100, Iteration 193/303, Loss: 0.17672878503799438\n",
      "Epoch 12/100, Iteration 194/303, Loss: 0.16561660170555115\n",
      "Epoch 12/100, Iteration 195/303, Loss: 0.08865317702293396\n",
      "Epoch 12/100, Iteration 196/303, Loss: 0.22250081598758698\n",
      "Epoch 12/100, Iteration 197/303, Loss: 0.14915527403354645\n",
      "Epoch 12/100, Iteration 198/303, Loss: 0.16527527570724487\n",
      "Epoch 12/100, Iteration 199/303, Loss: 0.08573505282402039\n",
      "Epoch 12/100, Iteration 200/303, Loss: 0.3910400867462158\n",
      "Epoch 12/100, Iteration 201/303, Loss: 0.2735871374607086\n",
      "Epoch 12/100, Iteration 202/303, Loss: 0.11443988233804703\n",
      "Epoch 12/100, Iteration 203/303, Loss: 0.15660759806632996\n",
      "Epoch 12/100, Iteration 204/303, Loss: 0.1105082556605339\n",
      "Epoch 12/100, Iteration 205/303, Loss: 0.11065420508384705\n",
      "Epoch 12/100, Iteration 206/303, Loss: 0.34941330552101135\n",
      "Epoch 12/100, Iteration 207/303, Loss: 0.28478172421455383\n",
      "Epoch 12/100, Iteration 208/303, Loss: 0.22891022264957428\n",
      "Epoch 12/100, Iteration 209/303, Loss: 0.23009192943572998\n",
      "Epoch 12/100, Iteration 210/303, Loss: 0.21774902939796448\n",
      "Epoch 12/100, Iteration 211/303, Loss: 0.2647845447063446\n",
      "Epoch 12/100, Iteration 212/303, Loss: 0.09636940062046051\n",
      "Epoch 12/100, Iteration 213/303, Loss: 0.1561802327632904\n",
      "Epoch 12/100, Iteration 214/303, Loss: 0.23432864248752594\n",
      "Epoch 12/100, Iteration 215/303, Loss: 0.31908532977104187\n",
      "Epoch 12/100, Iteration 216/303, Loss: 0.12408509850502014\n",
      "Epoch 12/100, Iteration 217/303, Loss: 0.11698278039693832\n",
      "Epoch 12/100, Iteration 218/303, Loss: 0.20971320569515228\n",
      "Epoch 12/100, Iteration 219/303, Loss: 0.22917421162128448\n",
      "Epoch 12/100, Iteration 220/303, Loss: 0.06965561211109161\n",
      "Epoch 12/100, Iteration 221/303, Loss: 0.14432547986507416\n",
      "Epoch 12/100, Iteration 222/303, Loss: 0.2469395101070404\n",
      "Epoch 12/100, Iteration 223/303, Loss: 0.15224134922027588\n",
      "Epoch 12/100, Iteration 224/303, Loss: 0.20035773515701294\n",
      "Epoch 12/100, Iteration 225/303, Loss: 0.43269991874694824\n",
      "Epoch 12/100, Iteration 226/303, Loss: 0.21549880504608154\n",
      "Epoch 12/100, Iteration 227/303, Loss: 0.06872294843196869\n",
      "Epoch 12/100, Iteration 228/303, Loss: 0.09443493187427521\n",
      "Epoch 12/100, Iteration 229/303, Loss: 0.14491888880729675\n",
      "Epoch 12/100, Iteration 230/303, Loss: 0.09424299001693726\n",
      "Epoch 12/100, Iteration 231/303, Loss: 0.06812146306037903\n",
      "Epoch 12/100, Iteration 232/303, Loss: 0.11829435080289841\n",
      "Epoch 12/100, Iteration 233/303, Loss: 0.05042337253689766\n",
      "Epoch 12/100, Iteration 234/303, Loss: 0.2437727451324463\n",
      "Epoch 12/100, Iteration 235/303, Loss: 0.20919980108737946\n",
      "Epoch 12/100, Iteration 236/303, Loss: 0.35290175676345825\n",
      "Epoch 12/100, Iteration 237/303, Loss: 0.2129645049571991\n",
      "Epoch 12/100, Iteration 238/303, Loss: 0.28103482723236084\n",
      "Epoch 12/100, Iteration 239/303, Loss: 0.3443605899810791\n",
      "Epoch 12/100, Iteration 240/303, Loss: 0.1989668309688568\n",
      "Epoch 12/100, Iteration 241/303, Loss: 0.40037545561790466\n",
      "Epoch 12/100, Iteration 242/303, Loss: 0.11091253161430359\n",
      "Epoch 12/100, Iteration 243/303, Loss: 0.16424605250358582\n",
      "Epoch 12/100, Iteration 244/303, Loss: 0.15586376190185547\n",
      "Epoch 12/100, Iteration 245/303, Loss: 0.37148424983024597\n",
      "Epoch 12/100, Iteration 246/303, Loss: 0.2351561039686203\n",
      "Epoch 12/100, Iteration 247/303, Loss: 0.15533652901649475\n",
      "Epoch 12/100, Iteration 248/303, Loss: 0.18389029800891876\n",
      "Epoch 12/100, Iteration 249/303, Loss: 0.2817680537700653\n",
      "Epoch 12/100, Iteration 250/303, Loss: 0.28916963934898376\n",
      "Epoch 12/100, Iteration 251/303, Loss: 0.230750173330307\n",
      "Epoch 12/100, Iteration 252/303, Loss: 0.13746562600135803\n",
      "Epoch 12/100, Iteration 253/303, Loss: 0.214456245303154\n",
      "Epoch 12/100, Iteration 254/303, Loss: 0.14380678534507751\n",
      "Epoch 12/100, Iteration 255/303, Loss: 0.06342568248510361\n",
      "Epoch 12/100, Iteration 256/303, Loss: 0.06739705801010132\n",
      "Epoch 12/100, Iteration 257/303, Loss: 0.2356446236371994\n",
      "Epoch 12/100, Iteration 258/303, Loss: 0.0764276385307312\n",
      "Epoch 12/100, Iteration 259/303, Loss: 0.2689417004585266\n",
      "Epoch 12/100, Iteration 260/303, Loss: 0.1585424691438675\n",
      "Epoch 12/100, Iteration 261/303, Loss: 0.19746990501880646\n",
      "Epoch 12/100, Iteration 262/303, Loss: 0.14894652366638184\n",
      "Epoch 12/100, Iteration 263/303, Loss: 0.05789857357740402\n",
      "Epoch 12/100, Iteration 264/303, Loss: 0.1777772158384323\n",
      "Epoch 12/100, Iteration 265/303, Loss: 0.18774554133415222\n",
      "Epoch 12/100, Iteration 266/303, Loss: 0.13798463344573975\n",
      "Epoch 12/100, Iteration 267/303, Loss: 0.25332874059677124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Iteration 268/303, Loss: 0.0658053308725357\n",
      "Epoch 12/100, Iteration 269/303, Loss: 0.2217462658882141\n",
      "Epoch 12/100, Iteration 270/303, Loss: 0.09840217977762222\n",
      "Epoch 12/100, Iteration 271/303, Loss: 0.11796864122152328\n",
      "Epoch 12/100, Iteration 272/303, Loss: 0.09224370121955872\n",
      "Epoch 12/100, Iteration 273/303, Loss: 0.10775434225797653\n",
      "Epoch 12/100, Iteration 274/303, Loss: 0.17521411180496216\n",
      "Epoch 12/100, Iteration 275/303, Loss: 0.23921149969100952\n",
      "Epoch 12/100, Iteration 276/303, Loss: 0.06363076716661453\n",
      "Epoch 12/100, Iteration 277/303, Loss: 0.276406854391098\n",
      "Epoch 12/100, Iteration 278/303, Loss: 0.11086831241846085\n",
      "Epoch 12/100, Iteration 279/303, Loss: 0.09974823892116547\n",
      "Epoch 12/100, Iteration 280/303, Loss: 0.17047449946403503\n",
      "Epoch 12/100, Iteration 281/303, Loss: 0.13520370423793793\n",
      "Epoch 12/100, Iteration 282/303, Loss: 0.1008571982383728\n",
      "Epoch 12/100, Iteration 283/303, Loss: 0.06442482769489288\n",
      "Epoch 12/100, Iteration 284/303, Loss: 0.18119029700756073\n",
      "Epoch 12/100, Iteration 285/303, Loss: 0.11792900413274765\n",
      "Epoch 12/100, Iteration 286/303, Loss: 0.6052678823471069\n",
      "Epoch 12/100, Iteration 287/303, Loss: 0.38352084159851074\n",
      "Epoch 12/100, Iteration 288/303, Loss: 0.8412142992019653\n",
      "Epoch 12/100, Iteration 289/303, Loss: 0.32907700538635254\n",
      "Epoch 12/100, Iteration 290/303, Loss: 0.19439399242401123\n",
      "Epoch 12/100, Iteration 291/303, Loss: 0.2504395842552185\n",
      "Epoch 12/100, Iteration 292/303, Loss: 0.13995049893856049\n",
      "Epoch 12/100, Iteration 293/303, Loss: 0.18103580176830292\n",
      "Epoch 12/100, Iteration 294/303, Loss: 0.144888773560524\n",
      "Epoch 12/100, Iteration 295/303, Loss: 0.15950842201709747\n",
      "Epoch 12/100, Iteration 296/303, Loss: 0.31860217452049255\n",
      "Epoch 12/100, Iteration 297/303, Loss: 0.07513869553804398\n",
      "Epoch 12/100, Iteration 298/303, Loss: 0.22034910321235657\n",
      "Epoch 12/100, Iteration 299/303, Loss: 0.17619507014751434\n",
      "Epoch 12/100, Iteration 300/303, Loss: 0.1349211484193802\n",
      "Epoch 12/100, Iteration 301/303, Loss: 0.1179652288556099\n",
      "Epoch 12/100, Iteration 302/303, Loss: 0.07701452821493149\n",
      "Epoch 12/100, Iteration 303/303, Loss: 0.1202952042222023\n",
      "Epoch 13/100, Iteration 1/303, Loss: 0.08185642957687378\n",
      "Epoch 13/100, Iteration 2/303, Loss: 0.0901074931025505\n",
      "Epoch 13/100, Iteration 3/303, Loss: 0.08085740357637405\n",
      "Epoch 13/100, Iteration 4/303, Loss: 0.04609610140323639\n",
      "Epoch 13/100, Iteration 5/303, Loss: 0.06980746984481812\n",
      "Epoch 13/100, Iteration 6/303, Loss: 0.11829125881195068\n",
      "Epoch 13/100, Iteration 7/303, Loss: 0.08046878129243851\n",
      "Epoch 13/100, Iteration 8/303, Loss: 0.08356742560863495\n",
      "Epoch 13/100, Iteration 9/303, Loss: 0.0256919227540493\n",
      "Epoch 13/100, Iteration 10/303, Loss: 0.16884009540081024\n",
      "Epoch 13/100, Iteration 11/303, Loss: 0.12143762409687042\n",
      "Epoch 13/100, Iteration 12/303, Loss: 0.18152549862861633\n",
      "Epoch 13/100, Iteration 13/303, Loss: 0.23291125893592834\n",
      "Epoch 13/100, Iteration 14/303, Loss: 0.11624971777200699\n",
      "Epoch 13/100, Iteration 15/303, Loss: 0.07116734981536865\n",
      "Epoch 13/100, Iteration 16/303, Loss: 0.07192573696374893\n",
      "Epoch 13/100, Iteration 17/303, Loss: 0.06030696630477905\n",
      "Epoch 13/100, Iteration 18/303, Loss: 0.1337146908044815\n",
      "Epoch 13/100, Iteration 19/303, Loss: 0.09071706980466843\n",
      "Epoch 13/100, Iteration 20/303, Loss: 0.2626534402370453\n",
      "Epoch 13/100, Iteration 21/303, Loss: 0.0594911053776741\n",
      "Epoch 13/100, Iteration 22/303, Loss: 0.10270915180444717\n",
      "Epoch 13/100, Iteration 23/303, Loss: 0.04594390466809273\n",
      "Epoch 13/100, Iteration 24/303, Loss: 0.04977928847074509\n",
      "Epoch 13/100, Iteration 25/303, Loss: 0.06705746799707413\n",
      "Epoch 13/100, Iteration 26/303, Loss: 0.052065201103687286\n",
      "Epoch 13/100, Iteration 27/303, Loss: 0.09467733651399612\n",
      "Epoch 13/100, Iteration 28/303, Loss: 0.04332594573497772\n",
      "Epoch 13/100, Iteration 29/303, Loss: 0.14206480979919434\n",
      "Epoch 13/100, Iteration 30/303, Loss: 0.07625415921211243\n",
      "Epoch 13/100, Iteration 31/303, Loss: 0.05206192657351494\n",
      "Epoch 13/100, Iteration 32/303, Loss: 0.08945444226264954\n",
      "Epoch 13/100, Iteration 33/303, Loss: 0.021040108054876328\n",
      "Epoch 13/100, Iteration 34/303, Loss: 0.07590652257204056\n",
      "Epoch 13/100, Iteration 35/303, Loss: 0.1317395120859146\n",
      "Epoch 13/100, Iteration 36/303, Loss: 0.0617370642721653\n",
      "Epoch 13/100, Iteration 37/303, Loss: 0.21126587688922882\n",
      "Epoch 13/100, Iteration 38/303, Loss: 0.25919967889785767\n",
      "Epoch 13/100, Iteration 39/303, Loss: 0.08386115729808807\n",
      "Epoch 13/100, Iteration 40/303, Loss: 0.11925110220909119\n",
      "Epoch 13/100, Iteration 41/303, Loss: 0.06445569545030594\n",
      "Epoch 13/100, Iteration 42/303, Loss: 0.23443880677223206\n",
      "Epoch 13/100, Iteration 43/303, Loss: 0.1880371868610382\n",
      "Epoch 13/100, Iteration 44/303, Loss: 0.2552226781845093\n",
      "Epoch 13/100, Iteration 45/303, Loss: 0.04022657871246338\n",
      "Epoch 13/100, Iteration 46/303, Loss: 0.15854781866073608\n",
      "Epoch 13/100, Iteration 47/303, Loss: 0.2413431704044342\n",
      "Epoch 13/100, Iteration 48/303, Loss: 0.012343510054051876\n",
      "Epoch 13/100, Iteration 49/303, Loss: 0.08444380015134811\n",
      "Epoch 13/100, Iteration 50/303, Loss: 0.10500992834568024\n",
      "Epoch 13/100, Iteration 51/303, Loss: 0.10457802563905716\n",
      "Epoch 13/100, Iteration 52/303, Loss: 0.060322463512420654\n",
      "Epoch 13/100, Iteration 53/303, Loss: 0.13670380413532257\n",
      "Epoch 13/100, Iteration 54/303, Loss: 0.09966868907213211\n",
      "Epoch 13/100, Iteration 55/303, Loss: 0.12716881930828094\n",
      "Epoch 13/100, Iteration 56/303, Loss: 0.21005885303020477\n",
      "Epoch 13/100, Iteration 57/303, Loss: 0.08312705904245377\n",
      "Epoch 13/100, Iteration 58/303, Loss: 0.04068818688392639\n",
      "Epoch 13/100, Iteration 59/303, Loss: 0.09467402845621109\n",
      "Epoch 13/100, Iteration 60/303, Loss: 0.14304235577583313\n",
      "Epoch 13/100, Iteration 61/303, Loss: 0.048286162316799164\n",
      "Epoch 13/100, Iteration 62/303, Loss: 0.08967681974172592\n",
      "Epoch 13/100, Iteration 63/303, Loss: 0.12242257595062256\n",
      "Epoch 13/100, Iteration 64/303, Loss: 0.07161111384630203\n",
      "Epoch 13/100, Iteration 65/303, Loss: 0.08046206086874008\n",
      "Epoch 13/100, Iteration 66/303, Loss: 0.15176531672477722\n",
      "Epoch 13/100, Iteration 67/303, Loss: 0.05460408329963684\n",
      "Epoch 13/100, Iteration 68/303, Loss: 0.13558851182460785\n",
      "Epoch 13/100, Iteration 69/303, Loss: 0.04939180240035057\n",
      "Epoch 13/100, Iteration 70/303, Loss: 0.10632602125406265\n",
      "Epoch 13/100, Iteration 71/303, Loss: 0.1602642685174942\n",
      "Epoch 13/100, Iteration 72/303, Loss: 0.11478010565042496\n",
      "Epoch 13/100, Iteration 73/303, Loss: 0.19415856897830963\n",
      "Epoch 13/100, Iteration 74/303, Loss: 0.11853524297475815\n",
      "Epoch 13/100, Iteration 75/303, Loss: 0.10824955999851227\n",
      "Epoch 13/100, Iteration 76/303, Loss: 0.2054423689842224\n",
      "Epoch 13/100, Iteration 77/303, Loss: 0.05140034854412079\n",
      "Epoch 13/100, Iteration 78/303, Loss: 0.0914003998041153\n",
      "Epoch 13/100, Iteration 79/303, Loss: 0.19335314631462097\n",
      "Epoch 13/100, Iteration 80/303, Loss: 0.1644744724035263\n",
      "Epoch 13/100, Iteration 81/303, Loss: 0.21040435135364532\n",
      "Epoch 13/100, Iteration 82/303, Loss: 0.11793813109397888\n",
      "Epoch 13/100, Iteration 83/303, Loss: 0.14249290525913239\n",
      "Epoch 13/100, Iteration 84/303, Loss: 0.2221558690071106\n",
      "Epoch 13/100, Iteration 85/303, Loss: 0.10319705307483673\n",
      "Epoch 13/100, Iteration 86/303, Loss: 0.04315894842147827\n",
      "Epoch 13/100, Iteration 87/303, Loss: 0.11742164194583893\n",
      "Epoch 13/100, Iteration 88/303, Loss: 0.16205066442489624\n",
      "Epoch 13/100, Iteration 89/303, Loss: 0.3490152657032013\n",
      "Epoch 13/100, Iteration 90/303, Loss: 0.26358115673065186\n",
      "Epoch 13/100, Iteration 91/303, Loss: 0.08261668682098389\n",
      "Epoch 13/100, Iteration 92/303, Loss: 0.21198531985282898\n",
      "Epoch 13/100, Iteration 93/303, Loss: 0.09883520007133484\n",
      "Epoch 13/100, Iteration 94/303, Loss: 0.21871498227119446\n",
      "Epoch 13/100, Iteration 95/303, Loss: 0.15934307873249054\n",
      "Epoch 13/100, Iteration 96/303, Loss: 0.15376652777194977\n",
      "Epoch 13/100, Iteration 97/303, Loss: 0.12967272102832794\n",
      "Epoch 13/100, Iteration 98/303, Loss: 0.12977367639541626\n",
      "Epoch 13/100, Iteration 99/303, Loss: 0.04469124600291252\n",
      "Epoch 13/100, Iteration 100/303, Loss: 0.04338002949953079\n",
      "Epoch 13/100, Iteration 101/303, Loss: 0.07399075478315353\n",
      "Epoch 13/100, Iteration 102/303, Loss: 0.060161229223012924\n",
      "Epoch 13/100, Iteration 103/303, Loss: 0.02420966699719429\n",
      "Epoch 13/100, Iteration 104/303, Loss: 0.1786406934261322\n",
      "Epoch 13/100, Iteration 105/303, Loss: 0.036139361560344696\n",
      "Epoch 13/100, Iteration 106/303, Loss: 0.2672657370567322\n",
      "Epoch 13/100, Iteration 107/303, Loss: 0.11740955710411072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Iteration 108/303, Loss: 0.03407099097967148\n",
      "Epoch 13/100, Iteration 109/303, Loss: 0.03168356418609619\n",
      "Epoch 13/100, Iteration 110/303, Loss: 0.013732517138123512\n",
      "Epoch 13/100, Iteration 111/303, Loss: 0.16849544644355774\n",
      "Epoch 13/100, Iteration 112/303, Loss: 0.07487145811319351\n",
      "Epoch 13/100, Iteration 113/303, Loss: 0.1475450098514557\n",
      "Epoch 13/100, Iteration 114/303, Loss: 0.07516267895698547\n",
      "Epoch 13/100, Iteration 115/303, Loss: 0.11345244944095612\n",
      "Epoch 13/100, Iteration 116/303, Loss: 0.13942106068134308\n",
      "Epoch 13/100, Iteration 117/303, Loss: 0.22567306458950043\n",
      "Epoch 13/100, Iteration 118/303, Loss: 0.1345774531364441\n",
      "Epoch 13/100, Iteration 119/303, Loss: 0.1661583036184311\n",
      "Epoch 13/100, Iteration 120/303, Loss: 0.16511847078800201\n",
      "Epoch 13/100, Iteration 121/303, Loss: 0.056140728294849396\n",
      "Epoch 13/100, Iteration 122/303, Loss: 0.07305687665939331\n",
      "Epoch 13/100, Iteration 123/303, Loss: 0.09482356160879135\n",
      "Epoch 13/100, Iteration 124/303, Loss: 0.06565477699041367\n",
      "Epoch 13/100, Iteration 125/303, Loss: 0.43592408299446106\n",
      "Epoch 13/100, Iteration 126/303, Loss: 0.07716171443462372\n",
      "Epoch 13/100, Iteration 127/303, Loss: 0.2282940149307251\n",
      "Epoch 13/100, Iteration 128/303, Loss: 0.17171281576156616\n",
      "Epoch 13/100, Iteration 129/303, Loss: 0.2284233123064041\n",
      "Epoch 13/100, Iteration 130/303, Loss: 0.18751543760299683\n",
      "Epoch 13/100, Iteration 131/303, Loss: 0.10899665206670761\n",
      "Epoch 13/100, Iteration 132/303, Loss: 0.04895484820008278\n",
      "Epoch 13/100, Iteration 133/303, Loss: 0.15293169021606445\n",
      "Epoch 13/100, Iteration 134/303, Loss: 0.12756890058517456\n",
      "Epoch 13/100, Iteration 135/303, Loss: 0.32923781871795654\n",
      "Epoch 13/100, Iteration 136/303, Loss: 0.13218677043914795\n",
      "Epoch 13/100, Iteration 137/303, Loss: 0.13193577527999878\n",
      "Epoch 13/100, Iteration 138/303, Loss: 0.2044926881790161\n",
      "Epoch 13/100, Iteration 139/303, Loss: 0.20502164959907532\n",
      "Epoch 13/100, Iteration 140/303, Loss: 0.0832299292087555\n",
      "Epoch 13/100, Iteration 141/303, Loss: 0.1596238911151886\n",
      "Epoch 13/100, Iteration 142/303, Loss: 0.08770235627889633\n",
      "Epoch 13/100, Iteration 143/303, Loss: 0.13587023317813873\n",
      "Epoch 13/100, Iteration 144/303, Loss: 0.10849516838788986\n",
      "Epoch 13/100, Iteration 145/303, Loss: 0.05510975420475006\n",
      "Epoch 13/100, Iteration 146/303, Loss: 0.10253579169511795\n",
      "Epoch 13/100, Iteration 147/303, Loss: 0.25577884912490845\n",
      "Epoch 13/100, Iteration 148/303, Loss: 0.17059439420700073\n",
      "Epoch 13/100, Iteration 149/303, Loss: 0.12865877151489258\n",
      "Epoch 13/100, Iteration 150/303, Loss: 0.21384572982788086\n",
      "Epoch 13/100, Iteration 151/303, Loss: 0.17132481932640076\n",
      "Epoch 13/100, Iteration 152/303, Loss: 0.0828038901090622\n",
      "Epoch 13/100, Iteration 153/303, Loss: 0.15633590519428253\n",
      "Epoch 13/100, Iteration 154/303, Loss: 0.16055479645729065\n",
      "Epoch 13/100, Iteration 155/303, Loss: 0.0741746798157692\n",
      "Epoch 13/100, Iteration 156/303, Loss: 0.05022964999079704\n",
      "Epoch 13/100, Iteration 157/303, Loss: 0.029652543365955353\n",
      "Epoch 13/100, Iteration 158/303, Loss: 0.06720107048749924\n",
      "Epoch 13/100, Iteration 159/303, Loss: 0.09886357188224792\n",
      "Epoch 13/100, Iteration 160/303, Loss: 0.021892959251999855\n",
      "Epoch 13/100, Iteration 161/303, Loss: 0.05314042791724205\n",
      "Epoch 13/100, Iteration 162/303, Loss: 0.05899995565414429\n",
      "Epoch 13/100, Iteration 163/303, Loss: 0.12143349647521973\n",
      "Epoch 13/100, Iteration 164/303, Loss: 0.17652559280395508\n",
      "Epoch 13/100, Iteration 165/303, Loss: 0.07107386738061905\n",
      "Epoch 13/100, Iteration 166/303, Loss: 0.11276763677597046\n",
      "Epoch 13/100, Iteration 167/303, Loss: 0.08537478744983673\n",
      "Epoch 13/100, Iteration 168/303, Loss: 0.08383980393409729\n",
      "Epoch 13/100, Iteration 169/303, Loss: 0.0467425212264061\n",
      "Epoch 13/100, Iteration 170/303, Loss: 0.10210548341274261\n",
      "Epoch 13/100, Iteration 171/303, Loss: 0.11730198562145233\n",
      "Epoch 13/100, Iteration 172/303, Loss: 0.05174022167921066\n",
      "Epoch 13/100, Iteration 173/303, Loss: 0.08392252773046494\n",
      "Epoch 13/100, Iteration 174/303, Loss: 0.27490994334220886\n",
      "Epoch 13/100, Iteration 175/303, Loss: 0.16717775166034698\n",
      "Epoch 13/100, Iteration 176/303, Loss: 0.26938432455062866\n",
      "Epoch 13/100, Iteration 177/303, Loss: 0.18725885450839996\n",
      "Epoch 13/100, Iteration 178/303, Loss: 0.3270549476146698\n",
      "Epoch 13/100, Iteration 179/303, Loss: 0.5330098271369934\n",
      "Epoch 13/100, Iteration 180/303, Loss: 0.6439471244812012\n",
      "Epoch 13/100, Iteration 181/303, Loss: 0.25110194087028503\n",
      "Epoch 13/100, Iteration 182/303, Loss: 0.09928122907876968\n",
      "Epoch 13/100, Iteration 183/303, Loss: 0.05376574397087097\n",
      "Epoch 13/100, Iteration 184/303, Loss: 0.21869169175624847\n",
      "Epoch 13/100, Iteration 185/303, Loss: 0.0756988376379013\n",
      "Epoch 13/100, Iteration 186/303, Loss: 0.34749194979667664\n",
      "Epoch 13/100, Iteration 187/303, Loss: 0.11811339110136032\n",
      "Epoch 13/100, Iteration 188/303, Loss: 0.0997634306550026\n",
      "Epoch 13/100, Iteration 189/303, Loss: 0.08372718840837479\n",
      "Epoch 13/100, Iteration 190/303, Loss: 0.0877239853143692\n",
      "Epoch 13/100, Iteration 191/303, Loss: 0.18639463186264038\n",
      "Epoch 13/100, Iteration 192/303, Loss: 0.043442122638225555\n",
      "Epoch 13/100, Iteration 193/303, Loss: 0.18797801434993744\n",
      "Epoch 13/100, Iteration 194/303, Loss: 0.12513467669487\n",
      "Epoch 13/100, Iteration 195/303, Loss: 0.13540932536125183\n",
      "Epoch 13/100, Iteration 196/303, Loss: 0.19676707684993744\n",
      "Epoch 13/100, Iteration 197/303, Loss: 0.14627861976623535\n",
      "Epoch 13/100, Iteration 198/303, Loss: 0.1763150542974472\n",
      "Epoch 13/100, Iteration 199/303, Loss: 0.04501543939113617\n",
      "Epoch 13/100, Iteration 200/303, Loss: 0.10267277806997299\n",
      "Epoch 13/100, Iteration 201/303, Loss: 0.04764341935515404\n",
      "Epoch 13/100, Iteration 202/303, Loss: 0.11432065814733505\n",
      "Epoch 13/100, Iteration 203/303, Loss: 0.07122454047203064\n",
      "Epoch 13/100, Iteration 204/303, Loss: 0.1365356296300888\n",
      "Epoch 13/100, Iteration 205/303, Loss: 0.1029326468706131\n",
      "Epoch 13/100, Iteration 206/303, Loss: 0.1529402732849121\n",
      "Epoch 13/100, Iteration 207/303, Loss: 0.13468323647975922\n",
      "Epoch 13/100, Iteration 208/303, Loss: 0.1341601312160492\n",
      "Epoch 13/100, Iteration 209/303, Loss: 0.15147443115711212\n",
      "Epoch 13/100, Iteration 210/303, Loss: 0.06415414065122604\n",
      "Epoch 13/100, Iteration 211/303, Loss: 0.16455590724945068\n",
      "Epoch 13/100, Iteration 212/303, Loss: 0.06602869182825089\n",
      "Epoch 13/100, Iteration 213/303, Loss: 0.09298543632030487\n",
      "Epoch 13/100, Iteration 214/303, Loss: 0.06784380972385406\n",
      "Epoch 13/100, Iteration 215/303, Loss: 0.08031480014324188\n",
      "Epoch 13/100, Iteration 216/303, Loss: 0.062217917293310165\n",
      "Epoch 13/100, Iteration 217/303, Loss: 0.07888957113027573\n",
      "Epoch 13/100, Iteration 218/303, Loss: 0.10914817452430725\n",
      "Epoch 13/100, Iteration 219/303, Loss: 0.15739154815673828\n",
      "Epoch 13/100, Iteration 220/303, Loss: 0.0670691654086113\n",
      "Epoch 13/100, Iteration 221/303, Loss: 0.11241929978132248\n",
      "Epoch 13/100, Iteration 222/303, Loss: 0.15650570392608643\n",
      "Epoch 13/100, Iteration 223/303, Loss: 0.19762220978736877\n",
      "Epoch 13/100, Iteration 224/303, Loss: 0.37284690141677856\n",
      "Epoch 13/100, Iteration 225/303, Loss: 0.21446920931339264\n",
      "Epoch 13/100, Iteration 226/303, Loss: 0.12511742115020752\n",
      "Epoch 13/100, Iteration 227/303, Loss: 0.08679702877998352\n",
      "Epoch 13/100, Iteration 228/303, Loss: 0.09490778297185898\n",
      "Epoch 13/100, Iteration 229/303, Loss: 0.06729360669851303\n",
      "Epoch 13/100, Iteration 230/303, Loss: 0.1368599385023117\n",
      "Epoch 13/100, Iteration 231/303, Loss: 0.06429645419120789\n",
      "Epoch 13/100, Iteration 232/303, Loss: 0.03483673557639122\n",
      "Epoch 13/100, Iteration 233/303, Loss: 0.12417246401309967\n",
      "Epoch 13/100, Iteration 234/303, Loss: 0.17249594628810883\n",
      "Epoch 13/100, Iteration 235/303, Loss: 0.16702723503112793\n",
      "Epoch 13/100, Iteration 236/303, Loss: 0.1505763828754425\n",
      "Epoch 13/100, Iteration 237/303, Loss: 0.17591753602027893\n",
      "Epoch 13/100, Iteration 238/303, Loss: 0.15819139778614044\n",
      "Epoch 13/100, Iteration 239/303, Loss: 0.16460129618644714\n",
      "Epoch 13/100, Iteration 240/303, Loss: 0.2678781747817993\n",
      "Epoch 13/100, Iteration 241/303, Loss: 0.14520089328289032\n",
      "Epoch 13/100, Iteration 242/303, Loss: 0.18389762938022614\n",
      "Epoch 13/100, Iteration 243/303, Loss: 0.2644246816635132\n",
      "Epoch 13/100, Iteration 244/303, Loss: 0.10888772457838058\n",
      "Epoch 13/100, Iteration 245/303, Loss: 0.3194597065448761\n",
      "Epoch 13/100, Iteration 246/303, Loss: 0.34307220578193665\n",
      "Epoch 13/100, Iteration 247/303, Loss: 0.368775337934494\n",
      "Epoch 13/100, Iteration 248/303, Loss: 0.501427948474884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Iteration 249/303, Loss: 0.18695294857025146\n",
      "Epoch 13/100, Iteration 250/303, Loss: 0.12599866092205048\n",
      "Epoch 13/100, Iteration 251/303, Loss: 0.06696636229753494\n",
      "Epoch 13/100, Iteration 252/303, Loss: 0.11214446276426315\n",
      "Epoch 13/100, Iteration 253/303, Loss: 0.19054014980793\n",
      "Epoch 13/100, Iteration 254/303, Loss: 0.0978810042142868\n",
      "Epoch 13/100, Iteration 255/303, Loss: 0.12730048596858978\n",
      "Epoch 13/100, Iteration 256/303, Loss: 0.09660495072603226\n",
      "Epoch 13/100, Iteration 257/303, Loss: 0.15068474411964417\n",
      "Epoch 13/100, Iteration 258/303, Loss: 0.027489425614476204\n",
      "Epoch 13/100, Iteration 259/303, Loss: 0.11531169712543488\n",
      "Epoch 13/100, Iteration 260/303, Loss: 0.04964398965239525\n",
      "Epoch 13/100, Iteration 261/303, Loss: 0.04811285436153412\n",
      "Epoch 13/100, Iteration 262/303, Loss: 0.24659596383571625\n",
      "Epoch 13/100, Iteration 263/303, Loss: 0.12040973454713821\n",
      "Epoch 13/100, Iteration 264/303, Loss: 0.11299546808004379\n",
      "Epoch 13/100, Iteration 265/303, Loss: 0.20787328481674194\n",
      "Epoch 13/100, Iteration 266/303, Loss: 0.08582846820354462\n",
      "Epoch 13/100, Iteration 267/303, Loss: 0.18278160691261292\n",
      "Epoch 13/100, Iteration 268/303, Loss: 0.24348263442516327\n",
      "Epoch 13/100, Iteration 269/303, Loss: 0.07047013193368912\n",
      "Epoch 13/100, Iteration 270/303, Loss: 0.03496018052101135\n",
      "Epoch 13/100, Iteration 271/303, Loss: 0.04896797239780426\n",
      "Epoch 13/100, Iteration 272/303, Loss: 0.28680750727653503\n",
      "Epoch 13/100, Iteration 273/303, Loss: 0.1997869610786438\n",
      "Epoch 13/100, Iteration 274/303, Loss: 0.16245576739311218\n",
      "Epoch 13/100, Iteration 275/303, Loss: 0.09514237195253372\n",
      "Epoch 13/100, Iteration 276/303, Loss: 0.044459737837314606\n",
      "Epoch 13/100, Iteration 277/303, Loss: 0.14517511427402496\n",
      "Epoch 13/100, Iteration 278/303, Loss: 0.21606293320655823\n",
      "Epoch 13/100, Iteration 279/303, Loss: 0.06240736320614815\n",
      "Epoch 13/100, Iteration 280/303, Loss: 0.1724812537431717\n",
      "Epoch 13/100, Iteration 281/303, Loss: 0.16738902032375336\n",
      "Epoch 13/100, Iteration 282/303, Loss: 0.09365599602460861\n",
      "Epoch 13/100, Iteration 283/303, Loss: 0.07573169469833374\n",
      "Epoch 13/100, Iteration 284/303, Loss: 0.08442893624305725\n",
      "Epoch 13/100, Iteration 285/303, Loss: 0.1056537926197052\n",
      "Epoch 13/100, Iteration 286/303, Loss: 0.1360049545764923\n",
      "Epoch 13/100, Iteration 287/303, Loss: 0.13136295974254608\n",
      "Epoch 13/100, Iteration 288/303, Loss: 0.08861071616411209\n",
      "Epoch 13/100, Iteration 289/303, Loss: 0.12983360886573792\n",
      "Epoch 13/100, Iteration 290/303, Loss: 0.2817029654979706\n",
      "Epoch 13/100, Iteration 291/303, Loss: 0.2470378577709198\n",
      "Epoch 13/100, Iteration 292/303, Loss: 0.15080179274082184\n",
      "Epoch 13/100, Iteration 293/303, Loss: 0.06697236001491547\n",
      "Epoch 13/100, Iteration 294/303, Loss: 0.1276860237121582\n",
      "Epoch 13/100, Iteration 295/303, Loss: 0.18682339787483215\n",
      "Epoch 13/100, Iteration 296/303, Loss: 0.06624411046504974\n",
      "Epoch 13/100, Iteration 297/303, Loss: 0.08605306595563889\n",
      "Epoch 13/100, Iteration 298/303, Loss: 0.14252740144729614\n",
      "Epoch 13/100, Iteration 299/303, Loss: 0.06610880047082901\n",
      "Epoch 13/100, Iteration 300/303, Loss: 0.025665922090411186\n",
      "Epoch 13/100, Iteration 301/303, Loss: 0.25825196504592896\n",
      "Epoch 13/100, Iteration 302/303, Loss: 0.4473322629928589\n",
      "Epoch 13/100, Iteration 303/303, Loss: 0.6065254211425781\n",
      "Epoch 14/100, Iteration 1/303, Loss: 0.7255557179450989\n",
      "Epoch 14/100, Iteration 2/303, Loss: 0.18935732543468475\n",
      "Epoch 14/100, Iteration 3/303, Loss: 0.09446631371974945\n",
      "Epoch 14/100, Iteration 4/303, Loss: 0.16141268610954285\n",
      "Epoch 14/100, Iteration 5/303, Loss: 0.1262039989233017\n",
      "Epoch 14/100, Iteration 6/303, Loss: 0.13545143604278564\n",
      "Epoch 14/100, Iteration 7/303, Loss: 0.08223284780979156\n",
      "Epoch 14/100, Iteration 8/303, Loss: 0.1165214329957962\n",
      "Epoch 14/100, Iteration 9/303, Loss: 0.09866349399089813\n",
      "Epoch 14/100, Iteration 10/303, Loss: 0.06489904224872589\n",
      "Epoch 14/100, Iteration 11/303, Loss: 0.10292138159275055\n",
      "Epoch 14/100, Iteration 12/303, Loss: 0.12465696036815643\n",
      "Epoch 14/100, Iteration 13/303, Loss: 0.06851955503225327\n",
      "Epoch 14/100, Iteration 14/303, Loss: 0.10462339967489243\n",
      "Epoch 14/100, Iteration 15/303, Loss: 0.06215124577283859\n",
      "Epoch 14/100, Iteration 16/303, Loss: 0.1875312328338623\n",
      "Epoch 14/100, Iteration 17/303, Loss: 0.0915733054280281\n",
      "Epoch 14/100, Iteration 18/303, Loss: 0.06272409856319427\n",
      "Epoch 14/100, Iteration 19/303, Loss: 0.10615266114473343\n",
      "Epoch 14/100, Iteration 20/303, Loss: 0.12344947457313538\n",
      "Epoch 14/100, Iteration 21/303, Loss: 0.11884108930826187\n",
      "Epoch 14/100, Iteration 22/303, Loss: 0.04914826527237892\n",
      "Epoch 14/100, Iteration 23/303, Loss: 0.19272108376026154\n",
      "Epoch 14/100, Iteration 24/303, Loss: 0.1161251813173294\n",
      "Epoch 14/100, Iteration 25/303, Loss: 0.14745751023292542\n",
      "Epoch 14/100, Iteration 26/303, Loss: 0.06406380236148834\n",
      "Epoch 14/100, Iteration 27/303, Loss: 0.02257959172129631\n",
      "Epoch 14/100, Iteration 28/303, Loss: 0.02712228149175644\n",
      "Epoch 14/100, Iteration 29/303, Loss: 0.037105679512023926\n",
      "Epoch 14/100, Iteration 30/303, Loss: 0.08637652546167374\n",
      "Epoch 14/100, Iteration 31/303, Loss: 0.12073639780282974\n",
      "Epoch 14/100, Iteration 32/303, Loss: 0.05081196501851082\n",
      "Epoch 14/100, Iteration 33/303, Loss: 0.10417422652244568\n",
      "Epoch 14/100, Iteration 34/303, Loss: 0.07591351866722107\n",
      "Epoch 14/100, Iteration 35/303, Loss: 0.16664639115333557\n",
      "Epoch 14/100, Iteration 36/303, Loss: 0.07711902260780334\n",
      "Epoch 14/100, Iteration 37/303, Loss: 0.12211976200342178\n",
      "Epoch 14/100, Iteration 38/303, Loss: 0.17950551211833954\n",
      "Epoch 14/100, Iteration 39/303, Loss: 0.06911514699459076\n",
      "Epoch 14/100, Iteration 40/303, Loss: 0.09000633656978607\n",
      "Epoch 14/100, Iteration 41/303, Loss: 0.49990251660346985\n",
      "Epoch 14/100, Iteration 42/303, Loss: 0.11504243314266205\n",
      "Epoch 14/100, Iteration 43/303, Loss: 0.09014909714460373\n",
      "Epoch 14/100, Iteration 44/303, Loss: 0.03865097835659981\n",
      "Epoch 14/100, Iteration 45/303, Loss: 0.10866587609052658\n",
      "Epoch 14/100, Iteration 46/303, Loss: 0.19895942509174347\n",
      "Epoch 14/100, Iteration 47/303, Loss: 0.08687157928943634\n",
      "Epoch 14/100, Iteration 48/303, Loss: 0.07627356797456741\n",
      "Epoch 14/100, Iteration 49/303, Loss: 0.1036020815372467\n",
      "Epoch 14/100, Iteration 50/303, Loss: 0.13070163130760193\n",
      "Epoch 14/100, Iteration 51/303, Loss: 0.059122234582901\n",
      "Epoch 14/100, Iteration 52/303, Loss: 0.12499284744262695\n",
      "Epoch 14/100, Iteration 53/303, Loss: 0.06415043771266937\n",
      "Epoch 14/100, Iteration 54/303, Loss: 0.056781213730573654\n",
      "Epoch 14/100, Iteration 55/303, Loss: 0.1425217092037201\n",
      "Epoch 14/100, Iteration 56/303, Loss: 0.11575538665056229\n",
      "Epoch 14/100, Iteration 57/303, Loss: 0.07034077495336533\n",
      "Epoch 14/100, Iteration 58/303, Loss: 0.10757903754711151\n",
      "Epoch 14/100, Iteration 59/303, Loss: 0.05820174142718315\n",
      "Epoch 14/100, Iteration 60/303, Loss: 0.14524906873703003\n",
      "Epoch 14/100, Iteration 61/303, Loss: 0.09703977406024933\n",
      "Epoch 14/100, Iteration 62/303, Loss: 0.03389298543334007\n",
      "Epoch 14/100, Iteration 63/303, Loss: 0.05525258183479309\n",
      "Epoch 14/100, Iteration 64/303, Loss: 0.05757668986916542\n",
      "Epoch 14/100, Iteration 65/303, Loss: 0.11634983122348785\n",
      "Epoch 14/100, Iteration 66/303, Loss: 0.15262934565544128\n",
      "Epoch 14/100, Iteration 67/303, Loss: 0.058915749192237854\n",
      "Epoch 14/100, Iteration 68/303, Loss: 0.06554415822029114\n",
      "Epoch 14/100, Iteration 69/303, Loss: 0.16862334311008453\n",
      "Epoch 14/100, Iteration 70/303, Loss: 0.02899875119328499\n",
      "Epoch 14/100, Iteration 71/303, Loss: 0.1224474236369133\n",
      "Epoch 14/100, Iteration 72/303, Loss: 0.12699320912361145\n",
      "Epoch 14/100, Iteration 73/303, Loss: 0.04325073957443237\n",
      "Epoch 14/100, Iteration 74/303, Loss: 0.04444477707147598\n",
      "Epoch 14/100, Iteration 75/303, Loss: 0.11064000427722931\n",
      "Epoch 14/100, Iteration 76/303, Loss: 0.12190893292427063\n",
      "Epoch 14/100, Iteration 77/303, Loss: 0.19794589281082153\n",
      "Epoch 14/100, Iteration 78/303, Loss: 0.11298272758722305\n",
      "Epoch 14/100, Iteration 79/303, Loss: 0.08339688926935196\n",
      "Epoch 14/100, Iteration 80/303, Loss: 0.06591150164604187\n",
      "Epoch 14/100, Iteration 81/303, Loss: 0.08844462782144547\n",
      "Epoch 14/100, Iteration 82/303, Loss: 0.019439030438661575\n",
      "Epoch 14/100, Iteration 83/303, Loss: 0.2524275481700897\n",
      "Epoch 14/100, Iteration 84/303, Loss: 0.04600512236356735\n",
      "Epoch 14/100, Iteration 85/303, Loss: 0.11060899496078491\n",
      "Epoch 14/100, Iteration 86/303, Loss: 0.023081475868821144\n",
      "Epoch 14/100, Iteration 87/303, Loss: 0.04321851208806038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Iteration 88/303, Loss: 0.07340916246175766\n",
      "Epoch 14/100, Iteration 89/303, Loss: 0.02512303553521633\n",
      "Epoch 14/100, Iteration 90/303, Loss: 0.052325841039419174\n",
      "Epoch 14/100, Iteration 91/303, Loss: 0.02041805163025856\n",
      "Epoch 14/100, Iteration 92/303, Loss: 0.04450085014104843\n",
      "Epoch 14/100, Iteration 93/303, Loss: 0.056042470037937164\n",
      "Epoch 14/100, Iteration 94/303, Loss: 0.057251617312431335\n",
      "Epoch 14/100, Iteration 95/303, Loss: 0.06229644641280174\n",
      "Epoch 14/100, Iteration 96/303, Loss: 0.056696150451898575\n",
      "Epoch 14/100, Iteration 97/303, Loss: 0.27430102229118347\n",
      "Epoch 14/100, Iteration 98/303, Loss: 0.1599799245595932\n",
      "Epoch 14/100, Iteration 99/303, Loss: 0.07236634939908981\n",
      "Epoch 14/100, Iteration 100/303, Loss: 0.0907873809337616\n",
      "Epoch 14/100, Iteration 101/303, Loss: 0.0793147161602974\n",
      "Epoch 14/100, Iteration 102/303, Loss: 0.13870438933372498\n",
      "Epoch 14/100, Iteration 103/303, Loss: 0.10487954318523407\n",
      "Epoch 14/100, Iteration 104/303, Loss: 0.11089435964822769\n",
      "Epoch 14/100, Iteration 105/303, Loss: 0.043274104595184326\n",
      "Epoch 14/100, Iteration 106/303, Loss: 0.12993526458740234\n",
      "Epoch 14/100, Iteration 107/303, Loss: 0.06273145228624344\n",
      "Epoch 14/100, Iteration 108/303, Loss: 0.07921643555164337\n",
      "Epoch 14/100, Iteration 109/303, Loss: 0.10717371106147766\n",
      "Epoch 14/100, Iteration 110/303, Loss: 0.017083659768104553\n",
      "Epoch 14/100, Iteration 111/303, Loss: 0.032253198325634\n",
      "Epoch 14/100, Iteration 112/303, Loss: 0.017948171123862267\n",
      "Epoch 14/100, Iteration 113/303, Loss: 0.0631704330444336\n",
      "Epoch 14/100, Iteration 114/303, Loss: 0.31337112188339233\n",
      "Epoch 14/100, Iteration 115/303, Loss: 0.08374179899692535\n",
      "Epoch 14/100, Iteration 116/303, Loss: 0.048517126590013504\n",
      "Epoch 14/100, Iteration 117/303, Loss: 0.21185892820358276\n",
      "Epoch 14/100, Iteration 118/303, Loss: 0.09985629469156265\n",
      "Epoch 14/100, Iteration 119/303, Loss: 0.04039502888917923\n",
      "Epoch 14/100, Iteration 120/303, Loss: 0.027406692504882812\n",
      "Epoch 14/100, Iteration 121/303, Loss: 0.056006960570812225\n",
      "Epoch 14/100, Iteration 122/303, Loss: 0.05725785717368126\n",
      "Epoch 14/100, Iteration 123/303, Loss: 0.026511196047067642\n",
      "Epoch 14/100, Iteration 124/303, Loss: 0.07500907778739929\n",
      "Epoch 14/100, Iteration 125/303, Loss: 0.17030060291290283\n",
      "Epoch 14/100, Iteration 126/303, Loss: 0.052906207740306854\n",
      "Epoch 14/100, Iteration 127/303, Loss: 0.14976339042186737\n",
      "Epoch 14/100, Iteration 128/303, Loss: 0.0785984992980957\n",
      "Epoch 14/100, Iteration 129/303, Loss: 0.19308464229106903\n",
      "Epoch 14/100, Iteration 130/303, Loss: 0.0849008858203888\n",
      "Epoch 14/100, Iteration 131/303, Loss: 0.07260239124298096\n",
      "Epoch 14/100, Iteration 132/303, Loss: 0.27148929238319397\n",
      "Epoch 14/100, Iteration 133/303, Loss: 0.1048479825258255\n",
      "Epoch 14/100, Iteration 134/303, Loss: 0.11741273105144501\n",
      "Epoch 14/100, Iteration 135/303, Loss: 0.18166980147361755\n",
      "Epoch 14/100, Iteration 136/303, Loss: 0.07948855310678482\n",
      "Epoch 14/100, Iteration 137/303, Loss: 0.12854287028312683\n",
      "Epoch 14/100, Iteration 138/303, Loss: 0.052271366119384766\n",
      "Epoch 14/100, Iteration 139/303, Loss: 0.09581512212753296\n",
      "Epoch 14/100, Iteration 140/303, Loss: 0.060350071638822556\n",
      "Epoch 14/100, Iteration 141/303, Loss: 0.053149785846471786\n",
      "Epoch 14/100, Iteration 142/303, Loss: 0.0529143400490284\n",
      "Epoch 14/100, Iteration 143/303, Loss: 0.06614094972610474\n",
      "Epoch 14/100, Iteration 144/303, Loss: 0.288938045501709\n",
      "Epoch 14/100, Iteration 145/303, Loss: 0.16901373863220215\n",
      "Epoch 14/100, Iteration 146/303, Loss: 0.24913817644119263\n",
      "Epoch 14/100, Iteration 147/303, Loss: 0.1331586092710495\n",
      "Epoch 14/100, Iteration 148/303, Loss: 0.2034461796283722\n",
      "Epoch 14/100, Iteration 149/303, Loss: 0.053743500262498856\n",
      "Epoch 14/100, Iteration 150/303, Loss: 0.028334110975265503\n",
      "Epoch 14/100, Iteration 151/303, Loss: 0.05763285607099533\n",
      "Epoch 14/100, Iteration 152/303, Loss: 0.05063636973500252\n",
      "Epoch 14/100, Iteration 153/303, Loss: 0.05429438501596451\n",
      "Epoch 14/100, Iteration 154/303, Loss: 0.02679087221622467\n",
      "Epoch 14/100, Iteration 155/303, Loss: 0.41240501403808594\n",
      "Epoch 14/100, Iteration 156/303, Loss: 0.02217094972729683\n",
      "Epoch 14/100, Iteration 157/303, Loss: 0.05109495669603348\n",
      "Epoch 14/100, Iteration 158/303, Loss: 0.10425498336553574\n",
      "Epoch 14/100, Iteration 159/303, Loss: 0.08616562187671661\n",
      "Epoch 14/100, Iteration 160/303, Loss: 0.16445204615592957\n",
      "Epoch 14/100, Iteration 161/303, Loss: 0.15554480254650116\n",
      "Epoch 14/100, Iteration 162/303, Loss: 0.05478065088391304\n",
      "Epoch 14/100, Iteration 163/303, Loss: 0.04048777371644974\n",
      "Epoch 14/100, Iteration 164/303, Loss: 0.09538918733596802\n",
      "Epoch 14/100, Iteration 165/303, Loss: 0.024580825120210648\n",
      "Epoch 14/100, Iteration 166/303, Loss: 0.16522356867790222\n",
      "Epoch 14/100, Iteration 167/303, Loss: 0.08784741163253784\n",
      "Epoch 14/100, Iteration 168/303, Loss: 0.052972495555877686\n",
      "Epoch 14/100, Iteration 169/303, Loss: 0.024038895964622498\n",
      "Epoch 14/100, Iteration 170/303, Loss: 0.0897943302989006\n",
      "Epoch 14/100, Iteration 171/303, Loss: 0.09471981972455978\n",
      "Epoch 14/100, Iteration 172/303, Loss: 0.09888695180416107\n",
      "Epoch 14/100, Iteration 173/303, Loss: 0.012626972049474716\n",
      "Epoch 14/100, Iteration 174/303, Loss: 0.041712839156389236\n",
      "Epoch 14/100, Iteration 175/303, Loss: 0.21029230952262878\n",
      "Epoch 14/100, Iteration 176/303, Loss: 0.14918875694274902\n",
      "Epoch 14/100, Iteration 177/303, Loss: 0.05285876244306564\n",
      "Epoch 14/100, Iteration 178/303, Loss: 0.044359028339385986\n",
      "Epoch 14/100, Iteration 179/303, Loss: 0.06454996764659882\n",
      "Epoch 14/100, Iteration 180/303, Loss: 0.04837905988097191\n",
      "Epoch 14/100, Iteration 181/303, Loss: 0.03783608227968216\n",
      "Epoch 14/100, Iteration 182/303, Loss: 0.09393610805273056\n",
      "Epoch 14/100, Iteration 183/303, Loss: 0.09888722747564316\n",
      "Epoch 14/100, Iteration 184/303, Loss: 0.11309320479631424\n",
      "Epoch 14/100, Iteration 185/303, Loss: 0.18395423889160156\n",
      "Epoch 14/100, Iteration 186/303, Loss: 0.05663938820362091\n",
      "Epoch 14/100, Iteration 187/303, Loss: 0.17689219117164612\n",
      "Epoch 14/100, Iteration 188/303, Loss: 0.066614530980587\n",
      "Epoch 14/100, Iteration 189/303, Loss: 0.08907599002122879\n",
      "Epoch 14/100, Iteration 190/303, Loss: 0.03350791335105896\n",
      "Epoch 14/100, Iteration 191/303, Loss: 0.10720234364271164\n",
      "Epoch 14/100, Iteration 192/303, Loss: 0.03296664357185364\n",
      "Epoch 14/100, Iteration 193/303, Loss: 0.10251680016517639\n",
      "Epoch 14/100, Iteration 194/303, Loss: 0.008507085032761097\n",
      "Epoch 14/100, Iteration 195/303, Loss: 0.08288872241973877\n",
      "Epoch 14/100, Iteration 196/303, Loss: 0.2354794591665268\n",
      "Epoch 14/100, Iteration 197/303, Loss: 0.14714151620864868\n",
      "Epoch 14/100, Iteration 198/303, Loss: 0.07056963443756104\n",
      "Epoch 14/100, Iteration 199/303, Loss: 0.2738620638847351\n",
      "Epoch 14/100, Iteration 200/303, Loss: 0.024088166654109955\n",
      "Epoch 14/100, Iteration 201/303, Loss: 0.02572719380259514\n",
      "Epoch 14/100, Iteration 202/303, Loss: 0.10286357998847961\n",
      "Epoch 14/100, Iteration 203/303, Loss: 0.2554817199707031\n",
      "Epoch 14/100, Iteration 204/303, Loss: 0.08740457147359848\n",
      "Epoch 14/100, Iteration 205/303, Loss: 0.13982811570167542\n",
      "Epoch 14/100, Iteration 206/303, Loss: 0.074188232421875\n",
      "Epoch 14/100, Iteration 207/303, Loss: 0.07639465481042862\n",
      "Epoch 14/100, Iteration 208/303, Loss: 0.0523068942129612\n",
      "Epoch 14/100, Iteration 209/303, Loss: 0.13576194643974304\n",
      "Epoch 14/100, Iteration 210/303, Loss: 0.07239633798599243\n",
      "Epoch 14/100, Iteration 211/303, Loss: 0.09927712380886078\n",
      "Epoch 14/100, Iteration 212/303, Loss: 0.06128760427236557\n",
      "Epoch 14/100, Iteration 213/303, Loss: 0.04676586017012596\n",
      "Epoch 14/100, Iteration 214/303, Loss: 0.09438902139663696\n",
      "Epoch 14/100, Iteration 215/303, Loss: 0.1741071492433548\n",
      "Epoch 14/100, Iteration 216/303, Loss: 0.21892312169075012\n",
      "Epoch 14/100, Iteration 217/303, Loss: 0.19597148895263672\n",
      "Epoch 14/100, Iteration 218/303, Loss: 0.2927939295768738\n",
      "Epoch 14/100, Iteration 219/303, Loss: 0.06958920508623123\n",
      "Epoch 14/100, Iteration 220/303, Loss: 0.09549598395824432\n",
      "Epoch 14/100, Iteration 221/303, Loss: 0.10867828130722046\n",
      "Epoch 14/100, Iteration 222/303, Loss: 0.13077934086322784\n",
      "Epoch 14/100, Iteration 223/303, Loss: 0.03949771448969841\n",
      "Epoch 14/100, Iteration 224/303, Loss: 0.12211399525403976\n",
      "Epoch 14/100, Iteration 225/303, Loss: 0.0643734261393547\n",
      "Epoch 14/100, Iteration 226/303, Loss: 0.07369638979434967\n",
      "Epoch 14/100, Iteration 227/303, Loss: 0.04280850291252136\n",
      "Epoch 14/100, Iteration 228/303, Loss: 0.09257917106151581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Iteration 229/303, Loss: 0.21846716105937958\n",
      "Epoch 14/100, Iteration 230/303, Loss: 0.15089631080627441\n",
      "Epoch 14/100, Iteration 231/303, Loss: 0.07004346698522568\n",
      "Epoch 14/100, Iteration 232/303, Loss: 0.06217261403799057\n",
      "Epoch 14/100, Iteration 233/303, Loss: 0.07876275479793549\n",
      "Epoch 14/100, Iteration 234/303, Loss: 0.11198160797357559\n",
      "Epoch 14/100, Iteration 235/303, Loss: 0.11706280708312988\n",
      "Epoch 14/100, Iteration 236/303, Loss: 0.09722928702831268\n",
      "Epoch 14/100, Iteration 237/303, Loss: 0.11162041127681732\n",
      "Epoch 14/100, Iteration 238/303, Loss: 0.1957278996706009\n",
      "Epoch 14/100, Iteration 239/303, Loss: 0.06641335785388947\n",
      "Epoch 14/100, Iteration 240/303, Loss: 0.014613967388868332\n",
      "Epoch 14/100, Iteration 241/303, Loss: 0.05468084290623665\n",
      "Epoch 14/100, Iteration 242/303, Loss: 0.17676116526126862\n",
      "Epoch 14/100, Iteration 243/303, Loss: 0.1724562644958496\n",
      "Epoch 14/100, Iteration 244/303, Loss: 0.052425891160964966\n",
      "Epoch 14/100, Iteration 245/303, Loss: 0.1196407750248909\n",
      "Epoch 14/100, Iteration 246/303, Loss: 0.1578662097454071\n",
      "Epoch 14/100, Iteration 247/303, Loss: 0.04946403205394745\n",
      "Epoch 14/100, Iteration 248/303, Loss: 0.013069422915577888\n",
      "Epoch 14/100, Iteration 249/303, Loss: 0.08600159734487534\n",
      "Epoch 14/100, Iteration 250/303, Loss: 0.08651180565357208\n",
      "Epoch 14/100, Iteration 251/303, Loss: 0.06449927389621735\n",
      "Epoch 14/100, Iteration 252/303, Loss: 0.12043961137533188\n",
      "Epoch 14/100, Iteration 253/303, Loss: 0.0964420735836029\n",
      "Epoch 14/100, Iteration 254/303, Loss: 0.5088456273078918\n",
      "Epoch 14/100, Iteration 255/303, Loss: 0.15808936953544617\n",
      "Epoch 14/100, Iteration 256/303, Loss: 0.21988123655319214\n",
      "Epoch 14/100, Iteration 257/303, Loss: 0.06253904104232788\n",
      "Epoch 14/100, Iteration 258/303, Loss: 0.0696275532245636\n",
      "Epoch 14/100, Iteration 259/303, Loss: 0.16638123989105225\n",
      "Epoch 14/100, Iteration 260/303, Loss: 0.12098053842782974\n",
      "Epoch 14/100, Iteration 261/303, Loss: 0.11639025062322617\n",
      "Epoch 14/100, Iteration 262/303, Loss: 0.13161221146583557\n",
      "Epoch 14/100, Iteration 263/303, Loss: 0.30480435490608215\n",
      "Epoch 14/100, Iteration 264/303, Loss: 0.06476517766714096\n",
      "Epoch 14/100, Iteration 265/303, Loss: 0.13558833301067352\n",
      "Epoch 14/100, Iteration 266/303, Loss: 0.21044327318668365\n",
      "Epoch 14/100, Iteration 267/303, Loss: 0.5017732381820679\n",
      "Epoch 14/100, Iteration 268/303, Loss: 0.38570356369018555\n",
      "Epoch 14/100, Iteration 269/303, Loss: 0.11012498289346695\n",
      "Epoch 14/100, Iteration 270/303, Loss: 0.12049493193626404\n",
      "Epoch 14/100, Iteration 271/303, Loss: 0.10984279215335846\n",
      "Epoch 14/100, Iteration 272/303, Loss: 0.10116565972566605\n",
      "Epoch 14/100, Iteration 273/303, Loss: 0.04664858803153038\n",
      "Epoch 14/100, Iteration 274/303, Loss: 0.15148614346981049\n",
      "Epoch 14/100, Iteration 275/303, Loss: 0.08276903629302979\n",
      "Epoch 14/100, Iteration 276/303, Loss: 0.08774358034133911\n",
      "Epoch 14/100, Iteration 277/303, Loss: 0.0783698558807373\n",
      "Epoch 14/100, Iteration 278/303, Loss: 0.13995549082756042\n",
      "Epoch 14/100, Iteration 279/303, Loss: 0.05349348485469818\n",
      "Epoch 14/100, Iteration 280/303, Loss: 0.07591889798641205\n",
      "Epoch 14/100, Iteration 281/303, Loss: 0.20273327827453613\n",
      "Epoch 14/100, Iteration 282/303, Loss: 0.15676720440387726\n",
      "Epoch 14/100, Iteration 283/303, Loss: 0.19524556398391724\n",
      "Epoch 14/100, Iteration 284/303, Loss: 0.31119504570961\n",
      "Epoch 14/100, Iteration 285/303, Loss: 0.10378649085760117\n",
      "Epoch 14/100, Iteration 286/303, Loss: 0.08125612884759903\n",
      "Epoch 14/100, Iteration 287/303, Loss: 0.06517031043767929\n",
      "Epoch 14/100, Iteration 288/303, Loss: 0.04339681938290596\n",
      "Epoch 14/100, Iteration 289/303, Loss: 0.15872575342655182\n",
      "Epoch 14/100, Iteration 290/303, Loss: 0.04780879244208336\n",
      "Epoch 14/100, Iteration 291/303, Loss: 0.2541031241416931\n",
      "Epoch 14/100, Iteration 292/303, Loss: 0.07609786838293076\n",
      "Epoch 14/100, Iteration 293/303, Loss: 0.07244832068681717\n",
      "Epoch 14/100, Iteration 294/303, Loss: 0.028426431119441986\n",
      "Epoch 14/100, Iteration 295/303, Loss: 0.0169980488717556\n",
      "Epoch 14/100, Iteration 296/303, Loss: 0.05091053619980812\n",
      "Epoch 14/100, Iteration 297/303, Loss: 0.2757391035556793\n",
      "Epoch 14/100, Iteration 298/303, Loss: 0.10023628920316696\n",
      "Epoch 14/100, Iteration 299/303, Loss: 0.16735298931598663\n",
      "Epoch 14/100, Iteration 300/303, Loss: 0.2986672818660736\n",
      "Epoch 14/100, Iteration 301/303, Loss: 0.06000634282827377\n",
      "Epoch 14/100, Iteration 302/303, Loss: 0.23815782368183136\n",
      "Epoch 14/100, Iteration 303/303, Loss: 0.05863749980926514\n",
      "Epoch 15/100, Iteration 1/303, Loss: 0.051127009093761444\n",
      "Epoch 15/100, Iteration 2/303, Loss: 0.05043925344944\n",
      "Epoch 15/100, Iteration 3/303, Loss: 0.14197707176208496\n",
      "Epoch 15/100, Iteration 4/303, Loss: 0.06055369973182678\n",
      "Epoch 15/100, Iteration 5/303, Loss: 0.03119315765798092\n",
      "Epoch 15/100, Iteration 6/303, Loss: 0.0940089225769043\n",
      "Epoch 15/100, Iteration 7/303, Loss: 0.09092652797698975\n",
      "Epoch 15/100, Iteration 8/303, Loss: 0.17181800305843353\n",
      "Epoch 15/100, Iteration 9/303, Loss: 0.0444425567984581\n",
      "Epoch 15/100, Iteration 10/303, Loss: 0.13868533074855804\n",
      "Epoch 15/100, Iteration 11/303, Loss: 0.16825436055660248\n",
      "Epoch 15/100, Iteration 12/303, Loss: 0.03213616833090782\n",
      "Epoch 15/100, Iteration 13/303, Loss: 0.019654255360364914\n",
      "Epoch 15/100, Iteration 14/303, Loss: 0.05867650359869003\n",
      "Epoch 15/100, Iteration 15/303, Loss: 0.03508409485220909\n",
      "Epoch 15/100, Iteration 16/303, Loss: 0.04343416541814804\n",
      "Epoch 15/100, Iteration 17/303, Loss: 0.07397425174713135\n",
      "Epoch 15/100, Iteration 18/303, Loss: 0.06422088295221329\n",
      "Epoch 15/100, Iteration 19/303, Loss: 0.04044269025325775\n",
      "Epoch 15/100, Iteration 20/303, Loss: 0.03952948376536369\n",
      "Epoch 15/100, Iteration 21/303, Loss: 0.06248694658279419\n",
      "Epoch 15/100, Iteration 22/303, Loss: 0.1843899041414261\n",
      "Epoch 15/100, Iteration 23/303, Loss: 0.02425992116332054\n",
      "Epoch 15/100, Iteration 24/303, Loss: 0.0637015774846077\n",
      "Epoch 15/100, Iteration 25/303, Loss: 0.03502940759062767\n",
      "Epoch 15/100, Iteration 26/303, Loss: 0.04313788190484047\n",
      "Epoch 15/100, Iteration 27/303, Loss: 0.039962977170944214\n",
      "Epoch 15/100, Iteration 28/303, Loss: 0.06873515248298645\n",
      "Epoch 15/100, Iteration 29/303, Loss: 0.035544052720069885\n",
      "Epoch 15/100, Iteration 30/303, Loss: 0.03830372914671898\n",
      "Epoch 15/100, Iteration 31/303, Loss: 0.036631133407354355\n",
      "Epoch 15/100, Iteration 32/303, Loss: 0.08901336789131165\n",
      "Epoch 15/100, Iteration 33/303, Loss: 0.05145735293626785\n",
      "Epoch 15/100, Iteration 34/303, Loss: 0.1053728386759758\n",
      "Epoch 15/100, Iteration 35/303, Loss: 0.10772156715393066\n",
      "Epoch 15/100, Iteration 36/303, Loss: 0.06232411786913872\n",
      "Epoch 15/100, Iteration 37/303, Loss: 0.09379643201828003\n",
      "Epoch 15/100, Iteration 38/303, Loss: 0.0923883393406868\n",
      "Epoch 15/100, Iteration 39/303, Loss: 0.012484018690884113\n",
      "Epoch 15/100, Iteration 40/303, Loss: 0.02452109009027481\n",
      "Epoch 15/100, Iteration 41/303, Loss: 0.03168375790119171\n",
      "Epoch 15/100, Iteration 42/303, Loss: 0.019431401044130325\n",
      "Epoch 15/100, Iteration 43/303, Loss: 0.023367319256067276\n",
      "Epoch 15/100, Iteration 44/303, Loss: 0.029609492048621178\n",
      "Epoch 15/100, Iteration 45/303, Loss: 0.008448406122624874\n",
      "Epoch 15/100, Iteration 46/303, Loss: 0.046611689031124115\n",
      "Epoch 15/100, Iteration 47/303, Loss: 0.06459743529558182\n",
      "Epoch 15/100, Iteration 48/303, Loss: 0.015832845121622086\n",
      "Epoch 15/100, Iteration 49/303, Loss: 0.04382181912660599\n",
      "Epoch 15/100, Iteration 50/303, Loss: 0.06653397530317307\n",
      "Epoch 15/100, Iteration 51/303, Loss: 0.10536989569664001\n",
      "Epoch 15/100, Iteration 52/303, Loss: 0.03887056186795235\n",
      "Epoch 15/100, Iteration 53/303, Loss: 0.035579849034547806\n",
      "Epoch 15/100, Iteration 54/303, Loss: 0.0396907739341259\n",
      "Epoch 15/100, Iteration 55/303, Loss: 0.03769494965672493\n",
      "Epoch 15/100, Iteration 56/303, Loss: 0.06393778324127197\n",
      "Epoch 15/100, Iteration 57/303, Loss: 0.057357821613550186\n",
      "Epoch 15/100, Iteration 58/303, Loss: 0.05788583680987358\n",
      "Epoch 15/100, Iteration 59/303, Loss: 0.020192034542560577\n",
      "Epoch 15/100, Iteration 60/303, Loss: 0.04647015035152435\n",
      "Epoch 15/100, Iteration 61/303, Loss: 0.04780033230781555\n",
      "Epoch 15/100, Iteration 62/303, Loss: 0.03512975201010704\n",
      "Epoch 15/100, Iteration 63/303, Loss: 0.05090292543172836\n",
      "Epoch 15/100, Iteration 64/303, Loss: 0.017047539353370667\n",
      "Epoch 15/100, Iteration 65/303, Loss: 0.02630261331796646\n",
      "Epoch 15/100, Iteration 66/303, Loss: 0.010654060170054436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100, Iteration 67/303, Loss: 0.053957752883434296\n",
      "Epoch 15/100, Iteration 68/303, Loss: 0.03312398120760918\n",
      "Epoch 15/100, Iteration 69/303, Loss: 0.00884188525378704\n",
      "Epoch 15/100, Iteration 70/303, Loss: 0.01679699495434761\n",
      "Epoch 15/100, Iteration 71/303, Loss: 0.00700295390561223\n",
      "Epoch 15/100, Iteration 72/303, Loss: 0.08139398694038391\n",
      "Epoch 15/100, Iteration 73/303, Loss: 0.05344805121421814\n",
      "Epoch 15/100, Iteration 74/303, Loss: 0.14368410408496857\n",
      "Epoch 15/100, Iteration 75/303, Loss: 0.05357503518462181\n",
      "Epoch 15/100, Iteration 76/303, Loss: 0.01840713806450367\n",
      "Epoch 15/100, Iteration 77/303, Loss: 0.031532835215330124\n",
      "Epoch 15/100, Iteration 78/303, Loss: 0.04100582376122475\n",
      "Epoch 15/100, Iteration 79/303, Loss: 0.027880460023880005\n",
      "Epoch 15/100, Iteration 80/303, Loss: 0.05870669335126877\n",
      "Epoch 15/100, Iteration 81/303, Loss: 0.17523369193077087\n",
      "Epoch 15/100, Iteration 82/303, Loss: 0.08259039372205734\n",
      "Epoch 15/100, Iteration 83/303, Loss: 0.03764602914452553\n",
      "Epoch 15/100, Iteration 84/303, Loss: 0.07458245009183884\n",
      "Epoch 15/100, Iteration 85/303, Loss: 0.03827131912112236\n",
      "Epoch 15/100, Iteration 86/303, Loss: 0.13946345448493958\n",
      "Epoch 15/100, Iteration 87/303, Loss: 0.02507973089814186\n",
      "Epoch 15/100, Iteration 88/303, Loss: 0.07873719185590744\n",
      "Epoch 15/100, Iteration 89/303, Loss: 0.0638432577252388\n",
      "Epoch 15/100, Iteration 90/303, Loss: 0.05519783869385719\n",
      "Epoch 15/100, Iteration 91/303, Loss: 0.03620152920484543\n",
      "Epoch 15/100, Iteration 92/303, Loss: 0.08068081736564636\n",
      "Epoch 15/100, Iteration 93/303, Loss: 0.03157144412398338\n",
      "Epoch 15/100, Iteration 94/303, Loss: 0.12366379052400589\n",
      "Epoch 15/100, Iteration 95/303, Loss: 0.015942301601171494\n",
      "Epoch 15/100, Iteration 96/303, Loss: 0.0030801636166870594\n",
      "Epoch 15/100, Iteration 97/303, Loss: 0.0245585385710001\n",
      "Epoch 15/100, Iteration 98/303, Loss: 0.07300806790590286\n",
      "Epoch 15/100, Iteration 99/303, Loss: 0.025395730510354042\n",
      "Epoch 15/100, Iteration 100/303, Loss: 0.0833958089351654\n",
      "Epoch 15/100, Iteration 101/303, Loss: 0.059076499193906784\n",
      "Epoch 15/100, Iteration 102/303, Loss: 0.012839683331549168\n",
      "Epoch 15/100, Iteration 103/303, Loss: 0.033283017575740814\n",
      "Epoch 15/100, Iteration 104/303, Loss: 0.03416726738214493\n",
      "Epoch 15/100, Iteration 105/303, Loss: 0.028566470369696617\n",
      "Epoch 15/100, Iteration 106/303, Loss: 0.04389692842960358\n",
      "Epoch 15/100, Iteration 107/303, Loss: 0.04117918759584427\n",
      "Epoch 15/100, Iteration 108/303, Loss: 0.0876292809844017\n",
      "Epoch 15/100, Iteration 109/303, Loss: 0.05308017507195473\n",
      "Epoch 15/100, Iteration 110/303, Loss: 0.023273766040802002\n",
      "Epoch 15/100, Iteration 111/303, Loss: 0.05372517928481102\n",
      "Epoch 15/100, Iteration 112/303, Loss: 0.19902147352695465\n",
      "Epoch 15/100, Iteration 113/303, Loss: 0.321708619594574\n",
      "Epoch 15/100, Iteration 114/303, Loss: 0.17148016393184662\n",
      "Epoch 15/100, Iteration 115/303, Loss: 0.35277801752090454\n",
      "Epoch 15/100, Iteration 116/303, Loss: 0.251409113407135\n",
      "Epoch 15/100, Iteration 117/303, Loss: 0.24515676498413086\n",
      "Epoch 15/100, Iteration 118/303, Loss: 0.11661597341299057\n",
      "Epoch 15/100, Iteration 119/303, Loss: 0.02799287624657154\n",
      "Epoch 15/100, Iteration 120/303, Loss: 0.023881955072283745\n",
      "Epoch 15/100, Iteration 121/303, Loss: 0.05075819417834282\n",
      "Epoch 15/100, Iteration 122/303, Loss: 0.16003793478012085\n",
      "Epoch 15/100, Iteration 123/303, Loss: 0.04730831831693649\n",
      "Epoch 15/100, Iteration 124/303, Loss: 0.09541860222816467\n",
      "Epoch 15/100, Iteration 125/303, Loss: 0.09423238784074783\n",
      "Epoch 15/100, Iteration 126/303, Loss: 0.2872719168663025\n",
      "Epoch 15/100, Iteration 127/303, Loss: 0.14180436730384827\n",
      "Epoch 15/100, Iteration 128/303, Loss: 0.01805829256772995\n",
      "Epoch 15/100, Iteration 129/303, Loss: 0.40447577834129333\n",
      "Epoch 15/100, Iteration 130/303, Loss: 0.05400365591049194\n",
      "Epoch 15/100, Iteration 131/303, Loss: 0.06026832014322281\n",
      "Epoch 15/100, Iteration 132/303, Loss: 0.10462065041065216\n",
      "Epoch 15/100, Iteration 133/303, Loss: 0.06184021010994911\n",
      "Epoch 15/100, Iteration 134/303, Loss: 0.08094114810228348\n",
      "Epoch 15/100, Iteration 135/303, Loss: 0.11769405007362366\n",
      "Epoch 15/100, Iteration 136/303, Loss: 0.055646903812885284\n",
      "Epoch 15/100, Iteration 137/303, Loss: 0.03365899994969368\n",
      "Epoch 15/100, Iteration 138/303, Loss: 0.037952035665512085\n",
      "Epoch 15/100, Iteration 139/303, Loss: 0.03572582080960274\n",
      "Epoch 15/100, Iteration 140/303, Loss: 0.03324374556541443\n",
      "Epoch 15/100, Iteration 141/303, Loss: 0.08780445903539658\n",
      "Epoch 15/100, Iteration 142/303, Loss: 0.07878240942955017\n",
      "Epoch 15/100, Iteration 143/303, Loss: 0.06870660930871964\n",
      "Epoch 15/100, Iteration 144/303, Loss: 0.15962423384189606\n",
      "Epoch 15/100, Iteration 145/303, Loss: 0.1699569672346115\n",
      "Epoch 15/100, Iteration 146/303, Loss: 0.008082508109509945\n",
      "Epoch 15/100, Iteration 147/303, Loss: 0.0875738263130188\n",
      "Epoch 15/100, Iteration 148/303, Loss: 0.08175761252641678\n",
      "Epoch 15/100, Iteration 149/303, Loss: 0.04925840348005295\n",
      "Epoch 15/100, Iteration 150/303, Loss: 0.09031028300523758\n",
      "Epoch 15/100, Iteration 151/303, Loss: 0.07119900733232498\n",
      "Epoch 15/100, Iteration 152/303, Loss: 0.03442000597715378\n",
      "Epoch 15/100, Iteration 153/303, Loss: 0.07906793057918549\n",
      "Epoch 15/100, Iteration 154/303, Loss: 0.0644056648015976\n",
      "Epoch 15/100, Iteration 155/303, Loss: 0.060788027942180634\n",
      "Epoch 15/100, Iteration 156/303, Loss: 0.15896601974964142\n",
      "Epoch 15/100, Iteration 157/303, Loss: 0.03674060106277466\n",
      "Epoch 15/100, Iteration 158/303, Loss: 0.032736778259277344\n",
      "Epoch 15/100, Iteration 159/303, Loss: 0.09451771527528763\n",
      "Epoch 15/100, Iteration 160/303, Loss: 0.03000650182366371\n",
      "Epoch 15/100, Iteration 161/303, Loss: 0.018579360097646713\n",
      "Epoch 15/100, Iteration 162/303, Loss: 0.05188975855708122\n",
      "Epoch 15/100, Iteration 163/303, Loss: 0.06226634606719017\n",
      "Epoch 15/100, Iteration 164/303, Loss: 0.06466787308454514\n",
      "Epoch 15/100, Iteration 165/303, Loss: 0.06932839006185532\n",
      "Epoch 15/100, Iteration 166/303, Loss: 0.047556549310684204\n",
      "Epoch 15/100, Iteration 167/303, Loss: 0.0584513284265995\n",
      "Epoch 15/100, Iteration 168/303, Loss: 0.10353956371545792\n",
      "Epoch 15/100, Iteration 169/303, Loss: 0.03744009882211685\n",
      "Epoch 15/100, Iteration 170/303, Loss: 0.06798073649406433\n",
      "Epoch 15/100, Iteration 171/303, Loss: 0.039462458342313766\n",
      "Epoch 15/100, Iteration 172/303, Loss: 0.031842105090618134\n",
      "Epoch 15/100, Iteration 173/303, Loss: 0.025801530107855797\n",
      "Epoch 15/100, Iteration 174/303, Loss: 0.04397991672158241\n",
      "Epoch 15/100, Iteration 175/303, Loss: 0.06917308270931244\n",
      "Epoch 15/100, Iteration 176/303, Loss: 0.0449061281979084\n",
      "Epoch 15/100, Iteration 177/303, Loss: 0.03699341043829918\n",
      "Epoch 15/100, Iteration 178/303, Loss: 0.03721259906888008\n",
      "Epoch 15/100, Iteration 179/303, Loss: 0.12843024730682373\n",
      "Epoch 15/100, Iteration 180/303, Loss: 0.09910237789154053\n",
      "Epoch 15/100, Iteration 181/303, Loss: 0.12975075840950012\n",
      "Epoch 15/100, Iteration 182/303, Loss: 0.0668179839849472\n",
      "Epoch 15/100, Iteration 183/303, Loss: 0.136076882481575\n",
      "Epoch 15/100, Iteration 184/303, Loss: 0.03060493804514408\n",
      "Epoch 15/100, Iteration 185/303, Loss: 0.0823160856962204\n",
      "Epoch 15/100, Iteration 186/303, Loss: 0.05510590225458145\n",
      "Epoch 15/100, Iteration 187/303, Loss: 0.1538221836090088\n",
      "Epoch 15/100, Iteration 188/303, Loss: 0.15438398718833923\n",
      "Epoch 15/100, Iteration 189/303, Loss: 0.05625249072909355\n",
      "Epoch 15/100, Iteration 190/303, Loss: 0.04094681516289711\n",
      "Epoch 15/100, Iteration 191/303, Loss: 0.02418469451367855\n",
      "Epoch 15/100, Iteration 192/303, Loss: 0.09686528891324997\n",
      "Epoch 15/100, Iteration 193/303, Loss: 0.32672494649887085\n",
      "Epoch 15/100, Iteration 194/303, Loss: 0.5718683004379272\n",
      "Epoch 15/100, Iteration 195/303, Loss: 0.3110019564628601\n",
      "Epoch 15/100, Iteration 196/303, Loss: 0.13939695060253143\n",
      "Epoch 15/100, Iteration 197/303, Loss: 0.11178272217512131\n",
      "Epoch 15/100, Iteration 198/303, Loss: 0.08675707876682281\n",
      "Epoch 15/100, Iteration 199/303, Loss: 0.06913524121046066\n",
      "Epoch 15/100, Iteration 200/303, Loss: 0.01903826743364334\n",
      "Epoch 15/100, Iteration 201/303, Loss: 0.09113718569278717\n",
      "Epoch 15/100, Iteration 202/303, Loss: 0.08298337459564209\n",
      "Epoch 15/100, Iteration 203/303, Loss: 0.11630435287952423\n",
      "Epoch 15/100, Iteration 204/303, Loss: 0.06286357343196869\n",
      "Epoch 15/100, Iteration 205/303, Loss: 0.19529542326927185\n",
      "Epoch 15/100, Iteration 206/303, Loss: 0.09218316525220871\n",
      "Epoch 15/100, Iteration 207/303, Loss: 0.11589368432760239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100, Iteration 208/303, Loss: 0.22433502972126007\n",
      "Epoch 15/100, Iteration 209/303, Loss: 0.1638949066400528\n",
      "Epoch 15/100, Iteration 210/303, Loss: 0.1136832907795906\n",
      "Epoch 15/100, Iteration 211/303, Loss: 0.02878035418689251\n",
      "Epoch 15/100, Iteration 212/303, Loss: 0.08013381063938141\n",
      "Epoch 15/100, Iteration 213/303, Loss: 0.03840865567326546\n",
      "Epoch 15/100, Iteration 214/303, Loss: 0.1999487727880478\n",
      "Epoch 15/100, Iteration 215/303, Loss: 0.13355442881584167\n",
      "Epoch 15/100, Iteration 216/303, Loss: 0.2668529748916626\n",
      "Epoch 15/100, Iteration 217/303, Loss: 0.04257895052433014\n",
      "Epoch 15/100, Iteration 218/303, Loss: 0.08520153164863586\n",
      "Epoch 15/100, Iteration 219/303, Loss: 0.03747548535466194\n",
      "Epoch 15/100, Iteration 220/303, Loss: 0.17176108062267303\n",
      "Epoch 15/100, Iteration 221/303, Loss: 0.015010058879852295\n",
      "Epoch 15/100, Iteration 222/303, Loss: 0.03395708277821541\n",
      "Epoch 15/100, Iteration 223/303, Loss: 0.0549410805106163\n",
      "Epoch 15/100, Iteration 224/303, Loss: 0.09761040657758713\n",
      "Epoch 15/100, Iteration 225/303, Loss: 0.10466758161783218\n",
      "Epoch 15/100, Iteration 226/303, Loss: 0.022300459444522858\n",
      "Epoch 15/100, Iteration 227/303, Loss: 0.0395175963640213\n",
      "Epoch 15/100, Iteration 228/303, Loss: 0.10368796437978745\n",
      "Epoch 15/100, Iteration 229/303, Loss: 0.07486238330602646\n",
      "Epoch 15/100, Iteration 230/303, Loss: 0.04415750131011009\n",
      "Epoch 15/100, Iteration 231/303, Loss: 0.3277782201766968\n",
      "Epoch 15/100, Iteration 232/303, Loss: 0.04358811303973198\n",
      "Epoch 15/100, Iteration 233/303, Loss: 0.033881280571222305\n",
      "Epoch 15/100, Iteration 234/303, Loss: 0.05831705033779144\n",
      "Epoch 15/100, Iteration 235/303, Loss: 0.10653433948755264\n",
      "Epoch 15/100, Iteration 236/303, Loss: 0.03534390777349472\n",
      "Epoch 15/100, Iteration 237/303, Loss: 0.11111172288656235\n",
      "Epoch 15/100, Iteration 238/303, Loss: 0.15545113384723663\n",
      "Epoch 15/100, Iteration 239/303, Loss: 0.1740792840719223\n",
      "Epoch 15/100, Iteration 240/303, Loss: 0.11784431338310242\n",
      "Epoch 15/100, Iteration 241/303, Loss: 0.06294122338294983\n",
      "Epoch 15/100, Iteration 242/303, Loss: 0.05978507921099663\n",
      "Epoch 15/100, Iteration 243/303, Loss: 0.1523512303829193\n",
      "Epoch 15/100, Iteration 244/303, Loss: 0.06222257763147354\n",
      "Epoch 15/100, Iteration 245/303, Loss: 0.11323721706867218\n",
      "Epoch 15/100, Iteration 246/303, Loss: 0.11114662885665894\n",
      "Epoch 15/100, Iteration 247/303, Loss: 0.02421283908188343\n",
      "Epoch 15/100, Iteration 248/303, Loss: 0.018160630017518997\n",
      "Epoch 15/100, Iteration 249/303, Loss: 0.016390902921557426\n",
      "Epoch 15/100, Iteration 250/303, Loss: 0.14089958369731903\n",
      "Epoch 15/100, Iteration 251/303, Loss: 0.024484500288963318\n",
      "Epoch 15/100, Iteration 252/303, Loss: 0.010266098193824291\n",
      "Epoch 15/100, Iteration 253/303, Loss: 0.01517607644200325\n",
      "Epoch 15/100, Iteration 254/303, Loss: 0.07723649591207504\n",
      "Epoch 15/100, Iteration 255/303, Loss: 0.030499309301376343\n",
      "Epoch 15/100, Iteration 256/303, Loss: 0.09155327081680298\n",
      "Epoch 15/100, Iteration 257/303, Loss: 0.054264526814222336\n",
      "Epoch 15/100, Iteration 258/303, Loss: 0.03681928291916847\n",
      "Epoch 15/100, Iteration 259/303, Loss: 0.08834326267242432\n",
      "Epoch 15/100, Iteration 260/303, Loss: 0.09964610636234283\n",
      "Epoch 15/100, Iteration 261/303, Loss: 0.06295570731163025\n",
      "Epoch 15/100, Iteration 262/303, Loss: 0.07114194333553314\n",
      "Epoch 15/100, Iteration 263/303, Loss: 0.21776869893074036\n",
      "Epoch 15/100, Iteration 264/303, Loss: 0.053152140229940414\n",
      "Epoch 15/100, Iteration 265/303, Loss: 0.059613268822431564\n",
      "Epoch 15/100, Iteration 266/303, Loss: 0.07441193610429764\n",
      "Epoch 15/100, Iteration 267/303, Loss: 0.041766341775655746\n",
      "Epoch 15/100, Iteration 268/303, Loss: 0.1456901580095291\n",
      "Epoch 15/100, Iteration 269/303, Loss: 0.0783587098121643\n",
      "Epoch 15/100, Iteration 270/303, Loss: 0.04287814721465111\n",
      "Epoch 15/100, Iteration 271/303, Loss: 0.08586722612380981\n",
      "Epoch 15/100, Iteration 272/303, Loss: 0.053961656987667084\n",
      "Epoch 15/100, Iteration 273/303, Loss: 0.050838153809309006\n",
      "Epoch 15/100, Iteration 274/303, Loss: 0.0791095644235611\n",
      "Epoch 15/100, Iteration 275/303, Loss: 0.10285282880067825\n",
      "Epoch 15/100, Iteration 276/303, Loss: 0.049201466143131256\n",
      "Epoch 15/100, Iteration 277/303, Loss: 0.08540870249271393\n",
      "Epoch 15/100, Iteration 278/303, Loss: 0.08297130465507507\n",
      "Epoch 15/100, Iteration 279/303, Loss: 0.015523271635174751\n",
      "Epoch 15/100, Iteration 280/303, Loss: 0.06646940112113953\n",
      "Epoch 15/100, Iteration 281/303, Loss: 0.08269882202148438\n",
      "Epoch 15/100, Iteration 282/303, Loss: 0.06769554316997528\n",
      "Epoch 15/100, Iteration 283/303, Loss: 0.062334977090358734\n",
      "Epoch 15/100, Iteration 284/303, Loss: 0.11357460170984268\n",
      "Epoch 15/100, Iteration 285/303, Loss: 0.06478894501924515\n",
      "Epoch 15/100, Iteration 286/303, Loss: 0.06641808897256851\n",
      "Epoch 15/100, Iteration 287/303, Loss: 0.21001949906349182\n",
      "Epoch 15/100, Iteration 288/303, Loss: 0.2297547608613968\n",
      "Epoch 15/100, Iteration 289/303, Loss: 0.08199916034936905\n",
      "Epoch 15/100, Iteration 290/303, Loss: 0.1277739703655243\n",
      "Epoch 15/100, Iteration 291/303, Loss: 0.13837140798568726\n",
      "Epoch 15/100, Iteration 292/303, Loss: 0.02076856605708599\n",
      "Epoch 15/100, Iteration 293/303, Loss: 0.11463044583797455\n",
      "Epoch 15/100, Iteration 294/303, Loss: 0.08454678952693939\n",
      "Epoch 15/100, Iteration 295/303, Loss: 0.0806543231010437\n",
      "Epoch 15/100, Iteration 296/303, Loss: 0.06903231889009476\n",
      "Epoch 15/100, Iteration 297/303, Loss: 0.21922937035560608\n",
      "Epoch 15/100, Iteration 298/303, Loss: 0.18930724263191223\n",
      "Epoch 15/100, Iteration 299/303, Loss: 0.045623257756233215\n",
      "Epoch 15/100, Iteration 300/303, Loss: 0.034547243267297745\n",
      "Epoch 15/100, Iteration 301/303, Loss: 0.11612880229949951\n",
      "Epoch 15/100, Iteration 302/303, Loss: 0.16617615520954132\n",
      "Epoch 15/100, Iteration 303/303, Loss: 0.0545676164329052\n",
      "Epoch 16/100, Iteration 1/303, Loss: 0.01940535195171833\n",
      "Epoch 16/100, Iteration 2/303, Loss: 0.044218890368938446\n",
      "Epoch 16/100, Iteration 3/303, Loss: 0.025314319878816605\n",
      "Epoch 16/100, Iteration 4/303, Loss: 0.04724540561437607\n",
      "Epoch 16/100, Iteration 5/303, Loss: 0.03509758412837982\n",
      "Epoch 16/100, Iteration 6/303, Loss: 0.0198017917573452\n",
      "Epoch 16/100, Iteration 7/303, Loss: 0.02095550112426281\n",
      "Epoch 16/100, Iteration 8/303, Loss: 0.31551802158355713\n",
      "Epoch 16/100, Iteration 9/303, Loss: 0.05309455096721649\n",
      "Epoch 16/100, Iteration 10/303, Loss: 0.023988250643014908\n",
      "Epoch 16/100, Iteration 11/303, Loss: 0.021041063591837883\n",
      "Epoch 16/100, Iteration 12/303, Loss: 0.02562760002911091\n",
      "Epoch 16/100, Iteration 13/303, Loss: 0.06601617485284805\n",
      "Epoch 16/100, Iteration 14/303, Loss: 0.023744579404592514\n",
      "Epoch 16/100, Iteration 15/303, Loss: 0.051930610090494156\n",
      "Epoch 16/100, Iteration 16/303, Loss: 0.03504228591918945\n",
      "Epoch 16/100, Iteration 17/303, Loss: 0.012877029366791248\n",
      "Epoch 16/100, Iteration 18/303, Loss: 0.12284920364618301\n",
      "Epoch 16/100, Iteration 19/303, Loss: 0.04418928921222687\n",
      "Epoch 16/100, Iteration 20/303, Loss: 0.009318653494119644\n",
      "Epoch 16/100, Iteration 21/303, Loss: 0.02276448719203472\n",
      "Epoch 16/100, Iteration 22/303, Loss: 0.03811933472752571\n",
      "Epoch 16/100, Iteration 23/303, Loss: 0.06490416079759598\n",
      "Epoch 16/100, Iteration 24/303, Loss: 0.020680876448750496\n",
      "Epoch 16/100, Iteration 25/303, Loss: 0.01399572379887104\n",
      "Epoch 16/100, Iteration 26/303, Loss: 0.03729443624615669\n",
      "Epoch 16/100, Iteration 27/303, Loss: 0.009232617914676666\n",
      "Epoch 16/100, Iteration 28/303, Loss: 0.019847340881824493\n",
      "Epoch 16/100, Iteration 29/303, Loss: 0.02280353754758835\n",
      "Epoch 16/100, Iteration 30/303, Loss: 0.06557197123765945\n",
      "Epoch 16/100, Iteration 31/303, Loss: 0.022066893056035042\n",
      "Epoch 16/100, Iteration 32/303, Loss: 0.016393117606639862\n",
      "Epoch 16/100, Iteration 33/303, Loss: 0.10115450620651245\n",
      "Epoch 16/100, Iteration 34/303, Loss: 0.023677904158830643\n",
      "Epoch 16/100, Iteration 35/303, Loss: 0.011968142352998257\n",
      "Epoch 16/100, Iteration 36/303, Loss: 0.06599412858486176\n",
      "Epoch 16/100, Iteration 37/303, Loss: 0.04100550338625908\n",
      "Epoch 16/100, Iteration 38/303, Loss: 0.02236790955066681\n",
      "Epoch 16/100, Iteration 39/303, Loss: 0.0442412905395031\n",
      "Epoch 16/100, Iteration 40/303, Loss: 0.01014420110732317\n",
      "Epoch 16/100, Iteration 41/303, Loss: 0.038696348667144775\n",
      "Epoch 16/100, Iteration 42/303, Loss: 0.005449782591313124\n",
      "Epoch 16/100, Iteration 43/303, Loss: 0.03131069615483284\n",
      "Epoch 16/100, Iteration 44/303, Loss: 0.050348155200481415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Iteration 45/303, Loss: 0.012507162988185883\n",
      "Epoch 16/100, Iteration 46/303, Loss: 0.032042257487773895\n",
      "Epoch 16/100, Iteration 47/303, Loss: 0.055593132972717285\n",
      "Epoch 16/100, Iteration 48/303, Loss: 0.012413221411406994\n",
      "Epoch 16/100, Iteration 49/303, Loss: 0.0094883032143116\n",
      "Epoch 16/100, Iteration 50/303, Loss: 0.05601474642753601\n",
      "Epoch 16/100, Iteration 51/303, Loss: 0.03168632462620735\n",
      "Epoch 16/100, Iteration 52/303, Loss: 0.020996183156967163\n",
      "Epoch 16/100, Iteration 53/303, Loss: 0.007729736622422934\n",
      "Epoch 16/100, Iteration 54/303, Loss: 0.012371540069580078\n",
      "Epoch 16/100, Iteration 55/303, Loss: 0.0973970890045166\n",
      "Epoch 16/100, Iteration 56/303, Loss: 0.07417579740285873\n",
      "Epoch 16/100, Iteration 57/303, Loss: 0.015397953800857067\n",
      "Epoch 16/100, Iteration 58/303, Loss: 0.016293087974190712\n",
      "Epoch 16/100, Iteration 59/303, Loss: 0.016621019691228867\n",
      "Epoch 16/100, Iteration 60/303, Loss: 0.006450934335589409\n",
      "Epoch 16/100, Iteration 61/303, Loss: 0.0712815374135971\n",
      "Epoch 16/100, Iteration 62/303, Loss: 0.02532096393406391\n",
      "Epoch 16/100, Iteration 63/303, Loss: 0.04294241964817047\n",
      "Epoch 16/100, Iteration 64/303, Loss: 0.04581015184521675\n",
      "Epoch 16/100, Iteration 65/303, Loss: 0.022372929379343987\n",
      "Epoch 16/100, Iteration 66/303, Loss: 0.057179249823093414\n",
      "Epoch 16/100, Iteration 67/303, Loss: 0.006723881233483553\n",
      "Epoch 16/100, Iteration 68/303, Loss: 0.014763272367417812\n",
      "Epoch 16/100, Iteration 69/303, Loss: 0.06956765800714493\n",
      "Epoch 16/100, Iteration 70/303, Loss: 0.07708203047513962\n",
      "Epoch 16/100, Iteration 71/303, Loss: 0.005741399712860584\n",
      "Epoch 16/100, Iteration 72/303, Loss: 0.007434390950948\n",
      "Epoch 16/100, Iteration 73/303, Loss: 0.03348623961210251\n",
      "Epoch 16/100, Iteration 74/303, Loss: 0.03400300070643425\n",
      "Epoch 16/100, Iteration 75/303, Loss: 0.03004218079149723\n",
      "Epoch 16/100, Iteration 76/303, Loss: 0.04278136044740677\n",
      "Epoch 16/100, Iteration 77/303, Loss: 0.07335623353719711\n",
      "Epoch 16/100, Iteration 78/303, Loss: 0.08819092810153961\n",
      "Epoch 16/100, Iteration 79/303, Loss: 0.01617136411368847\n",
      "Epoch 16/100, Iteration 80/303, Loss: 0.03900735452771187\n",
      "Epoch 16/100, Iteration 81/303, Loss: 0.06893989443778992\n",
      "Epoch 16/100, Iteration 82/303, Loss: 0.012678081169724464\n",
      "Epoch 16/100, Iteration 83/303, Loss: 0.00605293083935976\n",
      "Epoch 16/100, Iteration 84/303, Loss: 0.02972549945116043\n",
      "Epoch 16/100, Iteration 85/303, Loss: 0.07442708313465118\n",
      "Epoch 16/100, Iteration 86/303, Loss: 0.014192808419466019\n",
      "Epoch 16/100, Iteration 87/303, Loss: 0.05448087304830551\n",
      "Epoch 16/100, Iteration 88/303, Loss: 0.009901290759444237\n",
      "Epoch 16/100, Iteration 89/303, Loss: 0.016512151807546616\n",
      "Epoch 16/100, Iteration 90/303, Loss: 0.01903221383690834\n",
      "Epoch 16/100, Iteration 91/303, Loss: 0.047604527324438095\n",
      "Epoch 16/100, Iteration 92/303, Loss: 0.037984225898981094\n",
      "Epoch 16/100, Iteration 93/303, Loss: 0.04033743962645531\n",
      "Epoch 16/100, Iteration 94/303, Loss: 0.0174245648086071\n",
      "Epoch 16/100, Iteration 95/303, Loss: 0.008004169911146164\n",
      "Epoch 16/100, Iteration 96/303, Loss: 0.005926998797804117\n",
      "Epoch 16/100, Iteration 97/303, Loss: 0.008382970467209816\n",
      "Epoch 16/100, Iteration 98/303, Loss: 0.0073521193116903305\n",
      "Epoch 16/100, Iteration 99/303, Loss: 0.0028996507171541452\n",
      "Epoch 16/100, Iteration 100/303, Loss: 0.025529086589813232\n",
      "Epoch 16/100, Iteration 101/303, Loss: 0.02833574078977108\n",
      "Epoch 16/100, Iteration 102/303, Loss: 0.01620236225426197\n",
      "Epoch 16/100, Iteration 103/303, Loss: 0.011854779906570911\n",
      "Epoch 16/100, Iteration 104/303, Loss: 0.008176866918802261\n",
      "Epoch 16/100, Iteration 105/303, Loss: 0.004289945587515831\n",
      "Epoch 16/100, Iteration 106/303, Loss: 0.06533822417259216\n",
      "Epoch 16/100, Iteration 107/303, Loss: 0.061616528779268265\n",
      "Epoch 16/100, Iteration 108/303, Loss: 0.048783473670482635\n",
      "Epoch 16/100, Iteration 109/303, Loss: 0.05974672734737396\n",
      "Epoch 16/100, Iteration 110/303, Loss: 0.07065370678901672\n",
      "Epoch 16/100, Iteration 111/303, Loss: 0.06469234079122543\n",
      "Epoch 16/100, Iteration 112/303, Loss: 0.002759179100394249\n",
      "Epoch 16/100, Iteration 113/303, Loss: 0.053601719439029694\n",
      "Epoch 16/100, Iteration 114/303, Loss: 0.009022130630910397\n",
      "Epoch 16/100, Iteration 115/303, Loss: 0.013160795904695988\n",
      "Epoch 16/100, Iteration 116/303, Loss: 0.0115820849314332\n",
      "Epoch 16/100, Iteration 117/303, Loss: 0.01629764772951603\n",
      "Epoch 16/100, Iteration 118/303, Loss: 0.0714995265007019\n",
      "Epoch 16/100, Iteration 119/303, Loss: 0.011125363409519196\n",
      "Epoch 16/100, Iteration 120/303, Loss: 0.02133474498987198\n",
      "Epoch 16/100, Iteration 121/303, Loss: 0.038848914206027985\n",
      "Epoch 16/100, Iteration 122/303, Loss: 0.01719304546713829\n",
      "Epoch 16/100, Iteration 123/303, Loss: 0.11651398241519928\n",
      "Epoch 16/100, Iteration 124/303, Loss: 0.03661547601222992\n",
      "Epoch 16/100, Iteration 125/303, Loss: 0.06917805969715118\n",
      "Epoch 16/100, Iteration 126/303, Loss: 0.08662741631269455\n",
      "Epoch 16/100, Iteration 127/303, Loss: 0.03334056958556175\n",
      "Epoch 16/100, Iteration 128/303, Loss: 0.01589234732091427\n",
      "Epoch 16/100, Iteration 129/303, Loss: 0.017564190551638603\n",
      "Epoch 16/100, Iteration 130/303, Loss: 0.012478744611144066\n",
      "Epoch 16/100, Iteration 131/303, Loss: 0.09463288635015488\n",
      "Epoch 16/100, Iteration 132/303, Loss: 0.04876711219549179\n",
      "Epoch 16/100, Iteration 133/303, Loss: 0.0757511779665947\n",
      "Epoch 16/100, Iteration 134/303, Loss: 0.018675558269023895\n",
      "Epoch 16/100, Iteration 135/303, Loss: 0.03034859523177147\n",
      "Epoch 16/100, Iteration 136/303, Loss: 0.06655390560626984\n",
      "Epoch 16/100, Iteration 137/303, Loss: 0.029848864302039146\n",
      "Epoch 16/100, Iteration 138/303, Loss: 0.08539740741252899\n",
      "Epoch 16/100, Iteration 139/303, Loss: 0.12947888672351837\n",
      "Epoch 16/100, Iteration 140/303, Loss: 0.025309596210718155\n",
      "Epoch 16/100, Iteration 141/303, Loss: 0.025925274938344955\n",
      "Epoch 16/100, Iteration 142/303, Loss: 0.06430242210626602\n",
      "Epoch 16/100, Iteration 143/303, Loss: 0.02367127127945423\n",
      "Epoch 16/100, Iteration 144/303, Loss: 0.042929451912641525\n",
      "Epoch 16/100, Iteration 145/303, Loss: 0.03412861377000809\n",
      "Epoch 16/100, Iteration 146/303, Loss: 0.012372737750411034\n",
      "Epoch 16/100, Iteration 147/303, Loss: 0.019265230745077133\n",
      "Epoch 16/100, Iteration 148/303, Loss: 0.007639355957508087\n",
      "Epoch 16/100, Iteration 149/303, Loss: 0.06399261206388474\n",
      "Epoch 16/100, Iteration 150/303, Loss: 0.019353074952960014\n",
      "Epoch 16/100, Iteration 151/303, Loss: 0.025036092847585678\n",
      "Epoch 16/100, Iteration 152/303, Loss: 0.016418376937508583\n",
      "Epoch 16/100, Iteration 153/303, Loss: 0.07848722487688065\n",
      "Epoch 16/100, Iteration 154/303, Loss: 0.009742450900375843\n",
      "Epoch 16/100, Iteration 155/303, Loss: 0.03529568389058113\n",
      "Epoch 16/100, Iteration 156/303, Loss: 0.19458837807178497\n",
      "Epoch 16/100, Iteration 157/303, Loss: 0.2520994246006012\n",
      "Epoch 16/100, Iteration 158/303, Loss: 0.1695536971092224\n",
      "Epoch 16/100, Iteration 159/303, Loss: 0.2623583674430847\n",
      "Epoch 16/100, Iteration 160/303, Loss: 0.42592108249664307\n",
      "Epoch 16/100, Iteration 161/303, Loss: 0.24799925088882446\n",
      "Epoch 16/100, Iteration 162/303, Loss: 0.19488829374313354\n",
      "Epoch 16/100, Iteration 163/303, Loss: 0.07335667312145233\n",
      "Epoch 16/100, Iteration 164/303, Loss: 0.013118376024067402\n",
      "Epoch 16/100, Iteration 165/303, Loss: 0.031561121344566345\n",
      "Epoch 16/100, Iteration 166/303, Loss: 0.04873453080654144\n",
      "Epoch 16/100, Iteration 167/303, Loss: 0.06638174504041672\n",
      "Epoch 16/100, Iteration 168/303, Loss: 0.023498669266700745\n",
      "Epoch 16/100, Iteration 169/303, Loss: 0.02607319876551628\n",
      "Epoch 16/100, Iteration 170/303, Loss: 0.019207829609513283\n",
      "Epoch 16/100, Iteration 171/303, Loss: 0.03004361316561699\n",
      "Epoch 16/100, Iteration 172/303, Loss: 0.02754516899585724\n",
      "Epoch 16/100, Iteration 173/303, Loss: 0.023721298202872276\n",
      "Epoch 16/100, Iteration 174/303, Loss: 0.08087706565856934\n",
      "Epoch 16/100, Iteration 175/303, Loss: 0.03218402713537216\n",
      "Epoch 16/100, Iteration 176/303, Loss: 0.015246802009642124\n",
      "Epoch 16/100, Iteration 177/303, Loss: 0.06680379807949066\n",
      "Epoch 16/100, Iteration 178/303, Loss: 0.04128775745630264\n",
      "Epoch 16/100, Iteration 179/303, Loss: 0.018400326371192932\n",
      "Epoch 16/100, Iteration 180/303, Loss: 0.027377119287848473\n",
      "Epoch 16/100, Iteration 181/303, Loss: 0.05359121784567833\n",
      "Epoch 16/100, Iteration 182/303, Loss: 0.020617714151740074\n",
      "Epoch 16/100, Iteration 183/303, Loss: 0.033541999757289886\n",
      "Epoch 16/100, Iteration 184/303, Loss: 0.05994625389575958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Iteration 185/303, Loss: 0.04330167919397354\n",
      "Epoch 16/100, Iteration 186/303, Loss: 0.016904689371585846\n",
      "Epoch 16/100, Iteration 187/303, Loss: 0.06995371729135513\n",
      "Epoch 16/100, Iteration 188/303, Loss: 0.01588720642030239\n",
      "Epoch 16/100, Iteration 189/303, Loss: 0.05269927904009819\n",
      "Epoch 16/100, Iteration 190/303, Loss: 0.09296755492687225\n",
      "Epoch 16/100, Iteration 191/303, Loss: 0.046095121651887894\n",
      "Epoch 16/100, Iteration 192/303, Loss: 0.08025649189949036\n",
      "Epoch 16/100, Iteration 193/303, Loss: 0.01901298388838768\n",
      "Epoch 16/100, Iteration 194/303, Loss: 0.09959666430950165\n",
      "Epoch 16/100, Iteration 195/303, Loss: 0.044348638504743576\n",
      "Epoch 16/100, Iteration 196/303, Loss: 0.03255641087889671\n",
      "Epoch 16/100, Iteration 197/303, Loss: 0.0735684186220169\n",
      "Epoch 16/100, Iteration 198/303, Loss: 0.014175294898450375\n",
      "Epoch 16/100, Iteration 199/303, Loss: 0.14126594364643097\n",
      "Epoch 16/100, Iteration 200/303, Loss: 0.03453043848276138\n",
      "Epoch 16/100, Iteration 201/303, Loss: 0.017039829865098\n",
      "Epoch 16/100, Iteration 202/303, Loss: 0.00515775429084897\n",
      "Epoch 16/100, Iteration 203/303, Loss: 0.03799008950591087\n",
      "Epoch 16/100, Iteration 204/303, Loss: 0.12572897970676422\n",
      "Epoch 16/100, Iteration 205/303, Loss: 0.07054165750741959\n",
      "Epoch 16/100, Iteration 206/303, Loss: 0.040120333433151245\n",
      "Epoch 16/100, Iteration 207/303, Loss: 0.027990834787487984\n",
      "Epoch 16/100, Iteration 208/303, Loss: 0.06400629132986069\n",
      "Epoch 16/100, Iteration 209/303, Loss: 0.1122187003493309\n",
      "Epoch 16/100, Iteration 210/303, Loss: 0.16288554668426514\n",
      "Epoch 16/100, Iteration 211/303, Loss: 0.31435102224349976\n",
      "Epoch 16/100, Iteration 212/303, Loss: 0.06478115916252136\n",
      "Epoch 16/100, Iteration 213/303, Loss: 0.05743372440338135\n",
      "Epoch 16/100, Iteration 214/303, Loss: 0.006218524184077978\n",
      "Epoch 16/100, Iteration 215/303, Loss: 0.05427689850330353\n",
      "Epoch 16/100, Iteration 216/303, Loss: 0.0930754542350769\n",
      "Epoch 16/100, Iteration 217/303, Loss: 0.07463967800140381\n",
      "Epoch 16/100, Iteration 218/303, Loss: 0.03928966447710991\n",
      "Epoch 16/100, Iteration 219/303, Loss: 0.07507789134979248\n",
      "Epoch 16/100, Iteration 220/303, Loss: 0.09803652763366699\n",
      "Epoch 16/100, Iteration 221/303, Loss: 0.06849502772092819\n",
      "Epoch 16/100, Iteration 222/303, Loss: 0.020531464368104935\n",
      "Epoch 16/100, Iteration 223/303, Loss: 0.0405469685792923\n",
      "Epoch 16/100, Iteration 224/303, Loss: 0.04052969068288803\n",
      "Epoch 16/100, Iteration 225/303, Loss: 0.0819818452000618\n",
      "Epoch 16/100, Iteration 226/303, Loss: 0.036850862205028534\n",
      "Epoch 16/100, Iteration 227/303, Loss: 0.030041201040148735\n",
      "Epoch 16/100, Iteration 228/303, Loss: 0.07214802503585815\n",
      "Epoch 16/100, Iteration 229/303, Loss: 0.13235460221767426\n",
      "Epoch 16/100, Iteration 230/303, Loss: 0.09329234808683395\n",
      "Epoch 16/100, Iteration 231/303, Loss: 0.12596477568149567\n",
      "Epoch 16/100, Iteration 232/303, Loss: 0.15139442682266235\n",
      "Epoch 16/100, Iteration 233/303, Loss: 0.04171740263700485\n",
      "Epoch 16/100, Iteration 234/303, Loss: 0.04011077806353569\n",
      "Epoch 16/100, Iteration 235/303, Loss: 0.11564916372299194\n",
      "Epoch 16/100, Iteration 236/303, Loss: 0.015782199800014496\n",
      "Epoch 16/100, Iteration 237/303, Loss: 0.017264418303966522\n",
      "Epoch 16/100, Iteration 238/303, Loss: 0.03476360812783241\n",
      "Epoch 16/100, Iteration 239/303, Loss: 0.004624910186976194\n",
      "Epoch 16/100, Iteration 240/303, Loss: 0.06235285848379135\n",
      "Epoch 16/100, Iteration 241/303, Loss: 0.1147051528096199\n",
      "Epoch 16/100, Iteration 242/303, Loss: 0.09442131221294403\n",
      "Epoch 16/100, Iteration 243/303, Loss: 0.1646810919046402\n",
      "Epoch 16/100, Iteration 244/303, Loss: 0.07582616806030273\n",
      "Epoch 16/100, Iteration 245/303, Loss: 0.19461847841739655\n",
      "Epoch 16/100, Iteration 246/303, Loss: 0.4159761071205139\n",
      "Epoch 16/100, Iteration 247/303, Loss: 0.39015457034111023\n",
      "Epoch 16/100, Iteration 248/303, Loss: 0.09387151896953583\n",
      "Epoch 16/100, Iteration 249/303, Loss: 0.05316412076354027\n",
      "Epoch 16/100, Iteration 250/303, Loss: 0.10781014710664749\n",
      "Epoch 16/100, Iteration 251/303, Loss: 0.13225162029266357\n",
      "Epoch 16/100, Iteration 252/303, Loss: 0.0763806477189064\n",
      "Epoch 16/100, Iteration 253/303, Loss: 0.0361219197511673\n",
      "Epoch 16/100, Iteration 254/303, Loss: 0.23433251678943634\n",
      "Epoch 16/100, Iteration 255/303, Loss: 0.09706354886293411\n",
      "Epoch 16/100, Iteration 256/303, Loss: 0.13447317481040955\n",
      "Epoch 16/100, Iteration 257/303, Loss: 0.01930342987179756\n",
      "Epoch 16/100, Iteration 258/303, Loss: 0.03282402828335762\n",
      "Epoch 16/100, Iteration 259/303, Loss: 0.14382418990135193\n",
      "Epoch 16/100, Iteration 260/303, Loss: 0.20190517604351044\n",
      "Epoch 16/100, Iteration 261/303, Loss: 0.04376590624451637\n",
      "Epoch 16/100, Iteration 262/303, Loss: 0.040160275995731354\n",
      "Epoch 16/100, Iteration 263/303, Loss: 0.07573452591896057\n",
      "Epoch 16/100, Iteration 264/303, Loss: 0.06084148585796356\n",
      "Epoch 16/100, Iteration 265/303, Loss: 0.025072084739804268\n",
      "Epoch 16/100, Iteration 266/303, Loss: 0.0627063661813736\n",
      "Epoch 16/100, Iteration 267/303, Loss: 0.07205765694379807\n",
      "Epoch 16/100, Iteration 268/303, Loss: 0.08096672594547272\n",
      "Epoch 16/100, Iteration 269/303, Loss: 0.04788684844970703\n",
      "Epoch 16/100, Iteration 270/303, Loss: 0.09780529886484146\n",
      "Epoch 16/100, Iteration 271/303, Loss: 0.07942274212837219\n",
      "Epoch 16/100, Iteration 272/303, Loss: 0.03464026376605034\n",
      "Epoch 16/100, Iteration 273/303, Loss: 0.05086604878306389\n",
      "Epoch 16/100, Iteration 274/303, Loss: 0.03442562744021416\n",
      "Epoch 16/100, Iteration 275/303, Loss: 0.04334300756454468\n",
      "Epoch 16/100, Iteration 276/303, Loss: 0.009015090763568878\n",
      "Epoch 16/100, Iteration 277/303, Loss: 0.04851227253675461\n",
      "Epoch 16/100, Iteration 278/303, Loss: 0.006860955618321896\n",
      "Epoch 16/100, Iteration 279/303, Loss: 0.044100720435380936\n",
      "Epoch 16/100, Iteration 280/303, Loss: 0.008482169359922409\n",
      "Epoch 16/100, Iteration 281/303, Loss: 0.04392459988594055\n",
      "Epoch 16/100, Iteration 282/303, Loss: 0.010837593115866184\n",
      "Epoch 16/100, Iteration 283/303, Loss: 0.1675778329372406\n",
      "Epoch 16/100, Iteration 284/303, Loss: 0.1590343713760376\n",
      "Epoch 16/100, Iteration 285/303, Loss: 0.06750534474849701\n",
      "Epoch 16/100, Iteration 286/303, Loss: 0.04757640138268471\n",
      "Epoch 16/100, Iteration 287/303, Loss: 0.03832920268177986\n",
      "Epoch 16/100, Iteration 288/303, Loss: 0.06901010870933533\n",
      "Epoch 16/100, Iteration 289/303, Loss: 0.10700879245996475\n",
      "Epoch 16/100, Iteration 290/303, Loss: 0.032691143453121185\n",
      "Epoch 16/100, Iteration 291/303, Loss: 0.08156736195087433\n",
      "Epoch 16/100, Iteration 292/303, Loss: 0.4202221632003784\n",
      "Epoch 16/100, Iteration 293/303, Loss: 0.040381044149398804\n",
      "Epoch 16/100, Iteration 294/303, Loss: 0.057571567595005035\n",
      "Epoch 16/100, Iteration 295/303, Loss: 0.07585876435041428\n",
      "Epoch 16/100, Iteration 296/303, Loss: 0.1336883306503296\n",
      "Epoch 16/100, Iteration 297/303, Loss: 0.05818823352456093\n",
      "Epoch 16/100, Iteration 298/303, Loss: 0.0904775932431221\n",
      "Epoch 16/100, Iteration 299/303, Loss: 0.07119397819042206\n",
      "Epoch 16/100, Iteration 300/303, Loss: 0.026049792766571045\n",
      "Epoch 16/100, Iteration 301/303, Loss: 0.04261692240834236\n",
      "Epoch 16/100, Iteration 302/303, Loss: 0.0052359928376972675\n",
      "Epoch 16/100, Iteration 303/303, Loss: 0.08876443654298782\n",
      "Epoch 17/100, Iteration 1/303, Loss: 0.04617218300700188\n",
      "Epoch 17/100, Iteration 2/303, Loss: 0.03343167528510094\n",
      "Epoch 17/100, Iteration 3/303, Loss: 0.01550107542425394\n",
      "Epoch 17/100, Iteration 4/303, Loss: 0.010459675453603268\n",
      "Epoch 17/100, Iteration 5/303, Loss: 0.06803462654352188\n",
      "Epoch 17/100, Iteration 6/303, Loss: 0.013431007042527199\n",
      "Epoch 17/100, Iteration 7/303, Loss: 0.1202201396226883\n",
      "Epoch 17/100, Iteration 8/303, Loss: 0.04583088308572769\n",
      "Epoch 17/100, Iteration 9/303, Loss: 0.07373734563589096\n",
      "Epoch 17/100, Iteration 10/303, Loss: 0.168555349111557\n",
      "Epoch 17/100, Iteration 11/303, Loss: 0.03963824734091759\n",
      "Epoch 17/100, Iteration 12/303, Loss: 0.12116677314043045\n",
      "Epoch 17/100, Iteration 13/303, Loss: 0.0668104812502861\n",
      "Epoch 17/100, Iteration 14/303, Loss: 0.025771155953407288\n",
      "Epoch 17/100, Iteration 15/303, Loss: 0.02436140738427639\n",
      "Epoch 17/100, Iteration 16/303, Loss: 0.07231123000383377\n",
      "Epoch 17/100, Iteration 17/303, Loss: 0.021159227937459946\n",
      "Epoch 17/100, Iteration 18/303, Loss: 0.029118090867996216\n",
      "Epoch 17/100, Iteration 19/303, Loss: 0.057460881769657135\n",
      "Epoch 17/100, Iteration 20/303, Loss: 0.007234157528728247\n",
      "Epoch 17/100, Iteration 21/303, Loss: 0.024639775976538658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Iteration 22/303, Loss: 0.04850266873836517\n",
      "Epoch 17/100, Iteration 23/303, Loss: 0.0059859538450837135\n",
      "Epoch 17/100, Iteration 24/303, Loss: 0.009475731290876865\n",
      "Epoch 17/100, Iteration 25/303, Loss: 0.024701306596398354\n",
      "Epoch 17/100, Iteration 26/303, Loss: 0.021090762689709663\n",
      "Epoch 17/100, Iteration 27/303, Loss: 0.05757284536957741\n",
      "Epoch 17/100, Iteration 28/303, Loss: 0.022744379937648773\n",
      "Epoch 17/100, Iteration 29/303, Loss: 0.013802040368318558\n",
      "Epoch 17/100, Iteration 30/303, Loss: 0.007202723063528538\n",
      "Epoch 17/100, Iteration 31/303, Loss: 0.03183313459157944\n",
      "Epoch 17/100, Iteration 32/303, Loss: 0.032663494348526\n",
      "Epoch 17/100, Iteration 33/303, Loss: 0.02174285613000393\n",
      "Epoch 17/100, Iteration 34/303, Loss: 0.03805641829967499\n",
      "Epoch 17/100, Iteration 35/303, Loss: 0.020680522546172142\n",
      "Epoch 17/100, Iteration 36/303, Loss: 0.00420382572337985\n",
      "Epoch 17/100, Iteration 37/303, Loss: 0.00874107051640749\n",
      "Epoch 17/100, Iteration 38/303, Loss: 0.02429373934864998\n",
      "Epoch 17/100, Iteration 39/303, Loss: 0.018944958224892616\n",
      "Epoch 17/100, Iteration 40/303, Loss: 0.0019033728167414665\n",
      "Epoch 17/100, Iteration 41/303, Loss: 0.0040428307838737965\n",
      "Epoch 17/100, Iteration 42/303, Loss: 0.13889235258102417\n",
      "Epoch 17/100, Iteration 43/303, Loss: 0.01918068155646324\n",
      "Epoch 17/100, Iteration 44/303, Loss: 0.0087998416274786\n",
      "Epoch 17/100, Iteration 45/303, Loss: 0.018765589222311974\n",
      "Epoch 17/100, Iteration 46/303, Loss: 0.042593907564878464\n",
      "Epoch 17/100, Iteration 47/303, Loss: 0.01873175986111164\n",
      "Epoch 17/100, Iteration 48/303, Loss: 0.01246633380651474\n",
      "Epoch 17/100, Iteration 49/303, Loss: 0.012146521359682083\n",
      "Epoch 17/100, Iteration 50/303, Loss: 0.013969119638204575\n",
      "Epoch 17/100, Iteration 51/303, Loss: 0.013549654744565487\n",
      "Epoch 17/100, Iteration 52/303, Loss: 0.006241020280867815\n",
      "Epoch 17/100, Iteration 53/303, Loss: 0.004639021120965481\n",
      "Epoch 17/100, Iteration 54/303, Loss: 0.014830118045210838\n",
      "Epoch 17/100, Iteration 55/303, Loss: 0.004131258465349674\n",
      "Epoch 17/100, Iteration 56/303, Loss: 0.013059615157544613\n",
      "Epoch 17/100, Iteration 57/303, Loss: 0.013519169762730598\n",
      "Epoch 17/100, Iteration 58/303, Loss: 0.01370713859796524\n",
      "Epoch 17/100, Iteration 59/303, Loss: 0.004150804132223129\n",
      "Epoch 17/100, Iteration 60/303, Loss: 0.03205270320177078\n",
      "Epoch 17/100, Iteration 61/303, Loss: 0.03700225055217743\n",
      "Epoch 17/100, Iteration 62/303, Loss: 0.009383446536958218\n",
      "Epoch 17/100, Iteration 63/303, Loss: 0.06845451146364212\n",
      "Epoch 17/100, Iteration 64/303, Loss: 0.11713290959596634\n",
      "Epoch 17/100, Iteration 65/303, Loss: 0.004310554824769497\n",
      "Epoch 17/100, Iteration 66/303, Loss: 0.016164327040314674\n",
      "Epoch 17/100, Iteration 67/303, Loss: 0.12632277607917786\n",
      "Epoch 17/100, Iteration 68/303, Loss: 0.1152811199426651\n",
      "Epoch 17/100, Iteration 69/303, Loss: 0.07587205618619919\n",
      "Epoch 17/100, Iteration 70/303, Loss: 0.006441260222345591\n",
      "Epoch 17/100, Iteration 71/303, Loss: 0.08474136888980865\n",
      "Epoch 17/100, Iteration 72/303, Loss: 0.05297774821519852\n",
      "Epoch 17/100, Iteration 73/303, Loss: 0.05318031832575798\n",
      "Epoch 17/100, Iteration 74/303, Loss: 0.010864397510886192\n",
      "Epoch 17/100, Iteration 75/303, Loss: 0.013852160423994064\n",
      "Epoch 17/100, Iteration 76/303, Loss: 0.009481541812419891\n",
      "Epoch 17/100, Iteration 77/303, Loss: 0.022566931322216988\n",
      "Epoch 17/100, Iteration 78/303, Loss: 0.023646580055356026\n",
      "Epoch 17/100, Iteration 79/303, Loss: 0.01821010559797287\n",
      "Epoch 17/100, Iteration 80/303, Loss: 0.02158181741833687\n",
      "Epoch 17/100, Iteration 81/303, Loss: 0.004716956056654453\n",
      "Epoch 17/100, Iteration 82/303, Loss: 0.046472739428281784\n",
      "Epoch 17/100, Iteration 83/303, Loss: 0.03215458616614342\n",
      "Epoch 17/100, Iteration 84/303, Loss: 0.022663237527012825\n",
      "Epoch 17/100, Iteration 85/303, Loss: 0.017023691907525063\n",
      "Epoch 17/100, Iteration 86/303, Loss: 0.024927087128162384\n",
      "Epoch 17/100, Iteration 87/303, Loss: 0.016679007560014725\n",
      "Epoch 17/100, Iteration 88/303, Loss: 0.01140824519097805\n",
      "Epoch 17/100, Iteration 89/303, Loss: 0.01247844286262989\n",
      "Epoch 17/100, Iteration 90/303, Loss: 0.01361776888370514\n",
      "Epoch 17/100, Iteration 91/303, Loss: 0.006197819020599127\n",
      "Epoch 17/100, Iteration 92/303, Loss: 0.005984602961689234\n",
      "Epoch 17/100, Iteration 93/303, Loss: 0.015570308081805706\n",
      "Epoch 17/100, Iteration 94/303, Loss: 0.04135636240243912\n",
      "Epoch 17/100, Iteration 95/303, Loss: 0.01222208421677351\n",
      "Epoch 17/100, Iteration 96/303, Loss: 0.0035085065755993128\n",
      "Epoch 17/100, Iteration 97/303, Loss: 0.00547051103785634\n",
      "Epoch 17/100, Iteration 98/303, Loss: 0.0015943339094519615\n",
      "Epoch 17/100, Iteration 99/303, Loss: 0.007060017436742783\n",
      "Epoch 17/100, Iteration 100/303, Loss: 0.00991116650402546\n",
      "Epoch 17/100, Iteration 101/303, Loss: 0.0026094678323715925\n",
      "Epoch 17/100, Iteration 102/303, Loss: 0.03521738201379776\n",
      "Epoch 17/100, Iteration 103/303, Loss: 0.04767337813973427\n",
      "Epoch 17/100, Iteration 104/303, Loss: 0.01581130549311638\n",
      "Epoch 17/100, Iteration 105/303, Loss: 0.004903033375740051\n",
      "Epoch 17/100, Iteration 106/303, Loss: 0.11079475283622742\n",
      "Epoch 17/100, Iteration 107/303, Loss: 0.013928686268627644\n",
      "Epoch 17/100, Iteration 108/303, Loss: 0.0897214412689209\n",
      "Epoch 17/100, Iteration 109/303, Loss: 0.013010745868086815\n",
      "Epoch 17/100, Iteration 110/303, Loss: 0.23309145867824554\n",
      "Epoch 17/100, Iteration 111/303, Loss: 0.14053472876548767\n",
      "Epoch 17/100, Iteration 112/303, Loss: 0.03042728453874588\n",
      "Epoch 17/100, Iteration 113/303, Loss: 0.051997024565935135\n",
      "Epoch 17/100, Iteration 114/303, Loss: 0.015618120320141315\n",
      "Epoch 17/100, Iteration 115/303, Loss: 0.02964087948203087\n",
      "Epoch 17/100, Iteration 116/303, Loss: 0.02036118134856224\n",
      "Epoch 17/100, Iteration 117/303, Loss: 0.08656453341245651\n",
      "Epoch 17/100, Iteration 118/303, Loss: 0.11541907489299774\n",
      "Epoch 17/100, Iteration 119/303, Loss: 0.08972389250993729\n",
      "Epoch 17/100, Iteration 120/303, Loss: 0.051043085753917694\n",
      "Epoch 17/100, Iteration 121/303, Loss: 0.06754596531391144\n",
      "Epoch 17/100, Iteration 122/303, Loss: 0.01374366506934166\n",
      "Epoch 17/100, Iteration 123/303, Loss: 0.024257320910692215\n",
      "Epoch 17/100, Iteration 124/303, Loss: 0.020681826397776604\n",
      "Epoch 17/100, Iteration 125/303, Loss: 0.03931122645735741\n",
      "Epoch 17/100, Iteration 126/303, Loss: 0.06834303587675095\n",
      "Epoch 17/100, Iteration 127/303, Loss: 0.07498530298471451\n",
      "Epoch 17/100, Iteration 128/303, Loss: 0.05508726090192795\n",
      "Epoch 17/100, Iteration 129/303, Loss: 0.07276240736246109\n",
      "Epoch 17/100, Iteration 130/303, Loss: 0.10601583123207092\n",
      "Epoch 17/100, Iteration 131/303, Loss: 0.14456342160701752\n",
      "Epoch 17/100, Iteration 132/303, Loss: 0.036922864615917206\n",
      "Epoch 17/100, Iteration 133/303, Loss: 0.002523028524592519\n",
      "Epoch 17/100, Iteration 134/303, Loss: 0.05009888857603073\n",
      "Epoch 17/100, Iteration 135/303, Loss: 0.023820910602808\n",
      "Epoch 17/100, Iteration 136/303, Loss: 0.012018690817058086\n",
      "Epoch 17/100, Iteration 137/303, Loss: 0.02036675065755844\n",
      "Epoch 17/100, Iteration 138/303, Loss: 0.014111353084445\n",
      "Epoch 17/100, Iteration 139/303, Loss: 0.00675164395943284\n",
      "Epoch 17/100, Iteration 140/303, Loss: 0.08367294818162918\n",
      "Epoch 17/100, Iteration 141/303, Loss: 0.043034136295318604\n",
      "Epoch 17/100, Iteration 142/303, Loss: 0.015819508582353592\n",
      "Epoch 17/100, Iteration 143/303, Loss: 0.011509217321872711\n",
      "Epoch 17/100, Iteration 144/303, Loss: 0.04828626289963722\n",
      "Epoch 17/100, Iteration 145/303, Loss: 0.017003539949655533\n",
      "Epoch 17/100, Iteration 146/303, Loss: 0.0031298950780183077\n",
      "Epoch 17/100, Iteration 147/303, Loss: 0.12956422567367554\n",
      "Epoch 17/100, Iteration 148/303, Loss: 0.03415178135037422\n",
      "Epoch 17/100, Iteration 149/303, Loss: 0.048726413398981094\n",
      "Epoch 17/100, Iteration 150/303, Loss: 0.02527511678636074\n",
      "Epoch 17/100, Iteration 151/303, Loss: 0.03396899998188019\n",
      "Epoch 17/100, Iteration 152/303, Loss: 0.014866085723042488\n",
      "Epoch 17/100, Iteration 153/303, Loss: 0.015176674351096153\n",
      "Epoch 17/100, Iteration 154/303, Loss: 0.01457157265394926\n",
      "Epoch 17/100, Iteration 155/303, Loss: 0.1020062193274498\n",
      "Epoch 17/100, Iteration 156/303, Loss: 0.07571788132190704\n",
      "Epoch 17/100, Iteration 157/303, Loss: 0.018575498834252357\n",
      "Epoch 17/100, Iteration 158/303, Loss: 0.02002287283539772\n",
      "Epoch 17/100, Iteration 159/303, Loss: 0.018203139305114746\n",
      "Epoch 17/100, Iteration 160/303, Loss: 0.035877473652362823\n",
      "Epoch 17/100, Iteration 161/303, Loss: 0.017300281673669815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Iteration 162/303, Loss: 0.025962594896554947\n",
      "Epoch 17/100, Iteration 163/303, Loss: 0.0015496942214667797\n",
      "Epoch 17/100, Iteration 164/303, Loss: 0.003298425115644932\n",
      "Epoch 17/100, Iteration 165/303, Loss: 0.02468772977590561\n",
      "Epoch 17/100, Iteration 166/303, Loss: 0.055797167122364044\n",
      "Epoch 17/100, Iteration 167/303, Loss: 0.03074520453810692\n",
      "Epoch 17/100, Iteration 168/303, Loss: 0.007055975962430239\n",
      "Epoch 17/100, Iteration 169/303, Loss: 0.03864903375506401\n",
      "Epoch 17/100, Iteration 170/303, Loss: 0.016557808965444565\n",
      "Epoch 17/100, Iteration 171/303, Loss: 0.03154017776250839\n",
      "Epoch 17/100, Iteration 172/303, Loss: 0.00986927654594183\n",
      "Epoch 17/100, Iteration 173/303, Loss: 0.08475781977176666\n",
      "Epoch 17/100, Iteration 174/303, Loss: 0.008303462527692318\n",
      "Epoch 17/100, Iteration 175/303, Loss: 0.04322803020477295\n",
      "Epoch 17/100, Iteration 176/303, Loss: 0.017548315227031708\n",
      "Epoch 17/100, Iteration 177/303, Loss: 0.01588793657720089\n",
      "Epoch 17/100, Iteration 178/303, Loss: 0.09605242311954498\n",
      "Epoch 17/100, Iteration 179/303, Loss: 0.008347121067345142\n",
      "Epoch 17/100, Iteration 180/303, Loss: 0.013392134569585323\n",
      "Epoch 17/100, Iteration 181/303, Loss: 0.050477974116802216\n",
      "Epoch 17/100, Iteration 182/303, Loss: 0.0385194793343544\n",
      "Epoch 17/100, Iteration 183/303, Loss: 0.063210129737854\n",
      "Epoch 17/100, Iteration 184/303, Loss: 0.09381147474050522\n",
      "Epoch 17/100, Iteration 185/303, Loss: 0.21712297201156616\n",
      "Epoch 17/100, Iteration 186/303, Loss: 0.017852701246738434\n",
      "Epoch 17/100, Iteration 187/303, Loss: 0.1086701899766922\n",
      "Epoch 17/100, Iteration 188/303, Loss: 0.0952184721827507\n",
      "Epoch 17/100, Iteration 189/303, Loss: 0.07876642048358917\n",
      "Epoch 17/100, Iteration 190/303, Loss: 0.021273108199238777\n",
      "Epoch 17/100, Iteration 191/303, Loss: 0.011379257775843143\n",
      "Epoch 17/100, Iteration 192/303, Loss: 0.11043400317430496\n",
      "Epoch 17/100, Iteration 193/303, Loss: 0.06164012476801872\n",
      "Epoch 17/100, Iteration 194/303, Loss: 0.18306177854537964\n",
      "Epoch 17/100, Iteration 195/303, Loss: 0.002985444152727723\n",
      "Epoch 17/100, Iteration 196/303, Loss: 0.07587599009275436\n",
      "Epoch 17/100, Iteration 197/303, Loss: 0.11149150133132935\n",
      "Epoch 17/100, Iteration 198/303, Loss: 0.11600746214389801\n",
      "Epoch 17/100, Iteration 199/303, Loss: 0.12702155113220215\n",
      "Epoch 17/100, Iteration 200/303, Loss: 0.0283734742552042\n",
      "Epoch 17/100, Iteration 201/303, Loss: 0.03713951259851456\n",
      "Epoch 17/100, Iteration 202/303, Loss: 0.06215054169297218\n",
      "Epoch 17/100, Iteration 203/303, Loss: 0.05821988731622696\n",
      "Epoch 17/100, Iteration 204/303, Loss: 0.015969952568411827\n",
      "Epoch 17/100, Iteration 205/303, Loss: 0.014984173700213432\n",
      "Epoch 17/100, Iteration 206/303, Loss: 0.006085376255214214\n",
      "Epoch 17/100, Iteration 207/303, Loss: 0.1112404316663742\n",
      "Epoch 17/100, Iteration 208/303, Loss: 0.0865110382437706\n",
      "Epoch 17/100, Iteration 209/303, Loss: 0.01707550697028637\n",
      "Epoch 17/100, Iteration 210/303, Loss: 0.030069060623645782\n",
      "Epoch 17/100, Iteration 211/303, Loss: 0.06707897037267685\n",
      "Epoch 17/100, Iteration 212/303, Loss: 0.055145345628261566\n",
      "Epoch 17/100, Iteration 213/303, Loss: 0.043392494320869446\n",
      "Epoch 17/100, Iteration 214/303, Loss: 0.014710663817822933\n",
      "Epoch 17/100, Iteration 215/303, Loss: 0.010326249524950981\n",
      "Epoch 17/100, Iteration 216/303, Loss: 0.027459032833576202\n",
      "Epoch 17/100, Iteration 217/303, Loss: 0.012146824970841408\n",
      "Epoch 17/100, Iteration 218/303, Loss: 0.05916626751422882\n",
      "Epoch 17/100, Iteration 219/303, Loss: 0.015800727531313896\n",
      "Epoch 17/100, Iteration 220/303, Loss: 0.014909548684954643\n",
      "Epoch 17/100, Iteration 221/303, Loss: 0.04194648563861847\n",
      "Epoch 17/100, Iteration 222/303, Loss: 0.04575766995549202\n",
      "Epoch 17/100, Iteration 223/303, Loss: 0.07184606790542603\n",
      "Epoch 17/100, Iteration 224/303, Loss: 0.022246958687901497\n",
      "Epoch 17/100, Iteration 225/303, Loss: 0.13133126497268677\n",
      "Epoch 17/100, Iteration 226/303, Loss: 0.026120390743017197\n",
      "Epoch 17/100, Iteration 227/303, Loss: 0.003611912950873375\n",
      "Epoch 17/100, Iteration 228/303, Loss: 0.027807556092739105\n",
      "Epoch 17/100, Iteration 229/303, Loss: 0.019426526501774788\n",
      "Epoch 17/100, Iteration 230/303, Loss: 0.034375034272670746\n",
      "Epoch 17/100, Iteration 231/303, Loss: 0.012426657602190971\n",
      "Epoch 17/100, Iteration 232/303, Loss: 0.013174116611480713\n",
      "Epoch 17/100, Iteration 233/303, Loss: 0.29573947191238403\n",
      "Epoch 17/100, Iteration 234/303, Loss: 0.11369254440069199\n",
      "Epoch 17/100, Iteration 235/303, Loss: 0.03231159597635269\n",
      "Epoch 17/100, Iteration 236/303, Loss: 0.036876630038022995\n",
      "Epoch 17/100, Iteration 237/303, Loss: 0.029442349448800087\n",
      "Epoch 17/100, Iteration 238/303, Loss: 0.07083022594451904\n",
      "Epoch 17/100, Iteration 239/303, Loss: 0.03238348662853241\n",
      "Epoch 17/100, Iteration 240/303, Loss: 0.11832316219806671\n",
      "Epoch 17/100, Iteration 241/303, Loss: 0.11161433905363083\n",
      "Epoch 17/100, Iteration 242/303, Loss: 0.04054912552237511\n",
      "Epoch 17/100, Iteration 243/303, Loss: 0.12409679591655731\n",
      "Epoch 17/100, Iteration 244/303, Loss: 0.26815301179885864\n",
      "Epoch 17/100, Iteration 245/303, Loss: 0.03174348175525665\n",
      "Epoch 17/100, Iteration 246/303, Loss: 0.0993407815694809\n",
      "Epoch 17/100, Iteration 247/303, Loss: 0.13495779037475586\n",
      "Epoch 17/100, Iteration 248/303, Loss: 0.06307132542133331\n",
      "Epoch 17/100, Iteration 249/303, Loss: 0.018996654078364372\n",
      "Epoch 17/100, Iteration 250/303, Loss: 0.03565952926874161\n",
      "Epoch 17/100, Iteration 251/303, Loss: 0.01251396257430315\n",
      "Epoch 17/100, Iteration 252/303, Loss: 0.02813824824988842\n",
      "Epoch 17/100, Iteration 253/303, Loss: 0.09628838300704956\n",
      "Epoch 17/100, Iteration 254/303, Loss: 0.07282145321369171\n",
      "Epoch 17/100, Iteration 255/303, Loss: 0.03203882649540901\n",
      "Epoch 17/100, Iteration 256/303, Loss: 0.017009763047099113\n",
      "Epoch 17/100, Iteration 257/303, Loss: 0.010540829040110111\n",
      "Epoch 17/100, Iteration 258/303, Loss: 0.07783453166484833\n",
      "Epoch 17/100, Iteration 259/303, Loss: 0.048621322959661484\n",
      "Epoch 17/100, Iteration 260/303, Loss: 0.020677288994193077\n",
      "Epoch 17/100, Iteration 261/303, Loss: 0.027697011828422546\n",
      "Epoch 17/100, Iteration 262/303, Loss: 0.14820003509521484\n",
      "Epoch 17/100, Iteration 263/303, Loss: 0.0409695990383625\n",
      "Epoch 17/100, Iteration 264/303, Loss: 0.02755076251924038\n",
      "Epoch 17/100, Iteration 265/303, Loss: 0.014623019844293594\n",
      "Epoch 17/100, Iteration 266/303, Loss: 0.04019130766391754\n",
      "Epoch 17/100, Iteration 267/303, Loss: 0.05884760990738869\n",
      "Epoch 17/100, Iteration 268/303, Loss: 0.029141493141651154\n",
      "Epoch 17/100, Iteration 269/303, Loss: 0.06340812891721725\n",
      "Epoch 17/100, Iteration 270/303, Loss: 0.004718131385743618\n",
      "Epoch 17/100, Iteration 271/303, Loss: 0.06563913077116013\n",
      "Epoch 17/100, Iteration 272/303, Loss: 0.008291461504995823\n",
      "Epoch 17/100, Iteration 273/303, Loss: 0.030008327215909958\n",
      "Epoch 17/100, Iteration 274/303, Loss: 0.01155304815620184\n",
      "Epoch 17/100, Iteration 275/303, Loss: 0.11931215971708298\n",
      "Epoch 17/100, Iteration 276/303, Loss: 0.007620486430823803\n",
      "Epoch 17/100, Iteration 277/303, Loss: 0.06924884766340256\n",
      "Epoch 17/100, Iteration 278/303, Loss: 0.0088913943618536\n",
      "Epoch 17/100, Iteration 279/303, Loss: 0.10712530463933945\n",
      "Epoch 17/100, Iteration 280/303, Loss: 0.027966978028416634\n",
      "Epoch 17/100, Iteration 281/303, Loss: 0.02317839115858078\n",
      "Epoch 17/100, Iteration 282/303, Loss: 0.07095437496900558\n",
      "Epoch 17/100, Iteration 283/303, Loss: 0.021992318332195282\n",
      "Epoch 17/100, Iteration 284/303, Loss: 0.02105015516281128\n",
      "Epoch 17/100, Iteration 285/303, Loss: 0.008872662670910358\n",
      "Epoch 17/100, Iteration 286/303, Loss: 0.005336900241672993\n",
      "Epoch 17/100, Iteration 287/303, Loss: 0.025829916819930077\n",
      "Epoch 17/100, Iteration 288/303, Loss: 0.021782085299491882\n",
      "Epoch 17/100, Iteration 289/303, Loss: 0.01271131169050932\n",
      "Epoch 17/100, Iteration 290/303, Loss: 0.010816359892487526\n",
      "Epoch 17/100, Iteration 291/303, Loss: 0.09837128967046738\n",
      "Epoch 17/100, Iteration 292/303, Loss: 0.1004328727722168\n",
      "Epoch 17/100, Iteration 293/303, Loss: 0.07935807853937149\n",
      "Epoch 17/100, Iteration 294/303, Loss: 0.2628915011882782\n",
      "Epoch 17/100, Iteration 295/303, Loss: 0.19035303592681885\n",
      "Epoch 17/100, Iteration 296/303, Loss: 0.11681996285915375\n",
      "Epoch 17/100, Iteration 297/303, Loss: 0.07388319820165634\n",
      "Epoch 17/100, Iteration 298/303, Loss: 0.03758829087018967\n",
      "Epoch 17/100, Iteration 299/303, Loss: 0.005017571616917849\n",
      "Epoch 17/100, Iteration 300/303, Loss: 0.03907138481736183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Iteration 301/303, Loss: 0.06706172227859497\n",
      "Epoch 17/100, Iteration 302/303, Loss: 0.03254236280918121\n",
      "Epoch 17/100, Iteration 303/303, Loss: 0.008232677355408669\n",
      "Epoch 18/100, Iteration 1/303, Loss: 0.024363979697227478\n",
      "Epoch 18/100, Iteration 2/303, Loss: 0.015233571641147137\n",
      "Epoch 18/100, Iteration 3/303, Loss: 0.015276305377483368\n",
      "Epoch 18/100, Iteration 4/303, Loss: 0.036777008324861526\n",
      "Epoch 18/100, Iteration 5/303, Loss: 0.014417793601751328\n",
      "Epoch 18/100, Iteration 6/303, Loss: 0.011286505497992039\n",
      "Epoch 18/100, Iteration 7/303, Loss: 0.033488932996988297\n",
      "Epoch 18/100, Iteration 8/303, Loss: 0.0015498173888772726\n",
      "Epoch 18/100, Iteration 9/303, Loss: 0.01010147761553526\n",
      "Epoch 18/100, Iteration 10/303, Loss: 0.046811796724796295\n",
      "Epoch 18/100, Iteration 11/303, Loss: 0.01875605434179306\n",
      "Epoch 18/100, Iteration 12/303, Loss: 0.027569416910409927\n",
      "Epoch 18/100, Iteration 13/303, Loss: 0.010887417010962963\n",
      "Epoch 18/100, Iteration 14/303, Loss: 0.036258190870285034\n",
      "Epoch 18/100, Iteration 15/303, Loss: 0.017342036589980125\n",
      "Epoch 18/100, Iteration 16/303, Loss: 0.0011268641101196408\n",
      "Epoch 18/100, Iteration 17/303, Loss: 0.015797508880496025\n",
      "Epoch 18/100, Iteration 18/303, Loss: 0.00381314754486084\n",
      "Epoch 18/100, Iteration 19/303, Loss: 0.019308367744088173\n",
      "Epoch 18/100, Iteration 20/303, Loss: 0.0017974099610000849\n",
      "Epoch 18/100, Iteration 21/303, Loss: 0.008894226513803005\n",
      "Epoch 18/100, Iteration 22/303, Loss: 0.015997298061847687\n",
      "Epoch 18/100, Iteration 23/303, Loss: 0.009561507031321526\n",
      "Epoch 18/100, Iteration 24/303, Loss: 0.01106354221701622\n",
      "Epoch 18/100, Iteration 25/303, Loss: 0.019762273877859116\n",
      "Epoch 18/100, Iteration 26/303, Loss: 0.006687217392027378\n",
      "Epoch 18/100, Iteration 27/303, Loss: 0.0026016677729785442\n",
      "Epoch 18/100, Iteration 28/303, Loss: 0.006257585249841213\n",
      "Epoch 18/100, Iteration 29/303, Loss: 0.005868183448910713\n",
      "Epoch 18/100, Iteration 30/303, Loss: 0.004436103627085686\n",
      "Epoch 18/100, Iteration 31/303, Loss: 0.006576276384294033\n",
      "Epoch 18/100, Iteration 32/303, Loss: 0.002190087456256151\n",
      "Epoch 18/100, Iteration 33/303, Loss: 0.04633381962776184\n",
      "Epoch 18/100, Iteration 34/303, Loss: 0.008217970840632915\n",
      "Epoch 18/100, Iteration 35/303, Loss: 0.06946948915719986\n",
      "Epoch 18/100, Iteration 36/303, Loss: 0.009326725266873837\n",
      "Epoch 18/100, Iteration 37/303, Loss: 0.0072708288207650185\n",
      "Epoch 18/100, Iteration 38/303, Loss: 0.03468677029013634\n",
      "Epoch 18/100, Iteration 39/303, Loss: 0.007685098331421614\n",
      "Epoch 18/100, Iteration 40/303, Loss: 0.024731338024139404\n",
      "Epoch 18/100, Iteration 41/303, Loss: 0.0033173980191349983\n",
      "Epoch 18/100, Iteration 42/303, Loss: 0.01480271015316248\n",
      "Epoch 18/100, Iteration 43/303, Loss: 0.044482726603746414\n",
      "Epoch 18/100, Iteration 44/303, Loss: 0.012150956317782402\n",
      "Epoch 18/100, Iteration 45/303, Loss: 0.0031359875574707985\n",
      "Epoch 18/100, Iteration 46/303, Loss: 0.025500379502773285\n",
      "Epoch 18/100, Iteration 47/303, Loss: 0.00618458166718483\n",
      "Epoch 18/100, Iteration 48/303, Loss: 0.001745440997183323\n",
      "Epoch 18/100, Iteration 49/303, Loss: 0.037016771733760834\n",
      "Epoch 18/100, Iteration 50/303, Loss: 0.016173535957932472\n",
      "Epoch 18/100, Iteration 51/303, Loss: 0.01075432077050209\n",
      "Epoch 18/100, Iteration 52/303, Loss: 0.021668972447514534\n",
      "Epoch 18/100, Iteration 53/303, Loss: 0.00966421514749527\n",
      "Epoch 18/100, Iteration 54/303, Loss: 0.043199870735406876\n",
      "Epoch 18/100, Iteration 55/303, Loss: 0.015891248360276222\n",
      "Epoch 18/100, Iteration 56/303, Loss: 0.022544901818037033\n",
      "Epoch 18/100, Iteration 57/303, Loss: 0.030183112248778343\n",
      "Epoch 18/100, Iteration 58/303, Loss: 0.008597624488174915\n",
      "Epoch 18/100, Iteration 59/303, Loss: 0.0629449188709259\n",
      "Epoch 18/100, Iteration 60/303, Loss: 0.004172069951891899\n",
      "Epoch 18/100, Iteration 61/303, Loss: 0.0044317166320979595\n",
      "Epoch 18/100, Iteration 62/303, Loss: 0.02319459617137909\n",
      "Epoch 18/100, Iteration 63/303, Loss: 0.00632296921685338\n",
      "Epoch 18/100, Iteration 64/303, Loss: 0.014321756549179554\n",
      "Epoch 18/100, Iteration 65/303, Loss: 0.01975356601178646\n",
      "Epoch 18/100, Iteration 66/303, Loss: 0.007600752636790276\n",
      "Epoch 18/100, Iteration 67/303, Loss: 0.005854901857674122\n",
      "Epoch 18/100, Iteration 68/303, Loss: 0.007891276851296425\n",
      "Epoch 18/100, Iteration 69/303, Loss: 0.01688583381474018\n",
      "Epoch 18/100, Iteration 70/303, Loss: 0.002337608253583312\n",
      "Epoch 18/100, Iteration 71/303, Loss: 0.01149426493793726\n",
      "Epoch 18/100, Iteration 72/303, Loss: 0.004806192126125097\n",
      "Epoch 18/100, Iteration 73/303, Loss: 0.0027373728808015585\n",
      "Epoch 18/100, Iteration 74/303, Loss: 0.014142902567982674\n",
      "Epoch 18/100, Iteration 75/303, Loss: 0.030965304002165794\n",
      "Epoch 18/100, Iteration 76/303, Loss: 0.01655115932226181\n",
      "Epoch 18/100, Iteration 77/303, Loss: 0.015262569300830364\n",
      "Epoch 18/100, Iteration 78/303, Loss: 0.005320262163877487\n",
      "Epoch 18/100, Iteration 79/303, Loss: 0.0023477966897189617\n",
      "Epoch 18/100, Iteration 80/303, Loss: 0.02482028678059578\n",
      "Epoch 18/100, Iteration 81/303, Loss: 0.00647522509098053\n",
      "Epoch 18/100, Iteration 82/303, Loss: 0.0725603848695755\n",
      "Epoch 18/100, Iteration 83/303, Loss: 0.0064545986242592335\n",
      "Epoch 18/100, Iteration 84/303, Loss: 0.10248488932847977\n",
      "Epoch 18/100, Iteration 85/303, Loss: 0.09761472046375275\n",
      "Epoch 18/100, Iteration 86/303, Loss: 0.08186866343021393\n",
      "Epoch 18/100, Iteration 87/303, Loss: 0.03352244198322296\n",
      "Epoch 18/100, Iteration 88/303, Loss: 0.002960975980386138\n",
      "Epoch 18/100, Iteration 89/303, Loss: 0.019523199647665024\n",
      "Epoch 18/100, Iteration 90/303, Loss: 0.009047817438840866\n",
      "Epoch 18/100, Iteration 91/303, Loss: 0.0046235742047429085\n",
      "Epoch 18/100, Iteration 92/303, Loss: 0.008848784491419792\n",
      "Epoch 18/100, Iteration 93/303, Loss: 0.00719433045014739\n",
      "Epoch 18/100, Iteration 94/303, Loss: 0.0020239255391061306\n",
      "Epoch 18/100, Iteration 95/303, Loss: 0.16009464859962463\n",
      "Epoch 18/100, Iteration 96/303, Loss: 0.022154511883854866\n",
      "Epoch 18/100, Iteration 97/303, Loss: 0.02623256854712963\n",
      "Epoch 18/100, Iteration 98/303, Loss: 0.036879103630781174\n",
      "Epoch 18/100, Iteration 99/303, Loss: 0.0255587138235569\n",
      "Epoch 18/100, Iteration 100/303, Loss: 0.02117352932691574\n",
      "Epoch 18/100, Iteration 101/303, Loss: 0.009684858843684196\n",
      "Epoch 18/100, Iteration 102/303, Loss: 0.006471630651503801\n",
      "Epoch 18/100, Iteration 103/303, Loss: 0.001532085007056594\n",
      "Epoch 18/100, Iteration 104/303, Loss: 0.00951782800257206\n",
      "Epoch 18/100, Iteration 105/303, Loss: 0.0028162947855889797\n",
      "Epoch 18/100, Iteration 106/303, Loss: 0.017338570207357407\n",
      "Epoch 18/100, Iteration 107/303, Loss: 0.015874646604061127\n",
      "Epoch 18/100, Iteration 108/303, Loss: 0.010487361811101437\n",
      "Epoch 18/100, Iteration 109/303, Loss: 0.030651256442070007\n",
      "Epoch 18/100, Iteration 110/303, Loss: 0.03931441158056259\n",
      "Epoch 18/100, Iteration 111/303, Loss: 0.0139493178576231\n",
      "Epoch 18/100, Iteration 112/303, Loss: 0.006308772601187229\n",
      "Epoch 18/100, Iteration 113/303, Loss: 0.21828693151474\n",
      "Epoch 18/100, Iteration 114/303, Loss: 0.04822154715657234\n",
      "Epoch 18/100, Iteration 115/303, Loss: 0.012578762136399746\n",
      "Epoch 18/100, Iteration 116/303, Loss: 0.0025855442509055138\n",
      "Epoch 18/100, Iteration 117/303, Loss: 0.01910576969385147\n",
      "Epoch 18/100, Iteration 118/303, Loss: 0.013545913621783257\n",
      "Epoch 18/100, Iteration 119/303, Loss: 0.0821462869644165\n",
      "Epoch 18/100, Iteration 120/303, Loss: 0.016516055911779404\n",
      "Epoch 18/100, Iteration 121/303, Loss: 0.007397413719445467\n",
      "Epoch 18/100, Iteration 122/303, Loss: 0.0030894801020622253\n",
      "Epoch 18/100, Iteration 123/303, Loss: 0.02361530065536499\n",
      "Epoch 18/100, Iteration 124/303, Loss: 0.003478298196569085\n",
      "Epoch 18/100, Iteration 125/303, Loss: 0.04499064385890961\n",
      "Epoch 18/100, Iteration 126/303, Loss: 0.044385168701410294\n",
      "Epoch 18/100, Iteration 127/303, Loss: 0.017402391880750656\n",
      "Epoch 18/100, Iteration 128/303, Loss: 0.010043995454907417\n",
      "Epoch 18/100, Iteration 129/303, Loss: 0.004511057864874601\n",
      "Epoch 18/100, Iteration 130/303, Loss: 0.025573449209332466\n",
      "Epoch 18/100, Iteration 131/303, Loss: 0.021113412454724312\n",
      "Epoch 18/100, Iteration 132/303, Loss: 0.006051317788660526\n",
      "Epoch 18/100, Iteration 133/303, Loss: 0.004475749097764492\n",
      "Epoch 18/100, Iteration 134/303, Loss: 0.0048142289742827415\n",
      "Epoch 18/100, Iteration 135/303, Loss: 0.01973002403974533\n",
      "Epoch 18/100, Iteration 136/303, Loss: 0.006336747203022242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100, Iteration 137/303, Loss: 0.0031222268007695675\n",
      "Epoch 18/100, Iteration 138/303, Loss: 0.024814100936055183\n",
      "Epoch 18/100, Iteration 139/303, Loss: 0.005062827840447426\n",
      "Epoch 18/100, Iteration 140/303, Loss: 0.007792424410581589\n",
      "Epoch 18/100, Iteration 141/303, Loss: 0.036864493042230606\n",
      "Epoch 18/100, Iteration 142/303, Loss: 0.008780457079410553\n",
      "Epoch 18/100, Iteration 143/303, Loss: 0.004665605258196592\n",
      "Epoch 18/100, Iteration 144/303, Loss: 0.0034086827654391527\n",
      "Epoch 18/100, Iteration 145/303, Loss: 0.012539122253656387\n",
      "Epoch 18/100, Iteration 146/303, Loss: 0.008137721568346024\n",
      "Epoch 18/100, Iteration 147/303, Loss: 0.022455992177128792\n",
      "Epoch 18/100, Iteration 148/303, Loss: 0.03486977890133858\n",
      "Epoch 18/100, Iteration 149/303, Loss: 0.006812978070229292\n",
      "Epoch 18/100, Iteration 150/303, Loss: 0.004768876358866692\n",
      "Epoch 18/100, Iteration 151/303, Loss: 0.0034655113704502583\n",
      "Epoch 18/100, Iteration 152/303, Loss: 0.005997542291879654\n",
      "Epoch 18/100, Iteration 153/303, Loss: 0.003270739456638694\n",
      "Epoch 18/100, Iteration 154/303, Loss: 0.002971066627651453\n",
      "Epoch 18/100, Iteration 155/303, Loss: 0.03535809740424156\n",
      "Epoch 18/100, Iteration 156/303, Loss: 0.004045272711664438\n",
      "Epoch 18/100, Iteration 157/303, Loss: 0.0043164994567632675\n",
      "Epoch 18/100, Iteration 158/303, Loss: 0.007187526673078537\n",
      "Epoch 18/100, Iteration 159/303, Loss: 0.00790785439312458\n",
      "Epoch 18/100, Iteration 160/303, Loss: 0.008641978725790977\n",
      "Epoch 18/100, Iteration 161/303, Loss: 0.012602549977600574\n",
      "Epoch 18/100, Iteration 162/303, Loss: 0.001050901017151773\n",
      "Epoch 18/100, Iteration 163/303, Loss: 0.0049408208578825\n",
      "Epoch 18/100, Iteration 164/303, Loss: 0.0597379095852375\n",
      "Epoch 18/100, Iteration 165/303, Loss: 0.11604206264019012\n",
      "Epoch 18/100, Iteration 166/303, Loss: 0.035860635340213776\n",
      "Epoch 18/100, Iteration 167/303, Loss: 0.014181610196828842\n",
      "Epoch 18/100, Iteration 168/303, Loss: 0.001914196414873004\n",
      "Epoch 18/100, Iteration 169/303, Loss: 0.0016308845952153206\n",
      "Epoch 18/100, Iteration 170/303, Loss: 0.0063840290531516075\n",
      "Epoch 18/100, Iteration 171/303, Loss: 0.036382418125867844\n",
      "Epoch 18/100, Iteration 172/303, Loss: 0.0019142765086144209\n",
      "Epoch 18/100, Iteration 173/303, Loss: 0.023279916495084763\n",
      "Epoch 18/100, Iteration 174/303, Loss: 0.001868473831564188\n",
      "Epoch 18/100, Iteration 175/303, Loss: 0.002269613789394498\n",
      "Epoch 18/100, Iteration 176/303, Loss: 0.012414093129336834\n",
      "Epoch 18/100, Iteration 177/303, Loss: 0.0033789854496717453\n",
      "Epoch 18/100, Iteration 178/303, Loss: 0.003638944821432233\n",
      "Epoch 18/100, Iteration 179/303, Loss: 0.022450273856520653\n",
      "Epoch 18/100, Iteration 180/303, Loss: 0.0025499106850475073\n",
      "Epoch 18/100, Iteration 181/303, Loss: 0.02076510339975357\n",
      "Epoch 18/100, Iteration 182/303, Loss: 0.014395353384315968\n",
      "Epoch 18/100, Iteration 183/303, Loss: 0.018420174717903137\n",
      "Epoch 18/100, Iteration 184/303, Loss: 0.003163366112858057\n",
      "Epoch 18/100, Iteration 185/303, Loss: 0.004845866933465004\n",
      "Epoch 18/100, Iteration 186/303, Loss: 0.010580092668533325\n",
      "Epoch 18/100, Iteration 187/303, Loss: 0.01003285776823759\n",
      "Epoch 18/100, Iteration 188/303, Loss: 0.00723864184692502\n",
      "Epoch 18/100, Iteration 189/303, Loss: 0.0028065841179341078\n",
      "Epoch 18/100, Iteration 190/303, Loss: 0.0038833022117614746\n",
      "Epoch 18/100, Iteration 191/303, Loss: 0.005296633113175631\n",
      "Epoch 18/100, Iteration 192/303, Loss: 0.011549046263098717\n",
      "Epoch 18/100, Iteration 193/303, Loss: 0.0008498670649714768\n",
      "Epoch 18/100, Iteration 194/303, Loss: 0.020899295806884766\n",
      "Epoch 18/100, Iteration 195/303, Loss: 0.014775174669921398\n",
      "Epoch 18/100, Iteration 196/303, Loss: 0.01765112392604351\n",
      "Epoch 18/100, Iteration 197/303, Loss: 0.005196623504161835\n",
      "Epoch 18/100, Iteration 198/303, Loss: 0.0030895390082150698\n",
      "Epoch 18/100, Iteration 199/303, Loss: 0.007856611162424088\n",
      "Epoch 18/100, Iteration 200/303, Loss: 0.00460823206230998\n",
      "Epoch 18/100, Iteration 201/303, Loss: 0.004186148755252361\n",
      "Epoch 18/100, Iteration 202/303, Loss: 0.0014778280165046453\n",
      "Epoch 18/100, Iteration 203/303, Loss: 0.0025415210984647274\n",
      "Epoch 18/100, Iteration 204/303, Loss: 0.00640083895996213\n",
      "Epoch 18/100, Iteration 205/303, Loss: 0.024787195026874542\n",
      "Epoch 18/100, Iteration 206/303, Loss: 0.012441221624612808\n",
      "Epoch 18/100, Iteration 207/303, Loss: 0.004475385881960392\n",
      "Epoch 18/100, Iteration 208/303, Loss: 0.02628915198147297\n",
      "Epoch 18/100, Iteration 209/303, Loss: 0.0017055332427844405\n",
      "Epoch 18/100, Iteration 210/303, Loss: 0.006986526772379875\n",
      "Epoch 18/100, Iteration 211/303, Loss: 0.037538520991802216\n",
      "Epoch 18/100, Iteration 212/303, Loss: 0.057021670043468475\n",
      "Epoch 18/100, Iteration 213/303, Loss: 0.11123634874820709\n",
      "Epoch 18/100, Iteration 214/303, Loss: 0.11059777438640594\n",
      "Epoch 18/100, Iteration 215/303, Loss: 0.018170779570937157\n",
      "Epoch 18/100, Iteration 216/303, Loss: 0.005432449281215668\n",
      "Epoch 18/100, Iteration 217/303, Loss: 0.03051270730793476\n",
      "Epoch 18/100, Iteration 218/303, Loss: 0.022511014714837074\n",
      "Epoch 18/100, Iteration 219/303, Loss: 0.02076145075261593\n",
      "Epoch 18/100, Iteration 220/303, Loss: 0.0017250556265935302\n",
      "Epoch 18/100, Iteration 221/303, Loss: 0.0003067775978706777\n",
      "Epoch 18/100, Iteration 222/303, Loss: 0.03722912818193436\n",
      "Epoch 18/100, Iteration 223/303, Loss: 0.013186700642108917\n",
      "Epoch 18/100, Iteration 224/303, Loss: 0.06862255930900574\n",
      "Epoch 18/100, Iteration 225/303, Loss: 0.030163582414388657\n",
      "Epoch 18/100, Iteration 226/303, Loss: 0.008341765962541103\n",
      "Epoch 18/100, Iteration 227/303, Loss: 0.00888590794056654\n",
      "Epoch 18/100, Iteration 228/303, Loss: 0.003705802373588085\n",
      "Epoch 18/100, Iteration 229/303, Loss: 0.017869282513856888\n",
      "Epoch 18/100, Iteration 230/303, Loss: 0.0002470744657330215\n",
      "Epoch 18/100, Iteration 231/303, Loss: 0.11289442330598831\n",
      "Epoch 18/100, Iteration 232/303, Loss: 0.23880046606063843\n",
      "Epoch 18/100, Iteration 233/303, Loss: 0.05731476843357086\n",
      "Epoch 18/100, Iteration 234/303, Loss: 0.006025336682796478\n",
      "Epoch 18/100, Iteration 235/303, Loss: 0.0380437932908535\n",
      "Epoch 18/100, Iteration 236/303, Loss: 0.0276924017816782\n",
      "Epoch 18/100, Iteration 237/303, Loss: 0.10339873284101486\n",
      "Epoch 18/100, Iteration 238/303, Loss: 0.08330592513084412\n",
      "Epoch 18/100, Iteration 239/303, Loss: 0.008334975689649582\n",
      "Epoch 18/100, Iteration 240/303, Loss: 0.007528526708483696\n",
      "Epoch 18/100, Iteration 241/303, Loss: 0.12938885390758514\n",
      "Epoch 18/100, Iteration 242/303, Loss: 0.05300847813487053\n",
      "Epoch 18/100, Iteration 243/303, Loss: 0.1375049352645874\n",
      "Epoch 18/100, Iteration 244/303, Loss: 0.16869868338108063\n",
      "Epoch 18/100, Iteration 245/303, Loss: 0.01997530646622181\n",
      "Epoch 18/100, Iteration 246/303, Loss: 0.0018774686614051461\n",
      "Epoch 18/100, Iteration 247/303, Loss: 0.061585962772369385\n",
      "Epoch 18/100, Iteration 248/303, Loss: 0.0026213391683995724\n",
      "Epoch 18/100, Iteration 249/303, Loss: 0.06892239302396774\n",
      "Epoch 18/100, Iteration 250/303, Loss: 0.021744191646575928\n",
      "Epoch 18/100, Iteration 251/303, Loss: 0.25418514013290405\n",
      "Epoch 18/100, Iteration 252/303, Loss: 0.07090771943330765\n",
      "Epoch 18/100, Iteration 253/303, Loss: 0.05319959297776222\n",
      "Epoch 18/100, Iteration 254/303, Loss: 0.03393755480647087\n",
      "Epoch 18/100, Iteration 255/303, Loss: 0.021818652749061584\n",
      "Epoch 18/100, Iteration 256/303, Loss: 0.025715019553899765\n",
      "Epoch 18/100, Iteration 257/303, Loss: 0.020872769877314568\n",
      "Epoch 18/100, Iteration 258/303, Loss: 0.11453238129615784\n",
      "Epoch 18/100, Iteration 259/303, Loss: 0.011446225456893444\n",
      "Epoch 18/100, Iteration 260/303, Loss: 0.14105363190174103\n",
      "Epoch 18/100, Iteration 261/303, Loss: 0.05602944642305374\n",
      "Epoch 18/100, Iteration 262/303, Loss: 0.01731482520699501\n",
      "Epoch 18/100, Iteration 263/303, Loss: 0.007912853732705116\n",
      "Epoch 18/100, Iteration 264/303, Loss: 0.008037617430090904\n",
      "Epoch 18/100, Iteration 265/303, Loss: 0.04542061313986778\n",
      "Epoch 18/100, Iteration 266/303, Loss: 0.10690836608409882\n",
      "Epoch 18/100, Iteration 267/303, Loss: 0.04446037486195564\n",
      "Epoch 18/100, Iteration 268/303, Loss: 0.008970765396952629\n",
      "Epoch 18/100, Iteration 269/303, Loss: 0.0768151506781578\n",
      "Epoch 18/100, Iteration 270/303, Loss: 0.040107302367687225\n",
      "Epoch 18/100, Iteration 271/303, Loss: 0.05269942432641983\n",
      "Epoch 18/100, Iteration 272/303, Loss: 0.010762319900095463\n",
      "Epoch 18/100, Iteration 273/303, Loss: 0.009069670923054218\n",
      "Epoch 18/100, Iteration 274/303, Loss: 0.09099514037370682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100, Iteration 275/303, Loss: 0.006928184535354376\n",
      "Epoch 18/100, Iteration 276/303, Loss: 0.05147407203912735\n",
      "Epoch 18/100, Iteration 277/303, Loss: 0.02334773726761341\n",
      "Epoch 18/100, Iteration 278/303, Loss: 0.01049136184155941\n",
      "Epoch 18/100, Iteration 279/303, Loss: 0.017535898834466934\n",
      "Epoch 18/100, Iteration 280/303, Loss: 0.010690435767173767\n",
      "Epoch 18/100, Iteration 281/303, Loss: 0.03160577267408371\n",
      "Epoch 18/100, Iteration 282/303, Loss: 0.045260000973939896\n",
      "Epoch 18/100, Iteration 283/303, Loss: 0.020922228693962097\n",
      "Epoch 18/100, Iteration 284/303, Loss: 0.009006021544337273\n",
      "Epoch 18/100, Iteration 285/303, Loss: 0.0211467407643795\n",
      "Epoch 18/100, Iteration 286/303, Loss: 0.0027659304905682802\n",
      "Epoch 18/100, Iteration 287/303, Loss: 0.005814786534756422\n",
      "Epoch 18/100, Iteration 288/303, Loss: 0.009338174015283585\n",
      "Epoch 18/100, Iteration 289/303, Loss: 0.017800169065594673\n",
      "Epoch 18/100, Iteration 290/303, Loss: 0.07851015031337738\n",
      "Epoch 18/100, Iteration 291/303, Loss: 0.006211495026946068\n",
      "Epoch 18/100, Iteration 292/303, Loss: 0.0034830349031835794\n",
      "Epoch 18/100, Iteration 293/303, Loss: 0.0030836062505841255\n",
      "Epoch 18/100, Iteration 294/303, Loss: 0.00372361415065825\n",
      "Epoch 18/100, Iteration 295/303, Loss: 0.023270756006240845\n",
      "Epoch 18/100, Iteration 296/303, Loss: 0.007605744060128927\n",
      "Epoch 18/100, Iteration 297/303, Loss: 0.0356987901031971\n",
      "Epoch 18/100, Iteration 298/303, Loss: 0.03645625710487366\n",
      "Epoch 18/100, Iteration 299/303, Loss: 0.11830014735460281\n",
      "Epoch 18/100, Iteration 300/303, Loss: 0.03332766145467758\n",
      "Epoch 18/100, Iteration 301/303, Loss: 0.016292955726385117\n",
      "Epoch 18/100, Iteration 302/303, Loss: 0.0017130263149738312\n",
      "Epoch 18/100, Iteration 303/303, Loss: 0.10246770828962326\n",
      "Epoch 19/100, Iteration 1/303, Loss: 0.16624192893505096\n",
      "Epoch 19/100, Iteration 2/303, Loss: 0.0756840854883194\n",
      "Epoch 19/100, Iteration 3/303, Loss: 0.0226137675344944\n",
      "Epoch 19/100, Iteration 4/303, Loss: 0.1491747945547104\n",
      "Epoch 19/100, Iteration 5/303, Loss: 0.03286821022629738\n",
      "Epoch 19/100, Iteration 6/303, Loss: 0.03372601419687271\n",
      "Epoch 19/100, Iteration 7/303, Loss: 0.001432693679817021\n",
      "Epoch 19/100, Iteration 8/303, Loss: 0.027737094089388847\n",
      "Epoch 19/100, Iteration 9/303, Loss: 0.020934658125042915\n",
      "Epoch 19/100, Iteration 10/303, Loss: 0.022281736135482788\n",
      "Epoch 19/100, Iteration 11/303, Loss: 0.016512906178832054\n",
      "Epoch 19/100, Iteration 12/303, Loss: 0.04168974235653877\n",
      "Epoch 19/100, Iteration 13/303, Loss: 0.01305368635803461\n",
      "Epoch 19/100, Iteration 14/303, Loss: 0.010289087891578674\n",
      "Epoch 19/100, Iteration 15/303, Loss: 0.026934558525681496\n",
      "Epoch 19/100, Iteration 16/303, Loss: 0.030304258689284325\n",
      "Epoch 19/100, Iteration 17/303, Loss: 0.012819425202906132\n",
      "Epoch 19/100, Iteration 18/303, Loss: 0.03672196716070175\n",
      "Epoch 19/100, Iteration 19/303, Loss: 0.017781514674425125\n",
      "Epoch 19/100, Iteration 20/303, Loss: 0.06979407370090485\n",
      "Epoch 19/100, Iteration 21/303, Loss: 0.042291976511478424\n",
      "Epoch 19/100, Iteration 22/303, Loss: 0.0034166788682341576\n",
      "Epoch 19/100, Iteration 23/303, Loss: 0.009961951524019241\n",
      "Epoch 19/100, Iteration 24/303, Loss: 0.012530451640486717\n",
      "Epoch 19/100, Iteration 25/303, Loss: 0.0015884898602962494\n",
      "Epoch 19/100, Iteration 26/303, Loss: 0.04602768272161484\n",
      "Epoch 19/100, Iteration 27/303, Loss: 0.0032178813125938177\n",
      "Epoch 19/100, Iteration 28/303, Loss: 0.0036984197795391083\n",
      "Epoch 19/100, Iteration 29/303, Loss: 0.009361965581774712\n",
      "Epoch 19/100, Iteration 30/303, Loss: 0.0034159913193434477\n",
      "Epoch 19/100, Iteration 31/303, Loss: 0.01384154986590147\n",
      "Epoch 19/100, Iteration 32/303, Loss: 0.011584585532546043\n",
      "Epoch 19/100, Iteration 33/303, Loss: 0.011366673745214939\n",
      "Epoch 19/100, Iteration 34/303, Loss: 0.008593767881393433\n",
      "Epoch 19/100, Iteration 35/303, Loss: 0.007350572384893894\n",
      "Epoch 19/100, Iteration 36/303, Loss: 0.0007772469543851912\n",
      "Epoch 19/100, Iteration 37/303, Loss: 0.009063836187124252\n",
      "Epoch 19/100, Iteration 38/303, Loss: 0.009906494058668613\n",
      "Epoch 19/100, Iteration 39/303, Loss: 0.02373466268181801\n",
      "Epoch 19/100, Iteration 40/303, Loss: 0.0021586378570646048\n",
      "Epoch 19/100, Iteration 41/303, Loss: 0.0025849007070064545\n",
      "Epoch 19/100, Iteration 42/303, Loss: 0.002754878019914031\n",
      "Epoch 19/100, Iteration 43/303, Loss: 0.016459884122014046\n",
      "Epoch 19/100, Iteration 44/303, Loss: 0.021413588896393776\n",
      "Epoch 19/100, Iteration 45/303, Loss: 0.018433470278978348\n",
      "Epoch 19/100, Iteration 46/303, Loss: 0.011713043786585331\n",
      "Epoch 19/100, Iteration 47/303, Loss: 0.004818769637495279\n",
      "Epoch 19/100, Iteration 48/303, Loss: 0.001992142992094159\n",
      "Epoch 19/100, Iteration 49/303, Loss: 0.008409969508647919\n",
      "Epoch 19/100, Iteration 50/303, Loss: 0.0011029538000002503\n",
      "Epoch 19/100, Iteration 51/303, Loss: 0.0026881673838943243\n",
      "Epoch 19/100, Iteration 52/303, Loss: 0.011924531310796738\n",
      "Epoch 19/100, Iteration 53/303, Loss: 0.004846551455557346\n",
      "Epoch 19/100, Iteration 54/303, Loss: 0.021739602088928223\n",
      "Epoch 19/100, Iteration 55/303, Loss: 0.014788171276450157\n",
      "Epoch 19/100, Iteration 56/303, Loss: 0.03672775253653526\n",
      "Epoch 19/100, Iteration 57/303, Loss: 0.03328239172697067\n",
      "Epoch 19/100, Iteration 58/303, Loss: 0.026596851646900177\n",
      "Epoch 19/100, Iteration 59/303, Loss: 0.008952227421104908\n",
      "Epoch 19/100, Iteration 60/303, Loss: 0.0021858890540897846\n",
      "Epoch 19/100, Iteration 61/303, Loss: 0.004617153666913509\n",
      "Epoch 19/100, Iteration 62/303, Loss: 0.009801719337701797\n",
      "Epoch 19/100, Iteration 63/303, Loss: 0.008598895743489265\n",
      "Epoch 19/100, Iteration 64/303, Loss: 0.015879711136221886\n",
      "Epoch 19/100, Iteration 65/303, Loss: 0.0007467413088306785\n",
      "Epoch 19/100, Iteration 66/303, Loss: 0.007671556901186705\n",
      "Epoch 19/100, Iteration 67/303, Loss: 0.007277708500623703\n",
      "Epoch 19/100, Iteration 68/303, Loss: 0.016573576256632805\n",
      "Epoch 19/100, Iteration 69/303, Loss: 0.006456082686781883\n",
      "Epoch 19/100, Iteration 70/303, Loss: 0.013498307205736637\n",
      "Epoch 19/100, Iteration 71/303, Loss: 0.023395903408527374\n",
      "Epoch 19/100, Iteration 72/303, Loss: 0.001570122316479683\n",
      "Epoch 19/100, Iteration 73/303, Loss: 0.003140397369861603\n",
      "Epoch 19/100, Iteration 74/303, Loss: 0.034392938017845154\n",
      "Epoch 19/100, Iteration 75/303, Loss: 0.007121825125068426\n",
      "Epoch 19/100, Iteration 76/303, Loss: 0.005455788690596819\n",
      "Epoch 19/100, Iteration 77/303, Loss: 0.003885301761329174\n",
      "Epoch 19/100, Iteration 78/303, Loss: 0.0006636953912675381\n",
      "Epoch 19/100, Iteration 79/303, Loss: 0.005964895244687796\n",
      "Epoch 19/100, Iteration 80/303, Loss: 0.0037730324547737837\n",
      "Epoch 19/100, Iteration 81/303, Loss: 0.0038400369230657816\n",
      "Epoch 19/100, Iteration 82/303, Loss: 0.003665172029286623\n",
      "Epoch 19/100, Iteration 83/303, Loss: 0.004295030143111944\n",
      "Epoch 19/100, Iteration 84/303, Loss: 0.014428932219743729\n",
      "Epoch 19/100, Iteration 85/303, Loss: 0.015972701832652092\n",
      "Epoch 19/100, Iteration 86/303, Loss: 0.01112110260874033\n",
      "Epoch 19/100, Iteration 87/303, Loss: 0.0021739827934652567\n",
      "Epoch 19/100, Iteration 88/303, Loss: 0.001549088628962636\n",
      "Epoch 19/100, Iteration 89/303, Loss: 0.020488191395998\n",
      "Epoch 19/100, Iteration 90/303, Loss: 0.0034960824996232986\n",
      "Epoch 19/100, Iteration 91/303, Loss: 0.0008050143369473517\n",
      "Epoch 19/100, Iteration 92/303, Loss: 0.007872341200709343\n",
      "Epoch 19/100, Iteration 93/303, Loss: 0.00037378695560619235\n",
      "Epoch 19/100, Iteration 94/303, Loss: 0.000630978203844279\n",
      "Epoch 19/100, Iteration 95/303, Loss: 0.002049650764092803\n",
      "Epoch 19/100, Iteration 96/303, Loss: 0.00280599482357502\n",
      "Epoch 19/100, Iteration 97/303, Loss: 0.00952380895614624\n",
      "Epoch 19/100, Iteration 98/303, Loss: 0.0013265495654195547\n",
      "Epoch 19/100, Iteration 99/303, Loss: 0.005851317197084427\n",
      "Epoch 19/100, Iteration 100/303, Loss: 0.007044331636279821\n",
      "Epoch 19/100, Iteration 101/303, Loss: 0.005174798890948296\n",
      "Epoch 19/100, Iteration 102/303, Loss: 0.008626360446214676\n",
      "Epoch 19/100, Iteration 103/303, Loss: 0.0016245171427726746\n",
      "Epoch 19/100, Iteration 104/303, Loss: 0.0004599736421369016\n",
      "Epoch 19/100, Iteration 105/303, Loss: 0.02774323895573616\n",
      "Epoch 19/100, Iteration 106/303, Loss: 0.019363589584827423\n",
      "Epoch 19/100, Iteration 107/303, Loss: 0.007757278624922037\n",
      "Epoch 19/100, Iteration 108/303, Loss: 0.0029892977327108383\n",
      "Epoch 19/100, Iteration 109/303, Loss: 0.0010235642548650503\n",
      "Epoch 19/100, Iteration 110/303, Loss: 0.009095494635403156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100, Iteration 111/303, Loss: 0.001673586666584015\n",
      "Epoch 19/100, Iteration 112/303, Loss: 0.021107209846377373\n",
      "Epoch 19/100, Iteration 113/303, Loss: 0.006510871462523937\n",
      "Epoch 19/100, Iteration 114/303, Loss: 0.0065170894376933575\n",
      "Epoch 19/100, Iteration 115/303, Loss: 0.006915345788002014\n",
      "Epoch 19/100, Iteration 116/303, Loss: 0.00039679306792095304\n",
      "Epoch 19/100, Iteration 117/303, Loss: 0.0012964644702151418\n",
      "Epoch 19/100, Iteration 118/303, Loss: 0.013183233328163624\n",
      "Epoch 19/100, Iteration 119/303, Loss: 0.005824498366564512\n",
      "Epoch 19/100, Iteration 120/303, Loss: 0.0009685295517556369\n",
      "Epoch 19/100, Iteration 121/303, Loss: 0.010269357822835445\n",
      "Epoch 19/100, Iteration 122/303, Loss: 0.001709258183836937\n",
      "Epoch 19/100, Iteration 123/303, Loss: 0.0018829420441761613\n",
      "Epoch 19/100, Iteration 124/303, Loss: 0.005180147476494312\n",
      "Epoch 19/100, Iteration 125/303, Loss: 0.005035209935158491\n",
      "Epoch 19/100, Iteration 126/303, Loss: 0.001669812249019742\n",
      "Epoch 19/100, Iteration 127/303, Loss: 0.0026092298794537783\n",
      "Epoch 19/100, Iteration 128/303, Loss: 0.0035568939056247473\n",
      "Epoch 19/100, Iteration 129/303, Loss: 0.007576311472803354\n",
      "Epoch 19/100, Iteration 130/303, Loss: 0.0014729959657415748\n",
      "Epoch 19/100, Iteration 131/303, Loss: 0.06355646252632141\n",
      "Epoch 19/100, Iteration 132/303, Loss: 0.07314713299274445\n",
      "Epoch 19/100, Iteration 133/303, Loss: 0.11131832748651505\n",
      "Epoch 19/100, Iteration 134/303, Loss: 0.15811818838119507\n",
      "Epoch 19/100, Iteration 135/303, Loss: 0.03426692634820938\n",
      "Epoch 19/100, Iteration 136/303, Loss: 0.05118439346551895\n",
      "Epoch 19/100, Iteration 137/303, Loss: 0.010225621983408928\n",
      "Epoch 19/100, Iteration 138/303, Loss: 0.0772237703204155\n",
      "Epoch 19/100, Iteration 139/303, Loss: 0.4265788197517395\n",
      "Epoch 19/100, Iteration 140/303, Loss: 0.3136749267578125\n",
      "Epoch 19/100, Iteration 141/303, Loss: 0.05660899728536606\n",
      "Epoch 19/100, Iteration 142/303, Loss: 0.11785620450973511\n",
      "Epoch 19/100, Iteration 143/303, Loss: 0.22363418340682983\n",
      "Epoch 19/100, Iteration 144/303, Loss: 0.6264819502830505\n",
      "Epoch 19/100, Iteration 145/303, Loss: 0.5765636563301086\n",
      "Epoch 19/100, Iteration 146/303, Loss: 0.06093142181634903\n",
      "Epoch 19/100, Iteration 147/303, Loss: 0.11403551697731018\n",
      "Epoch 19/100, Iteration 148/303, Loss: 0.17855829000473022\n",
      "Epoch 19/100, Iteration 149/303, Loss: 0.07074004411697388\n",
      "Epoch 19/100, Iteration 150/303, Loss: 0.15225860476493835\n",
      "Epoch 19/100, Iteration 151/303, Loss: 0.0405464768409729\n",
      "Epoch 19/100, Iteration 152/303, Loss: 0.0751766562461853\n",
      "Epoch 19/100, Iteration 153/303, Loss: 0.0020559774711728096\n",
      "Epoch 19/100, Iteration 154/303, Loss: 0.09752297401428223\n",
      "Epoch 19/100, Iteration 155/303, Loss: 0.01416088454425335\n",
      "Epoch 19/100, Iteration 156/303, Loss: 0.010439526289701462\n",
      "Epoch 19/100, Iteration 157/303, Loss: 0.11055447906255722\n",
      "Epoch 19/100, Iteration 158/303, Loss: 0.05908459424972534\n",
      "Epoch 19/100, Iteration 159/303, Loss: 0.01831740140914917\n",
      "Epoch 19/100, Iteration 160/303, Loss: 0.02253931760787964\n",
      "Epoch 19/100, Iteration 161/303, Loss: 0.07136040925979614\n",
      "Epoch 19/100, Iteration 162/303, Loss: 0.06644388288259506\n",
      "Epoch 19/100, Iteration 163/303, Loss: 0.08304084092378616\n",
      "Epoch 19/100, Iteration 164/303, Loss: 0.022968290373682976\n",
      "Epoch 19/100, Iteration 165/303, Loss: 0.0327148362994194\n",
      "Epoch 19/100, Iteration 166/303, Loss: 0.05034579336643219\n",
      "Epoch 19/100, Iteration 167/303, Loss: 0.05252887308597565\n",
      "Epoch 19/100, Iteration 168/303, Loss: 0.08767122030258179\n",
      "Epoch 19/100, Iteration 169/303, Loss: 0.03028230369091034\n",
      "Epoch 19/100, Iteration 170/303, Loss: 0.03337140381336212\n",
      "Epoch 19/100, Iteration 171/303, Loss: 0.030152974650263786\n",
      "Epoch 19/100, Iteration 172/303, Loss: 0.012361711822450161\n",
      "Epoch 19/100, Iteration 173/303, Loss: 0.04830117151141167\n",
      "Epoch 19/100, Iteration 174/303, Loss: 0.0070549556985497475\n",
      "Epoch 19/100, Iteration 175/303, Loss: 0.009427654556930065\n",
      "Epoch 19/100, Iteration 176/303, Loss: 0.014204221777617931\n",
      "Epoch 19/100, Iteration 177/303, Loss: 0.009689023718237877\n",
      "Epoch 19/100, Iteration 178/303, Loss: 0.01834339275956154\n",
      "Epoch 19/100, Iteration 179/303, Loss: 0.007034200709313154\n",
      "Epoch 19/100, Iteration 180/303, Loss: 0.0073827472515404224\n",
      "Epoch 19/100, Iteration 181/303, Loss: 0.06026538833975792\n",
      "Epoch 19/100, Iteration 182/303, Loss: 0.008279108442366123\n",
      "Epoch 19/100, Iteration 183/303, Loss: 0.02089778333902359\n",
      "Epoch 19/100, Iteration 184/303, Loss: 0.009456520900130272\n",
      "Epoch 19/100, Iteration 185/303, Loss: 0.010688493959605694\n",
      "Epoch 19/100, Iteration 186/303, Loss: 0.007589702028781176\n",
      "Epoch 19/100, Iteration 187/303, Loss: 0.010152251459658146\n",
      "Epoch 19/100, Iteration 188/303, Loss: 0.008055899292230606\n",
      "Epoch 19/100, Iteration 189/303, Loss: 0.008376234211027622\n",
      "Epoch 19/100, Iteration 190/303, Loss: 0.0025422098115086555\n",
      "Epoch 19/100, Iteration 191/303, Loss: 0.008747239597141743\n",
      "Epoch 19/100, Iteration 192/303, Loss: 0.010541604831814766\n",
      "Epoch 19/100, Iteration 193/303, Loss: 0.03210015222430229\n",
      "Epoch 19/100, Iteration 194/303, Loss: 0.011184271425008774\n",
      "Epoch 19/100, Iteration 195/303, Loss: 0.003821510821580887\n",
      "Epoch 19/100, Iteration 196/303, Loss: 0.004423090256750584\n",
      "Epoch 19/100, Iteration 197/303, Loss: 0.0005217966972850263\n",
      "Epoch 19/100, Iteration 198/303, Loss: 0.017721358686685562\n",
      "Epoch 19/100, Iteration 199/303, Loss: 0.0327538400888443\n",
      "Epoch 19/100, Iteration 200/303, Loss: 0.025708353146910667\n",
      "Epoch 19/100, Iteration 201/303, Loss: 0.020807377994060516\n",
      "Epoch 19/100, Iteration 202/303, Loss: 0.04177417233586311\n",
      "Epoch 19/100, Iteration 203/303, Loss: 0.00301408302038908\n",
      "Epoch 19/100, Iteration 204/303, Loss: 0.01262690033763647\n",
      "Epoch 19/100, Iteration 205/303, Loss: 0.02181258238852024\n",
      "Epoch 19/100, Iteration 206/303, Loss: 0.02306194417178631\n",
      "Epoch 19/100, Iteration 207/303, Loss: 0.014355993829667568\n",
      "Epoch 19/100, Iteration 208/303, Loss: 0.007475369144231081\n",
      "Epoch 19/100, Iteration 209/303, Loss: 0.007883213460445404\n",
      "Epoch 19/100, Iteration 210/303, Loss: 0.039058931171894073\n",
      "Epoch 19/100, Iteration 211/303, Loss: 0.055430758744478226\n",
      "Epoch 19/100, Iteration 212/303, Loss: 0.07677899301052094\n",
      "Epoch 19/100, Iteration 213/303, Loss: 0.1227324828505516\n",
      "Epoch 19/100, Iteration 214/303, Loss: 0.04664172977209091\n",
      "Epoch 19/100, Iteration 215/303, Loss: 0.03285124897956848\n",
      "Epoch 19/100, Iteration 216/303, Loss: 0.02128409966826439\n",
      "Epoch 19/100, Iteration 217/303, Loss: 0.07354192435741425\n",
      "Epoch 19/100, Iteration 218/303, Loss: 0.015667328611016273\n",
      "Epoch 19/100, Iteration 219/303, Loss: 0.06380726397037506\n",
      "Epoch 19/100, Iteration 220/303, Loss: 0.005058176815509796\n",
      "Epoch 19/100, Iteration 221/303, Loss: 0.007824042811989784\n",
      "Epoch 19/100, Iteration 222/303, Loss: 0.026396077126264572\n",
      "Epoch 19/100, Iteration 223/303, Loss: 0.005132661666721106\n",
      "Epoch 19/100, Iteration 224/303, Loss: 0.005841422826051712\n",
      "Epoch 19/100, Iteration 225/303, Loss: 0.04813408479094505\n",
      "Epoch 19/100, Iteration 226/303, Loss: 0.03985045850276947\n",
      "Epoch 19/100, Iteration 227/303, Loss: 0.017458908259868622\n",
      "Epoch 19/100, Iteration 228/303, Loss: 0.010181460529565811\n",
      "Epoch 19/100, Iteration 229/303, Loss: 0.0710626170039177\n",
      "Epoch 19/100, Iteration 230/303, Loss: 0.05247379094362259\n",
      "Epoch 19/100, Iteration 231/303, Loss: 0.06795646250247955\n",
      "Epoch 19/100, Iteration 232/303, Loss: 0.059848763048648834\n",
      "Epoch 19/100, Iteration 233/303, Loss: 0.11227366328239441\n",
      "Epoch 19/100, Iteration 234/303, Loss: 0.023813994601368904\n",
      "Epoch 19/100, Iteration 235/303, Loss: 0.006253709085285664\n",
      "Epoch 19/100, Iteration 236/303, Loss: 0.15700291097164154\n",
      "Epoch 19/100, Iteration 237/303, Loss: 0.016532521694898605\n",
      "Epoch 19/100, Iteration 238/303, Loss: 0.058089062571525574\n",
      "Epoch 19/100, Iteration 239/303, Loss: 0.019564058631658554\n",
      "Epoch 19/100, Iteration 240/303, Loss: 0.011885490268468857\n",
      "Epoch 19/100, Iteration 241/303, Loss: 0.028915809467434883\n",
      "Epoch 19/100, Iteration 242/303, Loss: 0.05674013867974281\n",
      "Epoch 19/100, Iteration 243/303, Loss: 0.047746431082487106\n",
      "Epoch 19/100, Iteration 244/303, Loss: 0.009606604464352131\n",
      "Epoch 19/100, Iteration 245/303, Loss: 0.10517410188913345\n",
      "Epoch 19/100, Iteration 246/303, Loss: 0.09718729555606842\n",
      "Epoch 19/100, Iteration 247/303, Loss: 0.03781060874462128\n",
      "Epoch 19/100, Iteration 248/303, Loss: 0.020136382430791855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100, Iteration 249/303, Loss: 0.013837750069797039\n",
      "Epoch 19/100, Iteration 250/303, Loss: 0.004090524278581142\n",
      "Epoch 19/100, Iteration 251/303, Loss: 0.0017734665889292955\n",
      "Epoch 19/100, Iteration 252/303, Loss: 0.004672821611166\n",
      "Epoch 19/100, Iteration 253/303, Loss: 0.005977311637252569\n",
      "Epoch 19/100, Iteration 254/303, Loss: 0.03193574398756027\n",
      "Epoch 19/100, Iteration 255/303, Loss: 0.012224034406244755\n",
      "Epoch 19/100, Iteration 256/303, Loss: 0.0720566138625145\n",
      "Epoch 19/100, Iteration 257/303, Loss: 0.02209523692727089\n",
      "Epoch 19/100, Iteration 258/303, Loss: 0.033417634665966034\n",
      "Epoch 19/100, Iteration 259/303, Loss: 0.016874508932232857\n",
      "Epoch 19/100, Iteration 260/303, Loss: 0.04569403454661369\n",
      "Epoch 19/100, Iteration 261/303, Loss: 0.02474425733089447\n",
      "Epoch 19/100, Iteration 262/303, Loss: 0.007296453230082989\n",
      "Epoch 19/100, Iteration 263/303, Loss: 0.02739991433918476\n",
      "Epoch 19/100, Iteration 264/303, Loss: 0.021677428856492043\n",
      "Epoch 19/100, Iteration 265/303, Loss: 0.06415095180273056\n",
      "Epoch 19/100, Iteration 266/303, Loss: 0.028926359489560127\n",
      "Epoch 19/100, Iteration 267/303, Loss: 0.030674530193209648\n",
      "Epoch 19/100, Iteration 268/303, Loss: 0.012369913049042225\n",
      "Epoch 19/100, Iteration 269/303, Loss: 0.011833779513835907\n",
      "Epoch 19/100, Iteration 270/303, Loss: 0.0049588922411203384\n",
      "Epoch 19/100, Iteration 271/303, Loss: 0.06664388626813889\n",
      "Epoch 19/100, Iteration 272/303, Loss: 0.19569002091884613\n",
      "Epoch 19/100, Iteration 273/303, Loss: 0.060804758220911026\n",
      "Epoch 19/100, Iteration 274/303, Loss: 0.10021183639764786\n",
      "Epoch 19/100, Iteration 275/303, Loss: 0.08535011112689972\n",
      "Epoch 19/100, Iteration 276/303, Loss: 0.028314173221588135\n",
      "Epoch 19/100, Iteration 277/303, Loss: 0.01723358780145645\n",
      "Epoch 19/100, Iteration 278/303, Loss: 0.0031917449086904526\n",
      "Epoch 19/100, Iteration 279/303, Loss: 0.039682067930698395\n",
      "Epoch 19/100, Iteration 280/303, Loss: 0.031742025166749954\n",
      "Epoch 19/100, Iteration 281/303, Loss: 0.05288270488381386\n",
      "Epoch 19/100, Iteration 282/303, Loss: 0.0041051339358091354\n",
      "Epoch 19/100, Iteration 283/303, Loss: 0.035730957984924316\n",
      "Epoch 19/100, Iteration 284/303, Loss: 0.0310677420347929\n",
      "Epoch 19/100, Iteration 285/303, Loss: 0.012784498743712902\n",
      "Epoch 19/100, Iteration 286/303, Loss: 0.004372036084532738\n",
      "Epoch 19/100, Iteration 287/303, Loss: 0.005839735269546509\n",
      "Epoch 19/100, Iteration 288/303, Loss: 0.00670103682205081\n",
      "Epoch 19/100, Iteration 289/303, Loss: 0.043409913778305054\n",
      "Epoch 19/100, Iteration 290/303, Loss: 0.023901918902993202\n",
      "Epoch 19/100, Iteration 291/303, Loss: 0.007376107852905989\n",
      "Epoch 19/100, Iteration 292/303, Loss: 0.014209229499101639\n",
      "Epoch 19/100, Iteration 293/303, Loss: 0.03234432265162468\n",
      "Epoch 19/100, Iteration 294/303, Loss: 0.002394723240286112\n",
      "Epoch 19/100, Iteration 295/303, Loss: 0.008581181056797504\n",
      "Epoch 19/100, Iteration 296/303, Loss: 0.05043590068817139\n",
      "Epoch 19/100, Iteration 297/303, Loss: 0.023059137165546417\n",
      "Epoch 19/100, Iteration 298/303, Loss: 0.03882458060979843\n",
      "Epoch 19/100, Iteration 299/303, Loss: 0.03484498709440231\n",
      "Epoch 19/100, Iteration 300/303, Loss: 0.01683647558093071\n",
      "Epoch 19/100, Iteration 301/303, Loss: 0.0069798496551811695\n",
      "Epoch 19/100, Iteration 302/303, Loss: 0.001147979055531323\n",
      "Epoch 19/100, Iteration 303/303, Loss: 0.005196291022002697\n",
      "Epoch 20/100, Iteration 1/303, Loss: 0.0038684154860675335\n",
      "Epoch 20/100, Iteration 2/303, Loss: 0.005064803175628185\n",
      "Epoch 20/100, Iteration 3/303, Loss: 0.0650842934846878\n",
      "Epoch 20/100, Iteration 4/303, Loss: 0.02485004812479019\n",
      "Epoch 20/100, Iteration 5/303, Loss: 0.0132070854306221\n",
      "Epoch 20/100, Iteration 6/303, Loss: 0.00363331101834774\n",
      "Epoch 20/100, Iteration 7/303, Loss: 0.006817169487476349\n",
      "Epoch 20/100, Iteration 8/303, Loss: 0.0026487160939723253\n",
      "Epoch 20/100, Iteration 9/303, Loss: 0.0024215104058384895\n",
      "Epoch 20/100, Iteration 10/303, Loss: 0.02231545001268387\n",
      "Epoch 20/100, Iteration 11/303, Loss: 0.033176809549331665\n",
      "Epoch 20/100, Iteration 12/303, Loss: 0.08552545309066772\n",
      "Epoch 20/100, Iteration 13/303, Loss: 0.006548150442540646\n",
      "Epoch 20/100, Iteration 14/303, Loss: 0.009816375561058521\n",
      "Epoch 20/100, Iteration 15/303, Loss: 0.005910432431846857\n",
      "Epoch 20/100, Iteration 16/303, Loss: 0.016513533890247345\n",
      "Epoch 20/100, Iteration 17/303, Loss: 0.0067337192595005035\n",
      "Epoch 20/100, Iteration 18/303, Loss: 0.01989670842885971\n",
      "Epoch 20/100, Iteration 19/303, Loss: 0.007784985471516848\n",
      "Epoch 20/100, Iteration 20/303, Loss: 0.02221338450908661\n",
      "Epoch 20/100, Iteration 21/303, Loss: 0.0070998347364366055\n",
      "Epoch 20/100, Iteration 22/303, Loss: 0.02195027843117714\n",
      "Epoch 20/100, Iteration 23/303, Loss: 0.0033587398938834667\n",
      "Epoch 20/100, Iteration 24/303, Loss: 0.014458887279033661\n",
      "Epoch 20/100, Iteration 25/303, Loss: 0.007583576254546642\n",
      "Epoch 20/100, Iteration 26/303, Loss: 0.005060653667896986\n",
      "Epoch 20/100, Iteration 27/303, Loss: 0.007217646110802889\n",
      "Epoch 20/100, Iteration 28/303, Loss: 0.0058613913133740425\n",
      "Epoch 20/100, Iteration 29/303, Loss: 0.009075779467821121\n",
      "Epoch 20/100, Iteration 30/303, Loss: 0.0018709221621975303\n",
      "Epoch 20/100, Iteration 31/303, Loss: 0.0033086929470300674\n",
      "Epoch 20/100, Iteration 32/303, Loss: 0.00957454927265644\n",
      "Epoch 20/100, Iteration 33/303, Loss: 0.007456527557224035\n",
      "Epoch 20/100, Iteration 34/303, Loss: 0.0014850443694740534\n",
      "Epoch 20/100, Iteration 35/303, Loss: 0.007952585816383362\n",
      "Epoch 20/100, Iteration 36/303, Loss: 0.011094975285232067\n",
      "Epoch 20/100, Iteration 37/303, Loss: 0.0025102044455707073\n",
      "Epoch 20/100, Iteration 38/303, Loss: 0.02926674485206604\n",
      "Epoch 20/100, Iteration 39/303, Loss: 0.0035156914964318275\n",
      "Epoch 20/100, Iteration 40/303, Loss: 0.01608463004231453\n",
      "Epoch 20/100, Iteration 41/303, Loss: 0.0023122099228203297\n",
      "Epoch 20/100, Iteration 42/303, Loss: 0.01810016669332981\n",
      "Epoch 20/100, Iteration 43/303, Loss: 0.08476600050926208\n",
      "Epoch 20/100, Iteration 44/303, Loss: 0.010817620903253555\n",
      "Epoch 20/100, Iteration 45/303, Loss: 0.004620700608938932\n",
      "Epoch 20/100, Iteration 46/303, Loss: 0.031143425032496452\n",
      "Epoch 20/100, Iteration 47/303, Loss: 0.03705783188343048\n",
      "Epoch 20/100, Iteration 48/303, Loss: 0.01714865118265152\n",
      "Epoch 20/100, Iteration 49/303, Loss: 0.04968106374144554\n",
      "Epoch 20/100, Iteration 50/303, Loss: 0.010675660334527493\n",
      "Epoch 20/100, Iteration 51/303, Loss: 0.01223345473408699\n",
      "Epoch 20/100, Iteration 52/303, Loss: 0.020472925156354904\n",
      "Epoch 20/100, Iteration 53/303, Loss: 0.044242531061172485\n",
      "Epoch 20/100, Iteration 54/303, Loss: 0.11798661202192307\n",
      "Epoch 20/100, Iteration 55/303, Loss: 0.03976369649171829\n",
      "Epoch 20/100, Iteration 56/303, Loss: 0.036900151520967484\n",
      "Epoch 20/100, Iteration 57/303, Loss: 0.037183474749326706\n",
      "Epoch 20/100, Iteration 58/303, Loss: 0.010101192630827427\n",
      "Epoch 20/100, Iteration 59/303, Loss: 0.013562429696321487\n",
      "Epoch 20/100, Iteration 60/303, Loss: 0.0025520341005176306\n",
      "Epoch 20/100, Iteration 61/303, Loss: 0.0009574383147992194\n",
      "Epoch 20/100, Iteration 62/303, Loss: 0.020885562524199486\n",
      "Epoch 20/100, Iteration 63/303, Loss: 0.01830424554646015\n",
      "Epoch 20/100, Iteration 64/303, Loss: 0.012450172565877438\n",
      "Epoch 20/100, Iteration 65/303, Loss: 0.0008553102961741388\n",
      "Epoch 20/100, Iteration 66/303, Loss: 0.0062317019328475\n",
      "Epoch 20/100, Iteration 67/303, Loss: 0.003784062108024955\n",
      "Epoch 20/100, Iteration 68/303, Loss: 0.004361937288194895\n",
      "Epoch 20/100, Iteration 69/303, Loss: 0.009708283469080925\n",
      "Epoch 20/100, Iteration 70/303, Loss: 0.004467924125492573\n",
      "Epoch 20/100, Iteration 71/303, Loss: 0.001329704886302352\n",
      "Epoch 20/100, Iteration 72/303, Loss: 0.00035908122663386166\n",
      "Epoch 20/100, Iteration 73/303, Loss: 0.0020540959667414427\n",
      "Epoch 20/100, Iteration 74/303, Loss: 0.003802909981459379\n",
      "Epoch 20/100, Iteration 75/303, Loss: 0.005025207996368408\n",
      "Epoch 20/100, Iteration 76/303, Loss: 0.002133573405444622\n",
      "Epoch 20/100, Iteration 77/303, Loss: 0.0011797789484262466\n",
      "Epoch 20/100, Iteration 78/303, Loss: 0.0011693144915625453\n",
      "Epoch 20/100, Iteration 79/303, Loss: 0.0010338039137423038\n",
      "Epoch 20/100, Iteration 80/303, Loss: 0.0008082950953394175\n",
      "Epoch 20/100, Iteration 81/303, Loss: 0.001661284128203988\n",
      "Epoch 20/100, Iteration 82/303, Loss: 0.019472761079669\n",
      "Epoch 20/100, Iteration 83/303, Loss: 0.006702149752527475\n",
      "Epoch 20/100, Iteration 84/303, Loss: 0.0033195491414517164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Iteration 85/303, Loss: 0.0012654332676902413\n",
      "Epoch 20/100, Iteration 86/303, Loss: 0.006130438297986984\n",
      "Epoch 20/100, Iteration 87/303, Loss: 0.009060202166438103\n",
      "Epoch 20/100, Iteration 88/303, Loss: 0.0007214401848614216\n",
      "Epoch 20/100, Iteration 89/303, Loss: 0.0005500893457792699\n",
      "Epoch 20/100, Iteration 90/303, Loss: 0.00392893748357892\n",
      "Epoch 20/100, Iteration 91/303, Loss: 0.010301460511982441\n",
      "Epoch 20/100, Iteration 92/303, Loss: 0.005615474656224251\n",
      "Epoch 20/100, Iteration 93/303, Loss: 0.005806964822113514\n",
      "Epoch 20/100, Iteration 94/303, Loss: 0.006223620846867561\n",
      "Epoch 20/100, Iteration 95/303, Loss: 0.0033384256530553102\n",
      "Epoch 20/100, Iteration 96/303, Loss: 0.0015080398879945278\n",
      "Epoch 20/100, Iteration 97/303, Loss: 0.006437049712985754\n",
      "Epoch 20/100, Iteration 98/303, Loss: 0.00036780667142011225\n",
      "Epoch 20/100, Iteration 99/303, Loss: 0.0007885931408964097\n",
      "Epoch 20/100, Iteration 100/303, Loss: 0.026840075850486755\n",
      "Epoch 20/100, Iteration 101/303, Loss: 0.002198487054556608\n",
      "Epoch 20/100, Iteration 102/303, Loss: 0.0008281783666461706\n",
      "Epoch 20/100, Iteration 103/303, Loss: 0.03203321993350983\n",
      "Epoch 20/100, Iteration 104/303, Loss: 0.0028630641754716635\n",
      "Epoch 20/100, Iteration 105/303, Loss: 0.025068333372473717\n",
      "Epoch 20/100, Iteration 106/303, Loss: 0.015670152381062508\n",
      "Epoch 20/100, Iteration 107/303, Loss: 0.0014094196958467364\n",
      "Epoch 20/100, Iteration 108/303, Loss: 0.008369704708456993\n",
      "Epoch 20/100, Iteration 109/303, Loss: 0.00585814518854022\n",
      "Epoch 20/100, Iteration 110/303, Loss: 0.0020047060679644346\n",
      "Epoch 20/100, Iteration 111/303, Loss: 0.0035030522849410772\n",
      "Epoch 20/100, Iteration 112/303, Loss: 0.024112461134791374\n",
      "Epoch 20/100, Iteration 113/303, Loss: 0.012443711049854755\n",
      "Epoch 20/100, Iteration 114/303, Loss: 0.0016195455100387335\n",
      "Epoch 20/100, Iteration 115/303, Loss: 0.0009933261899277568\n",
      "Epoch 20/100, Iteration 116/303, Loss: 0.003449182491749525\n",
      "Epoch 20/100, Iteration 117/303, Loss: 0.0016068837139755487\n",
      "Epoch 20/100, Iteration 118/303, Loss: 0.0063720326870679855\n",
      "Epoch 20/100, Iteration 119/303, Loss: 0.0029702410101890564\n",
      "Epoch 20/100, Iteration 120/303, Loss: 0.0047027235850691795\n",
      "Epoch 20/100, Iteration 121/303, Loss: 0.0018937737913802266\n",
      "Epoch 20/100, Iteration 122/303, Loss: 0.035753052681684494\n",
      "Epoch 20/100, Iteration 123/303, Loss: 0.010484552942216396\n",
      "Epoch 20/100, Iteration 124/303, Loss: 0.011290477588772774\n",
      "Epoch 20/100, Iteration 125/303, Loss: 0.004834963008761406\n",
      "Epoch 20/100, Iteration 126/303, Loss: 0.016285177320241928\n",
      "Epoch 20/100, Iteration 127/303, Loss: 0.0010137376375496387\n",
      "Epoch 20/100, Iteration 128/303, Loss: 0.0055475193075835705\n",
      "Epoch 20/100, Iteration 129/303, Loss: 0.019913824275135994\n",
      "Epoch 20/100, Iteration 130/303, Loss: 0.0013985979603603482\n",
      "Epoch 20/100, Iteration 131/303, Loss: 0.01040552742779255\n",
      "Epoch 20/100, Iteration 132/303, Loss: 0.0006561011541634798\n",
      "Epoch 20/100, Iteration 133/303, Loss: 0.01740119792521\n",
      "Epoch 20/100, Iteration 134/303, Loss: 0.0015417297836393118\n",
      "Epoch 20/100, Iteration 135/303, Loss: 0.0029735236894339323\n",
      "Epoch 20/100, Iteration 136/303, Loss: 0.0005686298827640712\n",
      "Epoch 20/100, Iteration 137/303, Loss: 0.001877324073575437\n",
      "Epoch 20/100, Iteration 138/303, Loss: 0.00019814542611129582\n",
      "Epoch 20/100, Iteration 139/303, Loss: 0.0037113467697054148\n",
      "Epoch 20/100, Iteration 140/303, Loss: 0.00552373006939888\n",
      "Epoch 20/100, Iteration 141/303, Loss: 0.0040726615116000175\n",
      "Epoch 20/100, Iteration 142/303, Loss: 0.0015298961661756039\n",
      "Epoch 20/100, Iteration 143/303, Loss: 0.0011984773445874453\n",
      "Epoch 20/100, Iteration 144/303, Loss: 0.0007245483575388789\n",
      "Epoch 20/100, Iteration 145/303, Loss: 0.005993564613163471\n",
      "Epoch 20/100, Iteration 146/303, Loss: 0.0014822970842942595\n",
      "Epoch 20/100, Iteration 147/303, Loss: 0.0004095813783351332\n",
      "Epoch 20/100, Iteration 148/303, Loss: 0.0011632886016741395\n",
      "Epoch 20/100, Iteration 149/303, Loss: 0.00027974037220701575\n",
      "Epoch 20/100, Iteration 150/303, Loss: 0.01671701669692993\n",
      "Epoch 20/100, Iteration 151/303, Loss: 0.0003844194288831204\n",
      "Epoch 20/100, Iteration 152/303, Loss: 0.0024413454812020063\n",
      "Epoch 20/100, Iteration 153/303, Loss: 0.0013735678512603045\n",
      "Epoch 20/100, Iteration 154/303, Loss: 0.0014629521174356341\n",
      "Epoch 20/100, Iteration 155/303, Loss: 0.004654973279684782\n",
      "Epoch 20/100, Iteration 156/303, Loss: 0.0017862075474113226\n",
      "Epoch 20/100, Iteration 157/303, Loss: 0.0027718921191990376\n",
      "Epoch 20/100, Iteration 158/303, Loss: 0.002454254776239395\n",
      "Epoch 20/100, Iteration 159/303, Loss: 0.0011504440335556865\n",
      "Epoch 20/100, Iteration 160/303, Loss: 0.004408043343573809\n",
      "Epoch 20/100, Iteration 161/303, Loss: 0.00017705076606944203\n",
      "Epoch 20/100, Iteration 162/303, Loss: 0.0018224886152893305\n",
      "Epoch 20/100, Iteration 163/303, Loss: 0.005625809542834759\n",
      "Epoch 20/100, Iteration 164/303, Loss: 0.0012261678930372\n",
      "Epoch 20/100, Iteration 165/303, Loss: 0.004791339859366417\n",
      "Epoch 20/100, Iteration 166/303, Loss: 0.005468897055834532\n",
      "Epoch 20/100, Iteration 167/303, Loss: 0.020430995151400566\n",
      "Epoch 20/100, Iteration 168/303, Loss: 0.004955506417900324\n",
      "Epoch 20/100, Iteration 169/303, Loss: 0.004748985171318054\n",
      "Epoch 20/100, Iteration 170/303, Loss: 0.0051170955412089825\n",
      "Epoch 20/100, Iteration 171/303, Loss: 0.011996078304946423\n",
      "Epoch 20/100, Iteration 172/303, Loss: 0.014398430474102497\n",
      "Epoch 20/100, Iteration 173/303, Loss: 0.004772498272359371\n",
      "Epoch 20/100, Iteration 174/303, Loss: 0.025466274470090866\n",
      "Epoch 20/100, Iteration 175/303, Loss: 0.0348377525806427\n",
      "Epoch 20/100, Iteration 176/303, Loss: 0.006145665422081947\n",
      "Epoch 20/100, Iteration 177/303, Loss: 0.002328551607206464\n",
      "Epoch 20/100, Iteration 178/303, Loss: 0.006607719697058201\n",
      "Epoch 20/100, Iteration 179/303, Loss: 0.003184001659974456\n",
      "Epoch 20/100, Iteration 180/303, Loss: 0.012522359378635883\n",
      "Epoch 20/100, Iteration 181/303, Loss: 0.002702511614188552\n",
      "Epoch 20/100, Iteration 182/303, Loss: 0.000525394338183105\n",
      "Epoch 20/100, Iteration 183/303, Loss: 0.004108501132577658\n",
      "Epoch 20/100, Iteration 184/303, Loss: 0.006643204018473625\n",
      "Epoch 20/100, Iteration 185/303, Loss: 0.002630329690873623\n",
      "Epoch 20/100, Iteration 186/303, Loss: 0.000740538933314383\n",
      "Epoch 20/100, Iteration 187/303, Loss: 0.003142275847494602\n",
      "Epoch 20/100, Iteration 188/303, Loss: 0.0029201155994087458\n",
      "Epoch 20/100, Iteration 189/303, Loss: 0.0039059650152921677\n",
      "Epoch 20/100, Iteration 190/303, Loss: 0.0002622232714202255\n",
      "Epoch 20/100, Iteration 191/303, Loss: 0.00546831963583827\n",
      "Epoch 20/100, Iteration 192/303, Loss: 0.009821183979511261\n",
      "Epoch 20/100, Iteration 193/303, Loss: 0.0010321646695956588\n",
      "Epoch 20/100, Iteration 194/303, Loss: 0.0007256505195982754\n",
      "Epoch 20/100, Iteration 195/303, Loss: 0.0008431939641013741\n",
      "Epoch 20/100, Iteration 196/303, Loss: 0.0001513100869487971\n",
      "Epoch 20/100, Iteration 197/303, Loss: 0.0016525592654943466\n",
      "Epoch 20/100, Iteration 198/303, Loss: 0.0009432390797883272\n",
      "Epoch 20/100, Iteration 199/303, Loss: 0.013393563218414783\n",
      "Epoch 20/100, Iteration 200/303, Loss: 0.002101263264194131\n",
      "Epoch 20/100, Iteration 201/303, Loss: 0.002661495003849268\n",
      "Epoch 20/100, Iteration 202/303, Loss: 0.0017575115198269486\n",
      "Epoch 20/100, Iteration 203/303, Loss: 0.0007917711045593023\n",
      "Epoch 20/100, Iteration 204/303, Loss: 0.003976022824645042\n",
      "Epoch 20/100, Iteration 205/303, Loss: 0.014510886743664742\n",
      "Epoch 20/100, Iteration 206/303, Loss: 0.0005771054420620203\n",
      "Epoch 20/100, Iteration 207/303, Loss: 0.002277090447023511\n",
      "Epoch 20/100, Iteration 208/303, Loss: 0.0037053083069622517\n",
      "Epoch 20/100, Iteration 209/303, Loss: 0.0009582627099007368\n",
      "Epoch 20/100, Iteration 210/303, Loss: 0.012938639149069786\n",
      "Epoch 20/100, Iteration 211/303, Loss: 0.006406653672456741\n",
      "Epoch 20/100, Iteration 212/303, Loss: 0.0030368450097739697\n",
      "Epoch 20/100, Iteration 213/303, Loss: 0.0035081617534160614\n",
      "Epoch 20/100, Iteration 214/303, Loss: 0.0023230004590004683\n",
      "Epoch 20/100, Iteration 215/303, Loss: 0.0037555531598627567\n",
      "Epoch 20/100, Iteration 216/303, Loss: 0.0028451632242649794\n",
      "Epoch 20/100, Iteration 217/303, Loss: 0.006880275905132294\n",
      "Epoch 20/100, Iteration 218/303, Loss: 0.0005049434257671237\n",
      "Epoch 20/100, Iteration 219/303, Loss: 0.0006841257563792169\n",
      "Epoch 20/100, Iteration 220/303, Loss: 0.0014053264167159796\n",
      "Epoch 20/100, Iteration 221/303, Loss: 0.0026886595878750086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Iteration 222/303, Loss: 0.00016814943228382617\n",
      "Epoch 20/100, Iteration 223/303, Loss: 0.0013129949802532792\n",
      "Epoch 20/100, Iteration 224/303, Loss: 0.0024302878882735968\n",
      "Epoch 20/100, Iteration 225/303, Loss: 0.006794072687625885\n",
      "Epoch 20/100, Iteration 226/303, Loss: 0.0005109069170430303\n",
      "Epoch 20/100, Iteration 227/303, Loss: 0.001434096833691001\n",
      "Epoch 20/100, Iteration 228/303, Loss: 0.0014293339336290956\n",
      "Epoch 20/100, Iteration 229/303, Loss: 0.0007986835553310812\n",
      "Epoch 20/100, Iteration 230/303, Loss: 0.0034813876263797283\n",
      "Epoch 20/100, Iteration 231/303, Loss: 0.002651957096531987\n",
      "Epoch 20/100, Iteration 232/303, Loss: 0.0007553775794804096\n",
      "Epoch 20/100, Iteration 233/303, Loss: 0.0009855665266513824\n",
      "Epoch 20/100, Iteration 234/303, Loss: 0.002509049605578184\n",
      "Epoch 20/100, Iteration 235/303, Loss: 0.004065764602273703\n",
      "Epoch 20/100, Iteration 236/303, Loss: 0.0013989837607368827\n",
      "Epoch 20/100, Iteration 237/303, Loss: 0.0021434270311146975\n",
      "Epoch 20/100, Iteration 238/303, Loss: 0.0006243870593607426\n",
      "Epoch 20/100, Iteration 239/303, Loss: 0.002652290277183056\n",
      "Epoch 20/100, Iteration 240/303, Loss: 0.0024227723479270935\n",
      "Epoch 20/100, Iteration 241/303, Loss: 0.0003304992860648781\n",
      "Epoch 20/100, Iteration 242/303, Loss: 0.000614263815805316\n",
      "Epoch 20/100, Iteration 243/303, Loss: 0.0005979027482680976\n",
      "Epoch 20/100, Iteration 244/303, Loss: 0.006838871631771326\n",
      "Epoch 20/100, Iteration 245/303, Loss: 0.000736132962629199\n",
      "Epoch 20/100, Iteration 246/303, Loss: 0.010645153000950813\n",
      "Epoch 20/100, Iteration 247/303, Loss: 0.0007298092823475599\n",
      "Epoch 20/100, Iteration 248/303, Loss: 0.0001703739253571257\n",
      "Epoch 20/100, Iteration 249/303, Loss: 0.0020774472504854202\n",
      "Epoch 20/100, Iteration 250/303, Loss: 0.0016700964188203216\n",
      "Epoch 20/100, Iteration 251/303, Loss: 0.0017771021230146289\n",
      "Epoch 20/100, Iteration 252/303, Loss: 0.001009343541227281\n",
      "Epoch 20/100, Iteration 253/303, Loss: 0.0019844616763293743\n",
      "Epoch 20/100, Iteration 254/303, Loss: 0.0006900549633428454\n",
      "Epoch 20/100, Iteration 255/303, Loss: 0.0004729688516817987\n",
      "Epoch 20/100, Iteration 256/303, Loss: 0.0007021944038569927\n",
      "Epoch 20/100, Iteration 257/303, Loss: 0.001178036443889141\n",
      "Epoch 20/100, Iteration 258/303, Loss: 0.0011221463792026043\n",
      "Epoch 20/100, Iteration 259/303, Loss: 0.00037901109317317605\n",
      "Epoch 20/100, Iteration 260/303, Loss: 0.0008518610266037285\n",
      "Epoch 20/100, Iteration 261/303, Loss: 0.007747927214950323\n",
      "Epoch 20/100, Iteration 262/303, Loss: 0.0012932434910908341\n",
      "Epoch 20/100, Iteration 263/303, Loss: 9.580395271768793e-05\n",
      "Epoch 20/100, Iteration 264/303, Loss: 0.0025696081575006247\n",
      "Epoch 20/100, Iteration 265/303, Loss: 0.0012069354997947812\n",
      "Epoch 20/100, Iteration 266/303, Loss: 0.0019522604998201132\n",
      "Epoch 20/100, Iteration 267/303, Loss: 0.001913412008434534\n",
      "Epoch 20/100, Iteration 268/303, Loss: 0.002085450105369091\n",
      "Epoch 20/100, Iteration 269/303, Loss: 0.00021163924247957766\n",
      "Epoch 20/100, Iteration 270/303, Loss: 0.0011642305180430412\n",
      "Epoch 20/100, Iteration 271/303, Loss: 0.0010495479218661785\n",
      "Epoch 20/100, Iteration 272/303, Loss: 0.0046179345808923244\n",
      "Epoch 20/100, Iteration 273/303, Loss: 0.043736137449741364\n",
      "Epoch 20/100, Iteration 274/303, Loss: 0.005097107496112585\n",
      "Epoch 20/100, Iteration 275/303, Loss: 0.0030710562132298946\n",
      "Epoch 20/100, Iteration 276/303, Loss: 0.012414643540978432\n",
      "Epoch 20/100, Iteration 277/303, Loss: 0.0007827425724826753\n",
      "Epoch 20/100, Iteration 278/303, Loss: 0.0010172955226153135\n",
      "Epoch 20/100, Iteration 279/303, Loss: 0.034345921128988266\n",
      "Epoch 20/100, Iteration 280/303, Loss: 0.0004482738731894642\n",
      "Epoch 20/100, Iteration 281/303, Loss: 0.000535081431735307\n",
      "Epoch 20/100, Iteration 282/303, Loss: 0.0425025150179863\n",
      "Epoch 20/100, Iteration 283/303, Loss: 0.19044354557991028\n",
      "Epoch 20/100, Iteration 284/303, Loss: 0.0819854810833931\n",
      "Epoch 20/100, Iteration 285/303, Loss: 0.008273668587207794\n",
      "Epoch 20/100, Iteration 286/303, Loss: 0.032378632575273514\n",
      "Epoch 20/100, Iteration 287/303, Loss: 0.00971262063831091\n",
      "Epoch 20/100, Iteration 288/303, Loss: 0.0021205295342952013\n",
      "Epoch 20/100, Iteration 289/303, Loss: 0.00974984746426344\n",
      "Epoch 20/100, Iteration 290/303, Loss: 0.0030870644841343164\n",
      "Epoch 20/100, Iteration 291/303, Loss: 0.011541452258825302\n",
      "Epoch 20/100, Iteration 292/303, Loss: 0.044091302901506424\n",
      "Epoch 20/100, Iteration 293/303, Loss: 0.04224001616239548\n",
      "Epoch 20/100, Iteration 294/303, Loss: 0.004595892503857613\n",
      "Epoch 20/100, Iteration 295/303, Loss: 0.009932133369147778\n",
      "Epoch 20/100, Iteration 296/303, Loss: 0.010134482756257057\n",
      "Epoch 20/100, Iteration 297/303, Loss: 0.01531321182847023\n",
      "Epoch 20/100, Iteration 298/303, Loss: 0.007870734669268131\n",
      "Epoch 20/100, Iteration 299/303, Loss: 0.030939508229494095\n",
      "Epoch 20/100, Iteration 300/303, Loss: 0.025717146694660187\n",
      "Epoch 20/100, Iteration 301/303, Loss: 0.019131207838654518\n",
      "Epoch 20/100, Iteration 302/303, Loss: 0.0905134528875351\n",
      "Epoch 20/100, Iteration 303/303, Loss: 0.02219594642519951\n",
      "Epoch 21/100, Iteration 1/303, Loss: 0.005275290925055742\n",
      "Epoch 21/100, Iteration 2/303, Loss: 0.01285642758011818\n",
      "Epoch 21/100, Iteration 3/303, Loss: 0.0013865784276276827\n",
      "Epoch 21/100, Iteration 4/303, Loss: 0.0013746990589424968\n",
      "Epoch 21/100, Iteration 5/303, Loss: 0.0011295820586383343\n",
      "Epoch 21/100, Iteration 6/303, Loss: 0.007351548410952091\n",
      "Epoch 21/100, Iteration 7/303, Loss: 0.012449078261852264\n",
      "Epoch 21/100, Iteration 8/303, Loss: 0.007619913201779127\n",
      "Epoch 21/100, Iteration 9/303, Loss: 0.0066848560236394405\n",
      "Epoch 21/100, Iteration 10/303, Loss: 0.0004521808004938066\n",
      "Epoch 21/100, Iteration 11/303, Loss: 0.0031008406076580286\n",
      "Epoch 21/100, Iteration 12/303, Loss: 0.0010777813149616122\n",
      "Epoch 21/100, Iteration 13/303, Loss: 0.0002779546775855124\n",
      "Epoch 21/100, Iteration 14/303, Loss: 0.002162541961297393\n",
      "Epoch 21/100, Iteration 15/303, Loss: 0.0006096501019783318\n",
      "Epoch 21/100, Iteration 16/303, Loss: 0.0024065717589110136\n",
      "Epoch 21/100, Iteration 17/303, Loss: 0.004605541937053204\n",
      "Epoch 21/100, Iteration 18/303, Loss: 0.009267122484743595\n",
      "Epoch 21/100, Iteration 19/303, Loss: 0.0025682360865175724\n",
      "Epoch 21/100, Iteration 20/303, Loss: 0.0012502537574619055\n",
      "Epoch 21/100, Iteration 21/303, Loss: 0.0032835938036441803\n",
      "Epoch 21/100, Iteration 22/303, Loss: 0.003952517174184322\n",
      "Epoch 21/100, Iteration 23/303, Loss: 0.0014615633990615606\n",
      "Epoch 21/100, Iteration 24/303, Loss: 0.001668640412390232\n",
      "Epoch 21/100, Iteration 25/303, Loss: 0.0004755907575599849\n",
      "Epoch 21/100, Iteration 26/303, Loss: 0.0035244657192379236\n",
      "Epoch 21/100, Iteration 27/303, Loss: 0.0023489187005907297\n",
      "Epoch 21/100, Iteration 28/303, Loss: 0.00790081825107336\n",
      "Epoch 21/100, Iteration 29/303, Loss: 0.006875781342387199\n",
      "Epoch 21/100, Iteration 30/303, Loss: 0.0015822971472516656\n",
      "Epoch 21/100, Iteration 31/303, Loss: 0.0021065252367407084\n",
      "Epoch 21/100, Iteration 32/303, Loss: 0.001184509601444006\n",
      "Epoch 21/100, Iteration 33/303, Loss: 0.004378265701234341\n",
      "Epoch 21/100, Iteration 34/303, Loss: 0.006250164937227964\n",
      "Epoch 21/100, Iteration 35/303, Loss: 0.0009732764447107911\n",
      "Epoch 21/100, Iteration 36/303, Loss: 0.0006889397627674043\n",
      "Epoch 21/100, Iteration 37/303, Loss: 0.004050713963806629\n",
      "Epoch 21/100, Iteration 38/303, Loss: 0.0011975456727668643\n",
      "Epoch 21/100, Iteration 39/303, Loss: 0.005321522708982229\n",
      "Epoch 21/100, Iteration 40/303, Loss: 0.001579475007019937\n",
      "Epoch 21/100, Iteration 41/303, Loss: 0.010151376016438007\n",
      "Epoch 21/100, Iteration 42/303, Loss: 0.0006916627171449363\n",
      "Epoch 21/100, Iteration 43/303, Loss: 0.0010289198253303766\n",
      "Epoch 21/100, Iteration 44/303, Loss: 0.004080063197761774\n",
      "Epoch 21/100, Iteration 45/303, Loss: 0.0006432614172808826\n",
      "Epoch 21/100, Iteration 46/303, Loss: 0.0048634568229317665\n",
      "Epoch 21/100, Iteration 47/303, Loss: 0.00017368413682561368\n",
      "Epoch 21/100, Iteration 48/303, Loss: 0.008254974149167538\n",
      "Epoch 21/100, Iteration 49/303, Loss: 0.0011397945927456021\n",
      "Epoch 21/100, Iteration 50/303, Loss: 0.006596957799047232\n",
      "Epoch 21/100, Iteration 51/303, Loss: 0.0024734295438975096\n",
      "Epoch 21/100, Iteration 52/303, Loss: 0.0019471412524580956\n",
      "Epoch 21/100, Iteration 53/303, Loss: 0.0012980710016563535\n",
      "Epoch 21/100, Iteration 54/303, Loss: 0.00499388575553894\n",
      "Epoch 21/100, Iteration 55/303, Loss: 0.004560688976198435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Iteration 56/303, Loss: 0.0012142363702878356\n",
      "Epoch 21/100, Iteration 57/303, Loss: 0.004146520514041185\n",
      "Epoch 21/100, Iteration 58/303, Loss: 0.0020984825678169727\n",
      "Epoch 21/100, Iteration 59/303, Loss: 0.0037958892062306404\n",
      "Epoch 21/100, Iteration 60/303, Loss: 0.0005671518738381565\n",
      "Epoch 21/100, Iteration 61/303, Loss: 0.00020678156579378992\n",
      "Epoch 21/100, Iteration 62/303, Loss: 0.005735188722610474\n",
      "Epoch 21/100, Iteration 63/303, Loss: 0.0009568238747306168\n",
      "Epoch 21/100, Iteration 64/303, Loss: 0.005249595735222101\n",
      "Epoch 21/100, Iteration 65/303, Loss: 0.0003863059973809868\n",
      "Epoch 21/100, Iteration 66/303, Loss: 0.0011953735956922174\n",
      "Epoch 21/100, Iteration 67/303, Loss: 0.00047067771083675325\n",
      "Epoch 21/100, Iteration 68/303, Loss: 0.00432442594319582\n",
      "Epoch 21/100, Iteration 69/303, Loss: 0.0002567499759607017\n",
      "Epoch 21/100, Iteration 70/303, Loss: 0.004294432234019041\n",
      "Epoch 21/100, Iteration 71/303, Loss: 0.007947523146867752\n",
      "Epoch 21/100, Iteration 72/303, Loss: 0.0021248941775411367\n",
      "Epoch 21/100, Iteration 73/303, Loss: 0.001241383608430624\n",
      "Epoch 21/100, Iteration 74/303, Loss: 0.0022883128840476274\n",
      "Epoch 21/100, Iteration 75/303, Loss: 0.007828270085155964\n",
      "Epoch 21/100, Iteration 76/303, Loss: 0.011616486124694347\n",
      "Epoch 21/100, Iteration 77/303, Loss: 0.0005415854975581169\n",
      "Epoch 21/100, Iteration 78/303, Loss: 0.0012726965360343456\n",
      "Epoch 21/100, Iteration 79/303, Loss: 0.0008613660465925932\n",
      "Epoch 21/100, Iteration 80/303, Loss: 0.0014497616793960333\n",
      "Epoch 21/100, Iteration 81/303, Loss: 0.0022123579401522875\n",
      "Epoch 21/100, Iteration 82/303, Loss: 0.0006418467964977026\n",
      "Epoch 21/100, Iteration 83/303, Loss: 0.0013932675356045365\n",
      "Epoch 21/100, Iteration 84/303, Loss: 0.0029040321242064238\n",
      "Epoch 21/100, Iteration 85/303, Loss: 0.00015268450079020113\n",
      "Epoch 21/100, Iteration 86/303, Loss: 0.000796856707893312\n",
      "Epoch 21/100, Iteration 87/303, Loss: 0.000571773387491703\n",
      "Epoch 21/100, Iteration 88/303, Loss: 0.0011110465275123715\n",
      "Epoch 21/100, Iteration 89/303, Loss: 0.0014034751802682877\n",
      "Epoch 21/100, Iteration 90/303, Loss: 0.00120889104437083\n",
      "Epoch 21/100, Iteration 91/303, Loss: 0.004623785149306059\n",
      "Epoch 21/100, Iteration 92/303, Loss: 0.000529872952029109\n",
      "Epoch 21/100, Iteration 93/303, Loss: 0.0006725688581354916\n",
      "Epoch 21/100, Iteration 94/303, Loss: 0.001992364414036274\n",
      "Epoch 21/100, Iteration 95/303, Loss: 0.0004789645900018513\n",
      "Epoch 21/100, Iteration 96/303, Loss: 0.0023933707270771265\n",
      "Epoch 21/100, Iteration 97/303, Loss: 0.0010597928194329143\n",
      "Epoch 21/100, Iteration 98/303, Loss: 0.0013669213512912393\n",
      "Epoch 21/100, Iteration 99/303, Loss: 0.0007318902062252164\n",
      "Epoch 21/100, Iteration 100/303, Loss: 0.0023928151931613684\n",
      "Epoch 21/100, Iteration 101/303, Loss: 0.0009028039639815688\n",
      "Epoch 21/100, Iteration 102/303, Loss: 0.0034293755888938904\n",
      "Epoch 21/100, Iteration 103/303, Loss: 0.0010754169197753072\n",
      "Epoch 21/100, Iteration 104/303, Loss: 0.0043665943667292595\n",
      "Epoch 21/100, Iteration 105/303, Loss: 0.00019039590551983565\n",
      "Epoch 21/100, Iteration 106/303, Loss: 0.0004803189367521554\n",
      "Epoch 21/100, Iteration 107/303, Loss: 0.0018285885453224182\n",
      "Epoch 21/100, Iteration 108/303, Loss: 0.005966332275420427\n",
      "Epoch 21/100, Iteration 109/303, Loss: 0.00044855347368866205\n",
      "Epoch 21/100, Iteration 110/303, Loss: 0.00401750672608614\n",
      "Epoch 21/100, Iteration 111/303, Loss: 0.0002474510984029621\n",
      "Epoch 21/100, Iteration 112/303, Loss: 0.0014190218644216657\n",
      "Epoch 21/100, Iteration 113/303, Loss: 0.0019861687906086445\n",
      "Epoch 21/100, Iteration 114/303, Loss: 0.02109197899699211\n",
      "Epoch 21/100, Iteration 115/303, Loss: 0.016539033502340317\n",
      "Epoch 21/100, Iteration 116/303, Loss: 0.0018577907467260957\n",
      "Epoch 21/100, Iteration 117/303, Loss: 0.0017270901007577777\n",
      "Epoch 21/100, Iteration 118/303, Loss: 0.0021635452285408974\n",
      "Epoch 21/100, Iteration 119/303, Loss: 0.003713746089488268\n",
      "Epoch 21/100, Iteration 120/303, Loss: 0.0002531139471102506\n",
      "Epoch 21/100, Iteration 121/303, Loss: 0.001831132685765624\n",
      "Epoch 21/100, Iteration 122/303, Loss: 0.001016900292597711\n",
      "Epoch 21/100, Iteration 123/303, Loss: 0.0005416822386905551\n",
      "Epoch 21/100, Iteration 124/303, Loss: 0.0005876202485524118\n",
      "Epoch 21/100, Iteration 125/303, Loss: 0.002182536758482456\n",
      "Epoch 21/100, Iteration 126/303, Loss: 0.003024202771484852\n",
      "Epoch 21/100, Iteration 127/303, Loss: 0.0024291053414344788\n",
      "Epoch 21/100, Iteration 128/303, Loss: 0.006150419823825359\n",
      "Epoch 21/100, Iteration 129/303, Loss: 0.00316255702637136\n",
      "Epoch 21/100, Iteration 130/303, Loss: 0.004317371640354395\n",
      "Epoch 21/100, Iteration 131/303, Loss: 0.001558914897032082\n",
      "Epoch 21/100, Iteration 132/303, Loss: 0.001307670259848237\n",
      "Epoch 21/100, Iteration 133/303, Loss: 0.0010184377897530794\n",
      "Epoch 21/100, Iteration 134/303, Loss: 0.0027261360082775354\n",
      "Epoch 21/100, Iteration 135/303, Loss: 0.0003641060320660472\n",
      "Epoch 21/100, Iteration 136/303, Loss: 0.015461679548025131\n",
      "Epoch 21/100, Iteration 137/303, Loss: 0.011792322620749474\n",
      "Epoch 21/100, Iteration 138/303, Loss: 0.001076550455763936\n",
      "Epoch 21/100, Iteration 139/303, Loss: 0.0018332084873691201\n",
      "Epoch 21/100, Iteration 140/303, Loss: 0.001946278614923358\n",
      "Epoch 21/100, Iteration 141/303, Loss: 0.014287050813436508\n",
      "Epoch 21/100, Iteration 142/303, Loss: 0.0005066059529781342\n",
      "Epoch 21/100, Iteration 143/303, Loss: 0.00039387986180372536\n",
      "Epoch 21/100, Iteration 144/303, Loss: 0.0010974095202982426\n",
      "Epoch 21/100, Iteration 145/303, Loss: 0.006408991292119026\n",
      "Epoch 21/100, Iteration 146/303, Loss: 0.002545079914852977\n",
      "Epoch 21/100, Iteration 147/303, Loss: 0.0004154110501985997\n",
      "Epoch 21/100, Iteration 148/303, Loss: 0.0032291309908032417\n",
      "Epoch 21/100, Iteration 149/303, Loss: 0.0014378781197592616\n",
      "Epoch 21/100, Iteration 150/303, Loss: 0.001233464339748025\n",
      "Epoch 21/100, Iteration 151/303, Loss: 0.0001496585173299536\n",
      "Epoch 21/100, Iteration 152/303, Loss: 0.004408980719745159\n",
      "Epoch 21/100, Iteration 153/303, Loss: 0.0025650630705058575\n",
      "Epoch 21/100, Iteration 154/303, Loss: 0.0002474989742040634\n",
      "Epoch 21/100, Iteration 155/303, Loss: 0.001245831954292953\n",
      "Epoch 21/100, Iteration 156/303, Loss: 0.0012054344406351447\n",
      "Epoch 21/100, Iteration 157/303, Loss: 0.0007694442756474018\n",
      "Epoch 21/100, Iteration 158/303, Loss: 0.0001706494076643139\n",
      "Epoch 21/100, Iteration 159/303, Loss: 0.0009397819521836936\n",
      "Epoch 21/100, Iteration 160/303, Loss: 0.0043330988846719265\n",
      "Epoch 21/100, Iteration 161/303, Loss: 0.0003999879991170019\n",
      "Epoch 21/100, Iteration 162/303, Loss: 0.003708611475303769\n",
      "Epoch 21/100, Iteration 163/303, Loss: 0.00030827338923700154\n",
      "Epoch 21/100, Iteration 164/303, Loss: 0.005608993582427502\n",
      "Epoch 21/100, Iteration 165/303, Loss: 0.0002235334977740422\n",
      "Epoch 21/100, Iteration 166/303, Loss: 0.00043451617239043117\n",
      "Epoch 21/100, Iteration 167/303, Loss: 0.0005010307068005204\n",
      "Epoch 21/100, Iteration 168/303, Loss: 0.0002907091984525323\n",
      "Epoch 21/100, Iteration 169/303, Loss: 0.008260192349553108\n",
      "Epoch 21/100, Iteration 170/303, Loss: 0.0009353995556011796\n",
      "Epoch 21/100, Iteration 171/303, Loss: 0.001359575311653316\n",
      "Epoch 21/100, Iteration 172/303, Loss: 0.0001746728376019746\n",
      "Epoch 21/100, Iteration 173/303, Loss: 0.000432840664871037\n",
      "Epoch 21/100, Iteration 174/303, Loss: 0.004764244891703129\n",
      "Epoch 21/100, Iteration 175/303, Loss: 0.006519554182887077\n",
      "Epoch 21/100, Iteration 176/303, Loss: 0.0010051984572783113\n",
      "Epoch 21/100, Iteration 177/303, Loss: 0.0007413114071823657\n",
      "Epoch 21/100, Iteration 178/303, Loss: 0.0006581231136806309\n",
      "Epoch 21/100, Iteration 179/303, Loss: 0.0007022381760179996\n",
      "Epoch 21/100, Iteration 180/303, Loss: 0.0009923574980348349\n",
      "Epoch 21/100, Iteration 181/303, Loss: 0.002702875528484583\n",
      "Epoch 21/100, Iteration 182/303, Loss: 0.00020929683523718268\n",
      "Epoch 21/100, Iteration 183/303, Loss: 0.0006872561643831432\n",
      "Epoch 21/100, Iteration 184/303, Loss: 5.893041816307232e-05\n",
      "Epoch 21/100, Iteration 185/303, Loss: 0.0002669260429684073\n",
      "Epoch 21/100, Iteration 186/303, Loss: 0.00015351470210589468\n",
      "Epoch 21/100, Iteration 187/303, Loss: 0.0009899591095745564\n",
      "Epoch 21/100, Iteration 188/303, Loss: 0.000639523786958307\n",
      "Epoch 21/100, Iteration 189/303, Loss: 0.0017629492795094848\n",
      "Epoch 21/100, Iteration 190/303, Loss: 0.0017109332839027047\n",
      "Epoch 21/100, Iteration 191/303, Loss: 0.0008011232130229473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Iteration 192/303, Loss: 1.8618040485307574e-05\n",
      "Epoch 21/100, Iteration 193/303, Loss: 0.0016873497515916824\n",
      "Epoch 21/100, Iteration 194/303, Loss: 0.00043853462557308376\n",
      "Epoch 21/100, Iteration 195/303, Loss: 0.0002131656074197963\n",
      "Epoch 21/100, Iteration 196/303, Loss: 0.0008841190137900412\n",
      "Epoch 21/100, Iteration 197/303, Loss: 0.0013595956843346357\n",
      "Epoch 21/100, Iteration 198/303, Loss: 0.0009595647570677102\n",
      "Epoch 21/100, Iteration 199/303, Loss: 0.0004746277118101716\n",
      "Epoch 21/100, Iteration 200/303, Loss: 0.00482375780120492\n",
      "Epoch 21/100, Iteration 201/303, Loss: 0.0011643124744296074\n",
      "Epoch 21/100, Iteration 202/303, Loss: 0.00019978839554823935\n",
      "Epoch 21/100, Iteration 203/303, Loss: 0.002490644110366702\n",
      "Epoch 21/100, Iteration 204/303, Loss: 0.00040650562732480466\n",
      "Epoch 21/100, Iteration 205/303, Loss: 0.0014427572023123503\n",
      "Epoch 21/100, Iteration 206/303, Loss: 0.002714708913117647\n",
      "Epoch 21/100, Iteration 207/303, Loss: 0.0011885473504662514\n",
      "Epoch 21/100, Iteration 208/303, Loss: 0.000544123409781605\n",
      "Epoch 21/100, Iteration 209/303, Loss: 0.0003788259346038103\n",
      "Epoch 21/100, Iteration 210/303, Loss: 0.00024089484941214323\n",
      "Epoch 21/100, Iteration 211/303, Loss: 0.001139316358603537\n",
      "Epoch 21/100, Iteration 212/303, Loss: 0.002128015272319317\n",
      "Epoch 21/100, Iteration 213/303, Loss: 0.002895016223192215\n",
      "Epoch 21/100, Iteration 214/303, Loss: 0.00045875346404500306\n",
      "Epoch 21/100, Iteration 215/303, Loss: 0.0021899468265473843\n",
      "Epoch 21/100, Iteration 216/303, Loss: 0.0007560130907222629\n",
      "Epoch 21/100, Iteration 217/303, Loss: 0.0001391104597132653\n",
      "Epoch 21/100, Iteration 218/303, Loss: 0.0009300220990553498\n",
      "Epoch 21/100, Iteration 219/303, Loss: 0.0011029932647943497\n",
      "Epoch 21/100, Iteration 220/303, Loss: 9.000569843919948e-05\n",
      "Epoch 21/100, Iteration 221/303, Loss: 0.0011224631452932954\n",
      "Epoch 21/100, Iteration 222/303, Loss: 0.0010097038466483355\n",
      "Epoch 21/100, Iteration 223/303, Loss: 0.0002833161852322519\n",
      "Epoch 21/100, Iteration 224/303, Loss: 0.00023316526494454592\n",
      "Epoch 21/100, Iteration 225/303, Loss: 0.00021041078434791416\n",
      "Epoch 21/100, Iteration 226/303, Loss: 0.000704203441273421\n",
      "Epoch 21/100, Iteration 227/303, Loss: 7.752718374831602e-05\n",
      "Epoch 21/100, Iteration 228/303, Loss: 0.002879351144656539\n",
      "Epoch 21/100, Iteration 229/303, Loss: 0.0007095937035046518\n",
      "Epoch 21/100, Iteration 230/303, Loss: 0.0008534872904419899\n",
      "Epoch 21/100, Iteration 231/303, Loss: 0.0002799669746309519\n",
      "Epoch 21/100, Iteration 232/303, Loss: 2.760575807769783e-05\n",
      "Epoch 21/100, Iteration 233/303, Loss: 0.004418731201440096\n",
      "Epoch 21/100, Iteration 234/303, Loss: 0.007017246913164854\n",
      "Epoch 21/100, Iteration 235/303, Loss: 0.006954844109714031\n",
      "Epoch 21/100, Iteration 236/303, Loss: 0.0002445180725771934\n",
      "Epoch 21/100, Iteration 237/303, Loss: 0.0016586087876930833\n",
      "Epoch 21/100, Iteration 238/303, Loss: 0.006804587319493294\n",
      "Epoch 21/100, Iteration 239/303, Loss: 0.00043804527376778424\n",
      "Epoch 21/100, Iteration 240/303, Loss: 0.0009251786395907402\n",
      "Epoch 21/100, Iteration 241/303, Loss: 0.0005887424340471625\n",
      "Epoch 21/100, Iteration 242/303, Loss: 0.0006229786085896194\n",
      "Epoch 21/100, Iteration 243/303, Loss: 0.003009758424013853\n",
      "Epoch 21/100, Iteration 244/303, Loss: 0.0007126934360712767\n",
      "Epoch 21/100, Iteration 245/303, Loss: 0.003139530075713992\n",
      "Epoch 21/100, Iteration 246/303, Loss: 0.005590576678514481\n",
      "Epoch 21/100, Iteration 247/303, Loss: 0.0005446345894597471\n",
      "Epoch 21/100, Iteration 248/303, Loss: 0.0005713816499337554\n",
      "Epoch 21/100, Iteration 249/303, Loss: 0.0018660960486158729\n",
      "Epoch 21/100, Iteration 250/303, Loss: 0.0008878046064637601\n",
      "Epoch 21/100, Iteration 251/303, Loss: 0.0003881976008415222\n",
      "Epoch 21/100, Iteration 252/303, Loss: 0.001457971753552556\n",
      "Epoch 21/100, Iteration 253/303, Loss: 0.00014963612193241715\n",
      "Epoch 21/100, Iteration 254/303, Loss: 0.0008815480396151543\n",
      "Epoch 21/100, Iteration 255/303, Loss: 0.0003313076449558139\n",
      "Epoch 21/100, Iteration 256/303, Loss: 0.001717974548228085\n",
      "Epoch 21/100, Iteration 257/303, Loss: 0.006447472143918276\n",
      "Epoch 21/100, Iteration 258/303, Loss: 0.0007038340554572642\n",
      "Epoch 21/100, Iteration 259/303, Loss: 0.001454144949093461\n",
      "Epoch 21/100, Iteration 260/303, Loss: 7.715773972449824e-05\n",
      "Epoch 21/100, Iteration 261/303, Loss: 0.0034374764654785395\n",
      "Epoch 21/100, Iteration 262/303, Loss: 0.0027994834817945957\n",
      "Epoch 21/100, Iteration 263/303, Loss: 0.0014368616975843906\n",
      "Epoch 21/100, Iteration 264/303, Loss: 0.000273775338428095\n",
      "Epoch 21/100, Iteration 265/303, Loss: 0.00036172199179418385\n",
      "Epoch 21/100, Iteration 266/303, Loss: 0.00023826990218367428\n",
      "Epoch 21/100, Iteration 267/303, Loss: 9.414068335900083e-05\n",
      "Epoch 21/100, Iteration 268/303, Loss: 0.00010458365431986749\n",
      "Epoch 21/100, Iteration 269/303, Loss: 0.0006190478452481329\n",
      "Epoch 21/100, Iteration 270/303, Loss: 0.0006680666701868176\n",
      "Epoch 21/100, Iteration 271/303, Loss: 0.0019232354825362563\n",
      "Epoch 21/100, Iteration 272/303, Loss: 0.0002499351976439357\n",
      "Epoch 21/100, Iteration 273/303, Loss: 0.00022759255080018193\n",
      "Epoch 21/100, Iteration 274/303, Loss: 0.0013718828558921814\n",
      "Epoch 21/100, Iteration 275/303, Loss: 0.0018601312767714262\n",
      "Epoch 21/100, Iteration 276/303, Loss: 0.0007293362868949771\n",
      "Epoch 21/100, Iteration 277/303, Loss: 0.0019125946564599872\n",
      "Epoch 21/100, Iteration 278/303, Loss: 0.002526752185076475\n",
      "Epoch 21/100, Iteration 279/303, Loss: 0.0040387483313679695\n",
      "Epoch 21/100, Iteration 280/303, Loss: 0.011948950588703156\n",
      "Epoch 21/100, Iteration 281/303, Loss: 0.000616973964497447\n",
      "Epoch 21/100, Iteration 282/303, Loss: 9.829992632148787e-05\n",
      "Epoch 21/100, Iteration 283/303, Loss: 0.00021340863895602524\n",
      "Epoch 21/100, Iteration 284/303, Loss: 0.001793809700757265\n",
      "Epoch 21/100, Iteration 285/303, Loss: 0.0004869327531196177\n",
      "Epoch 21/100, Iteration 286/303, Loss: 0.001426925417035818\n",
      "Epoch 21/100, Iteration 287/303, Loss: 0.0006695444462820888\n",
      "Epoch 21/100, Iteration 288/303, Loss: 0.0020625644829124212\n",
      "Epoch 21/100, Iteration 289/303, Loss: 0.000436172733316198\n",
      "Epoch 21/100, Iteration 290/303, Loss: 0.0007367737125605345\n",
      "Epoch 21/100, Iteration 291/303, Loss: 0.0020164577290415764\n",
      "Epoch 21/100, Iteration 292/303, Loss: 0.0035995447542518377\n",
      "Epoch 21/100, Iteration 293/303, Loss: 0.0007741294102743268\n",
      "Epoch 21/100, Iteration 294/303, Loss: 0.0004303987661842257\n",
      "Epoch 21/100, Iteration 295/303, Loss: 0.00012252148007974029\n",
      "Epoch 21/100, Iteration 296/303, Loss: 0.0003462840977590531\n",
      "Epoch 21/100, Iteration 297/303, Loss: 0.00028802434098906815\n",
      "Epoch 21/100, Iteration 298/303, Loss: 4.644280852517113e-05\n",
      "Epoch 21/100, Iteration 299/303, Loss: 0.00028315334930084646\n",
      "Epoch 21/100, Iteration 300/303, Loss: 0.00015710848674643785\n",
      "Epoch 21/100, Iteration 301/303, Loss: 0.0006955891731195152\n",
      "Epoch 21/100, Iteration 302/303, Loss: 0.0020399889908730984\n",
      "Epoch 21/100, Iteration 303/303, Loss: 0.0007857452146708965\n",
      "Epoch 22/100, Iteration 1/303, Loss: 0.00011128391633974388\n",
      "Epoch 22/100, Iteration 2/303, Loss: 0.0007313101086765528\n",
      "Epoch 22/100, Iteration 3/303, Loss: 0.00032178658875636756\n",
      "Epoch 22/100, Iteration 4/303, Loss: 0.0005444171256385744\n",
      "Epoch 22/100, Iteration 5/303, Loss: 0.0016895744483917952\n",
      "Epoch 22/100, Iteration 6/303, Loss: 0.004143272992223501\n",
      "Epoch 22/100, Iteration 7/303, Loss: 0.0008336813771165907\n",
      "Epoch 22/100, Iteration 8/303, Loss: 0.000418765761423856\n",
      "Epoch 22/100, Iteration 9/303, Loss: 0.0003616901522036642\n",
      "Epoch 22/100, Iteration 10/303, Loss: 0.00018980437016580254\n",
      "Epoch 22/100, Iteration 11/303, Loss: 0.00015948443615343422\n",
      "Epoch 22/100, Iteration 12/303, Loss: 0.0008424435509368777\n",
      "Epoch 22/100, Iteration 13/303, Loss: 0.0001383058843202889\n",
      "Epoch 22/100, Iteration 14/303, Loss: 0.000488879915792495\n",
      "Epoch 22/100, Iteration 15/303, Loss: 0.000109859713120386\n",
      "Epoch 22/100, Iteration 16/303, Loss: 0.0007473662262782454\n",
      "Epoch 22/100, Iteration 17/303, Loss: 0.00026679818984121084\n",
      "Epoch 22/100, Iteration 18/303, Loss: 0.0014763848157599568\n",
      "Epoch 22/100, Iteration 19/303, Loss: 0.0010610311292111874\n",
      "Epoch 22/100, Iteration 20/303, Loss: 0.0016261246055364609\n",
      "Epoch 22/100, Iteration 21/303, Loss: 0.0006147847161628306\n",
      "Epoch 22/100, Iteration 22/303, Loss: 0.002806221367791295\n",
      "Epoch 22/100, Iteration 23/303, Loss: 0.0002601509913802147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Iteration 24/303, Loss: 0.00013840924657415599\n",
      "Epoch 22/100, Iteration 25/303, Loss: 4.723458187072538e-05\n",
      "Epoch 22/100, Iteration 26/303, Loss: 0.00019168351718690246\n",
      "Epoch 22/100, Iteration 27/303, Loss: 0.0006568557000719011\n",
      "Epoch 22/100, Iteration 28/303, Loss: 0.0021889731287956238\n",
      "Epoch 22/100, Iteration 29/303, Loss: 0.00011027402069885284\n",
      "Epoch 22/100, Iteration 30/303, Loss: 0.0003787298337556422\n",
      "Epoch 22/100, Iteration 31/303, Loss: 4.2230120016029105e-05\n",
      "Epoch 22/100, Iteration 32/303, Loss: 0.002702654805034399\n",
      "Epoch 22/100, Iteration 33/303, Loss: 0.0008141448488458991\n",
      "Epoch 22/100, Iteration 34/303, Loss: 0.0005482130800373852\n",
      "Epoch 22/100, Iteration 35/303, Loss: 0.00022915270528756082\n",
      "Epoch 22/100, Iteration 36/303, Loss: 0.0006312166806310415\n",
      "Epoch 22/100, Iteration 37/303, Loss: 0.0005017841467633843\n",
      "Epoch 22/100, Iteration 38/303, Loss: 0.0003161781351082027\n",
      "Epoch 22/100, Iteration 39/303, Loss: 0.0005528584588319063\n",
      "Epoch 22/100, Iteration 40/303, Loss: 0.000559179054107517\n",
      "Epoch 22/100, Iteration 41/303, Loss: 0.0002533572551328689\n",
      "Epoch 22/100, Iteration 42/303, Loss: 7.47773447073996e-05\n",
      "Epoch 22/100, Iteration 43/303, Loss: 0.0015395674854516983\n",
      "Epoch 22/100, Iteration 44/303, Loss: 0.0001957448257599026\n",
      "Epoch 22/100, Iteration 45/303, Loss: 0.00026563566643744707\n",
      "Epoch 22/100, Iteration 46/303, Loss: 0.00028066514641977847\n",
      "Epoch 22/100, Iteration 47/303, Loss: 0.0001347012002952397\n",
      "Epoch 22/100, Iteration 48/303, Loss: 0.0013631985057145357\n",
      "Epoch 22/100, Iteration 49/303, Loss: 8.010148303583264e-05\n",
      "Epoch 22/100, Iteration 50/303, Loss: 0.00035546571598388255\n",
      "Epoch 22/100, Iteration 51/303, Loss: 0.0008558885892853141\n",
      "Epoch 22/100, Iteration 52/303, Loss: 0.00028176201158203185\n",
      "Epoch 22/100, Iteration 53/303, Loss: 0.00026925987913273275\n",
      "Epoch 22/100, Iteration 54/303, Loss: 0.0005661841714754701\n",
      "Epoch 22/100, Iteration 55/303, Loss: 0.001747583388350904\n",
      "Epoch 22/100, Iteration 56/303, Loss: 0.00042482526623643935\n",
      "Epoch 22/100, Iteration 57/303, Loss: 0.000859518360812217\n",
      "Epoch 22/100, Iteration 58/303, Loss: 0.00012180065823486075\n",
      "Epoch 22/100, Iteration 59/303, Loss: 0.00041515985503792763\n",
      "Epoch 22/100, Iteration 60/303, Loss: 0.001295934314839542\n",
      "Epoch 22/100, Iteration 61/303, Loss: 0.000892621697857976\n",
      "Epoch 22/100, Iteration 62/303, Loss: 4.8365738621214405e-05\n",
      "Epoch 22/100, Iteration 63/303, Loss: 0.0002873228513635695\n",
      "Epoch 22/100, Iteration 64/303, Loss: 0.0005085156299173832\n",
      "Epoch 22/100, Iteration 65/303, Loss: 0.0005183694302104414\n",
      "Epoch 22/100, Iteration 66/303, Loss: 0.00013143272371962667\n",
      "Epoch 22/100, Iteration 67/303, Loss: 0.000887035857886076\n",
      "Epoch 22/100, Iteration 68/303, Loss: 0.0004724230384454131\n",
      "Epoch 22/100, Iteration 69/303, Loss: 0.00017796334577724338\n",
      "Epoch 22/100, Iteration 70/303, Loss: 0.0005154273239895701\n",
      "Epoch 22/100, Iteration 71/303, Loss: 0.00022737924882676452\n",
      "Epoch 22/100, Iteration 72/303, Loss: 0.0010840672766789794\n",
      "Epoch 22/100, Iteration 73/303, Loss: 0.00011762896610889584\n",
      "Epoch 22/100, Iteration 74/303, Loss: 5.066861194791272e-05\n",
      "Epoch 22/100, Iteration 75/303, Loss: 0.0044191027991473675\n",
      "Epoch 22/100, Iteration 76/303, Loss: 0.0003208295674994588\n",
      "Epoch 22/100, Iteration 77/303, Loss: 0.0011196655686944723\n",
      "Epoch 22/100, Iteration 78/303, Loss: 0.00022984363022260368\n",
      "Epoch 22/100, Iteration 79/303, Loss: 0.0008610710501670837\n",
      "Epoch 22/100, Iteration 80/303, Loss: 0.00031436834251508117\n",
      "Epoch 22/100, Iteration 81/303, Loss: 0.0006283872062340379\n",
      "Epoch 22/100, Iteration 82/303, Loss: 0.00043184927199035883\n",
      "Epoch 22/100, Iteration 83/303, Loss: 0.0017205218318849802\n",
      "Epoch 22/100, Iteration 84/303, Loss: 1.9973802409367636e-05\n",
      "Epoch 22/100, Iteration 85/303, Loss: 0.0013910915004089475\n",
      "Epoch 22/100, Iteration 86/303, Loss: 0.0013004092033952475\n",
      "Epoch 22/100, Iteration 87/303, Loss: 0.0013260788982734084\n",
      "Epoch 22/100, Iteration 88/303, Loss: 0.00034552038414403796\n",
      "Epoch 22/100, Iteration 89/303, Loss: 0.0008771070861257613\n",
      "Epoch 22/100, Iteration 90/303, Loss: 0.0014129792107269168\n",
      "Epoch 22/100, Iteration 91/303, Loss: 0.0005252062110230327\n",
      "Epoch 22/100, Iteration 92/303, Loss: 0.00031656166538596153\n",
      "Epoch 22/100, Iteration 93/303, Loss: 0.00042259067413397133\n",
      "Epoch 22/100, Iteration 94/303, Loss: 0.00018013078079093248\n",
      "Epoch 22/100, Iteration 95/303, Loss: 0.0019980748184025288\n",
      "Epoch 22/100, Iteration 96/303, Loss: 0.00012345294817350805\n",
      "Epoch 22/100, Iteration 97/303, Loss: 0.0004955143085680902\n",
      "Epoch 22/100, Iteration 98/303, Loss: 8.427959983237088e-05\n",
      "Epoch 22/100, Iteration 99/303, Loss: 0.00018395716324448586\n",
      "Epoch 22/100, Iteration 100/303, Loss: 0.00014758799807168543\n",
      "Epoch 22/100, Iteration 101/303, Loss: 0.0002561764558777213\n",
      "Epoch 22/100, Iteration 102/303, Loss: 0.0002913009375333786\n",
      "Epoch 22/100, Iteration 103/303, Loss: 0.0008139729616232216\n",
      "Epoch 22/100, Iteration 104/303, Loss: 0.0009343301062472165\n",
      "Epoch 22/100, Iteration 105/303, Loss: 0.0005407395074144006\n",
      "Epoch 22/100, Iteration 106/303, Loss: 0.0005849962471984327\n",
      "Epoch 22/100, Iteration 107/303, Loss: 4.331994568929076e-05\n",
      "Epoch 22/100, Iteration 108/303, Loss: 0.0003549390530679375\n",
      "Epoch 22/100, Iteration 109/303, Loss: 0.0006033370736986399\n",
      "Epoch 22/100, Iteration 110/303, Loss: 0.0006334562785923481\n",
      "Epoch 22/100, Iteration 111/303, Loss: 0.0003857931005768478\n",
      "Epoch 22/100, Iteration 112/303, Loss: 0.0001774907432263717\n",
      "Epoch 22/100, Iteration 113/303, Loss: 0.0011433011386543512\n",
      "Epoch 22/100, Iteration 114/303, Loss: 0.00010738953278632835\n",
      "Epoch 22/100, Iteration 115/303, Loss: 0.0005669787060469389\n",
      "Epoch 22/100, Iteration 116/303, Loss: 0.0002717070165090263\n",
      "Epoch 22/100, Iteration 117/303, Loss: 0.0003530402609612793\n",
      "Epoch 22/100, Iteration 118/303, Loss: 0.000509502599015832\n",
      "Epoch 22/100, Iteration 119/303, Loss: 0.00117311195936054\n",
      "Epoch 22/100, Iteration 120/303, Loss: 0.0011701065814122558\n",
      "Epoch 22/100, Iteration 121/303, Loss: 0.00046429483336396515\n",
      "Epoch 22/100, Iteration 122/303, Loss: 0.00010458908946020529\n",
      "Epoch 22/100, Iteration 123/303, Loss: 9.809395851334557e-05\n",
      "Epoch 22/100, Iteration 124/303, Loss: 0.0005850448505952954\n",
      "Epoch 22/100, Iteration 125/303, Loss: 0.00037652428727597\n",
      "Epoch 22/100, Iteration 126/303, Loss: 0.001409487915225327\n",
      "Epoch 22/100, Iteration 127/303, Loss: 0.0005421604728326201\n",
      "Epoch 22/100, Iteration 128/303, Loss: 0.00019287355826236308\n",
      "Epoch 22/100, Iteration 129/303, Loss: 0.000516124302521348\n",
      "Epoch 22/100, Iteration 130/303, Loss: 0.000125146412756294\n",
      "Epoch 22/100, Iteration 131/303, Loss: 0.0015934400726109743\n",
      "Epoch 22/100, Iteration 132/303, Loss: 0.0002753148437477648\n",
      "Epoch 22/100, Iteration 133/303, Loss: 0.0003370072809047997\n",
      "Epoch 22/100, Iteration 134/303, Loss: 0.00023586848692502826\n",
      "Epoch 22/100, Iteration 135/303, Loss: 0.0002647189248818904\n",
      "Epoch 22/100, Iteration 136/303, Loss: 0.0008086189045570791\n",
      "Epoch 22/100, Iteration 137/303, Loss: 0.00030074224923737347\n",
      "Epoch 22/100, Iteration 138/303, Loss: 0.00017880935047287494\n",
      "Epoch 22/100, Iteration 139/303, Loss: 0.00043376022949814796\n",
      "Epoch 22/100, Iteration 140/303, Loss: 0.0013021668419241905\n",
      "Epoch 22/100, Iteration 141/303, Loss: 9.78744137682952e-05\n",
      "Epoch 22/100, Iteration 142/303, Loss: 0.0002895303477998823\n",
      "Epoch 22/100, Iteration 143/303, Loss: 9.754829079611227e-05\n",
      "Epoch 22/100, Iteration 144/303, Loss: 9.559287718730047e-05\n",
      "Epoch 22/100, Iteration 145/303, Loss: 0.00019574443285819143\n",
      "Epoch 22/100, Iteration 146/303, Loss: 0.001216764678247273\n",
      "Epoch 22/100, Iteration 147/303, Loss: 0.0003170709533151239\n",
      "Epoch 22/100, Iteration 148/303, Loss: 0.000287313450826332\n",
      "Epoch 22/100, Iteration 149/303, Loss: 0.0002598355058580637\n",
      "Epoch 22/100, Iteration 150/303, Loss: 0.0004322493332438171\n",
      "Epoch 22/100, Iteration 151/303, Loss: 0.0001658995170146227\n",
      "Epoch 22/100, Iteration 152/303, Loss: 0.00011171685036970302\n",
      "Epoch 22/100, Iteration 153/303, Loss: 0.0006899746367707849\n",
      "Epoch 22/100, Iteration 154/303, Loss: 0.0005071359337307513\n",
      "Epoch 22/100, Iteration 155/303, Loss: 2.6690120648709126e-05\n",
      "Epoch 22/100, Iteration 156/303, Loss: 0.00040398939745500684\n",
      "Epoch 22/100, Iteration 157/303, Loss: 0.0008137301192618906\n",
      "Epoch 22/100, Iteration 158/303, Loss: 0.00010751589434221387\n",
      "Epoch 22/100, Iteration 159/303, Loss: 0.0006235466571524739\n",
      "Epoch 22/100, Iteration 160/303, Loss: 0.0011245013447478414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Iteration 161/303, Loss: 0.0006208429113030434\n",
      "Epoch 22/100, Iteration 162/303, Loss: 1.9314005839987658e-05\n",
      "Epoch 22/100, Iteration 163/303, Loss: 0.0003045293560717255\n",
      "Epoch 22/100, Iteration 164/303, Loss: 0.0009015733376145363\n",
      "Epoch 22/100, Iteration 165/303, Loss: 0.0008088757749646902\n",
      "Epoch 22/100, Iteration 166/303, Loss: 0.0005921810516156256\n",
      "Epoch 22/100, Iteration 167/303, Loss: 0.0003326547157485038\n",
      "Epoch 22/100, Iteration 168/303, Loss: 0.0019689712207764387\n",
      "Epoch 22/100, Iteration 169/303, Loss: 0.00027150902315042913\n",
      "Epoch 22/100, Iteration 170/303, Loss: 0.0010755055118352175\n",
      "Epoch 22/100, Iteration 171/303, Loss: 0.0002480836119502783\n",
      "Epoch 22/100, Iteration 172/303, Loss: 0.00011510921467561275\n",
      "Epoch 22/100, Iteration 173/303, Loss: 0.0003485001507215202\n",
      "Epoch 22/100, Iteration 174/303, Loss: 0.0005772412405349314\n",
      "Epoch 22/100, Iteration 175/303, Loss: 0.0010984382824972272\n",
      "Epoch 22/100, Iteration 176/303, Loss: 2.273250174766872e-05\n",
      "Epoch 22/100, Iteration 177/303, Loss: 0.0005822050152346492\n",
      "Epoch 22/100, Iteration 178/303, Loss: 0.0003608785627875477\n",
      "Epoch 22/100, Iteration 179/303, Loss: 0.00024344796838704497\n",
      "Epoch 22/100, Iteration 180/303, Loss: 0.00039857576484791934\n",
      "Epoch 22/100, Iteration 181/303, Loss: 0.001303164754062891\n",
      "Epoch 22/100, Iteration 182/303, Loss: 8.327268005814403e-05\n",
      "Epoch 22/100, Iteration 183/303, Loss: 6.4589868998155e-05\n",
      "Epoch 22/100, Iteration 184/303, Loss: 0.0002601133310236037\n",
      "Epoch 22/100, Iteration 185/303, Loss: 0.000874471734277904\n",
      "Epoch 22/100, Iteration 186/303, Loss: 0.00025039579486474395\n",
      "Epoch 22/100, Iteration 187/303, Loss: 0.00034547477844171226\n",
      "Epoch 22/100, Iteration 188/303, Loss: 0.0004108785360585898\n",
      "Epoch 22/100, Iteration 189/303, Loss: 0.0002378167846472934\n",
      "Epoch 22/100, Iteration 190/303, Loss: 0.0004927854752168059\n",
      "Epoch 22/100, Iteration 191/303, Loss: 0.0013609884772449732\n",
      "Epoch 22/100, Iteration 192/303, Loss: 0.0006317818188108504\n",
      "Epoch 22/100, Iteration 193/303, Loss: 0.00021928135538473725\n",
      "Epoch 22/100, Iteration 194/303, Loss: 0.0001116559433285147\n",
      "Epoch 22/100, Iteration 195/303, Loss: 0.00047846155939623713\n",
      "Epoch 22/100, Iteration 196/303, Loss: 0.00030565678025595844\n",
      "Epoch 22/100, Iteration 197/303, Loss: 0.00020684745686594397\n",
      "Epoch 22/100, Iteration 198/303, Loss: 0.0006645333487540483\n",
      "Epoch 22/100, Iteration 199/303, Loss: 0.0006044156616553664\n",
      "Epoch 22/100, Iteration 200/303, Loss: 0.0007737386622466147\n",
      "Epoch 22/100, Iteration 201/303, Loss: 0.0006692942697554827\n",
      "Epoch 22/100, Iteration 202/303, Loss: 0.001988210715353489\n",
      "Epoch 22/100, Iteration 203/303, Loss: 0.00021104083862155676\n",
      "Epoch 22/100, Iteration 204/303, Loss: 0.00031824642792344093\n",
      "Epoch 22/100, Iteration 205/303, Loss: 0.0012214838061481714\n",
      "Epoch 22/100, Iteration 206/303, Loss: 9.287585271522403e-05\n",
      "Epoch 22/100, Iteration 207/303, Loss: 0.0005227053188718855\n",
      "Epoch 22/100, Iteration 208/303, Loss: 0.00042515224777162075\n",
      "Epoch 22/100, Iteration 209/303, Loss: 0.00020814960589632392\n",
      "Epoch 22/100, Iteration 210/303, Loss: 0.0006508319638669491\n",
      "Epoch 22/100, Iteration 211/303, Loss: 9.681675874162465e-05\n",
      "Epoch 22/100, Iteration 212/303, Loss: 0.0010493273148313165\n",
      "Epoch 22/100, Iteration 213/303, Loss: 0.0001957518106792122\n",
      "Epoch 22/100, Iteration 214/303, Loss: 0.0004382794722914696\n",
      "Epoch 22/100, Iteration 215/303, Loss: 0.001096727792173624\n",
      "Epoch 22/100, Iteration 216/303, Loss: 0.0004686472821049392\n",
      "Epoch 22/100, Iteration 217/303, Loss: 0.0004609263560269028\n",
      "Epoch 22/100, Iteration 218/303, Loss: 0.0005386070115491748\n",
      "Epoch 22/100, Iteration 219/303, Loss: 0.0008245754870586097\n",
      "Epoch 22/100, Iteration 220/303, Loss: 9.255643090000376e-05\n",
      "Epoch 22/100, Iteration 221/303, Loss: 0.00022024131612852216\n",
      "Epoch 22/100, Iteration 222/303, Loss: 0.0006794117507524788\n",
      "Epoch 22/100, Iteration 223/303, Loss: 0.00013193732593208551\n",
      "Epoch 22/100, Iteration 224/303, Loss: 0.0009274080512113869\n",
      "Epoch 22/100, Iteration 225/303, Loss: 0.0010951361618936062\n",
      "Epoch 22/100, Iteration 226/303, Loss: 0.0006815400556661189\n",
      "Epoch 22/100, Iteration 227/303, Loss: 0.0002460372634232044\n",
      "Epoch 22/100, Iteration 228/303, Loss: 0.0007318785646930337\n",
      "Epoch 22/100, Iteration 229/303, Loss: 0.0005314115551300347\n",
      "Epoch 22/100, Iteration 230/303, Loss: 0.001287771388888359\n",
      "Epoch 22/100, Iteration 231/303, Loss: 0.0002653394767548889\n",
      "Epoch 22/100, Iteration 232/303, Loss: 0.00014887118595652282\n",
      "Epoch 22/100, Iteration 233/303, Loss: 0.0003245029365643859\n",
      "Epoch 22/100, Iteration 234/303, Loss: 0.0011164714815095067\n",
      "Epoch 22/100, Iteration 235/303, Loss: 3.549284519976936e-05\n",
      "Epoch 22/100, Iteration 236/303, Loss: 6.628208211623132e-05\n",
      "Epoch 22/100, Iteration 237/303, Loss: 9.771432814886793e-05\n",
      "Epoch 22/100, Iteration 238/303, Loss: 0.00026790506672114134\n",
      "Epoch 22/100, Iteration 239/303, Loss: 0.00017489015590399504\n",
      "Epoch 22/100, Iteration 240/303, Loss: 0.0008530552149750292\n",
      "Epoch 22/100, Iteration 241/303, Loss: 9.444754687137902e-05\n",
      "Epoch 22/100, Iteration 242/303, Loss: 0.001336798770353198\n",
      "Epoch 22/100, Iteration 243/303, Loss: 0.00016734658856876194\n",
      "Epoch 22/100, Iteration 244/303, Loss: 0.00042641733307391405\n",
      "Epoch 22/100, Iteration 245/303, Loss: 0.0003347802849020809\n",
      "Epoch 22/100, Iteration 246/303, Loss: 0.0007857311866246164\n",
      "Epoch 22/100, Iteration 247/303, Loss: 0.0004192248161416501\n",
      "Epoch 22/100, Iteration 248/303, Loss: 0.00052436045370996\n",
      "Epoch 22/100, Iteration 249/303, Loss: 0.00012675092148128897\n",
      "Epoch 22/100, Iteration 250/303, Loss: 0.000800632347818464\n",
      "Epoch 22/100, Iteration 251/303, Loss: 0.00010691456554923207\n",
      "Epoch 22/100, Iteration 252/303, Loss: 0.0002817892236635089\n",
      "Epoch 22/100, Iteration 253/303, Loss: 6.0660142480628565e-05\n",
      "Epoch 22/100, Iteration 254/303, Loss: 0.0002083876170217991\n",
      "Epoch 22/100, Iteration 255/303, Loss: 0.0009972136467695236\n",
      "Epoch 22/100, Iteration 256/303, Loss: 0.0005181576125323772\n",
      "Epoch 22/100, Iteration 257/303, Loss: 0.002752655418589711\n",
      "Epoch 22/100, Iteration 258/303, Loss: 0.0005477770464494824\n",
      "Epoch 22/100, Iteration 259/303, Loss: 0.00017463411495555192\n",
      "Epoch 22/100, Iteration 260/303, Loss: 0.0010108284186571836\n",
      "Epoch 22/100, Iteration 261/303, Loss: 0.00025183032266795635\n",
      "Epoch 22/100, Iteration 262/303, Loss: 1.3652789675688837e-05\n",
      "Epoch 22/100, Iteration 263/303, Loss: 0.00023591802164446563\n",
      "Epoch 22/100, Iteration 264/303, Loss: 0.001087936107069254\n",
      "Epoch 22/100, Iteration 265/303, Loss: 0.0003506985667627305\n",
      "Epoch 22/100, Iteration 266/303, Loss: 0.0005376089247874916\n",
      "Epoch 22/100, Iteration 267/303, Loss: 0.000936254276894033\n",
      "Epoch 22/100, Iteration 268/303, Loss: 0.0010677248938009143\n",
      "Epoch 22/100, Iteration 269/303, Loss: 9.241449879482388e-05\n",
      "Epoch 22/100, Iteration 270/303, Loss: 0.0005229022353887558\n",
      "Epoch 22/100, Iteration 271/303, Loss: 5.6558987125754356e-05\n",
      "Epoch 22/100, Iteration 272/303, Loss: 0.00028110662242397666\n",
      "Epoch 22/100, Iteration 273/303, Loss: 0.00015025991888251156\n",
      "Epoch 22/100, Iteration 274/303, Loss: 0.00029407499823719263\n",
      "Epoch 22/100, Iteration 275/303, Loss: 0.00020932586630806327\n",
      "Epoch 22/100, Iteration 276/303, Loss: 0.00032009961432777345\n",
      "Epoch 22/100, Iteration 277/303, Loss: 3.381765782251023e-05\n",
      "Epoch 22/100, Iteration 278/303, Loss: 0.0001268937048735097\n",
      "Epoch 22/100, Iteration 279/303, Loss: 0.0010726565960794687\n",
      "Epoch 22/100, Iteration 280/303, Loss: 8.439386147074401e-05\n",
      "Epoch 22/100, Iteration 281/303, Loss: 0.00027008450706489384\n",
      "Epoch 22/100, Iteration 282/303, Loss: 0.0005183765315450728\n",
      "Epoch 22/100, Iteration 283/303, Loss: 4.4996260839980096e-05\n",
      "Epoch 22/100, Iteration 284/303, Loss: 0.00024294384638778865\n",
      "Epoch 22/100, Iteration 285/303, Loss: 0.0005826552514918149\n",
      "Epoch 22/100, Iteration 286/303, Loss: 0.000981528079137206\n",
      "Epoch 22/100, Iteration 287/303, Loss: 0.00021490389190148562\n",
      "Epoch 22/100, Iteration 288/303, Loss: 0.0006086614448577166\n",
      "Epoch 22/100, Iteration 289/303, Loss: 0.0002853349142242223\n",
      "Epoch 22/100, Iteration 290/303, Loss: 0.00036083138547837734\n",
      "Epoch 22/100, Iteration 291/303, Loss: 0.0007176753715611994\n",
      "Epoch 22/100, Iteration 292/303, Loss: 0.00012163510837126523\n",
      "Epoch 22/100, Iteration 293/303, Loss: 0.002309875562787056\n",
      "Epoch 22/100, Iteration 294/303, Loss: 0.0001691193028818816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Iteration 295/303, Loss: 0.0012010617647320032\n",
      "Epoch 22/100, Iteration 296/303, Loss: 0.001138380728662014\n",
      "Epoch 22/100, Iteration 297/303, Loss: 0.0006699045770801604\n",
      "Epoch 22/100, Iteration 298/303, Loss: 0.00027099697035737336\n",
      "Epoch 22/100, Iteration 299/303, Loss: 7.614409696543589e-05\n",
      "Epoch 22/100, Iteration 300/303, Loss: 8.109849295578897e-05\n",
      "Epoch 22/100, Iteration 301/303, Loss: 5.9919082559645176e-05\n",
      "Epoch 22/100, Iteration 302/303, Loss: 9.091116226045415e-05\n",
      "Epoch 22/100, Iteration 303/303, Loss: 0.0007489657728001475\n",
      "Epoch 23/100, Iteration 1/303, Loss: 0.0001580289681442082\n",
      "Epoch 23/100, Iteration 2/303, Loss: 0.00023087246518116444\n",
      "Epoch 23/100, Iteration 3/303, Loss: 0.0001371000544168055\n",
      "Epoch 23/100, Iteration 4/303, Loss: 2.0963740098522976e-05\n",
      "Epoch 23/100, Iteration 5/303, Loss: 0.00020170149218756706\n",
      "Epoch 23/100, Iteration 6/303, Loss: 0.0002227297954959795\n",
      "Epoch 23/100, Iteration 7/303, Loss: 0.0005931544001214206\n",
      "Epoch 23/100, Iteration 8/303, Loss: 4.952833478455432e-05\n",
      "Epoch 23/100, Iteration 9/303, Loss: 0.0002811560989357531\n",
      "Epoch 23/100, Iteration 10/303, Loss: 4.416613228386268e-05\n",
      "Epoch 23/100, Iteration 11/303, Loss: 0.0013851856347173452\n",
      "Epoch 23/100, Iteration 12/303, Loss: 0.0005380096263252199\n",
      "Epoch 23/100, Iteration 13/303, Loss: 0.0003379395348019898\n",
      "Epoch 23/100, Iteration 14/303, Loss: 0.0005614821566268802\n",
      "Epoch 23/100, Iteration 15/303, Loss: 0.0007168721640482545\n",
      "Epoch 23/100, Iteration 16/303, Loss: 0.00041763493209145963\n",
      "Epoch 23/100, Iteration 17/303, Loss: 0.00033994842669926584\n",
      "Epoch 23/100, Iteration 18/303, Loss: 0.00014840313815511763\n",
      "Epoch 23/100, Iteration 19/303, Loss: 0.00025652829208411276\n",
      "Epoch 23/100, Iteration 20/303, Loss: 9.016372496262193e-05\n",
      "Epoch 23/100, Iteration 21/303, Loss: 3.9251463022083044e-05\n",
      "Epoch 23/100, Iteration 22/303, Loss: 0.00011169150820933282\n",
      "Epoch 23/100, Iteration 23/303, Loss: 0.00013422872871160507\n",
      "Epoch 23/100, Iteration 24/303, Loss: 0.0006818782421760261\n",
      "Epoch 23/100, Iteration 25/303, Loss: 5.699813482351601e-05\n",
      "Epoch 23/100, Iteration 26/303, Loss: 0.0001822026533773169\n",
      "Epoch 23/100, Iteration 27/303, Loss: 0.0005173186073079705\n",
      "Epoch 23/100, Iteration 28/303, Loss: 0.0002345604298170656\n",
      "Epoch 23/100, Iteration 29/303, Loss: 2.762716030701995e-05\n",
      "Epoch 23/100, Iteration 30/303, Loss: 0.0016765657346695662\n",
      "Epoch 23/100, Iteration 31/303, Loss: 7.693086081417277e-05\n",
      "Epoch 23/100, Iteration 32/303, Loss: 0.00021772024047095329\n",
      "Epoch 23/100, Iteration 33/303, Loss: 0.000262684712652117\n",
      "Epoch 23/100, Iteration 34/303, Loss: 0.00034766847966238856\n",
      "Epoch 23/100, Iteration 35/303, Loss: 0.0004617251979652792\n",
      "Epoch 23/100, Iteration 36/303, Loss: 0.0006284533301368356\n",
      "Epoch 23/100, Iteration 37/303, Loss: 0.00034279702231287956\n",
      "Epoch 23/100, Iteration 38/303, Loss: 0.00016201427206397057\n",
      "Epoch 23/100, Iteration 39/303, Loss: 0.000282974389847368\n",
      "Epoch 23/100, Iteration 40/303, Loss: 7.310206274269149e-05\n",
      "Epoch 23/100, Iteration 41/303, Loss: 7.647076563443989e-05\n",
      "Epoch 23/100, Iteration 42/303, Loss: 0.00014855661720503122\n",
      "Epoch 23/100, Iteration 43/303, Loss: 0.00042213874985463917\n",
      "Epoch 23/100, Iteration 44/303, Loss: 0.0004359337326604873\n",
      "Epoch 23/100, Iteration 45/303, Loss: 0.00030866250745020807\n",
      "Epoch 23/100, Iteration 46/303, Loss: 0.00042430293979123235\n",
      "Epoch 23/100, Iteration 47/303, Loss: 0.00040721919503994286\n",
      "Epoch 23/100, Iteration 48/303, Loss: 0.00024885020684450865\n",
      "Epoch 23/100, Iteration 49/303, Loss: 0.00018299903604201972\n",
      "Epoch 23/100, Iteration 50/303, Loss: 4.85375348944217e-05\n",
      "Epoch 23/100, Iteration 51/303, Loss: 0.0002946338208857924\n",
      "Epoch 23/100, Iteration 52/303, Loss: 0.0004645942826755345\n",
      "Epoch 23/100, Iteration 53/303, Loss: 0.001187809626571834\n",
      "Epoch 23/100, Iteration 54/303, Loss: 0.0005214732955209911\n",
      "Epoch 23/100, Iteration 55/303, Loss: 5.225539280218072e-05\n",
      "Epoch 23/100, Iteration 56/303, Loss: 0.0003060491872020066\n",
      "Epoch 23/100, Iteration 57/303, Loss: 0.00036802960676141083\n",
      "Epoch 23/100, Iteration 58/303, Loss: 0.00017959505203180015\n",
      "Epoch 23/100, Iteration 59/303, Loss: 5.453049743664451e-05\n",
      "Epoch 23/100, Iteration 60/303, Loss: 0.00011481129331514239\n",
      "Epoch 23/100, Iteration 61/303, Loss: 0.00014787206600885838\n",
      "Epoch 23/100, Iteration 62/303, Loss: 0.00021879951236769557\n",
      "Epoch 23/100, Iteration 63/303, Loss: 0.0003734507190529257\n",
      "Epoch 23/100, Iteration 64/303, Loss: 0.00042143778409808874\n",
      "Epoch 23/100, Iteration 65/303, Loss: 0.00034786740434356034\n",
      "Epoch 23/100, Iteration 66/303, Loss: 0.0009518428705632687\n",
      "Epoch 23/100, Iteration 67/303, Loss: 0.00039966939948499203\n",
      "Epoch 23/100, Iteration 68/303, Loss: 0.0006521748146042228\n",
      "Epoch 23/100, Iteration 69/303, Loss: 7.193341298261657e-05\n",
      "Epoch 23/100, Iteration 70/303, Loss: 0.0002874064666684717\n",
      "Epoch 23/100, Iteration 71/303, Loss: 0.0010904634837061167\n",
      "Epoch 23/100, Iteration 72/303, Loss: 1.5794266801094636e-05\n",
      "Epoch 23/100, Iteration 73/303, Loss: 0.00016198444063775241\n",
      "Epoch 23/100, Iteration 74/303, Loss: 0.00040430715307593346\n",
      "Epoch 23/100, Iteration 75/303, Loss: 0.00020219794532749802\n",
      "Epoch 23/100, Iteration 76/303, Loss: 0.0005135896499268711\n",
      "Epoch 23/100, Iteration 77/303, Loss: 5.8439305576030165e-05\n",
      "Epoch 23/100, Iteration 78/303, Loss: 0.0004831500118598342\n",
      "Epoch 23/100, Iteration 79/303, Loss: 0.0005830779555253685\n",
      "Epoch 23/100, Iteration 80/303, Loss: 0.00047039895434863865\n",
      "Epoch 23/100, Iteration 81/303, Loss: 0.00033001750125549734\n",
      "Epoch 23/100, Iteration 82/303, Loss: 4.9414804379921407e-05\n",
      "Epoch 23/100, Iteration 83/303, Loss: 0.00046762358397245407\n",
      "Epoch 23/100, Iteration 84/303, Loss: 0.00010883635695790872\n",
      "Epoch 23/100, Iteration 85/303, Loss: 2.0688104996224865e-05\n",
      "Epoch 23/100, Iteration 86/303, Loss: 0.0002006616850849241\n",
      "Epoch 23/100, Iteration 87/303, Loss: 0.00020138044783379883\n",
      "Epoch 23/100, Iteration 88/303, Loss: 0.00034747092286124825\n",
      "Epoch 23/100, Iteration 89/303, Loss: 6.075226701796055e-05\n",
      "Epoch 23/100, Iteration 90/303, Loss: 0.00040290469769388437\n",
      "Epoch 23/100, Iteration 91/303, Loss: 0.00015378253010567278\n",
      "Epoch 23/100, Iteration 92/303, Loss: 0.00011559418635442853\n",
      "Epoch 23/100, Iteration 93/303, Loss: 0.0007888130494393408\n",
      "Epoch 23/100, Iteration 94/303, Loss: 0.0002520060515962541\n",
      "Epoch 23/100, Iteration 95/303, Loss: 0.0017169357743114233\n",
      "Epoch 23/100, Iteration 96/303, Loss: 2.5765835744095966e-05\n",
      "Epoch 23/100, Iteration 97/303, Loss: 0.0008210008963942528\n",
      "Epoch 23/100, Iteration 98/303, Loss: 4.8544930905336514e-05\n",
      "Epoch 23/100, Iteration 99/303, Loss: 0.00012211593275424093\n",
      "Epoch 23/100, Iteration 100/303, Loss: 0.0001392197737004608\n",
      "Epoch 23/100, Iteration 101/303, Loss: 0.0005713846767321229\n",
      "Epoch 23/100, Iteration 102/303, Loss: 0.0004161703400313854\n",
      "Epoch 23/100, Iteration 103/303, Loss: 2.0046292775077745e-05\n",
      "Epoch 23/100, Iteration 104/303, Loss: 0.00015192019054666162\n",
      "Epoch 23/100, Iteration 105/303, Loss: 0.0004420570330694318\n",
      "Epoch 23/100, Iteration 106/303, Loss: 0.00034702260745689273\n",
      "Epoch 23/100, Iteration 107/303, Loss: 0.0002342440711800009\n",
      "Epoch 23/100, Iteration 108/303, Loss: 8.680228347657248e-05\n",
      "Epoch 23/100, Iteration 109/303, Loss: 0.0002096405514748767\n",
      "Epoch 23/100, Iteration 110/303, Loss: 0.0009710766607895494\n",
      "Epoch 23/100, Iteration 111/303, Loss: 0.0003892238310072571\n",
      "Epoch 23/100, Iteration 112/303, Loss: 0.00042423661216162145\n",
      "Epoch 23/100, Iteration 113/303, Loss: 6.653233867837116e-06\n",
      "Epoch 23/100, Iteration 114/303, Loss: 0.0001045477984007448\n",
      "Epoch 23/100, Iteration 115/303, Loss: 0.0003637647314462811\n",
      "Epoch 23/100, Iteration 116/303, Loss: 0.0003603616787586361\n",
      "Epoch 23/100, Iteration 117/303, Loss: 2.7183674319530837e-05\n",
      "Epoch 23/100, Iteration 118/303, Loss: 0.00018251164874527603\n",
      "Epoch 23/100, Iteration 119/303, Loss: 0.00031826997292228043\n",
      "Epoch 23/100, Iteration 120/303, Loss: 3.578709947760217e-05\n",
      "Epoch 23/100, Iteration 121/303, Loss: 7.738795829936862e-05\n",
      "Epoch 23/100, Iteration 122/303, Loss: 0.00016020942712202668\n",
      "Epoch 23/100, Iteration 123/303, Loss: 0.0003237081691622734\n",
      "Epoch 23/100, Iteration 124/303, Loss: 0.0001550594315631315\n",
      "Epoch 23/100, Iteration 125/303, Loss: 7.16752401785925e-05\n",
      "Epoch 23/100, Iteration 126/303, Loss: 0.0003567152889445424\n",
      "Epoch 23/100, Iteration 127/303, Loss: 0.0009864061139523983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Iteration 128/303, Loss: 0.0006939077284187078\n",
      "Epoch 23/100, Iteration 129/303, Loss: 0.0003648775746114552\n",
      "Epoch 23/100, Iteration 130/303, Loss: 0.0004603764391504228\n",
      "Epoch 23/100, Iteration 131/303, Loss: 0.00021681914222426713\n",
      "Epoch 23/100, Iteration 132/303, Loss: 0.00037193854223005474\n",
      "Epoch 23/100, Iteration 133/303, Loss: 0.0001546576531836763\n",
      "Epoch 23/100, Iteration 134/303, Loss: 0.0006758960662409663\n",
      "Epoch 23/100, Iteration 135/303, Loss: 0.0003353899228386581\n",
      "Epoch 23/100, Iteration 136/303, Loss: 0.00018381864356342703\n",
      "Epoch 23/100, Iteration 137/303, Loss: 0.00018147779337596148\n",
      "Epoch 23/100, Iteration 138/303, Loss: 0.0008931687334552407\n",
      "Epoch 23/100, Iteration 139/303, Loss: 3.001625918841455e-05\n",
      "Epoch 23/100, Iteration 140/303, Loss: 0.0006644443492405117\n",
      "Epoch 23/100, Iteration 141/303, Loss: 0.00021737522911280394\n",
      "Epoch 23/100, Iteration 142/303, Loss: 9.889944340102375e-05\n",
      "Epoch 23/100, Iteration 143/303, Loss: 0.00013024357031099498\n",
      "Epoch 23/100, Iteration 144/303, Loss: 7.491902215406299e-05\n",
      "Epoch 23/100, Iteration 145/303, Loss: 8.771006832830608e-05\n",
      "Epoch 23/100, Iteration 146/303, Loss: 0.00010543776443228126\n",
      "Epoch 23/100, Iteration 147/303, Loss: 0.0001157079532276839\n",
      "Epoch 23/100, Iteration 148/303, Loss: 0.0001702492154436186\n",
      "Epoch 23/100, Iteration 149/303, Loss: 0.0006620782660320401\n",
      "Epoch 23/100, Iteration 150/303, Loss: 0.00020933980704285204\n",
      "Epoch 23/100, Iteration 151/303, Loss: 0.0005050438921898603\n",
      "Epoch 23/100, Iteration 152/303, Loss: 6.960434257052839e-05\n",
      "Epoch 23/100, Iteration 153/303, Loss: 0.0005127832992002368\n",
      "Epoch 23/100, Iteration 154/303, Loss: 8.043917478062212e-05\n",
      "Epoch 23/100, Iteration 155/303, Loss: 0.0001767030480550602\n",
      "Epoch 23/100, Iteration 156/303, Loss: 0.00039574195398017764\n",
      "Epoch 23/100, Iteration 157/303, Loss: 0.00014250475214794278\n",
      "Epoch 23/100, Iteration 158/303, Loss: 0.0004347052308730781\n",
      "Epoch 23/100, Iteration 159/303, Loss: 0.0007190151372924447\n",
      "Epoch 23/100, Iteration 160/303, Loss: 0.000298131926683709\n",
      "Epoch 23/100, Iteration 161/303, Loss: 0.0002559929562266916\n",
      "Epoch 23/100, Iteration 162/303, Loss: 1.8859716874430887e-05\n",
      "Epoch 23/100, Iteration 163/303, Loss: 0.0001202262646984309\n",
      "Epoch 23/100, Iteration 164/303, Loss: 0.00047810800606384873\n",
      "Epoch 23/100, Iteration 165/303, Loss: 6.0467704315669835e-05\n",
      "Epoch 23/100, Iteration 166/303, Loss: 0.0003621762152761221\n",
      "Epoch 23/100, Iteration 167/303, Loss: 0.0004251707869116217\n",
      "Epoch 23/100, Iteration 168/303, Loss: 0.0001885560341179371\n",
      "Epoch 23/100, Iteration 169/303, Loss: 7.577749784104526e-05\n",
      "Epoch 23/100, Iteration 170/303, Loss: 6.611526623601094e-05\n",
      "Epoch 23/100, Iteration 171/303, Loss: 0.0005402652896009386\n",
      "Epoch 23/100, Iteration 172/303, Loss: 0.0001576260692672804\n",
      "Epoch 23/100, Iteration 173/303, Loss: 8.567018085159361e-05\n",
      "Epoch 23/100, Iteration 174/303, Loss: 0.0003350361657794565\n",
      "Epoch 23/100, Iteration 175/303, Loss: 0.0002754565211944282\n",
      "Epoch 23/100, Iteration 176/303, Loss: 2.267662057420239e-05\n",
      "Epoch 23/100, Iteration 177/303, Loss: 0.00019742330187000334\n",
      "Epoch 23/100, Iteration 178/303, Loss: 0.0007545471307821572\n",
      "Epoch 23/100, Iteration 179/303, Loss: 3.717481376952492e-05\n",
      "Epoch 23/100, Iteration 180/303, Loss: 0.00011727725359378383\n",
      "Epoch 23/100, Iteration 181/303, Loss: 0.0004122478130739182\n",
      "Epoch 23/100, Iteration 182/303, Loss: 0.00031185566331259906\n",
      "Epoch 23/100, Iteration 183/303, Loss: 8.025924034882337e-05\n",
      "Epoch 23/100, Iteration 184/303, Loss: 0.0005209034425206482\n",
      "Epoch 23/100, Iteration 185/303, Loss: 0.00016089307609945536\n",
      "Epoch 23/100, Iteration 186/303, Loss: 0.0005123948212713003\n",
      "Epoch 23/100, Iteration 187/303, Loss: 0.0006232603336684406\n",
      "Epoch 23/100, Iteration 188/303, Loss: 0.00010098305938299745\n",
      "Epoch 23/100, Iteration 189/303, Loss: 4.70443264930509e-05\n",
      "Epoch 23/100, Iteration 190/303, Loss: 0.0003020818985532969\n",
      "Epoch 23/100, Iteration 191/303, Loss: 0.00034925638465210795\n",
      "Epoch 23/100, Iteration 192/303, Loss: 6.536624277941883e-05\n",
      "Epoch 23/100, Iteration 193/303, Loss: 0.000933007977437228\n",
      "Epoch 23/100, Iteration 194/303, Loss: 0.00027590731042437255\n",
      "Epoch 23/100, Iteration 195/303, Loss: 2.5995592295657843e-05\n",
      "Epoch 23/100, Iteration 196/303, Loss: 0.0004250245983712375\n",
      "Epoch 23/100, Iteration 197/303, Loss: 0.00027183181373402476\n",
      "Epoch 23/100, Iteration 198/303, Loss: 0.00031641163513995707\n",
      "Epoch 23/100, Iteration 199/303, Loss: 0.0004938402562402189\n",
      "Epoch 23/100, Iteration 200/303, Loss: 0.00012909014185424894\n",
      "Epoch 23/100, Iteration 201/303, Loss: 0.0004793232074007392\n",
      "Epoch 23/100, Iteration 202/303, Loss: 0.0007288475171662867\n",
      "Epoch 23/100, Iteration 203/303, Loss: 0.0002638099540490657\n",
      "Epoch 23/100, Iteration 204/303, Loss: 0.0005647134967148304\n",
      "Epoch 23/100, Iteration 205/303, Loss: 0.00013009725080337375\n",
      "Epoch 23/100, Iteration 206/303, Loss: 0.00038236414548009634\n",
      "Epoch 23/100, Iteration 207/303, Loss: 7.758266292512417e-05\n",
      "Epoch 23/100, Iteration 208/303, Loss: 0.00031309708720073104\n",
      "Epoch 23/100, Iteration 209/303, Loss: 0.00010400527389720082\n",
      "Epoch 23/100, Iteration 210/303, Loss: 0.00017116201343014836\n",
      "Epoch 23/100, Iteration 211/303, Loss: 0.0006754983332939446\n",
      "Epoch 23/100, Iteration 212/303, Loss: 0.0003138323954772204\n",
      "Epoch 23/100, Iteration 213/303, Loss: 0.00024123923503793776\n",
      "Epoch 23/100, Iteration 214/303, Loss: 0.00017464546544943005\n",
      "Epoch 23/100, Iteration 215/303, Loss: 8.755068120080978e-05\n",
      "Epoch 23/100, Iteration 216/303, Loss: 0.0005482136621139944\n",
      "Epoch 23/100, Iteration 217/303, Loss: 0.00015877795522101223\n",
      "Epoch 23/100, Iteration 218/303, Loss: 0.00015097553841769695\n",
      "Epoch 23/100, Iteration 219/303, Loss: 0.00012273536412976682\n",
      "Epoch 23/100, Iteration 220/303, Loss: 0.00018749537412077188\n",
      "Epoch 23/100, Iteration 221/303, Loss: 0.0006054777186363935\n",
      "Epoch 23/100, Iteration 222/303, Loss: 0.0008766816463321447\n",
      "Epoch 23/100, Iteration 223/303, Loss: 0.0004035764723084867\n",
      "Epoch 23/100, Iteration 224/303, Loss: 6.148996180854738e-05\n",
      "Epoch 23/100, Iteration 225/303, Loss: 0.0005147966439835727\n",
      "Epoch 23/100, Iteration 226/303, Loss: 0.0001253788941539824\n",
      "Epoch 23/100, Iteration 227/303, Loss: 7.396547152893618e-05\n",
      "Epoch 23/100, Iteration 228/303, Loss: 0.0011994978412985802\n",
      "Epoch 23/100, Iteration 229/303, Loss: 0.00039981314330361784\n",
      "Epoch 23/100, Iteration 230/303, Loss: 0.00018226941756438464\n",
      "Epoch 23/100, Iteration 231/303, Loss: 0.00033145264023914933\n",
      "Epoch 23/100, Iteration 232/303, Loss: 0.00016941330977715552\n",
      "Epoch 23/100, Iteration 233/303, Loss: 0.00021466171892825514\n",
      "Epoch 23/100, Iteration 234/303, Loss: 0.0008181895827874541\n",
      "Epoch 23/100, Iteration 235/303, Loss: 5.245718784863129e-05\n",
      "Epoch 23/100, Iteration 236/303, Loss: 0.00010503165685804561\n",
      "Epoch 23/100, Iteration 237/303, Loss: 6.128191307652742e-05\n",
      "Epoch 23/100, Iteration 238/303, Loss: 4.052821168443188e-05\n",
      "Epoch 23/100, Iteration 239/303, Loss: 0.0002165717596653849\n",
      "Epoch 23/100, Iteration 240/303, Loss: 0.0004475703462958336\n",
      "Epoch 23/100, Iteration 241/303, Loss: 0.00021591228141915053\n",
      "Epoch 23/100, Iteration 242/303, Loss: 6.21728686382994e-05\n",
      "Epoch 23/100, Iteration 243/303, Loss: 0.00031971943099051714\n",
      "Epoch 23/100, Iteration 244/303, Loss: 0.00011487797019071877\n",
      "Epoch 23/100, Iteration 245/303, Loss: 0.0008286085212603211\n",
      "Epoch 23/100, Iteration 246/303, Loss: 0.0003257561184000224\n",
      "Epoch 23/100, Iteration 247/303, Loss: 0.0002167681377613917\n",
      "Epoch 23/100, Iteration 248/303, Loss: 0.00041320855962112546\n",
      "Epoch 23/100, Iteration 249/303, Loss: 0.00015945869381539524\n",
      "Epoch 23/100, Iteration 250/303, Loss: 0.000250796671025455\n",
      "Epoch 23/100, Iteration 251/303, Loss: 0.0002038597740465775\n",
      "Epoch 23/100, Iteration 252/303, Loss: 2.397785647190176e-05\n",
      "Epoch 23/100, Iteration 253/303, Loss: 0.00033749142312444746\n",
      "Epoch 23/100, Iteration 254/303, Loss: 0.00020069049787707627\n",
      "Epoch 23/100, Iteration 255/303, Loss: 0.0003646484692580998\n",
      "Epoch 23/100, Iteration 256/303, Loss: 0.0005683156778104603\n",
      "Epoch 23/100, Iteration 257/303, Loss: 0.00039299234049394727\n",
      "Epoch 23/100, Iteration 258/303, Loss: 0.0008049476891756058\n",
      "Epoch 23/100, Iteration 259/303, Loss: 0.00013420185132417828\n",
      "Epoch 23/100, Iteration 260/303, Loss: 1.625167715246789e-05\n",
      "Epoch 23/100, Iteration 261/303, Loss: 2.271163248224184e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Iteration 262/303, Loss: 0.0003525076899677515\n",
      "Epoch 23/100, Iteration 263/303, Loss: 3.720333916135132e-05\n",
      "Epoch 23/100, Iteration 264/303, Loss: 0.00041625392623245716\n",
      "Epoch 23/100, Iteration 265/303, Loss: 0.00015901554434094578\n",
      "Epoch 23/100, Iteration 266/303, Loss: 0.00024031809880398214\n",
      "Epoch 23/100, Iteration 267/303, Loss: 0.0014791504945605993\n",
      "Epoch 23/100, Iteration 268/303, Loss: 4.665787855628878e-05\n",
      "Epoch 23/100, Iteration 269/303, Loss: 0.00028167603886686265\n",
      "Epoch 23/100, Iteration 270/303, Loss: 0.0004231705388519913\n",
      "Epoch 23/100, Iteration 271/303, Loss: 0.00046860583825036883\n",
      "Epoch 23/100, Iteration 272/303, Loss: 9.886075713438913e-05\n",
      "Epoch 23/100, Iteration 273/303, Loss: 0.0003022026503458619\n",
      "Epoch 23/100, Iteration 274/303, Loss: 0.00034470405080355704\n",
      "Epoch 23/100, Iteration 275/303, Loss: 0.00011384120443835855\n",
      "Epoch 23/100, Iteration 276/303, Loss: 0.0003485385386738926\n",
      "Epoch 23/100, Iteration 277/303, Loss: 0.00017451890744268894\n",
      "Epoch 23/100, Iteration 278/303, Loss: 4.439639815245755e-05\n",
      "Epoch 23/100, Iteration 279/303, Loss: 0.00031633058097213507\n",
      "Epoch 23/100, Iteration 280/303, Loss: 0.00015351656475104392\n",
      "Epoch 23/100, Iteration 281/303, Loss: 2.063196006929502e-05\n",
      "Epoch 23/100, Iteration 282/303, Loss: 0.0003725852002389729\n",
      "Epoch 23/100, Iteration 283/303, Loss: 0.00019302076543681324\n",
      "Epoch 23/100, Iteration 284/303, Loss: 0.00012874910316895694\n",
      "Epoch 23/100, Iteration 285/303, Loss: 0.0001583085540914908\n",
      "Epoch 23/100, Iteration 286/303, Loss: 0.0004046057292725891\n",
      "Epoch 23/100, Iteration 287/303, Loss: 0.002811807207763195\n",
      "Epoch 23/100, Iteration 288/303, Loss: 0.0004420671029947698\n",
      "Epoch 23/100, Iteration 289/303, Loss: 0.0001837333693401888\n",
      "Epoch 23/100, Iteration 290/303, Loss: 4.233209619997069e-05\n",
      "Epoch 23/100, Iteration 291/303, Loss: 0.00019349707872606814\n",
      "Epoch 23/100, Iteration 292/303, Loss: 0.0006831405917182565\n",
      "Epoch 23/100, Iteration 293/303, Loss: 0.00019676738884299994\n",
      "Epoch 23/100, Iteration 294/303, Loss: 0.00016053972649388015\n",
      "Epoch 23/100, Iteration 295/303, Loss: 0.00031704053981229663\n",
      "Epoch 23/100, Iteration 296/303, Loss: 0.00020411178411450237\n",
      "Epoch 23/100, Iteration 297/303, Loss: 0.00026194093516096473\n",
      "Epoch 23/100, Iteration 298/303, Loss: 0.00019197077199351043\n",
      "Epoch 23/100, Iteration 299/303, Loss: 0.0002262555353809148\n",
      "Epoch 23/100, Iteration 300/303, Loss: 0.00012789630272891372\n",
      "Epoch 23/100, Iteration 301/303, Loss: 0.0003828165354207158\n",
      "Epoch 23/100, Iteration 302/303, Loss: 0.0006758378585800529\n",
      "Epoch 23/100, Iteration 303/303, Loss: 8.849193363857921e-06\n",
      "Epoch 24/100, Iteration 1/303, Loss: 0.00027770589804276824\n",
      "Epoch 24/100, Iteration 2/303, Loss: 7.082891534082592e-05\n",
      "Epoch 24/100, Iteration 3/303, Loss: 0.0001349782687611878\n",
      "Epoch 24/100, Iteration 4/303, Loss: 0.00023797980975359678\n",
      "Epoch 24/100, Iteration 5/303, Loss: 0.00020169613708276302\n",
      "Epoch 24/100, Iteration 6/303, Loss: 0.0003709567536134273\n",
      "Epoch 24/100, Iteration 7/303, Loss: 4.1333474655402824e-05\n",
      "Epoch 24/100, Iteration 8/303, Loss: 0.0001995151542359963\n",
      "Epoch 24/100, Iteration 9/303, Loss: 0.0003110005345661193\n",
      "Epoch 24/100, Iteration 10/303, Loss: 0.00027805709396488965\n",
      "Epoch 24/100, Iteration 11/303, Loss: 7.633494533365592e-05\n",
      "Epoch 24/100, Iteration 12/303, Loss: 8.966099994722754e-05\n",
      "Epoch 24/100, Iteration 13/303, Loss: 0.0001154415076598525\n",
      "Epoch 24/100, Iteration 14/303, Loss: 3.943707270082086e-05\n",
      "Epoch 24/100, Iteration 15/303, Loss: 6.850343925179914e-05\n",
      "Epoch 24/100, Iteration 16/303, Loss: 0.00020394855528138578\n",
      "Epoch 24/100, Iteration 17/303, Loss: 0.0003247918502893299\n",
      "Epoch 24/100, Iteration 18/303, Loss: 0.00032258653664030135\n",
      "Epoch 24/100, Iteration 19/303, Loss: 0.0003259743971284479\n",
      "Epoch 24/100, Iteration 20/303, Loss: 0.0002515585510991514\n",
      "Epoch 24/100, Iteration 21/303, Loss: 0.0006618771003559232\n",
      "Epoch 24/100, Iteration 22/303, Loss: 5.091002822155133e-05\n",
      "Epoch 24/100, Iteration 23/303, Loss: 0.00030572444666177034\n",
      "Epoch 24/100, Iteration 24/303, Loss: 0.00018974379054270685\n",
      "Epoch 24/100, Iteration 25/303, Loss: 0.00019780949514824897\n",
      "Epoch 24/100, Iteration 26/303, Loss: 0.00037681779940612614\n",
      "Epoch 24/100, Iteration 27/303, Loss: 0.00017320425831712782\n",
      "Epoch 24/100, Iteration 28/303, Loss: 0.00014768725668545812\n",
      "Epoch 24/100, Iteration 29/303, Loss: 0.00010069124982692301\n",
      "Epoch 24/100, Iteration 30/303, Loss: 3.641259536379948e-05\n",
      "Epoch 24/100, Iteration 31/303, Loss: 0.00010973071039188653\n",
      "Epoch 24/100, Iteration 32/303, Loss: 0.00010480711353011429\n",
      "Epoch 24/100, Iteration 33/303, Loss: 0.00014086962619330734\n",
      "Epoch 24/100, Iteration 34/303, Loss: 4.785891360370442e-05\n",
      "Epoch 24/100, Iteration 35/303, Loss: 0.00027234075241722167\n",
      "Epoch 24/100, Iteration 36/303, Loss: 0.0002409920416539535\n",
      "Epoch 24/100, Iteration 37/303, Loss: 0.0002264233335154131\n",
      "Epoch 24/100, Iteration 38/303, Loss: 0.00020007381681352854\n",
      "Epoch 24/100, Iteration 39/303, Loss: 0.0001819251774577424\n",
      "Epoch 24/100, Iteration 40/303, Loss: 0.00014831907174084336\n",
      "Epoch 24/100, Iteration 41/303, Loss: 0.00013347089407034218\n",
      "Epoch 24/100, Iteration 42/303, Loss: 0.00040589686250314116\n",
      "Epoch 24/100, Iteration 43/303, Loss: 0.00013385084457695484\n",
      "Epoch 24/100, Iteration 44/303, Loss: 2.8159427529317327e-05\n",
      "Epoch 24/100, Iteration 45/303, Loss: 0.0002734683803282678\n",
      "Epoch 24/100, Iteration 46/303, Loss: 0.00026006976258940995\n",
      "Epoch 24/100, Iteration 47/303, Loss: 0.0001617234811419621\n",
      "Epoch 24/100, Iteration 48/303, Loss: 0.00013725414464715868\n",
      "Epoch 24/100, Iteration 49/303, Loss: 0.00015500190784223378\n",
      "Epoch 24/100, Iteration 50/303, Loss: 0.00012470720685087144\n",
      "Epoch 24/100, Iteration 51/303, Loss: 4.735149923362769e-05\n",
      "Epoch 24/100, Iteration 52/303, Loss: 0.0002777826739475131\n",
      "Epoch 24/100, Iteration 53/303, Loss: 0.00017206560005433857\n",
      "Epoch 24/100, Iteration 54/303, Loss: 7.654138607904315e-05\n",
      "Epoch 24/100, Iteration 55/303, Loss: 0.00017916479555424303\n",
      "Epoch 24/100, Iteration 56/303, Loss: 0.00018749597074929625\n",
      "Epoch 24/100, Iteration 57/303, Loss: 0.0006275903433561325\n",
      "Epoch 24/100, Iteration 58/303, Loss: 0.00028974347515031695\n",
      "Epoch 24/100, Iteration 59/303, Loss: 0.00024486443726345897\n",
      "Epoch 24/100, Iteration 60/303, Loss: 0.00019766126933973283\n",
      "Epoch 24/100, Iteration 61/303, Loss: 0.00011991846258752048\n",
      "Epoch 24/100, Iteration 62/303, Loss: 6.221935473149642e-05\n",
      "Epoch 24/100, Iteration 63/303, Loss: 0.0005546342581510544\n",
      "Epoch 24/100, Iteration 64/303, Loss: 0.0004965650732629001\n",
      "Epoch 24/100, Iteration 65/303, Loss: 0.0004337339196354151\n",
      "Epoch 24/100, Iteration 66/303, Loss: 0.00016128960123751312\n",
      "Epoch 24/100, Iteration 67/303, Loss: 3.130534605588764e-05\n",
      "Epoch 24/100, Iteration 68/303, Loss: 0.00037227687425911427\n",
      "Epoch 24/100, Iteration 69/303, Loss: 0.0001828484673751518\n",
      "Epoch 24/100, Iteration 70/303, Loss: 0.0016647999873384833\n",
      "Epoch 24/100, Iteration 71/303, Loss: 0.000269067328190431\n",
      "Epoch 24/100, Iteration 72/303, Loss: 4.402630656841211e-05\n",
      "Epoch 24/100, Iteration 73/303, Loss: 0.000202783674467355\n",
      "Epoch 24/100, Iteration 74/303, Loss: 0.00010490226850379258\n",
      "Epoch 24/100, Iteration 75/303, Loss: 0.00028857190045528114\n",
      "Epoch 24/100, Iteration 76/303, Loss: 0.00012432043149601668\n",
      "Epoch 24/100, Iteration 77/303, Loss: 1.637150489841588e-05\n",
      "Epoch 24/100, Iteration 78/303, Loss: 0.00048367457929998636\n",
      "Epoch 24/100, Iteration 79/303, Loss: 0.00016238378884736449\n",
      "Epoch 24/100, Iteration 80/303, Loss: 8.567114127799869e-05\n",
      "Epoch 24/100, Iteration 81/303, Loss: 1.2329903256613761e-05\n",
      "Epoch 24/100, Iteration 82/303, Loss: 0.00043058634037151933\n",
      "Epoch 24/100, Iteration 83/303, Loss: 0.00011115786037407815\n",
      "Epoch 24/100, Iteration 84/303, Loss: 0.00017344501975458115\n",
      "Epoch 24/100, Iteration 85/303, Loss: 9.545150533085689e-05\n",
      "Epoch 24/100, Iteration 86/303, Loss: 0.00017365771054755896\n",
      "Epoch 24/100, Iteration 87/303, Loss: 7.328663195949048e-05\n",
      "Epoch 24/100, Iteration 88/303, Loss: 0.00033402489498257637\n",
      "Epoch 24/100, Iteration 89/303, Loss: 0.00010131720046047121\n",
      "Epoch 24/100, Iteration 90/303, Loss: 0.00010452132119098678\n",
      "Epoch 24/100, Iteration 91/303, Loss: 0.00011255130812060088\n",
      "Epoch 24/100, Iteration 92/303, Loss: 0.0002970866917166859\n",
      "Epoch 24/100, Iteration 93/303, Loss: 0.00014410598669201136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Iteration 94/303, Loss: 0.00017404851678293198\n",
      "Epoch 24/100, Iteration 95/303, Loss: 9.009859059005976e-05\n",
      "Epoch 24/100, Iteration 96/303, Loss: 0.0012653651647269726\n",
      "Epoch 24/100, Iteration 97/303, Loss: 0.00028129658312536776\n",
      "Epoch 24/100, Iteration 98/303, Loss: 0.00038523587863892317\n",
      "Epoch 24/100, Iteration 99/303, Loss: 0.0003129574761260301\n",
      "Epoch 24/100, Iteration 100/303, Loss: 0.000245927571086213\n",
      "Epoch 24/100, Iteration 101/303, Loss: 4.89093508804217e-05\n",
      "Epoch 24/100, Iteration 102/303, Loss: 8.761732169659808e-05\n",
      "Epoch 24/100, Iteration 103/303, Loss: 0.00043729975004680455\n",
      "Epoch 24/100, Iteration 104/303, Loss: 0.00023307153605856001\n",
      "Epoch 24/100, Iteration 105/303, Loss: 5.240263999439776e-05\n",
      "Epoch 24/100, Iteration 106/303, Loss: 5.640135714202188e-05\n",
      "Epoch 24/100, Iteration 107/303, Loss: 7.573814946226776e-05\n",
      "Epoch 24/100, Iteration 108/303, Loss: 0.0002711132983677089\n",
      "Epoch 24/100, Iteration 109/303, Loss: 8.769304258748889e-05\n",
      "Epoch 24/100, Iteration 110/303, Loss: 0.0003836963733192533\n",
      "Epoch 24/100, Iteration 111/303, Loss: 0.0002693355781957507\n",
      "Epoch 24/100, Iteration 112/303, Loss: 7.62471099733375e-05\n",
      "Epoch 24/100, Iteration 113/303, Loss: 3.6192046536598355e-05\n",
      "Epoch 24/100, Iteration 114/303, Loss: 0.00034456097637303174\n",
      "Epoch 24/100, Iteration 115/303, Loss: 0.00016319358837790787\n",
      "Epoch 24/100, Iteration 116/303, Loss: 0.00010413359996164218\n",
      "Epoch 24/100, Iteration 117/303, Loss: 0.00010075771569972858\n",
      "Epoch 24/100, Iteration 118/303, Loss: 0.0002853595360647887\n",
      "Epoch 24/100, Iteration 119/303, Loss: 2.9063321562716737e-05\n",
      "Epoch 24/100, Iteration 120/303, Loss: 0.00036213468411006033\n",
      "Epoch 24/100, Iteration 121/303, Loss: 0.00014670428936369717\n",
      "Epoch 24/100, Iteration 122/303, Loss: 0.00016019251779653132\n",
      "Epoch 24/100, Iteration 123/303, Loss: 0.00024141989706549793\n",
      "Epoch 24/100, Iteration 124/303, Loss: 0.0003540020843502134\n",
      "Epoch 24/100, Iteration 125/303, Loss: 0.000201020622625947\n",
      "Epoch 24/100, Iteration 126/303, Loss: 0.00012513391266111284\n",
      "Epoch 24/100, Iteration 127/303, Loss: 0.00021235732128843665\n",
      "Epoch 24/100, Iteration 128/303, Loss: 0.00027625937946140766\n",
      "Epoch 24/100, Iteration 129/303, Loss: 9.648468403611332e-05\n",
      "Epoch 24/100, Iteration 130/303, Loss: 3.2218646083492786e-05\n",
      "Epoch 24/100, Iteration 131/303, Loss: 0.00043686930439434946\n",
      "Epoch 24/100, Iteration 132/303, Loss: 0.00011274140706518665\n",
      "Epoch 24/100, Iteration 133/303, Loss: 0.00023907575814519078\n",
      "Epoch 24/100, Iteration 134/303, Loss: 0.00029297592118382454\n",
      "Epoch 24/100, Iteration 135/303, Loss: 0.00029400730272755027\n",
      "Epoch 24/100, Iteration 136/303, Loss: 7.938795170048252e-05\n",
      "Epoch 24/100, Iteration 137/303, Loss: 6.418365501303924e-06\n",
      "Epoch 24/100, Iteration 138/303, Loss: 0.0003498194273561239\n",
      "Epoch 24/100, Iteration 139/303, Loss: 5.929979670327157e-05\n",
      "Epoch 24/100, Iteration 140/303, Loss: 0.00035397440660744905\n",
      "Epoch 24/100, Iteration 141/303, Loss: 0.0001437714381609112\n",
      "Epoch 24/100, Iteration 142/303, Loss: 0.0003584013320505619\n",
      "Epoch 24/100, Iteration 143/303, Loss: 0.0002588631759863347\n",
      "Epoch 24/100, Iteration 144/303, Loss: 9.495973790762946e-05\n",
      "Epoch 24/100, Iteration 145/303, Loss: 6.994784052949399e-05\n",
      "Epoch 24/100, Iteration 146/303, Loss: 0.0004704369930550456\n",
      "Epoch 24/100, Iteration 147/303, Loss: 0.0006544087082147598\n",
      "Epoch 24/100, Iteration 148/303, Loss: 0.00021798988746013492\n",
      "Epoch 24/100, Iteration 149/303, Loss: 0.000147215134347789\n",
      "Epoch 24/100, Iteration 150/303, Loss: 7.839964382583275e-05\n",
      "Epoch 24/100, Iteration 151/303, Loss: 0.0002043631102424115\n",
      "Epoch 24/100, Iteration 152/303, Loss: 0.00016206713917199522\n",
      "Epoch 24/100, Iteration 153/303, Loss: 0.00022627221187576652\n",
      "Epoch 24/100, Iteration 154/303, Loss: 0.00031096648308448493\n",
      "Epoch 24/100, Iteration 155/303, Loss: 0.00018494589312467724\n",
      "Epoch 24/100, Iteration 156/303, Loss: 0.0003669332363642752\n",
      "Epoch 24/100, Iteration 157/303, Loss: 0.00019499377231113613\n",
      "Epoch 24/100, Iteration 158/303, Loss: 0.00016487191896885633\n",
      "Epoch 24/100, Iteration 159/303, Loss: 0.0002354556490899995\n",
      "Epoch 24/100, Iteration 160/303, Loss: 0.0003539218450896442\n",
      "Epoch 24/100, Iteration 161/303, Loss: 4.065222674398683e-05\n",
      "Epoch 24/100, Iteration 162/303, Loss: 5.598878124146722e-05\n",
      "Epoch 24/100, Iteration 163/303, Loss: 7.048467523418367e-05\n",
      "Epoch 24/100, Iteration 164/303, Loss: 0.0005402332753874362\n",
      "Epoch 24/100, Iteration 165/303, Loss: 5.222712206887081e-05\n",
      "Epoch 24/100, Iteration 166/303, Loss: 0.0005487193120643497\n",
      "Epoch 24/100, Iteration 167/303, Loss: 0.0007653031498193741\n",
      "Epoch 24/100, Iteration 168/303, Loss: 0.001715283957310021\n",
      "Epoch 24/100, Iteration 169/303, Loss: 0.0006064365734346211\n",
      "Epoch 24/100, Iteration 170/303, Loss: 0.00019154860638082027\n",
      "Epoch 24/100, Iteration 171/303, Loss: 6.52632734272629e-05\n",
      "Epoch 24/100, Iteration 172/303, Loss: 2.803037568810396e-05\n",
      "Epoch 24/100, Iteration 173/303, Loss: 2.7290636353427544e-05\n",
      "Epoch 24/100, Iteration 174/303, Loss: 4.620735126081854e-05\n",
      "Epoch 24/100, Iteration 175/303, Loss: 0.0001302024902543053\n",
      "Epoch 24/100, Iteration 176/303, Loss: 0.00014651328092440963\n",
      "Epoch 24/100, Iteration 177/303, Loss: 0.0007470637210644782\n",
      "Epoch 24/100, Iteration 178/303, Loss: 0.00012323549890425056\n",
      "Epoch 24/100, Iteration 179/303, Loss: 8.237693691626191e-05\n",
      "Epoch 24/100, Iteration 180/303, Loss: 0.00017461305833421648\n",
      "Epoch 24/100, Iteration 181/303, Loss: 0.0007609297754243016\n",
      "Epoch 24/100, Iteration 182/303, Loss: 7.953240856295452e-05\n",
      "Epoch 24/100, Iteration 183/303, Loss: 0.00024148063675966114\n",
      "Epoch 24/100, Iteration 184/303, Loss: 0.00038602109998464584\n",
      "Epoch 24/100, Iteration 185/303, Loss: 0.00032841251231729984\n",
      "Epoch 24/100, Iteration 186/303, Loss: 9.2279638920445e-05\n",
      "Epoch 24/100, Iteration 187/303, Loss: 0.00019612445612438023\n",
      "Epoch 24/100, Iteration 188/303, Loss: 0.0004140000673942268\n",
      "Epoch 24/100, Iteration 189/303, Loss: 0.00018597504822537303\n",
      "Epoch 24/100, Iteration 190/303, Loss: 0.00018268797430209816\n",
      "Epoch 24/100, Iteration 191/303, Loss: 0.0001678431435720995\n",
      "Epoch 24/100, Iteration 192/303, Loss: 0.0003572131972759962\n",
      "Epoch 24/100, Iteration 193/303, Loss: 6.497055437648669e-05\n",
      "Epoch 24/100, Iteration 194/303, Loss: 0.00011331641144352034\n",
      "Epoch 24/100, Iteration 195/303, Loss: 0.0001054226013366133\n",
      "Epoch 24/100, Iteration 196/303, Loss: 0.0004866034723818302\n",
      "Epoch 24/100, Iteration 197/303, Loss: 0.0005214831908233464\n",
      "Epoch 24/100, Iteration 198/303, Loss: 2.845763629011344e-05\n",
      "Epoch 24/100, Iteration 199/303, Loss: 9.674845932750031e-05\n",
      "Epoch 24/100, Iteration 200/303, Loss: 0.00015421892749145627\n",
      "Epoch 24/100, Iteration 201/303, Loss: 0.0001692305668257177\n",
      "Epoch 24/100, Iteration 202/303, Loss: 0.00015282460663001984\n",
      "Epoch 24/100, Iteration 203/303, Loss: 0.0001281534496229142\n",
      "Epoch 24/100, Iteration 204/303, Loss: 0.00034947553649544716\n",
      "Epoch 24/100, Iteration 205/303, Loss: 8.577689732192084e-05\n",
      "Epoch 24/100, Iteration 206/303, Loss: 0.00012175978190498427\n",
      "Epoch 24/100, Iteration 207/303, Loss: 0.00020760553888976574\n",
      "Epoch 24/100, Iteration 208/303, Loss: 0.00014217698480933905\n",
      "Epoch 24/100, Iteration 209/303, Loss: 0.0006668504793196917\n",
      "Epoch 24/100, Iteration 210/303, Loss: 0.00031190301524475217\n",
      "Epoch 24/100, Iteration 211/303, Loss: 0.0002144717873306945\n",
      "Epoch 24/100, Iteration 212/303, Loss: 0.00016338078421540558\n",
      "Epoch 24/100, Iteration 213/303, Loss: 0.0002188153739552945\n",
      "Epoch 24/100, Iteration 214/303, Loss: 0.00018452548829372972\n",
      "Epoch 24/100, Iteration 215/303, Loss: 5.8183708461001515e-05\n",
      "Epoch 24/100, Iteration 216/303, Loss: 0.00017508372548036277\n",
      "Epoch 24/100, Iteration 217/303, Loss: 3.197443584213033e-05\n",
      "Epoch 24/100, Iteration 218/303, Loss: 0.00018310159794054925\n",
      "Epoch 24/100, Iteration 219/303, Loss: 7.43172422517091e-05\n",
      "Epoch 24/100, Iteration 220/303, Loss: 0.0006117597804404795\n",
      "Epoch 24/100, Iteration 221/303, Loss: 0.0005913927452638745\n",
      "Epoch 24/100, Iteration 222/303, Loss: 4.0080583858070895e-05\n",
      "Epoch 24/100, Iteration 223/303, Loss: 0.0002823019749484956\n",
      "Epoch 24/100, Iteration 224/303, Loss: 0.0003205336688552052\n",
      "Epoch 24/100, Iteration 225/303, Loss: 0.00010376532736700028\n",
      "Epoch 24/100, Iteration 226/303, Loss: 0.0003521518665365875\n",
      "Epoch 24/100, Iteration 227/303, Loss: 9.992050036089495e-05\n",
      "Epoch 24/100, Iteration 228/303, Loss: 0.00010415649740025401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Iteration 229/303, Loss: 0.0001003649813355878\n",
      "Epoch 24/100, Iteration 230/303, Loss: 4.0089063986670226e-05\n",
      "Epoch 24/100, Iteration 231/303, Loss: 0.0007237173267640173\n",
      "Epoch 24/100, Iteration 232/303, Loss: 0.0006463183090090752\n",
      "Epoch 24/100, Iteration 233/303, Loss: 8.532584615750238e-05\n",
      "Epoch 24/100, Iteration 234/303, Loss: 0.0006761956610716879\n",
      "Epoch 24/100, Iteration 235/303, Loss: 0.00027996793505735695\n",
      "Epoch 24/100, Iteration 236/303, Loss: 0.0006149658001959324\n",
      "Epoch 24/100, Iteration 237/303, Loss: 0.00021129166998434812\n",
      "Epoch 24/100, Iteration 238/303, Loss: 0.0002719816693570465\n",
      "Epoch 24/100, Iteration 239/303, Loss: 2.7635680453386158e-05\n",
      "Epoch 24/100, Iteration 240/303, Loss: 0.0008536469540558755\n",
      "Epoch 24/100, Iteration 241/303, Loss: 0.00041911471635103226\n",
      "Epoch 24/100, Iteration 242/303, Loss: 0.0007015642477199435\n",
      "Epoch 24/100, Iteration 243/303, Loss: 0.0001815325376810506\n",
      "Epoch 24/100, Iteration 244/303, Loss: 0.0005308208637870848\n",
      "Epoch 24/100, Iteration 245/303, Loss: 7.898568583186716e-05\n",
      "Epoch 24/100, Iteration 246/303, Loss: 0.00015492329839617014\n",
      "Epoch 24/100, Iteration 247/303, Loss: 5.7315482990816236e-05\n",
      "Epoch 24/100, Iteration 248/303, Loss: 0.00039121968438848853\n",
      "Epoch 24/100, Iteration 249/303, Loss: 0.0003491028328426182\n",
      "Epoch 24/100, Iteration 250/303, Loss: 8.171562512870878e-05\n",
      "Epoch 24/100, Iteration 251/303, Loss: 0.00010178567754337564\n",
      "Epoch 24/100, Iteration 252/303, Loss: 0.0008449640008620918\n",
      "Epoch 24/100, Iteration 253/303, Loss: 0.0006120629841461778\n",
      "Epoch 24/100, Iteration 254/303, Loss: 0.0001397701707901433\n",
      "Epoch 24/100, Iteration 255/303, Loss: 0.00018458256090525538\n",
      "Epoch 24/100, Iteration 256/303, Loss: 0.00015372633060906082\n",
      "Epoch 24/100, Iteration 257/303, Loss: 0.00012859265552833676\n",
      "Epoch 24/100, Iteration 258/303, Loss: 0.0004326389462221414\n",
      "Epoch 24/100, Iteration 259/303, Loss: 0.0002605430781841278\n",
      "Epoch 24/100, Iteration 260/303, Loss: 0.00010512478911550716\n",
      "Epoch 24/100, Iteration 261/303, Loss: 0.00024063971068244427\n",
      "Epoch 24/100, Iteration 262/303, Loss: 0.00017728604143485427\n",
      "Epoch 24/100, Iteration 263/303, Loss: 0.00014174336683936417\n",
      "Epoch 24/100, Iteration 264/303, Loss: 0.00028831095551140606\n",
      "Epoch 24/100, Iteration 265/303, Loss: 0.00039566532359458506\n",
      "Epoch 24/100, Iteration 266/303, Loss: 0.00011980285489698872\n",
      "Epoch 24/100, Iteration 267/303, Loss: 0.0004435549781192094\n",
      "Epoch 24/100, Iteration 268/303, Loss: 0.000149283412611112\n",
      "Epoch 24/100, Iteration 269/303, Loss: 9.800180851016194e-05\n",
      "Epoch 24/100, Iteration 270/303, Loss: 0.00014984433073550463\n",
      "Epoch 24/100, Iteration 271/303, Loss: 0.00019112051813863218\n",
      "Epoch 24/100, Iteration 272/303, Loss: 0.00085992063395679\n",
      "Epoch 24/100, Iteration 273/303, Loss: 0.00011644543701549992\n",
      "Epoch 24/100, Iteration 274/303, Loss: 0.0001522913808003068\n",
      "Epoch 24/100, Iteration 275/303, Loss: 0.0003509265079628676\n",
      "Epoch 24/100, Iteration 276/303, Loss: 0.00021548551740124822\n",
      "Epoch 24/100, Iteration 277/303, Loss: 0.00015824254660401493\n",
      "Epoch 24/100, Iteration 278/303, Loss: 0.00022555574832949787\n",
      "Epoch 24/100, Iteration 279/303, Loss: 0.000226760923396796\n",
      "Epoch 24/100, Iteration 280/303, Loss: 0.00035225541796535254\n",
      "Epoch 24/100, Iteration 281/303, Loss: 0.00011001024540746585\n",
      "Epoch 24/100, Iteration 282/303, Loss: 0.00011531770724104717\n",
      "Epoch 24/100, Iteration 283/303, Loss: 0.0002799198846332729\n",
      "Epoch 24/100, Iteration 284/303, Loss: 0.00030354835325852036\n",
      "Epoch 24/100, Iteration 285/303, Loss: 6.8022181949345395e-06\n",
      "Epoch 24/100, Iteration 286/303, Loss: 0.00018282154633197933\n",
      "Epoch 24/100, Iteration 287/303, Loss: 0.0006309545715339482\n",
      "Epoch 24/100, Iteration 288/303, Loss: 6.71977613819763e-05\n",
      "Epoch 24/100, Iteration 289/303, Loss: 0.0003028606006409973\n",
      "Epoch 24/100, Iteration 290/303, Loss: 0.0002083191939163953\n",
      "Epoch 24/100, Iteration 291/303, Loss: 0.00039100521826185286\n",
      "Epoch 24/100, Iteration 292/303, Loss: 6.072496762499213e-05\n",
      "Epoch 24/100, Iteration 293/303, Loss: 0.00015561096370220184\n",
      "Epoch 24/100, Iteration 294/303, Loss: 0.000468685437226668\n",
      "Epoch 24/100, Iteration 295/303, Loss: 0.0002078619145322591\n",
      "Epoch 24/100, Iteration 296/303, Loss: 0.00040072723641060293\n",
      "Epoch 24/100, Iteration 297/303, Loss: 9.966207289835438e-05\n",
      "Epoch 24/100, Iteration 298/303, Loss: 0.00030056812101975083\n",
      "Epoch 24/100, Iteration 299/303, Loss: 0.00012353698548395187\n",
      "Epoch 24/100, Iteration 300/303, Loss: 0.0005509030306711793\n",
      "Epoch 24/100, Iteration 301/303, Loss: 0.00013683964789379388\n",
      "Epoch 24/100, Iteration 302/303, Loss: 0.00018841406563296914\n",
      "Epoch 24/100, Iteration 303/303, Loss: 2.397283424215857e-05\n",
      "Epoch 25/100, Iteration 1/303, Loss: 0.00021854581427760422\n",
      "Epoch 25/100, Iteration 2/303, Loss: 0.00018970818200614303\n",
      "Epoch 25/100, Iteration 3/303, Loss: 6.304025737335905e-05\n",
      "Epoch 25/100, Iteration 4/303, Loss: 5.091084312880412e-05\n",
      "Epoch 25/100, Iteration 5/303, Loss: 2.804677569656633e-05\n",
      "Epoch 25/100, Iteration 6/303, Loss: 0.0001859643089119345\n",
      "Epoch 25/100, Iteration 7/303, Loss: 0.00015541084576398134\n",
      "Epoch 25/100, Iteration 8/303, Loss: 0.00014086507144384086\n",
      "Epoch 25/100, Iteration 9/303, Loss: 0.0001031806823448278\n",
      "Epoch 25/100, Iteration 10/303, Loss: 0.00023274599516298622\n",
      "Epoch 25/100, Iteration 11/303, Loss: 8.347805123776197e-05\n",
      "Epoch 25/100, Iteration 12/303, Loss: 6.992676935624331e-05\n",
      "Epoch 25/100, Iteration 13/303, Loss: 0.00015341027756221592\n",
      "Epoch 25/100, Iteration 14/303, Loss: 1.7879407096188515e-05\n",
      "Epoch 25/100, Iteration 15/303, Loss: 9.905853221425787e-05\n",
      "Epoch 25/100, Iteration 16/303, Loss: 0.00011089915642514825\n",
      "Epoch 25/100, Iteration 17/303, Loss: 0.0004160605603829026\n",
      "Epoch 25/100, Iteration 18/303, Loss: 0.00020511395996436477\n",
      "Epoch 25/100, Iteration 19/303, Loss: 0.0001651518978178501\n",
      "Epoch 25/100, Iteration 20/303, Loss: 0.00013780831068288535\n",
      "Epoch 25/100, Iteration 21/303, Loss: 5.541853533941321e-05\n",
      "Epoch 25/100, Iteration 22/303, Loss: 0.0002507625031284988\n",
      "Epoch 25/100, Iteration 23/303, Loss: 0.00016922953363973647\n",
      "Epoch 25/100, Iteration 24/303, Loss: 0.0006737613002769649\n",
      "Epoch 25/100, Iteration 25/303, Loss: 4.676941898651421e-05\n",
      "Epoch 25/100, Iteration 26/303, Loss: 0.00013753995881415904\n",
      "Epoch 25/100, Iteration 27/303, Loss: 0.0002967208274640143\n",
      "Epoch 25/100, Iteration 28/303, Loss: 0.00019354754476808012\n",
      "Epoch 25/100, Iteration 29/303, Loss: 0.0002230204117950052\n",
      "Epoch 25/100, Iteration 30/303, Loss: 2.7517300623003393e-05\n",
      "Epoch 25/100, Iteration 31/303, Loss: 0.0004707966581918299\n",
      "Epoch 25/100, Iteration 32/303, Loss: 2.274743928865064e-05\n",
      "Epoch 25/100, Iteration 33/303, Loss: 0.00027843439602293074\n",
      "Epoch 25/100, Iteration 34/303, Loss: 0.00010477755131432787\n",
      "Epoch 25/100, Iteration 35/303, Loss: 9.51469992287457e-05\n",
      "Epoch 25/100, Iteration 36/303, Loss: 7.458874461008236e-05\n",
      "Epoch 25/100, Iteration 37/303, Loss: 0.0003531390684656799\n",
      "Epoch 25/100, Iteration 38/303, Loss: 0.00038472237065434456\n",
      "Epoch 25/100, Iteration 39/303, Loss: 0.0003392216458451003\n",
      "Epoch 25/100, Iteration 40/303, Loss: 0.00014368913252837956\n",
      "Epoch 25/100, Iteration 41/303, Loss: 6.329950701911002e-05\n",
      "Epoch 25/100, Iteration 42/303, Loss: 2.0866998966084793e-05\n",
      "Epoch 25/100, Iteration 43/303, Loss: 0.0002507561002857983\n",
      "Epoch 25/100, Iteration 44/303, Loss: 9.219937783200294e-05\n",
      "Epoch 25/100, Iteration 45/303, Loss: 0.00019860405882354826\n",
      "Epoch 25/100, Iteration 46/303, Loss: 0.00017937651136890054\n",
      "Epoch 25/100, Iteration 47/303, Loss: 0.00016139303625095636\n",
      "Epoch 25/100, Iteration 48/303, Loss: 1.4304320757219102e-05\n",
      "Epoch 25/100, Iteration 49/303, Loss: 0.0004096720658708364\n",
      "Epoch 25/100, Iteration 50/303, Loss: 0.00043937776354141533\n",
      "Epoch 25/100, Iteration 51/303, Loss: 0.00040453020483255386\n",
      "Epoch 25/100, Iteration 52/303, Loss: 0.00028609723085537553\n",
      "Epoch 25/100, Iteration 53/303, Loss: 7.865884253988042e-05\n",
      "Epoch 25/100, Iteration 54/303, Loss: 0.00021985673811286688\n",
      "Epoch 25/100, Iteration 55/303, Loss: 7.351367821684107e-05\n",
      "Epoch 25/100, Iteration 56/303, Loss: 0.0001709186763036996\n",
      "Epoch 25/100, Iteration 57/303, Loss: 0.00019885135407093912\n",
      "Epoch 25/100, Iteration 58/303, Loss: 6.590237171621993e-05\n",
      "Epoch 25/100, Iteration 59/303, Loss: 0.00022091582650318742\n",
      "Epoch 25/100, Iteration 60/303, Loss: 0.0001417041930835694\n",
      "Epoch 25/100, Iteration 61/303, Loss: 0.000198256631847471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Iteration 62/303, Loss: 0.00011120294948341325\n",
      "Epoch 25/100, Iteration 63/303, Loss: 0.00013391613902058452\n",
      "Epoch 25/100, Iteration 64/303, Loss: 4.188455204712227e-05\n",
      "Epoch 25/100, Iteration 65/303, Loss: 0.00010095905599882826\n",
      "Epoch 25/100, Iteration 66/303, Loss: 5.5555101425852627e-05\n",
      "Epoch 25/100, Iteration 67/303, Loss: 0.0014851611340418458\n",
      "Epoch 25/100, Iteration 68/303, Loss: 0.0002854859922081232\n",
      "Epoch 25/100, Iteration 69/303, Loss: 0.00015618588076904416\n",
      "Epoch 25/100, Iteration 70/303, Loss: 0.000375270436052233\n",
      "Epoch 25/100, Iteration 71/303, Loss: 0.00015444854216184467\n",
      "Epoch 25/100, Iteration 72/303, Loss: 0.00016701810818631202\n",
      "Epoch 25/100, Iteration 73/303, Loss: 6.057582140783779e-05\n",
      "Epoch 25/100, Iteration 74/303, Loss: 0.000310638191876933\n",
      "Epoch 25/100, Iteration 75/303, Loss: 0.00021946983179077506\n",
      "Epoch 25/100, Iteration 76/303, Loss: 0.00023619786952622235\n",
      "Epoch 25/100, Iteration 77/303, Loss: 0.0002077123790513724\n",
      "Epoch 25/100, Iteration 78/303, Loss: 6.965529610170051e-05\n",
      "Epoch 25/100, Iteration 79/303, Loss: 0.00020525102445390075\n",
      "Epoch 25/100, Iteration 80/303, Loss: 0.00016595299530308694\n",
      "Epoch 25/100, Iteration 81/303, Loss: 0.00020941055845469236\n",
      "Epoch 25/100, Iteration 82/303, Loss: 0.0002163281460525468\n",
      "Epoch 25/100, Iteration 83/303, Loss: 0.00027733168099075556\n",
      "Epoch 25/100, Iteration 84/303, Loss: 0.0002727358660195023\n",
      "Epoch 25/100, Iteration 85/303, Loss: 0.00035721491440199316\n",
      "Epoch 25/100, Iteration 86/303, Loss: 0.00021471871878020465\n",
      "Epoch 25/100, Iteration 87/303, Loss: 0.00022275466471910477\n",
      "Epoch 25/100, Iteration 88/303, Loss: 0.00019895040895789862\n",
      "Epoch 25/100, Iteration 89/303, Loss: 0.00014174304669722915\n",
      "Epoch 25/100, Iteration 90/303, Loss: 1.13874575617956e-05\n",
      "Epoch 25/100, Iteration 91/303, Loss: 8.07025280664675e-05\n",
      "Epoch 25/100, Iteration 92/303, Loss: 0.0002669120440259576\n",
      "Epoch 25/100, Iteration 93/303, Loss: 6.891676093800925e-06\n",
      "Epoch 25/100, Iteration 94/303, Loss: 0.00017081106489058584\n",
      "Epoch 25/100, Iteration 95/303, Loss: 3.379282134119421e-05\n",
      "Epoch 25/100, Iteration 96/303, Loss: 4.784609700436704e-05\n",
      "Epoch 25/100, Iteration 97/303, Loss: 0.00021400637342594564\n",
      "Epoch 25/100, Iteration 98/303, Loss: 0.00032476894557476044\n",
      "Epoch 25/100, Iteration 99/303, Loss: 0.00012190466077299789\n",
      "Epoch 25/100, Iteration 100/303, Loss: 0.00036572065437212586\n",
      "Epoch 25/100, Iteration 101/303, Loss: 0.00018643095972947776\n",
      "Epoch 25/100, Iteration 102/303, Loss: 0.00048248429084196687\n",
      "Epoch 25/100, Iteration 103/303, Loss: 6.023905734764412e-05\n",
      "Epoch 25/100, Iteration 104/303, Loss: 4.0615206671645865e-05\n",
      "Epoch 25/100, Iteration 105/303, Loss: 3.543472848832607e-05\n",
      "Epoch 25/100, Iteration 106/303, Loss: 0.00022515031741932034\n",
      "Epoch 25/100, Iteration 107/303, Loss: 6.26048058620654e-05\n",
      "Epoch 25/100, Iteration 108/303, Loss: 0.00016965795657597482\n",
      "Epoch 25/100, Iteration 109/303, Loss: 0.00014924829883966595\n",
      "Epoch 25/100, Iteration 110/303, Loss: 4.3428455683169886e-05\n",
      "Epoch 25/100, Iteration 111/303, Loss: 0.00012858018453698605\n",
      "Epoch 25/100, Iteration 112/303, Loss: 9.739239612827078e-05\n",
      "Epoch 25/100, Iteration 113/303, Loss: 8.119228732539341e-05\n",
      "Epoch 25/100, Iteration 114/303, Loss: 3.8298148865578696e-05\n",
      "Epoch 25/100, Iteration 115/303, Loss: 8.58225830597803e-05\n",
      "Epoch 25/100, Iteration 116/303, Loss: 0.00015903568419162184\n",
      "Epoch 25/100, Iteration 117/303, Loss: 0.00017370084242429584\n",
      "Epoch 25/100, Iteration 118/303, Loss: 0.0002788070705719292\n",
      "Epoch 25/100, Iteration 119/303, Loss: 5.525049346033484e-05\n",
      "Epoch 25/100, Iteration 120/303, Loss: 0.00018228810222353786\n",
      "Epoch 25/100, Iteration 121/303, Loss: 4.691098365583457e-05\n",
      "Epoch 25/100, Iteration 122/303, Loss: 0.00017069402383640409\n",
      "Epoch 25/100, Iteration 123/303, Loss: 0.0002310118288733065\n",
      "Epoch 25/100, Iteration 124/303, Loss: 0.0004713011148851365\n",
      "Epoch 25/100, Iteration 125/303, Loss: 3.323107375763357e-05\n",
      "Epoch 25/100, Iteration 126/303, Loss: 0.00014718635065946728\n",
      "Epoch 25/100, Iteration 127/303, Loss: 0.0002499731199350208\n",
      "Epoch 25/100, Iteration 128/303, Loss: 2.2279155018622987e-05\n",
      "Epoch 25/100, Iteration 129/303, Loss: 5.880645403522067e-05\n",
      "Epoch 25/100, Iteration 130/303, Loss: 2.7598285669228062e-05\n",
      "Epoch 25/100, Iteration 131/303, Loss: 5.485469228005968e-05\n",
      "Epoch 25/100, Iteration 132/303, Loss: 0.0002321645151823759\n",
      "Epoch 25/100, Iteration 133/303, Loss: 0.00041825263178907335\n",
      "Epoch 25/100, Iteration 134/303, Loss: 0.00014692374679725617\n",
      "Epoch 25/100, Iteration 135/303, Loss: 0.00014418427599593997\n",
      "Epoch 25/100, Iteration 136/303, Loss: 0.00017655758711043745\n",
      "Epoch 25/100, Iteration 137/303, Loss: 9.473005775362253e-05\n",
      "Epoch 25/100, Iteration 138/303, Loss: 4.906414324068464e-05\n",
      "Epoch 25/100, Iteration 139/303, Loss: 0.00012496826821006835\n",
      "Epoch 25/100, Iteration 140/303, Loss: 2.4272279915749095e-05\n",
      "Epoch 25/100, Iteration 141/303, Loss: 0.00012449965288396925\n",
      "Epoch 25/100, Iteration 142/303, Loss: 0.00010425815708003938\n",
      "Epoch 25/100, Iteration 143/303, Loss: 0.00014265631034504622\n",
      "Epoch 25/100, Iteration 144/303, Loss: 3.813867078861222e-05\n",
      "Epoch 25/100, Iteration 145/303, Loss: 0.0001386110670864582\n",
      "Epoch 25/100, Iteration 146/303, Loss: 5.208684888202697e-05\n",
      "Epoch 25/100, Iteration 147/303, Loss: 6.706464773742482e-05\n",
      "Epoch 25/100, Iteration 148/303, Loss: 6.710068555548787e-05\n",
      "Epoch 25/100, Iteration 149/303, Loss: 0.00011060940596507862\n",
      "Epoch 25/100, Iteration 150/303, Loss: 0.0001698198466328904\n",
      "Epoch 25/100, Iteration 151/303, Loss: 0.0001221064740093425\n",
      "Epoch 25/100, Iteration 152/303, Loss: 0.00023812429571989924\n",
      "Epoch 25/100, Iteration 153/303, Loss: 0.00012701560626737773\n",
      "Epoch 25/100, Iteration 154/303, Loss: 0.00048648176016286016\n",
      "Epoch 25/100, Iteration 155/303, Loss: 3.7043348129373044e-05\n",
      "Epoch 25/100, Iteration 156/303, Loss: 0.00021347941947169602\n",
      "Epoch 25/100, Iteration 157/303, Loss: 0.00020864474936388433\n",
      "Epoch 25/100, Iteration 158/303, Loss: 8.988792251329869e-05\n",
      "Epoch 25/100, Iteration 159/303, Loss: 0.00010262674186378717\n",
      "Epoch 25/100, Iteration 160/303, Loss: 0.0006416024989448488\n",
      "Epoch 25/100, Iteration 161/303, Loss: 0.00019806201453320682\n",
      "Epoch 25/100, Iteration 162/303, Loss: 0.00029784842627123\n",
      "Epoch 25/100, Iteration 163/303, Loss: 0.0001581065880600363\n",
      "Epoch 25/100, Iteration 164/303, Loss: 5.972321014269255e-05\n",
      "Epoch 25/100, Iteration 165/303, Loss: 0.00014399482461158186\n",
      "Epoch 25/100, Iteration 166/303, Loss: 0.00013876226148568094\n",
      "Epoch 25/100, Iteration 167/303, Loss: 0.0006335764774121344\n",
      "Epoch 25/100, Iteration 168/303, Loss: 0.0002966931788250804\n",
      "Epoch 25/100, Iteration 169/303, Loss: 0.0004985801642760634\n",
      "Epoch 25/100, Iteration 170/303, Loss: 4.1859901102725416e-05\n",
      "Epoch 25/100, Iteration 171/303, Loss: 2.5365196052007377e-05\n",
      "Epoch 25/100, Iteration 172/303, Loss: 0.0001517915225122124\n",
      "Epoch 25/100, Iteration 173/303, Loss: 0.00012671998410951346\n",
      "Epoch 25/100, Iteration 174/303, Loss: 0.00020828208653256297\n",
      "Epoch 25/100, Iteration 175/303, Loss: 0.00021464847668539733\n",
      "Epoch 25/100, Iteration 176/303, Loss: 9.417153341928497e-05\n",
      "Epoch 25/100, Iteration 177/303, Loss: 5.083392170490697e-05\n",
      "Epoch 25/100, Iteration 178/303, Loss: 0.0003392363723833114\n",
      "Epoch 25/100, Iteration 179/303, Loss: 0.0002785363176371902\n",
      "Epoch 25/100, Iteration 180/303, Loss: 0.00019294336379971355\n",
      "Epoch 25/100, Iteration 181/303, Loss: 0.0001985701674129814\n",
      "Epoch 25/100, Iteration 182/303, Loss: 0.0003416846157051623\n",
      "Epoch 25/100, Iteration 183/303, Loss: 0.0002791956067085266\n",
      "Epoch 25/100, Iteration 184/303, Loss: 0.00029197265394032\n",
      "Epoch 25/100, Iteration 185/303, Loss: 0.0001748597132973373\n",
      "Epoch 25/100, Iteration 186/303, Loss: 0.00017490721074864268\n",
      "Epoch 25/100, Iteration 187/303, Loss: 0.0003711465105880052\n",
      "Epoch 25/100, Iteration 188/303, Loss: 0.00026287633227184415\n",
      "Epoch 25/100, Iteration 189/303, Loss: 0.00016236610827036202\n",
      "Epoch 25/100, Iteration 190/303, Loss: 0.00021029644994996488\n",
      "Epoch 25/100, Iteration 191/303, Loss: 0.0001979119988391176\n",
      "Epoch 25/100, Iteration 192/303, Loss: 0.0005258448072709143\n",
      "Epoch 25/100, Iteration 193/303, Loss: 4.631789488485083e-05\n",
      "Epoch 25/100, Iteration 194/303, Loss: 0.00014223027392290533\n",
      "Epoch 25/100, Iteration 195/303, Loss: 0.0002621767926029861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Iteration 196/303, Loss: 8.289267134387046e-05\n",
      "Epoch 25/100, Iteration 197/303, Loss: 0.00021183093485888094\n",
      "Epoch 25/100, Iteration 198/303, Loss: 0.00032086201827041805\n",
      "Epoch 25/100, Iteration 199/303, Loss: 0.00018231250578537583\n",
      "Epoch 25/100, Iteration 200/303, Loss: 0.0002873077755793929\n",
      "Epoch 25/100, Iteration 201/303, Loss: 0.00022876207367517054\n",
      "Epoch 25/100, Iteration 202/303, Loss: 0.0001205020016641356\n",
      "Epoch 25/100, Iteration 203/303, Loss: 0.0002692938724067062\n",
      "Epoch 25/100, Iteration 204/303, Loss: 7.419415487674996e-05\n",
      "Epoch 25/100, Iteration 205/303, Loss: 0.0006199262570589781\n",
      "Epoch 25/100, Iteration 206/303, Loss: 9.65753206401132e-05\n",
      "Epoch 25/100, Iteration 207/303, Loss: 0.0010944836540147662\n",
      "Epoch 25/100, Iteration 208/303, Loss: 5.220765888225287e-05\n",
      "Epoch 25/100, Iteration 209/303, Loss: 5.309711559675634e-05\n",
      "Epoch 25/100, Iteration 210/303, Loss: 6.801339623052627e-05\n",
      "Epoch 25/100, Iteration 211/303, Loss: 0.00024631861015222967\n",
      "Epoch 25/100, Iteration 212/303, Loss: 0.0006276610074564815\n",
      "Epoch 25/100, Iteration 213/303, Loss: 2.6949761377181858e-05\n",
      "Epoch 25/100, Iteration 214/303, Loss: 0.00023423884704243392\n",
      "Epoch 25/100, Iteration 215/303, Loss: 6.857640983071178e-05\n",
      "Epoch 25/100, Iteration 216/303, Loss: 0.00016814001719467342\n",
      "Epoch 25/100, Iteration 217/303, Loss: 8.207938662962988e-05\n",
      "Epoch 25/100, Iteration 218/303, Loss: 0.00011411593004595488\n",
      "Epoch 25/100, Iteration 219/303, Loss: 0.00021411034686025232\n",
      "Epoch 25/100, Iteration 220/303, Loss: 1.797950972104445e-05\n",
      "Epoch 25/100, Iteration 221/303, Loss: 0.0001381085894536227\n",
      "Epoch 25/100, Iteration 222/303, Loss: 8.219237497542053e-05\n",
      "Epoch 25/100, Iteration 223/303, Loss: 0.0004186013829894364\n",
      "Epoch 25/100, Iteration 224/303, Loss: 3.249782821512781e-05\n",
      "Epoch 25/100, Iteration 225/303, Loss: 0.00013211200712248683\n",
      "Epoch 25/100, Iteration 226/303, Loss: 0.00035971429315395653\n",
      "Epoch 25/100, Iteration 227/303, Loss: 0.0004269194323569536\n",
      "Epoch 25/100, Iteration 228/303, Loss: 1.8877039110520855e-05\n",
      "Epoch 25/100, Iteration 229/303, Loss: 0.00026549893664196134\n",
      "Epoch 25/100, Iteration 230/303, Loss: 9.39732781262137e-05\n",
      "Epoch 25/100, Iteration 231/303, Loss: 4.9911126552615315e-05\n",
      "Epoch 25/100, Iteration 232/303, Loss: 0.00031206946005113423\n",
      "Epoch 25/100, Iteration 233/303, Loss: 0.00024042655422817916\n",
      "Epoch 25/100, Iteration 234/303, Loss: 0.0003727894800249487\n",
      "Epoch 25/100, Iteration 235/303, Loss: 7.869653927627951e-05\n",
      "Epoch 25/100, Iteration 236/303, Loss: 4.052363510709256e-05\n",
      "Epoch 25/100, Iteration 237/303, Loss: 0.0014365798560902476\n",
      "Epoch 25/100, Iteration 238/303, Loss: 0.0003308128216303885\n",
      "Epoch 25/100, Iteration 239/303, Loss: 0.00019430043175816536\n",
      "Epoch 25/100, Iteration 240/303, Loss: 0.0002272076962981373\n",
      "Epoch 25/100, Iteration 241/303, Loss: 0.00019674809300340712\n",
      "Epoch 25/100, Iteration 242/303, Loss: 0.0006179187912493944\n",
      "Epoch 25/100, Iteration 243/303, Loss: 0.00012536915892269462\n",
      "Epoch 25/100, Iteration 244/303, Loss: 0.0004571401805151254\n",
      "Epoch 25/100, Iteration 245/303, Loss: 0.0001399358152411878\n",
      "Epoch 25/100, Iteration 246/303, Loss: 0.00023985205916687846\n",
      "Epoch 25/100, Iteration 247/303, Loss: 0.0005111201317049563\n",
      "Epoch 25/100, Iteration 248/303, Loss: 0.00020766252418980002\n",
      "Epoch 25/100, Iteration 249/303, Loss: 0.00011789824930019677\n",
      "Epoch 25/100, Iteration 250/303, Loss: 3.824416489806026e-05\n",
      "Epoch 25/100, Iteration 251/303, Loss: 5.923673961660825e-05\n",
      "Epoch 25/100, Iteration 252/303, Loss: 0.0001508925633970648\n",
      "Epoch 25/100, Iteration 253/303, Loss: 6.287966971285641e-05\n",
      "Epoch 25/100, Iteration 254/303, Loss: 2.272903293487616e-05\n",
      "Epoch 25/100, Iteration 255/303, Loss: 7.182775880210102e-05\n",
      "Epoch 25/100, Iteration 256/303, Loss: 0.00013400844181887805\n",
      "Epoch 25/100, Iteration 257/303, Loss: 0.0002140490832971409\n",
      "Epoch 25/100, Iteration 258/303, Loss: 0.00012540555326268077\n",
      "Epoch 25/100, Iteration 259/303, Loss: 0.00017472455510869622\n",
      "Epoch 25/100, Iteration 260/303, Loss: 0.00027561720344237983\n",
      "Epoch 25/100, Iteration 261/303, Loss: 0.00026267478824593127\n",
      "Epoch 25/100, Iteration 262/303, Loss: 0.00024188405950553715\n",
      "Epoch 25/100, Iteration 263/303, Loss: 0.00015257307677529752\n",
      "Epoch 25/100, Iteration 264/303, Loss: 6.223715172382072e-05\n",
      "Epoch 25/100, Iteration 265/303, Loss: 2.586872869869694e-05\n",
      "Epoch 25/100, Iteration 266/303, Loss: 0.00010451208800077438\n",
      "Epoch 25/100, Iteration 267/303, Loss: 0.0001894038141472265\n",
      "Epoch 25/100, Iteration 268/303, Loss: 0.00011328830441925675\n",
      "Epoch 25/100, Iteration 269/303, Loss: 0.0007830817485228181\n",
      "Epoch 25/100, Iteration 270/303, Loss: 0.00041364264325238764\n",
      "Epoch 25/100, Iteration 271/303, Loss: 8.315993909491226e-05\n",
      "Epoch 25/100, Iteration 272/303, Loss: 0.0002857581421267241\n",
      "Epoch 25/100, Iteration 273/303, Loss: 0.0003534918650984764\n",
      "Epoch 25/100, Iteration 274/303, Loss: 0.00041447445983067155\n",
      "Epoch 25/100, Iteration 275/303, Loss: 6.629919516853988e-05\n",
      "Epoch 25/100, Iteration 276/303, Loss: 0.00015083565085660666\n",
      "Epoch 25/100, Iteration 277/303, Loss: 0.0001457325997762382\n",
      "Epoch 25/100, Iteration 278/303, Loss: 0.0001764685002854094\n",
      "Epoch 25/100, Iteration 279/303, Loss: 8.117612742353231e-05\n",
      "Epoch 25/100, Iteration 280/303, Loss: 7.05848287907429e-05\n",
      "Epoch 25/100, Iteration 281/303, Loss: 0.0002528380136936903\n",
      "Epoch 25/100, Iteration 282/303, Loss: 0.00014479491801466793\n",
      "Epoch 25/100, Iteration 283/303, Loss: 0.0002492898202035576\n",
      "Epoch 25/100, Iteration 284/303, Loss: 9.726526332087815e-05\n",
      "Epoch 25/100, Iteration 285/303, Loss: 0.00015087125939317048\n",
      "Epoch 25/100, Iteration 286/303, Loss: 0.000325435190461576\n",
      "Epoch 25/100, Iteration 287/303, Loss: 3.0625000363215804e-05\n",
      "Epoch 25/100, Iteration 288/303, Loss: 0.0007258147816173732\n",
      "Epoch 25/100, Iteration 289/303, Loss: 0.00018333387561142445\n",
      "Epoch 25/100, Iteration 290/303, Loss: 9.339953248854727e-05\n",
      "Epoch 25/100, Iteration 291/303, Loss: 1.8361064576311037e-05\n",
      "Epoch 25/100, Iteration 292/303, Loss: 0.00011195406113984063\n",
      "Epoch 25/100, Iteration 293/303, Loss: 0.0005127684562467039\n",
      "Epoch 25/100, Iteration 294/303, Loss: 2.3985152438399382e-05\n",
      "Epoch 25/100, Iteration 295/303, Loss: 6.858447886770591e-05\n",
      "Epoch 25/100, Iteration 296/303, Loss: 0.0001558785734232515\n",
      "Epoch 25/100, Iteration 297/303, Loss: 0.00013507429684977978\n",
      "Epoch 25/100, Iteration 298/303, Loss: 0.0009151477133855224\n",
      "Epoch 25/100, Iteration 299/303, Loss: 0.0003130993281956762\n",
      "Epoch 25/100, Iteration 300/303, Loss: 6.895441038068384e-05\n",
      "Epoch 25/100, Iteration 301/303, Loss: 0.00014760359772481024\n",
      "Epoch 25/100, Iteration 302/303, Loss: 0.000205116331926547\n",
      "Epoch 25/100, Iteration 303/303, Loss: 7.583806291222572e-05\n",
      "Epoch 26/100, Iteration 1/303, Loss: 0.00015846133464947343\n",
      "Epoch 26/100, Iteration 2/303, Loss: 0.00015782266564201564\n",
      "Epoch 26/100, Iteration 3/303, Loss: 0.0001301871961914003\n",
      "Epoch 26/100, Iteration 4/303, Loss: 0.0010894492734223604\n",
      "Epoch 26/100, Iteration 5/303, Loss: 0.00010277426918037236\n",
      "Epoch 26/100, Iteration 6/303, Loss: 0.00031070061959326267\n",
      "Epoch 26/100, Iteration 7/303, Loss: 0.00022128618729766458\n",
      "Epoch 26/100, Iteration 8/303, Loss: 0.00015721064119134098\n",
      "Epoch 26/100, Iteration 9/303, Loss: 0.00011662709584925324\n",
      "Epoch 26/100, Iteration 10/303, Loss: 0.00030612165573984385\n",
      "Epoch 26/100, Iteration 11/303, Loss: 9.727274300530553e-05\n",
      "Epoch 26/100, Iteration 12/303, Loss: 0.00011987657489953563\n",
      "Epoch 26/100, Iteration 13/303, Loss: 0.0002235293941339478\n",
      "Epoch 26/100, Iteration 14/303, Loss: 3.797551107709296e-05\n",
      "Epoch 26/100, Iteration 15/303, Loss: 0.00024973650579340756\n",
      "Epoch 26/100, Iteration 16/303, Loss: 8.28707343316637e-05\n",
      "Epoch 26/100, Iteration 17/303, Loss: 0.00014992229989729822\n",
      "Epoch 26/100, Iteration 18/303, Loss: 2.893942109949421e-05\n",
      "Epoch 26/100, Iteration 19/303, Loss: 6.256312190089375e-05\n",
      "Epoch 26/100, Iteration 20/303, Loss: 0.000262258923612535\n",
      "Epoch 26/100, Iteration 21/303, Loss: 0.00035864836536347866\n",
      "Epoch 26/100, Iteration 22/303, Loss: 7.067983824526891e-05\n",
      "Epoch 26/100, Iteration 23/303, Loss: 0.00018251921574119478\n",
      "Epoch 26/100, Iteration 24/303, Loss: 0.0004498812777455896\n",
      "Epoch 26/100, Iteration 25/303, Loss: 0.00042148970533162355\n",
      "Epoch 26/100, Iteration 26/303, Loss: 0.00010208658932242543\n",
      "Epoch 26/100, Iteration 27/303, Loss: 3.114592982456088e-05\n",
      "Epoch 26/100, Iteration 28/303, Loss: 4.549874211079441e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Iteration 29/303, Loss: 0.00023609676281921566\n",
      "Epoch 26/100, Iteration 30/303, Loss: 0.00013975784531794488\n",
      "Epoch 26/100, Iteration 31/303, Loss: 5.3364452469395474e-05\n",
      "Epoch 26/100, Iteration 32/303, Loss: 0.00029238086426630616\n",
      "Epoch 26/100, Iteration 33/303, Loss: 0.00022414664272218943\n",
      "Epoch 26/100, Iteration 34/303, Loss: 2.5075449229916558e-05\n",
      "Epoch 26/100, Iteration 35/303, Loss: 0.0001608175807632506\n",
      "Epoch 26/100, Iteration 36/303, Loss: 0.00038412498543038964\n",
      "Epoch 26/100, Iteration 37/303, Loss: 7.428603566950187e-05\n",
      "Epoch 26/100, Iteration 38/303, Loss: 8.811964653432369e-05\n",
      "Epoch 26/100, Iteration 39/303, Loss: 6.665984983555973e-05\n",
      "Epoch 26/100, Iteration 40/303, Loss: 0.00023294238781090826\n",
      "Epoch 26/100, Iteration 41/303, Loss: 0.00019202966359443963\n",
      "Epoch 26/100, Iteration 42/303, Loss: 0.0002844123519025743\n",
      "Epoch 26/100, Iteration 43/303, Loss: 9.690695878816769e-05\n",
      "Epoch 26/100, Iteration 44/303, Loss: 5.4508360335603356e-05\n",
      "Epoch 26/100, Iteration 45/303, Loss: 2.8260950784897432e-05\n",
      "Epoch 26/100, Iteration 46/303, Loss: 0.00014103764260653406\n",
      "Epoch 26/100, Iteration 47/303, Loss: 9.924521145876497e-05\n",
      "Epoch 26/100, Iteration 48/303, Loss: 6.093749834690243e-05\n",
      "Epoch 26/100, Iteration 49/303, Loss: 0.00036506704054772854\n",
      "Epoch 26/100, Iteration 50/303, Loss: 5.6633318308740854e-05\n",
      "Epoch 26/100, Iteration 51/303, Loss: 0.00017937233496923\n",
      "Epoch 26/100, Iteration 52/303, Loss: 6.93171241437085e-05\n",
      "Epoch 26/100, Iteration 53/303, Loss: 0.0001864343066699803\n",
      "Epoch 26/100, Iteration 54/303, Loss: 0.0001295703841606155\n",
      "Epoch 26/100, Iteration 55/303, Loss: 6.634812598349527e-05\n",
      "Epoch 26/100, Iteration 56/303, Loss: 6.404856685549021e-05\n",
      "Epoch 26/100, Iteration 57/303, Loss: 0.00012010132195428014\n",
      "Epoch 26/100, Iteration 58/303, Loss: 9.466025949222967e-05\n",
      "Epoch 26/100, Iteration 59/303, Loss: 0.00018241781799588352\n",
      "Epoch 26/100, Iteration 60/303, Loss: 0.000360482488758862\n",
      "Epoch 26/100, Iteration 61/303, Loss: 4.6221255615819246e-05\n",
      "Epoch 26/100, Iteration 62/303, Loss: 8.536077075405046e-05\n",
      "Epoch 26/100, Iteration 63/303, Loss: 0.0001903070806292817\n",
      "Epoch 26/100, Iteration 64/303, Loss: 0.0002989117056131363\n",
      "Epoch 26/100, Iteration 65/303, Loss: 0.00020489527378231287\n",
      "Epoch 26/100, Iteration 66/303, Loss: 4.382611223263666e-05\n",
      "Epoch 26/100, Iteration 67/303, Loss: 3.2855918107088655e-05\n",
      "Epoch 26/100, Iteration 68/303, Loss: 0.00027810566825792193\n",
      "Epoch 26/100, Iteration 69/303, Loss: 5.211981988395564e-05\n",
      "Epoch 26/100, Iteration 70/303, Loss: 0.0001336729183094576\n",
      "Epoch 26/100, Iteration 71/303, Loss: 0.0003276120114605874\n",
      "Epoch 26/100, Iteration 72/303, Loss: 0.00037402036832645535\n",
      "Epoch 26/100, Iteration 73/303, Loss: 0.0004642243729904294\n",
      "Epoch 26/100, Iteration 74/303, Loss: 0.0002522673748899251\n",
      "Epoch 26/100, Iteration 75/303, Loss: 0.00015840142441447824\n",
      "Epoch 26/100, Iteration 76/303, Loss: 0.00017903870320878923\n",
      "Epoch 26/100, Iteration 77/303, Loss: 0.00011111711501143873\n",
      "Epoch 26/100, Iteration 78/303, Loss: 0.00033008604077622294\n",
      "Epoch 26/100, Iteration 79/303, Loss: 0.00010795627167681232\n",
      "Epoch 26/100, Iteration 80/303, Loss: 0.00011291480768704787\n",
      "Epoch 26/100, Iteration 81/303, Loss: 0.00020399774075485766\n",
      "Epoch 26/100, Iteration 82/303, Loss: 0.00013485884119290859\n",
      "Epoch 26/100, Iteration 83/303, Loss: 7.952918531373143e-05\n",
      "Epoch 26/100, Iteration 84/303, Loss: 8.106135646812618e-05\n",
      "Epoch 26/100, Iteration 85/303, Loss: 0.0005494184442795813\n",
      "Epoch 26/100, Iteration 86/303, Loss: 0.00015762522525619715\n",
      "Epoch 26/100, Iteration 87/303, Loss: 0.00010580127855064347\n",
      "Epoch 26/100, Iteration 88/303, Loss: 0.00018846301827579737\n",
      "Epoch 26/100, Iteration 89/303, Loss: 7.961294613778591e-05\n",
      "Epoch 26/100, Iteration 90/303, Loss: 0.00018973465193994343\n",
      "Epoch 26/100, Iteration 91/303, Loss: 9.551298717269674e-06\n",
      "Epoch 26/100, Iteration 92/303, Loss: 5.9177524235565215e-05\n",
      "Epoch 26/100, Iteration 93/303, Loss: 3.970560646848753e-05\n",
      "Epoch 26/100, Iteration 94/303, Loss: 0.00026044505648314953\n",
      "Epoch 26/100, Iteration 95/303, Loss: 0.00011107552563771605\n",
      "Epoch 26/100, Iteration 96/303, Loss: 0.00026160385459661484\n",
      "Epoch 26/100, Iteration 97/303, Loss: 0.00014207378262653947\n",
      "Epoch 26/100, Iteration 98/303, Loss: 0.00012998643796890974\n",
      "Epoch 26/100, Iteration 99/303, Loss: 0.00016580884403083473\n",
      "Epoch 26/100, Iteration 100/303, Loss: 9.502122338744812e-06\n",
      "Epoch 26/100, Iteration 101/303, Loss: 3.480839586700313e-05\n",
      "Epoch 26/100, Iteration 102/303, Loss: 0.0001412659912602976\n",
      "Epoch 26/100, Iteration 103/303, Loss: 1.4118388207862154e-05\n",
      "Epoch 26/100, Iteration 104/303, Loss: 0.0001021775315166451\n",
      "Epoch 26/100, Iteration 105/303, Loss: 9.165168012259528e-05\n",
      "Epoch 26/100, Iteration 106/303, Loss: 0.00020781945204362273\n",
      "Epoch 26/100, Iteration 107/303, Loss: 4.545281990431249e-05\n",
      "Epoch 26/100, Iteration 108/303, Loss: 0.00010363195178797469\n",
      "Epoch 26/100, Iteration 109/303, Loss: 0.0002703641075640917\n",
      "Epoch 26/100, Iteration 110/303, Loss: 0.0002519238623790443\n",
      "Epoch 26/100, Iteration 111/303, Loss: 7.504063250962645e-05\n",
      "Epoch 26/100, Iteration 112/303, Loss: 0.00011802317021647468\n",
      "Epoch 26/100, Iteration 113/303, Loss: 0.00023053184850141406\n",
      "Epoch 26/100, Iteration 114/303, Loss: 4.027015529572964e-05\n",
      "Epoch 26/100, Iteration 115/303, Loss: 0.0002656056603882462\n",
      "Epoch 26/100, Iteration 116/303, Loss: 4.3764575821114704e-05\n",
      "Epoch 26/100, Iteration 117/303, Loss: 0.00022922818607185036\n",
      "Epoch 26/100, Iteration 118/303, Loss: 0.00017229198419954628\n",
      "Epoch 26/100, Iteration 119/303, Loss: 0.00011046012514270842\n",
      "Epoch 26/100, Iteration 120/303, Loss: 5.206382047617808e-05\n",
      "Epoch 26/100, Iteration 121/303, Loss: 0.00011560697021195665\n",
      "Epoch 26/100, Iteration 122/303, Loss: 7.465644739568233e-05\n",
      "Epoch 26/100, Iteration 123/303, Loss: 0.00017785491945687681\n",
      "Epoch 26/100, Iteration 124/303, Loss: 0.00018591413390822709\n",
      "Epoch 26/100, Iteration 125/303, Loss: 8.696355507709086e-05\n",
      "Epoch 26/100, Iteration 126/303, Loss: 0.00016375612176489085\n",
      "Epoch 26/100, Iteration 127/303, Loss: 0.00012215523747727275\n",
      "Epoch 26/100, Iteration 128/303, Loss: 0.00018549521337263286\n",
      "Epoch 26/100, Iteration 129/303, Loss: 4.913541124551557e-05\n",
      "Epoch 26/100, Iteration 130/303, Loss: 0.00019955154857598245\n",
      "Epoch 26/100, Iteration 131/303, Loss: 0.00035089717130176723\n",
      "Epoch 26/100, Iteration 132/303, Loss: 0.00033520522993057966\n",
      "Epoch 26/100, Iteration 133/303, Loss: 0.00015854372759349644\n",
      "Epoch 26/100, Iteration 134/303, Loss: 0.00019633526972029358\n",
      "Epoch 26/100, Iteration 135/303, Loss: 0.00037219273508526385\n",
      "Epoch 26/100, Iteration 136/303, Loss: 0.00014501952682621777\n",
      "Epoch 26/100, Iteration 137/303, Loss: 0.00025372131494805217\n",
      "Epoch 26/100, Iteration 138/303, Loss: 0.0003524246858432889\n",
      "Epoch 26/100, Iteration 139/303, Loss: 8.574072853662074e-05\n",
      "Epoch 26/100, Iteration 140/303, Loss: 9.598357428330928e-05\n",
      "Epoch 26/100, Iteration 141/303, Loss: 0.00026646125479601324\n",
      "Epoch 26/100, Iteration 142/303, Loss: 0.00026277900906279683\n",
      "Epoch 26/100, Iteration 143/303, Loss: 0.00021182508498895913\n",
      "Epoch 26/100, Iteration 144/303, Loss: 1.0395891877124086e-05\n",
      "Epoch 26/100, Iteration 145/303, Loss: 0.000178507441887632\n",
      "Epoch 26/100, Iteration 146/303, Loss: 9.162654168903828e-05\n",
      "Epoch 26/100, Iteration 147/303, Loss: 1.988425174204167e-05\n",
      "Epoch 26/100, Iteration 148/303, Loss: 0.00020351515559013933\n",
      "Epoch 26/100, Iteration 149/303, Loss: 0.0003707821306306869\n",
      "Epoch 26/100, Iteration 150/303, Loss: 4.714826354756951e-05\n",
      "Epoch 26/100, Iteration 151/303, Loss: 0.0005689046229235828\n",
      "Epoch 26/100, Iteration 152/303, Loss: 0.00016364709881599993\n",
      "Epoch 26/100, Iteration 153/303, Loss: 0.00012871818034909666\n",
      "Epoch 26/100, Iteration 154/303, Loss: 9.940596646629274e-05\n",
      "Epoch 26/100, Iteration 155/303, Loss: 0.00016552387387491763\n",
      "Epoch 26/100, Iteration 156/303, Loss: 4.776558489538729e-05\n",
      "Epoch 26/100, Iteration 157/303, Loss: 0.00014498474774882197\n",
      "Epoch 26/100, Iteration 158/303, Loss: 0.00018967817595694214\n",
      "Epoch 26/100, Iteration 159/303, Loss: 0.0001243095175595954\n",
      "Epoch 26/100, Iteration 160/303, Loss: 7.109123544069007e-05\n",
      "Epoch 26/100, Iteration 161/303, Loss: 8.544028969481587e-05\n",
      "Epoch 26/100, Iteration 162/303, Loss: 2.8563001251313835e-05\n",
      "Epoch 26/100, Iteration 163/303, Loss: 9.365297592012212e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Iteration 164/303, Loss: 0.0001463948137825355\n",
      "Epoch 26/100, Iteration 165/303, Loss: 0.0001768066140357405\n",
      "Epoch 26/100, Iteration 166/303, Loss: 0.00035619118716567755\n",
      "Epoch 26/100, Iteration 167/303, Loss: 0.00010286777978762984\n",
      "Epoch 26/100, Iteration 168/303, Loss: 6.880160071887076e-05\n",
      "Epoch 26/100, Iteration 169/303, Loss: 0.00020596284593921155\n",
      "Epoch 26/100, Iteration 170/303, Loss: 9.898823918774724e-05\n",
      "Epoch 26/100, Iteration 171/303, Loss: 0.00027018121909350157\n",
      "Epoch 26/100, Iteration 172/303, Loss: 0.00012441790022421628\n",
      "Epoch 26/100, Iteration 173/303, Loss: 0.0003534631396178156\n",
      "Epoch 26/100, Iteration 174/303, Loss: 4.7941768571035936e-05\n",
      "Epoch 26/100, Iteration 175/303, Loss: 0.0002593453391455114\n",
      "Epoch 26/100, Iteration 176/303, Loss: 0.00011133120278827846\n",
      "Epoch 26/100, Iteration 177/303, Loss: 0.00011342969082761556\n",
      "Epoch 26/100, Iteration 178/303, Loss: 0.00017523755377624184\n",
      "Epoch 26/100, Iteration 179/303, Loss: 0.0004586668510455638\n",
      "Epoch 26/100, Iteration 180/303, Loss: 1.7087220840039663e-05\n",
      "Epoch 26/100, Iteration 181/303, Loss: 0.00020464760018512607\n",
      "Epoch 26/100, Iteration 182/303, Loss: 0.000722093100193888\n",
      "Epoch 26/100, Iteration 183/303, Loss: 8.46745097078383e-05\n",
      "Epoch 26/100, Iteration 184/303, Loss: 0.00012707409041468054\n",
      "Epoch 26/100, Iteration 185/303, Loss: 8.325671660713851e-05\n",
      "Epoch 26/100, Iteration 186/303, Loss: 2.3329173927777447e-05\n",
      "Epoch 26/100, Iteration 187/303, Loss: 0.0008516443776898086\n",
      "Epoch 26/100, Iteration 188/303, Loss: 0.0003601980279199779\n",
      "Epoch 26/100, Iteration 189/303, Loss: 0.000144023826578632\n",
      "Epoch 26/100, Iteration 190/303, Loss: 9.965478238882497e-05\n",
      "Epoch 26/100, Iteration 191/303, Loss: 4.665307278628461e-05\n",
      "Epoch 26/100, Iteration 192/303, Loss: 0.0001665156305534765\n",
      "Epoch 26/100, Iteration 193/303, Loss: 0.00040172977605834603\n",
      "Epoch 26/100, Iteration 194/303, Loss: 0.00012220308417454362\n",
      "Epoch 26/100, Iteration 195/303, Loss: 0.00014261070464272052\n",
      "Epoch 26/100, Iteration 196/303, Loss: 7.2417019509884994e-06\n",
      "Epoch 26/100, Iteration 197/303, Loss: 1.3876138837076724e-05\n",
      "Epoch 26/100, Iteration 198/303, Loss: 0.00030819105450063944\n",
      "Epoch 26/100, Iteration 199/303, Loss: 0.00043027984793297946\n",
      "Epoch 26/100, Iteration 200/303, Loss: 0.0003765809233300388\n",
      "Epoch 26/100, Iteration 201/303, Loss: 0.00014935310173314065\n",
      "Epoch 26/100, Iteration 202/303, Loss: 0.0002478296519257128\n",
      "Epoch 26/100, Iteration 203/303, Loss: 0.00023741918266750872\n",
      "Epoch 26/100, Iteration 204/303, Loss: 0.0001185202636406757\n",
      "Epoch 26/100, Iteration 205/303, Loss: 4.8058242100523785e-05\n",
      "Epoch 26/100, Iteration 206/303, Loss: 0.00012498089927248657\n",
      "Epoch 26/100, Iteration 207/303, Loss: 0.00017792561266105622\n",
      "Epoch 26/100, Iteration 208/303, Loss: 0.0001014588851830922\n",
      "Epoch 26/100, Iteration 209/303, Loss: 0.0004346904461272061\n",
      "Epoch 26/100, Iteration 210/303, Loss: 0.0004727476625703275\n",
      "Epoch 26/100, Iteration 211/303, Loss: 9.356628288514912e-05\n",
      "Epoch 26/100, Iteration 212/303, Loss: 1.707175215415191e-05\n",
      "Epoch 26/100, Iteration 213/303, Loss: 8.65768306539394e-05\n",
      "Epoch 26/100, Iteration 214/303, Loss: 8.93797114258632e-05\n",
      "Epoch 26/100, Iteration 215/303, Loss: 7.873824506532401e-05\n",
      "Epoch 26/100, Iteration 216/303, Loss: 0.00019896056619472802\n",
      "Epoch 26/100, Iteration 217/303, Loss: 0.00018942373571917415\n",
      "Epoch 26/100, Iteration 218/303, Loss: 0.00022827516659162939\n",
      "Epoch 26/100, Iteration 219/303, Loss: 0.00011347665713401511\n",
      "Epoch 26/100, Iteration 220/303, Loss: 0.00041123799746856093\n",
      "Epoch 26/100, Iteration 221/303, Loss: 0.0001412032579537481\n",
      "Epoch 26/100, Iteration 222/303, Loss: 9.930736268870533e-05\n",
      "Epoch 26/100, Iteration 223/303, Loss: 7.909408304840326e-05\n",
      "Epoch 26/100, Iteration 224/303, Loss: 0.00015578974853269756\n",
      "Epoch 26/100, Iteration 225/303, Loss: 0.00031565382960252464\n",
      "Epoch 26/100, Iteration 226/303, Loss: 3.9191381802083924e-05\n",
      "Epoch 26/100, Iteration 227/303, Loss: 1.416921350028133e-05\n",
      "Epoch 26/100, Iteration 228/303, Loss: 0.00010523713717702776\n",
      "Epoch 26/100, Iteration 229/303, Loss: 0.00012485710612963885\n",
      "Epoch 26/100, Iteration 230/303, Loss: 6.6490909375716e-05\n",
      "Epoch 26/100, Iteration 231/303, Loss: 0.0012556606670841575\n",
      "Epoch 26/100, Iteration 232/303, Loss: 0.0001387506490573287\n",
      "Epoch 26/100, Iteration 233/303, Loss: 6.588191899936646e-05\n",
      "Epoch 26/100, Iteration 234/303, Loss: 0.00021349974849727005\n",
      "Epoch 26/100, Iteration 235/303, Loss: 0.0001856193703133613\n",
      "Epoch 26/100, Iteration 236/303, Loss: 2.4356882931897417e-05\n",
      "Epoch 26/100, Iteration 237/303, Loss: 3.350756014697254e-05\n",
      "Epoch 26/100, Iteration 238/303, Loss: 8.526036981493235e-05\n",
      "Epoch 26/100, Iteration 239/303, Loss: 0.00010741422011051327\n",
      "Epoch 26/100, Iteration 240/303, Loss: 0.0002207767392974347\n",
      "Epoch 26/100, Iteration 241/303, Loss: 0.00022997852647677064\n",
      "Epoch 26/100, Iteration 242/303, Loss: 0.00022332304797600955\n",
      "Epoch 26/100, Iteration 243/303, Loss: 5.4374566389014944e-05\n",
      "Epoch 26/100, Iteration 244/303, Loss: 4.572757097776048e-05\n",
      "Epoch 26/100, Iteration 245/303, Loss: 0.0001894278102554381\n",
      "Epoch 26/100, Iteration 246/303, Loss: 0.00013388016668614\n",
      "Epoch 26/100, Iteration 247/303, Loss: 0.0002201547904405743\n",
      "Epoch 26/100, Iteration 248/303, Loss: 7.902788638602942e-05\n",
      "Epoch 26/100, Iteration 249/303, Loss: 0.0002382642705924809\n",
      "Epoch 26/100, Iteration 250/303, Loss: 0.0001431761629646644\n",
      "Epoch 26/100, Iteration 251/303, Loss: 8.182183955796063e-05\n",
      "Epoch 26/100, Iteration 252/303, Loss: 0.000151454791193828\n",
      "Epoch 26/100, Iteration 253/303, Loss: 0.0001767888606991619\n",
      "Epoch 26/100, Iteration 254/303, Loss: 1.2315034837229177e-05\n",
      "Epoch 26/100, Iteration 255/303, Loss: 0.0001465718523832038\n",
      "Epoch 26/100, Iteration 256/303, Loss: 0.0005264729261398315\n",
      "Epoch 26/100, Iteration 257/303, Loss: 0.00020666979253292084\n",
      "Epoch 26/100, Iteration 258/303, Loss: 9.120905451709405e-05\n",
      "Epoch 26/100, Iteration 259/303, Loss: 7.65883014537394e-05\n",
      "Epoch 26/100, Iteration 260/303, Loss: 0.00018247784464620054\n",
      "Epoch 26/100, Iteration 261/303, Loss: 8.391778828809038e-05\n",
      "Epoch 26/100, Iteration 262/303, Loss: 4.43231692770496e-05\n",
      "Epoch 26/100, Iteration 263/303, Loss: 0.00014791425201110542\n",
      "Epoch 26/100, Iteration 264/303, Loss: 0.00010999815276591107\n",
      "Epoch 26/100, Iteration 265/303, Loss: 4.23702658736147e-05\n",
      "Epoch 26/100, Iteration 266/303, Loss: 0.00046746054431423545\n",
      "Epoch 26/100, Iteration 267/303, Loss: 3.919748269254342e-05\n",
      "Epoch 26/100, Iteration 268/303, Loss: 0.00022322687436826527\n",
      "Epoch 26/100, Iteration 269/303, Loss: 9.167494863504544e-05\n",
      "Epoch 26/100, Iteration 270/303, Loss: 0.00017728153034113348\n",
      "Epoch 26/100, Iteration 271/303, Loss: 0.00032239992287941277\n",
      "Epoch 26/100, Iteration 272/303, Loss: 0.00015914936375338584\n",
      "Epoch 26/100, Iteration 273/303, Loss: 7.946767436806113e-05\n",
      "Epoch 26/100, Iteration 274/303, Loss: 5.4087384341983125e-05\n",
      "Epoch 26/100, Iteration 275/303, Loss: 6.451260560424998e-05\n",
      "Epoch 26/100, Iteration 276/303, Loss: 0.0004422676865942776\n",
      "Epoch 26/100, Iteration 277/303, Loss: 4.147270738030784e-05\n",
      "Epoch 26/100, Iteration 278/303, Loss: 0.00011833690950879827\n",
      "Epoch 26/100, Iteration 279/303, Loss: 3.567922249203548e-05\n",
      "Epoch 26/100, Iteration 280/303, Loss: 6.318338273558766e-05\n",
      "Epoch 26/100, Iteration 281/303, Loss: 1.2389735275064595e-05\n",
      "Epoch 26/100, Iteration 282/303, Loss: 2.5124536477960646e-05\n",
      "Epoch 26/100, Iteration 283/303, Loss: 9.612685244064778e-05\n",
      "Epoch 26/100, Iteration 284/303, Loss: 0.0002737028116825968\n",
      "Epoch 26/100, Iteration 285/303, Loss: 7.488510163966566e-05\n",
      "Epoch 26/100, Iteration 286/303, Loss: 0.00014920745161361992\n",
      "Epoch 26/100, Iteration 287/303, Loss: 4.700533099821769e-05\n",
      "Epoch 26/100, Iteration 288/303, Loss: 0.0005701814079657197\n",
      "Epoch 26/100, Iteration 289/303, Loss: 9.0746209025383e-05\n",
      "Epoch 26/100, Iteration 290/303, Loss: 9.802732529351488e-05\n",
      "Epoch 26/100, Iteration 291/303, Loss: 4.468510451260954e-05\n",
      "Epoch 26/100, Iteration 292/303, Loss: 8.21959984023124e-05\n",
      "Epoch 26/100, Iteration 293/303, Loss: 1.3778633729089051e-05\n",
      "Epoch 26/100, Iteration 294/303, Loss: 0.0001353081315755844\n",
      "Epoch 26/100, Iteration 295/303, Loss: 4.901585270999931e-05\n",
      "Epoch 26/100, Iteration 296/303, Loss: 0.0004502940864767879\n",
      "Epoch 26/100, Iteration 297/303, Loss: 8.895653445506468e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Iteration 298/303, Loss: 6.975515861995518e-05\n",
      "Epoch 26/100, Iteration 299/303, Loss: 0.0001418367464793846\n",
      "Epoch 26/100, Iteration 300/303, Loss: 0.0004024003283120692\n",
      "Epoch 26/100, Iteration 301/303, Loss: 5.3815427236258984e-05\n",
      "Epoch 26/100, Iteration 302/303, Loss: 3.7626326957251877e-05\n",
      "Epoch 26/100, Iteration 303/303, Loss: 0.0003387595061212778\n",
      "Epoch 27/100, Iteration 1/303, Loss: 9.444505849387497e-05\n",
      "Epoch 27/100, Iteration 2/303, Loss: 5.2088958909735084e-05\n",
      "Epoch 27/100, Iteration 3/303, Loss: 0.00012864964082837105\n",
      "Epoch 27/100, Iteration 4/303, Loss: 0.0001227317115990445\n",
      "Epoch 27/100, Iteration 5/303, Loss: 0.00011750777048291638\n",
      "Epoch 27/100, Iteration 6/303, Loss: 0.0001256719697266817\n",
      "Epoch 27/100, Iteration 7/303, Loss: 0.0008338273619301617\n",
      "Epoch 27/100, Iteration 8/303, Loss: 1.928368328663055e-05\n",
      "Epoch 27/100, Iteration 9/303, Loss: 0.00011061233817599714\n",
      "Epoch 27/100, Iteration 10/303, Loss: 0.00023637470440007746\n",
      "Epoch 27/100, Iteration 11/303, Loss: 0.00046878066495992243\n",
      "Epoch 27/100, Iteration 12/303, Loss: 0.00015612156130373478\n",
      "Epoch 27/100, Iteration 13/303, Loss: 8.701356273377314e-05\n",
      "Epoch 27/100, Iteration 14/303, Loss: 0.00010635438229655847\n",
      "Epoch 27/100, Iteration 15/303, Loss: 0.00019679962133523077\n",
      "Epoch 27/100, Iteration 16/303, Loss: 0.0001308308565057814\n",
      "Epoch 27/100, Iteration 17/303, Loss: 0.00010524113895371556\n",
      "Epoch 27/100, Iteration 18/303, Loss: 2.9512757464544848e-05\n",
      "Epoch 27/100, Iteration 19/303, Loss: 0.0002043438726104796\n",
      "Epoch 27/100, Iteration 20/303, Loss: 0.00012793320638593286\n",
      "Epoch 27/100, Iteration 21/303, Loss: 4.7719258873257786e-05\n",
      "Epoch 27/100, Iteration 22/303, Loss: 0.0002480683906469494\n",
      "Epoch 27/100, Iteration 23/303, Loss: 5.657164365402423e-05\n",
      "Epoch 27/100, Iteration 24/303, Loss: 3.3744770917110145e-05\n",
      "Epoch 27/100, Iteration 25/303, Loss: 6.221040166565217e-06\n",
      "Epoch 27/100, Iteration 26/303, Loss: 6.275764462770894e-05\n",
      "Epoch 27/100, Iteration 27/303, Loss: 7.965489930938929e-05\n",
      "Epoch 27/100, Iteration 28/303, Loss: 0.0001720476138871163\n",
      "Epoch 27/100, Iteration 29/303, Loss: 0.00010327362542739138\n",
      "Epoch 27/100, Iteration 30/303, Loss: 0.00031419741571880877\n",
      "Epoch 27/100, Iteration 31/303, Loss: 4.858684042119421e-05\n",
      "Epoch 27/100, Iteration 32/303, Loss: 0.00010184595157625154\n",
      "Epoch 27/100, Iteration 33/303, Loss: 4.8651181714376435e-06\n",
      "Epoch 27/100, Iteration 34/303, Loss: 0.00021782210387755185\n",
      "Epoch 27/100, Iteration 35/303, Loss: 0.00015124533092603087\n",
      "Epoch 27/100, Iteration 36/303, Loss: 0.000201351911528036\n",
      "Epoch 27/100, Iteration 37/303, Loss: 5.668051744578406e-05\n",
      "Epoch 27/100, Iteration 38/303, Loss: 5.0724323955364525e-05\n",
      "Epoch 27/100, Iteration 39/303, Loss: 4.176968286628835e-05\n",
      "Epoch 27/100, Iteration 40/303, Loss: 0.00015951305977068841\n",
      "Epoch 27/100, Iteration 41/303, Loss: 0.00036228494718670845\n",
      "Epoch 27/100, Iteration 42/303, Loss: 0.0002833743637893349\n",
      "Epoch 27/100, Iteration 43/303, Loss: 0.00011592750524869189\n",
      "Epoch 27/100, Iteration 44/303, Loss: 0.00011690195242408663\n",
      "Epoch 27/100, Iteration 45/303, Loss: 0.0001373232080368325\n",
      "Epoch 27/100, Iteration 46/303, Loss: 1.4959786312829237e-05\n",
      "Epoch 27/100, Iteration 47/303, Loss: 4.240471025696024e-05\n",
      "Epoch 27/100, Iteration 48/303, Loss: 0.00010341557208448648\n",
      "Epoch 27/100, Iteration 49/303, Loss: 0.0001287402119487524\n",
      "Epoch 27/100, Iteration 50/303, Loss: 1.8250966604682617e-05\n",
      "Epoch 27/100, Iteration 51/303, Loss: 4.237321263644844e-05\n",
      "Epoch 27/100, Iteration 52/303, Loss: 0.0001971428864635527\n",
      "Epoch 27/100, Iteration 53/303, Loss: 4.2402225517435e-05\n",
      "Epoch 27/100, Iteration 54/303, Loss: 1.4445950000663288e-05\n",
      "Epoch 27/100, Iteration 55/303, Loss: 3.6033856304129586e-05\n",
      "Epoch 27/100, Iteration 56/303, Loss: 0.0002528486947994679\n",
      "Epoch 27/100, Iteration 57/303, Loss: 0.00013821777247358114\n",
      "Epoch 27/100, Iteration 58/303, Loss: 0.0005152535741217434\n",
      "Epoch 27/100, Iteration 59/303, Loss: 4.726537736132741e-05\n",
      "Epoch 27/100, Iteration 60/303, Loss: 0.00010371144162490964\n",
      "Epoch 27/100, Iteration 61/303, Loss: 1.5238704691000748e-05\n",
      "Epoch 27/100, Iteration 62/303, Loss: 3.828927219728939e-05\n",
      "Epoch 27/100, Iteration 63/303, Loss: 0.0004053046286571771\n",
      "Epoch 27/100, Iteration 64/303, Loss: 1.6594993212493137e-05\n",
      "Epoch 27/100, Iteration 65/303, Loss: 7.92847276898101e-05\n",
      "Epoch 27/100, Iteration 66/303, Loss: 0.00012092061660951003\n",
      "Epoch 27/100, Iteration 67/303, Loss: 0.0002749393170233816\n",
      "Epoch 27/100, Iteration 68/303, Loss: 0.00016004446661099792\n",
      "Epoch 27/100, Iteration 69/303, Loss: 6.995857802394312e-06\n",
      "Epoch 27/100, Iteration 70/303, Loss: 5.1418748626019806e-05\n",
      "Epoch 27/100, Iteration 71/303, Loss: 0.00012539814633782953\n",
      "Epoch 27/100, Iteration 72/303, Loss: 0.00017386829131282866\n",
      "Epoch 27/100, Iteration 73/303, Loss: 0.0003023341705556959\n",
      "Epoch 27/100, Iteration 74/303, Loss: 0.00011382819502614439\n",
      "Epoch 27/100, Iteration 75/303, Loss: 0.0004820631875190884\n",
      "Epoch 27/100, Iteration 76/303, Loss: 0.00012316223001107574\n",
      "Epoch 27/100, Iteration 77/303, Loss: 0.0001363103074254468\n",
      "Epoch 27/100, Iteration 78/303, Loss: 0.00031022619805298746\n",
      "Epoch 27/100, Iteration 79/303, Loss: 3.508112422423437e-05\n",
      "Epoch 27/100, Iteration 80/303, Loss: 9.404995216755196e-05\n",
      "Epoch 27/100, Iteration 81/303, Loss: 0.00039461400592699647\n",
      "Epoch 27/100, Iteration 82/303, Loss: 0.0002938634715974331\n",
      "Epoch 27/100, Iteration 83/303, Loss: 0.00012811794294975698\n",
      "Epoch 27/100, Iteration 84/303, Loss: 0.00016452222189400345\n",
      "Epoch 27/100, Iteration 85/303, Loss: 3.324648423586041e-05\n",
      "Epoch 27/100, Iteration 86/303, Loss: 0.00026325471117161214\n",
      "Epoch 27/100, Iteration 87/303, Loss: 0.00012257343041710556\n",
      "Epoch 27/100, Iteration 88/303, Loss: 0.00010193442722084001\n",
      "Epoch 27/100, Iteration 89/303, Loss: 4.140326927881688e-05\n",
      "Epoch 27/100, Iteration 90/303, Loss: 1.3341879821382463e-05\n",
      "Epoch 27/100, Iteration 91/303, Loss: 7.940496288938448e-05\n",
      "Epoch 27/100, Iteration 92/303, Loss: 0.00022100849309936166\n",
      "Epoch 27/100, Iteration 93/303, Loss: 6.678068166365847e-05\n",
      "Epoch 27/100, Iteration 94/303, Loss: 5.162400339031592e-05\n",
      "Epoch 27/100, Iteration 95/303, Loss: 7.839066529413685e-05\n",
      "Epoch 27/100, Iteration 96/303, Loss: 6.999145989539102e-05\n",
      "Epoch 27/100, Iteration 97/303, Loss: 1.6270838386844844e-05\n",
      "Epoch 27/100, Iteration 98/303, Loss: 0.0004409163084346801\n",
      "Epoch 27/100, Iteration 99/303, Loss: 0.0002516693202778697\n",
      "Epoch 27/100, Iteration 100/303, Loss: 0.00013836647849529982\n",
      "Epoch 27/100, Iteration 101/303, Loss: 0.00016673844947945327\n",
      "Epoch 27/100, Iteration 102/303, Loss: 0.0001266434701392427\n",
      "Epoch 27/100, Iteration 103/303, Loss: 0.0002012749610003084\n",
      "Epoch 27/100, Iteration 104/303, Loss: 0.00022671605984214693\n",
      "Epoch 27/100, Iteration 105/303, Loss: 0.0001517651544418186\n",
      "Epoch 27/100, Iteration 106/303, Loss: 0.0010694380616769195\n",
      "Epoch 27/100, Iteration 107/303, Loss: 0.00025993966846726835\n",
      "Epoch 27/100, Iteration 108/303, Loss: 9.95351183519233e-06\n",
      "Epoch 27/100, Iteration 109/303, Loss: 9.392446372658014e-05\n",
      "Epoch 27/100, Iteration 110/303, Loss: 6.799167022109032e-05\n",
      "Epoch 27/100, Iteration 111/303, Loss: 0.00012202944344608113\n",
      "Epoch 27/100, Iteration 112/303, Loss: 0.00023425367544405162\n",
      "Epoch 27/100, Iteration 113/303, Loss: 0.00014683950575999916\n",
      "Epoch 27/100, Iteration 114/303, Loss: 9.146377124125138e-05\n",
      "Epoch 27/100, Iteration 115/303, Loss: 7.26033904356882e-05\n",
      "Epoch 27/100, Iteration 116/303, Loss: 0.00012009472993668169\n",
      "Epoch 27/100, Iteration 117/303, Loss: 0.00018023203301709145\n",
      "Epoch 27/100, Iteration 118/303, Loss: 3.19827813655138e-05\n",
      "Epoch 27/100, Iteration 119/303, Loss: 0.00012130810500821099\n",
      "Epoch 27/100, Iteration 120/303, Loss: 0.00011746829841285944\n",
      "Epoch 27/100, Iteration 121/303, Loss: 4.196947338641621e-05\n",
      "Epoch 27/100, Iteration 122/303, Loss: 0.0002553751692175865\n",
      "Epoch 27/100, Iteration 123/303, Loss: 0.0003094442072324455\n",
      "Epoch 27/100, Iteration 124/303, Loss: 0.00011036901560146362\n",
      "Epoch 27/100, Iteration 125/303, Loss: 0.00014786659448873252\n",
      "Epoch 27/100, Iteration 126/303, Loss: 0.00015894134412519634\n",
      "Epoch 27/100, Iteration 127/303, Loss: 0.00010439634206704795\n",
      "Epoch 27/100, Iteration 128/303, Loss: 0.00015697389608249068\n",
      "Epoch 27/100, Iteration 129/303, Loss: 2.6822754080058075e-05\n",
      "Epoch 27/100, Iteration 130/303, Loss: 5.9727331972680986e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Iteration 131/303, Loss: 5.9275545936543494e-05\n",
      "Epoch 27/100, Iteration 132/303, Loss: 0.00012115618301322684\n",
      "Epoch 27/100, Iteration 133/303, Loss: 0.00011807362898252904\n",
      "Epoch 27/100, Iteration 134/303, Loss: 6.83236721670255e-05\n",
      "Epoch 27/100, Iteration 135/303, Loss: 0.00016785672050900757\n",
      "Epoch 27/100, Iteration 136/303, Loss: 0.00022359190916176885\n",
      "Epoch 27/100, Iteration 137/303, Loss: 0.0002472665219102055\n",
      "Epoch 27/100, Iteration 138/303, Loss: 8.420429367106408e-05\n",
      "Epoch 27/100, Iteration 139/303, Loss: 0.0002508950128685683\n",
      "Epoch 27/100, Iteration 140/303, Loss: 8.434642950305715e-05\n",
      "Epoch 27/100, Iteration 141/303, Loss: 3.110950274276547e-05\n",
      "Epoch 27/100, Iteration 142/303, Loss: 0.0003007086634170264\n",
      "Epoch 27/100, Iteration 143/303, Loss: 0.00010589534940663725\n",
      "Epoch 27/100, Iteration 144/303, Loss: 0.0001088580975192599\n",
      "Epoch 27/100, Iteration 145/303, Loss: 9.731234604259953e-05\n",
      "Epoch 27/100, Iteration 146/303, Loss: 0.00019125058315694332\n",
      "Epoch 27/100, Iteration 147/303, Loss: 0.00010660791303962469\n",
      "Epoch 27/100, Iteration 148/303, Loss: 9.160442277789116e-05\n",
      "Epoch 27/100, Iteration 149/303, Loss: 2.691220106498804e-05\n",
      "Epoch 27/100, Iteration 150/303, Loss: 4.4306689233053476e-05\n",
      "Epoch 27/100, Iteration 151/303, Loss: 0.00021963805193081498\n",
      "Epoch 27/100, Iteration 152/303, Loss: 0.00043465441558510065\n",
      "Epoch 27/100, Iteration 153/303, Loss: 8.3025915955659e-05\n",
      "Epoch 27/100, Iteration 154/303, Loss: 2.087066968670115e-05\n",
      "Epoch 27/100, Iteration 155/303, Loss: 0.00010352394019719213\n",
      "Epoch 27/100, Iteration 156/303, Loss: 0.00018642486247699708\n",
      "Epoch 27/100, Iteration 157/303, Loss: 0.0002476380323059857\n",
      "Epoch 27/100, Iteration 158/303, Loss: 0.0004035625606775284\n",
      "Epoch 27/100, Iteration 159/303, Loss: 0.00012232585868332535\n",
      "Epoch 27/100, Iteration 160/303, Loss: 0.00010572879546089098\n",
      "Epoch 27/100, Iteration 161/303, Loss: 7.971544982865453e-05\n",
      "Epoch 27/100, Iteration 162/303, Loss: 9.133770072367042e-05\n",
      "Epoch 27/100, Iteration 163/303, Loss: 0.00016528539708815515\n",
      "Epoch 27/100, Iteration 164/303, Loss: 0.00023979076649993658\n",
      "Epoch 27/100, Iteration 165/303, Loss: 0.00027902142028324306\n",
      "Epoch 27/100, Iteration 166/303, Loss: 0.00029203170561231673\n",
      "Epoch 27/100, Iteration 167/303, Loss: 6.069539813324809e-05\n",
      "Epoch 27/100, Iteration 168/303, Loss: 0.00012679686187766492\n",
      "Epoch 27/100, Iteration 169/303, Loss: 0.0010548855643719435\n",
      "Epoch 27/100, Iteration 170/303, Loss: 0.00018878874834626913\n",
      "Epoch 27/100, Iteration 171/303, Loss: 8.511538908351213e-05\n",
      "Epoch 27/100, Iteration 172/303, Loss: 0.00010447228123666719\n",
      "Epoch 27/100, Iteration 173/303, Loss: 7.61743140174076e-05\n",
      "Epoch 27/100, Iteration 174/303, Loss: 0.0002903332351706922\n",
      "Epoch 27/100, Iteration 175/303, Loss: 7.610550528625026e-05\n",
      "Epoch 27/100, Iteration 176/303, Loss: 0.0002770242281258106\n",
      "Epoch 27/100, Iteration 177/303, Loss: 3.900591764249839e-05\n",
      "Epoch 27/100, Iteration 178/303, Loss: 0.000618656282313168\n",
      "Epoch 27/100, Iteration 179/303, Loss: 0.00037489095120690763\n",
      "Epoch 27/100, Iteration 180/303, Loss: 0.0003169756382703781\n",
      "Epoch 27/100, Iteration 181/303, Loss: 4.757862916449085e-05\n",
      "Epoch 27/100, Iteration 182/303, Loss: 6.097219738876447e-05\n",
      "Epoch 27/100, Iteration 183/303, Loss: 3.582082354114391e-05\n",
      "Epoch 27/100, Iteration 184/303, Loss: 0.00017703822231851518\n",
      "Epoch 27/100, Iteration 185/303, Loss: 0.00034095896990038455\n",
      "Epoch 27/100, Iteration 186/303, Loss: 0.00015082770551089197\n",
      "Epoch 27/100, Iteration 187/303, Loss: 0.00011133347288705409\n",
      "Epoch 27/100, Iteration 188/303, Loss: 8.870329475030303e-05\n",
      "Epoch 27/100, Iteration 189/303, Loss: 9.189563570544124e-05\n",
      "Epoch 27/100, Iteration 190/303, Loss: 0.00016165782290045172\n",
      "Epoch 27/100, Iteration 191/303, Loss: 0.0001215630181832239\n",
      "Epoch 27/100, Iteration 192/303, Loss: 4.549244840745814e-05\n",
      "Epoch 27/100, Iteration 193/303, Loss: 0.0001546689891256392\n",
      "Epoch 27/100, Iteration 194/303, Loss: 0.00016176325152628124\n",
      "Epoch 27/100, Iteration 195/303, Loss: 0.00025693184579722583\n",
      "Epoch 27/100, Iteration 196/303, Loss: 0.00025748327607288957\n",
      "Epoch 27/100, Iteration 197/303, Loss: 0.0001343210751656443\n",
      "Epoch 27/100, Iteration 198/303, Loss: 0.00010732848022598773\n",
      "Epoch 27/100, Iteration 199/303, Loss: 0.0001631416380405426\n",
      "Epoch 27/100, Iteration 200/303, Loss: 0.0004951072041876614\n",
      "Epoch 27/100, Iteration 201/303, Loss: 9.442995360586792e-05\n",
      "Epoch 27/100, Iteration 202/303, Loss: 3.260183802922256e-05\n",
      "Epoch 27/100, Iteration 203/303, Loss: 0.0001939681387739256\n",
      "Epoch 27/100, Iteration 204/303, Loss: 9.205621608998626e-05\n",
      "Epoch 27/100, Iteration 205/303, Loss: 0.00012030659127049148\n",
      "Epoch 27/100, Iteration 206/303, Loss: 0.00021344936976674944\n",
      "Epoch 27/100, Iteration 207/303, Loss: 5.173749377718195e-05\n",
      "Epoch 27/100, Iteration 208/303, Loss: 8.378297206945717e-05\n",
      "Epoch 27/100, Iteration 209/303, Loss: 4.451347194844857e-05\n",
      "Epoch 27/100, Iteration 210/303, Loss: 0.0001494104799348861\n",
      "Epoch 27/100, Iteration 211/303, Loss: 0.00025988026754930615\n",
      "Epoch 27/100, Iteration 212/303, Loss: 4.712192458100617e-05\n",
      "Epoch 27/100, Iteration 213/303, Loss: 0.00030225151567719877\n",
      "Epoch 27/100, Iteration 214/303, Loss: 0.00024773343466222286\n",
      "Epoch 27/100, Iteration 215/303, Loss: 8.94478362170048e-05\n",
      "Epoch 27/100, Iteration 216/303, Loss: 8.20349741843529e-05\n",
      "Epoch 27/100, Iteration 217/303, Loss: 1.3938648407929577e-05\n",
      "Epoch 27/100, Iteration 218/303, Loss: 9.183443034999073e-05\n",
      "Epoch 27/100, Iteration 219/303, Loss: 2.6667497877497226e-05\n",
      "Epoch 27/100, Iteration 220/303, Loss: 5.1283437642268836e-05\n",
      "Epoch 27/100, Iteration 221/303, Loss: 0.0003140254702884704\n",
      "Epoch 27/100, Iteration 222/303, Loss: 5.029825115343556e-05\n",
      "Epoch 27/100, Iteration 223/303, Loss: 7.020850171102211e-05\n",
      "Epoch 27/100, Iteration 224/303, Loss: 0.00019276904640719295\n",
      "Epoch 27/100, Iteration 225/303, Loss: 5.5832628277130425e-05\n",
      "Epoch 27/100, Iteration 226/303, Loss: 1.667892502155155e-05\n",
      "Epoch 27/100, Iteration 227/303, Loss: 2.8147849661763757e-05\n",
      "Epoch 27/100, Iteration 228/303, Loss: 5.478605817188509e-05\n",
      "Epoch 27/100, Iteration 229/303, Loss: 5.899462121305987e-05\n",
      "Epoch 27/100, Iteration 230/303, Loss: 0.000126196289784275\n",
      "Epoch 27/100, Iteration 231/303, Loss: 3.935175482183695e-05\n",
      "Epoch 27/100, Iteration 232/303, Loss: 5.9199002862442285e-05\n",
      "Epoch 27/100, Iteration 233/303, Loss: 5.375315140554449e-06\n",
      "Epoch 27/100, Iteration 234/303, Loss: 0.0002483040443621576\n",
      "Epoch 27/100, Iteration 235/303, Loss: 0.0003338654350955039\n",
      "Epoch 27/100, Iteration 236/303, Loss: 0.00015627514221705496\n",
      "Epoch 27/100, Iteration 237/303, Loss: 0.0005468767485581338\n",
      "Epoch 27/100, Iteration 238/303, Loss: 5.405268893809989e-05\n",
      "Epoch 27/100, Iteration 239/303, Loss: 0.0004181584226898849\n",
      "Epoch 27/100, Iteration 240/303, Loss: 3.1423700420418754e-05\n",
      "Epoch 27/100, Iteration 241/303, Loss: 0.0001455774763599038\n",
      "Epoch 27/100, Iteration 242/303, Loss: 4.4661272113444284e-05\n",
      "Epoch 27/100, Iteration 243/303, Loss: 0.00010230809130007401\n",
      "Epoch 27/100, Iteration 244/303, Loss: 0.00012515705020632595\n",
      "Epoch 27/100, Iteration 245/303, Loss: 0.00030741156660951674\n",
      "Epoch 27/100, Iteration 246/303, Loss: 2.4237981051555835e-05\n",
      "Epoch 27/100, Iteration 247/303, Loss: 0.00017792358994483948\n",
      "Epoch 27/100, Iteration 248/303, Loss: 1.7764952644938603e-05\n",
      "Epoch 27/100, Iteration 249/303, Loss: 8.213528781197965e-05\n",
      "Epoch 27/100, Iteration 250/303, Loss: 0.0002712901623453945\n",
      "Epoch 27/100, Iteration 251/303, Loss: 0.0001210295595228672\n",
      "Epoch 27/100, Iteration 252/303, Loss: 0.00010195653885602951\n",
      "Epoch 27/100, Iteration 253/303, Loss: 9.095496352529153e-05\n",
      "Epoch 27/100, Iteration 254/303, Loss: 5.326881819200935e-06\n",
      "Epoch 27/100, Iteration 255/303, Loss: 0.00015513428661506623\n",
      "Epoch 27/100, Iteration 256/303, Loss: 4.051285213790834e-05\n",
      "Epoch 27/100, Iteration 257/303, Loss: 7.97126631368883e-05\n",
      "Epoch 27/100, Iteration 258/303, Loss: 1.5216572137433104e-05\n",
      "Epoch 27/100, Iteration 259/303, Loss: 0.0003273444017395377\n",
      "Epoch 27/100, Iteration 260/303, Loss: 5.841958773089573e-05\n",
      "Epoch 27/100, Iteration 261/303, Loss: 6.217396003194153e-05\n",
      "Epoch 27/100, Iteration 262/303, Loss: 9.16824719752185e-05\n",
      "Epoch 27/100, Iteration 263/303, Loss: 4.842409907723777e-05\n",
      "Epoch 27/100, Iteration 264/303, Loss: 8.483782585244626e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Iteration 265/303, Loss: 0.00016838022565934807\n",
      "Epoch 27/100, Iteration 266/303, Loss: 1.7328260582871735e-05\n",
      "Epoch 27/100, Iteration 267/303, Loss: 0.0001708755735307932\n",
      "Epoch 27/100, Iteration 268/303, Loss: 1.8416452803649008e-05\n",
      "Epoch 27/100, Iteration 269/303, Loss: 0.0001934975734911859\n",
      "Epoch 27/100, Iteration 270/303, Loss: 8.618733409093693e-05\n",
      "Epoch 27/100, Iteration 271/303, Loss: 0.0002324782544746995\n",
      "Epoch 27/100, Iteration 272/303, Loss: 0.00034133560257032514\n",
      "Epoch 27/100, Iteration 273/303, Loss: 7.831088441889733e-05\n",
      "Epoch 27/100, Iteration 274/303, Loss: 0.00036148406798020005\n",
      "Epoch 27/100, Iteration 275/303, Loss: 0.00033341761445626616\n",
      "Epoch 27/100, Iteration 276/303, Loss: 0.00014279861352406442\n",
      "Epoch 27/100, Iteration 277/303, Loss: 5.3575651691062376e-05\n",
      "Epoch 27/100, Iteration 278/303, Loss: 5.681487527908757e-05\n",
      "Epoch 27/100, Iteration 279/303, Loss: 8.408387657254934e-05\n",
      "Epoch 27/100, Iteration 280/303, Loss: 9.816728561418131e-05\n",
      "Epoch 27/100, Iteration 281/303, Loss: 6.403955921996385e-05\n",
      "Epoch 27/100, Iteration 282/303, Loss: 5.39442989975214e-05\n",
      "Epoch 27/100, Iteration 283/303, Loss: 0.00010305477917427197\n",
      "Epoch 27/100, Iteration 284/303, Loss: 5.945650627836585e-05\n",
      "Epoch 27/100, Iteration 285/303, Loss: 0.0004038761544506997\n",
      "Epoch 27/100, Iteration 286/303, Loss: 1.585473910381552e-05\n",
      "Epoch 27/100, Iteration 287/303, Loss: 2.5283387003582902e-05\n",
      "Epoch 27/100, Iteration 288/303, Loss: 3.682507303892635e-05\n",
      "Epoch 27/100, Iteration 289/303, Loss: 0.00033675029408186674\n",
      "Epoch 27/100, Iteration 290/303, Loss: 0.00011218307190574706\n",
      "Epoch 27/100, Iteration 291/303, Loss: 5.2405383030418307e-05\n",
      "Epoch 27/100, Iteration 292/303, Loss: 0.00011525930312927812\n",
      "Epoch 27/100, Iteration 293/303, Loss: 9.297529322793707e-05\n",
      "Epoch 27/100, Iteration 294/303, Loss: 0.00011559856648091227\n",
      "Epoch 27/100, Iteration 295/303, Loss: 0.00017240286979358643\n",
      "Epoch 27/100, Iteration 296/303, Loss: 0.00015078058640938252\n",
      "Epoch 27/100, Iteration 297/303, Loss: 3.339462637086399e-05\n",
      "Epoch 27/100, Iteration 298/303, Loss: 0.00035766614018939435\n",
      "Epoch 27/100, Iteration 299/303, Loss: 8.125841850414872e-05\n",
      "Epoch 27/100, Iteration 300/303, Loss: 2.481343108229339e-05\n",
      "Epoch 27/100, Iteration 301/303, Loss: 8.453046757495031e-05\n",
      "Epoch 27/100, Iteration 302/303, Loss: 0.0002580972795840353\n",
      "Epoch 27/100, Iteration 303/303, Loss: 4.126250496483408e-05\n",
      "Epoch 28/100, Iteration 1/303, Loss: 8.976944809546694e-05\n",
      "Epoch 28/100, Iteration 2/303, Loss: 0.00014696497237309813\n",
      "Epoch 28/100, Iteration 3/303, Loss: 0.0002049231406999752\n",
      "Epoch 28/100, Iteration 4/303, Loss: 0.00017791331629268825\n",
      "Epoch 28/100, Iteration 5/303, Loss: 2.215324821008835e-05\n",
      "Epoch 28/100, Iteration 6/303, Loss: 2.558964661147911e-05\n",
      "Epoch 28/100, Iteration 7/303, Loss: 0.00010755414405139163\n",
      "Epoch 28/100, Iteration 8/303, Loss: 0.00019772181985899806\n",
      "Epoch 28/100, Iteration 9/303, Loss: 9.346174920210615e-05\n",
      "Epoch 28/100, Iteration 10/303, Loss: 0.00028082318021915853\n",
      "Epoch 28/100, Iteration 11/303, Loss: 0.0001024723969749175\n",
      "Epoch 28/100, Iteration 12/303, Loss: 0.00017028499860316515\n",
      "Epoch 28/100, Iteration 13/303, Loss: 0.00019099093333352357\n",
      "Epoch 28/100, Iteration 14/303, Loss: 5.951779894530773e-05\n",
      "Epoch 28/100, Iteration 15/303, Loss: 0.00014830968575552106\n",
      "Epoch 28/100, Iteration 16/303, Loss: 0.00016059022163972259\n",
      "Epoch 28/100, Iteration 17/303, Loss: 0.00018459736020304263\n",
      "Epoch 28/100, Iteration 18/303, Loss: 2.9988563255756162e-05\n",
      "Epoch 28/100, Iteration 19/303, Loss: 0.00014790364366490394\n",
      "Epoch 28/100, Iteration 20/303, Loss: 0.00012128007801948115\n",
      "Epoch 28/100, Iteration 21/303, Loss: 0.0002994091482833028\n",
      "Epoch 28/100, Iteration 22/303, Loss: 0.00023360058548860252\n",
      "Epoch 28/100, Iteration 23/303, Loss: 0.00010940054198727012\n",
      "Epoch 28/100, Iteration 24/303, Loss: 9.178831533063203e-05\n",
      "Epoch 28/100, Iteration 25/303, Loss: 4.403411003295332e-05\n",
      "Epoch 28/100, Iteration 26/303, Loss: 8.834860636852682e-05\n",
      "Epoch 28/100, Iteration 27/303, Loss: 0.00020171850337646902\n",
      "Epoch 28/100, Iteration 28/303, Loss: 0.00031575915636494756\n",
      "Epoch 28/100, Iteration 29/303, Loss: 0.00016946386313065886\n",
      "Epoch 28/100, Iteration 30/303, Loss: 0.0003082197508774698\n",
      "Epoch 28/100, Iteration 31/303, Loss: 0.00019621342653408647\n",
      "Epoch 28/100, Iteration 32/303, Loss: 3.11943658743985e-05\n",
      "Epoch 28/100, Iteration 33/303, Loss: 2.8602727979887277e-05\n",
      "Epoch 28/100, Iteration 34/303, Loss: 1.4609845493396278e-05\n",
      "Epoch 28/100, Iteration 35/303, Loss: 0.0001592962653376162\n",
      "Epoch 28/100, Iteration 36/303, Loss: 3.534436473273672e-05\n",
      "Epoch 28/100, Iteration 37/303, Loss: 5.6802287872415036e-05\n",
      "Epoch 28/100, Iteration 38/303, Loss: 0.00012333120685070753\n",
      "Epoch 28/100, Iteration 39/303, Loss: 2.2397751308744773e-05\n",
      "Epoch 28/100, Iteration 40/303, Loss: 0.00017332014977000654\n",
      "Epoch 28/100, Iteration 41/303, Loss: 9.939426672644913e-05\n",
      "Epoch 28/100, Iteration 42/303, Loss: 0.0001220691337948665\n",
      "Epoch 28/100, Iteration 43/303, Loss: 0.0001066021213773638\n",
      "Epoch 28/100, Iteration 44/303, Loss: 0.00015756119682919234\n",
      "Epoch 28/100, Iteration 45/303, Loss: 3.091139660682529e-05\n",
      "Epoch 28/100, Iteration 46/303, Loss: 4.333812103141099e-05\n",
      "Epoch 28/100, Iteration 47/303, Loss: 0.00011460100358817726\n",
      "Epoch 28/100, Iteration 48/303, Loss: 6.947782821953297e-05\n",
      "Epoch 28/100, Iteration 49/303, Loss: 0.00034558773040771484\n",
      "Epoch 28/100, Iteration 50/303, Loss: 5.290237459121272e-05\n",
      "Epoch 28/100, Iteration 51/303, Loss: 0.00017155360546894372\n",
      "Epoch 28/100, Iteration 52/303, Loss: 9.195387247018516e-05\n",
      "Epoch 28/100, Iteration 53/303, Loss: 0.00011320319754304364\n",
      "Epoch 28/100, Iteration 54/303, Loss: 5.835522460984066e-05\n",
      "Epoch 28/100, Iteration 55/303, Loss: 0.00018088275101035833\n",
      "Epoch 28/100, Iteration 56/303, Loss: 0.0001439597108401358\n",
      "Epoch 28/100, Iteration 57/303, Loss: 7.953336171340197e-05\n",
      "Epoch 28/100, Iteration 58/303, Loss: 7.945542165543884e-05\n",
      "Epoch 28/100, Iteration 59/303, Loss: 0.0003841251309495419\n",
      "Epoch 28/100, Iteration 60/303, Loss: 3.744816785911098e-05\n",
      "Epoch 28/100, Iteration 61/303, Loss: 2.805108488246333e-05\n",
      "Epoch 28/100, Iteration 62/303, Loss: 7.385677599813789e-05\n",
      "Epoch 28/100, Iteration 63/303, Loss: 7.430144614772871e-05\n",
      "Epoch 28/100, Iteration 64/303, Loss: 0.00010100475628860295\n",
      "Epoch 28/100, Iteration 65/303, Loss: 3.306182406959124e-05\n",
      "Epoch 28/100, Iteration 66/303, Loss: 0.00016687680908944458\n",
      "Epoch 28/100, Iteration 67/303, Loss: 0.0001743305183481425\n",
      "Epoch 28/100, Iteration 68/303, Loss: 6.998729077167809e-05\n",
      "Epoch 28/100, Iteration 69/303, Loss: 0.00014615154941566288\n",
      "Epoch 28/100, Iteration 70/303, Loss: 2.5376953999511898e-05\n",
      "Epoch 28/100, Iteration 71/303, Loss: 7.632742926944047e-05\n",
      "Epoch 28/100, Iteration 72/303, Loss: 1.2065773262293078e-05\n",
      "Epoch 28/100, Iteration 73/303, Loss: 7.58942769607529e-05\n",
      "Epoch 28/100, Iteration 74/303, Loss: 0.00033478601835668087\n",
      "Epoch 28/100, Iteration 75/303, Loss: 0.00012724676344078034\n",
      "Epoch 28/100, Iteration 76/303, Loss: 4.46466074208729e-05\n",
      "Epoch 28/100, Iteration 77/303, Loss: 4.859608816332184e-05\n",
      "Epoch 28/100, Iteration 78/303, Loss: 3.1519582989858463e-05\n",
      "Epoch 28/100, Iteration 79/303, Loss: 0.00043676773202605546\n",
      "Epoch 28/100, Iteration 80/303, Loss: 0.00010155262134503573\n",
      "Epoch 28/100, Iteration 81/303, Loss: 0.0001549899607198313\n",
      "Epoch 28/100, Iteration 82/303, Loss: 4.593203357217135e-06\n",
      "Epoch 28/100, Iteration 83/303, Loss: 8.787658771325368e-06\n",
      "Epoch 28/100, Iteration 84/303, Loss: 0.00020113812934141606\n",
      "Epoch 28/100, Iteration 85/303, Loss: 0.0002629972295835614\n",
      "Epoch 28/100, Iteration 86/303, Loss: 8.697239536559209e-05\n",
      "Epoch 28/100, Iteration 87/303, Loss: 1.4546336387866177e-05\n",
      "Epoch 28/100, Iteration 88/303, Loss: 0.0011092972708866\n",
      "Epoch 28/100, Iteration 89/303, Loss: 1.1852293937408831e-05\n",
      "Epoch 28/100, Iteration 90/303, Loss: 0.00035507281427271664\n",
      "Epoch 28/100, Iteration 91/303, Loss: 0.0001251653884537518\n",
      "Epoch 28/100, Iteration 92/303, Loss: 0.00027804705314338207\n",
      "Epoch 28/100, Iteration 93/303, Loss: 7.284127059392631e-05\n",
      "Epoch 28/100, Iteration 94/303, Loss: 0.00016423464694526047\n",
      "Epoch 28/100, Iteration 95/303, Loss: 7.698511763010174e-05\n",
      "Epoch 28/100, Iteration 96/303, Loss: 7.087868289090693e-05\n",
      "Epoch 28/100, Iteration 97/303, Loss: 6.507380021503195e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Iteration 98/303, Loss: 9.31695249164477e-05\n",
      "Epoch 28/100, Iteration 99/303, Loss: 0.0005967635079286993\n",
      "Epoch 28/100, Iteration 100/303, Loss: 8.283927309093997e-05\n",
      "Epoch 28/100, Iteration 101/303, Loss: 0.00012691928714048117\n",
      "Epoch 28/100, Iteration 102/303, Loss: 9.595753363100812e-05\n",
      "Epoch 28/100, Iteration 103/303, Loss: 6.596569437533617e-05\n",
      "Epoch 28/100, Iteration 104/303, Loss: 6.250373553484678e-05\n",
      "Epoch 28/100, Iteration 105/303, Loss: 9.179949120152742e-05\n",
      "Epoch 28/100, Iteration 106/303, Loss: 9.748907177709043e-05\n",
      "Epoch 28/100, Iteration 107/303, Loss: 0.0001623135613044724\n",
      "Epoch 28/100, Iteration 108/303, Loss: 3.694663246278651e-05\n",
      "Epoch 28/100, Iteration 109/303, Loss: 2.138287982234033e-06\n",
      "Epoch 28/100, Iteration 110/303, Loss: 3.128933531115763e-05\n",
      "Epoch 28/100, Iteration 111/303, Loss: 9.08550191525137e-06\n",
      "Epoch 28/100, Iteration 112/303, Loss: 0.00018103979527950287\n",
      "Epoch 28/100, Iteration 113/303, Loss: 0.00020429069991223514\n",
      "Epoch 28/100, Iteration 114/303, Loss: 5.563595914281905e-05\n",
      "Epoch 28/100, Iteration 115/303, Loss: 3.3523298043292016e-05\n",
      "Epoch 28/100, Iteration 116/303, Loss: 2.4445291273877956e-05\n",
      "Epoch 28/100, Iteration 117/303, Loss: 5.855457857251167e-05\n",
      "Epoch 28/100, Iteration 118/303, Loss: 1.764348962751683e-05\n",
      "Epoch 28/100, Iteration 119/303, Loss: 1.5160694601945579e-05\n",
      "Epoch 28/100, Iteration 120/303, Loss: 8.940079715102911e-05\n",
      "Epoch 28/100, Iteration 121/303, Loss: 8.565009193262085e-05\n",
      "Epoch 28/100, Iteration 122/303, Loss: 0.00020771456183865666\n",
      "Epoch 28/100, Iteration 123/303, Loss: 3.473268589004874e-05\n",
      "Epoch 28/100, Iteration 124/303, Loss: 0.00020193819364067167\n",
      "Epoch 28/100, Iteration 125/303, Loss: 0.00024903190205805004\n",
      "Epoch 28/100, Iteration 126/303, Loss: 5.0785944040399045e-05\n",
      "Epoch 28/100, Iteration 127/303, Loss: 0.00019836783758364618\n",
      "Epoch 28/100, Iteration 128/303, Loss: 0.0003581541823223233\n",
      "Epoch 28/100, Iteration 129/303, Loss: 0.0001047427867888473\n",
      "Epoch 28/100, Iteration 130/303, Loss: 0.0003057234571315348\n",
      "Epoch 28/100, Iteration 131/303, Loss: 0.00020270171808078885\n",
      "Epoch 28/100, Iteration 132/303, Loss: 1.169689858215861e-05\n",
      "Epoch 28/100, Iteration 133/303, Loss: 5.254855932435021e-05\n",
      "Epoch 28/100, Iteration 134/303, Loss: 0.00020869799482170492\n",
      "Epoch 28/100, Iteration 135/303, Loss: 3.699866647366434e-05\n",
      "Epoch 28/100, Iteration 136/303, Loss: 5.34413629793562e-05\n",
      "Epoch 28/100, Iteration 137/303, Loss: 0.0001532663154648617\n",
      "Epoch 28/100, Iteration 138/303, Loss: 1.5228270058287308e-05\n",
      "Epoch 28/100, Iteration 139/303, Loss: 4.048214032081887e-05\n",
      "Epoch 28/100, Iteration 140/303, Loss: 0.00013419819879345596\n",
      "Epoch 28/100, Iteration 141/303, Loss: 0.00014574766100849956\n",
      "Epoch 28/100, Iteration 142/303, Loss: 8.208491635741666e-05\n",
      "Epoch 28/100, Iteration 143/303, Loss: 0.0002413017355138436\n",
      "Epoch 28/100, Iteration 144/303, Loss: 6.826777826063335e-05\n",
      "Epoch 28/100, Iteration 145/303, Loss: 0.00011090814950875938\n",
      "Epoch 28/100, Iteration 146/303, Loss: 0.00010539439972490072\n",
      "Epoch 28/100, Iteration 147/303, Loss: 9.823106665862724e-05\n",
      "Epoch 28/100, Iteration 148/303, Loss: 0.00010014759754994884\n",
      "Epoch 28/100, Iteration 149/303, Loss: 1.3331908121472225e-05\n",
      "Epoch 28/100, Iteration 150/303, Loss: 0.00011484025162644684\n",
      "Epoch 28/100, Iteration 151/303, Loss: 0.00035270408261567354\n",
      "Epoch 28/100, Iteration 152/303, Loss: 0.00013154448242858052\n",
      "Epoch 28/100, Iteration 153/303, Loss: 2.5251161787309684e-05\n",
      "Epoch 28/100, Iteration 154/303, Loss: 0.00014417954662349075\n",
      "Epoch 28/100, Iteration 155/303, Loss: 6.814044172642753e-05\n",
      "Epoch 28/100, Iteration 156/303, Loss: 7.748103598714806e-06\n",
      "Epoch 28/100, Iteration 157/303, Loss: 0.00026885775150731206\n",
      "Epoch 28/100, Iteration 158/303, Loss: 7.751736120553687e-05\n",
      "Epoch 28/100, Iteration 159/303, Loss: 0.0001556459756102413\n",
      "Epoch 28/100, Iteration 160/303, Loss: 0.00014196490519680083\n",
      "Epoch 28/100, Iteration 161/303, Loss: 8.650775998830795e-05\n",
      "Epoch 28/100, Iteration 162/303, Loss: 0.00010622797708492726\n",
      "Epoch 28/100, Iteration 163/303, Loss: 8.57980630826205e-05\n",
      "Epoch 28/100, Iteration 164/303, Loss: 0.0001717825507512316\n",
      "Epoch 28/100, Iteration 165/303, Loss: 1.400084511260502e-05\n",
      "Epoch 28/100, Iteration 166/303, Loss: 0.00010381951869931072\n",
      "Epoch 28/100, Iteration 167/303, Loss: 7.183533307397738e-05\n",
      "Epoch 28/100, Iteration 168/303, Loss: 6.74318871460855e-05\n",
      "Epoch 28/100, Iteration 169/303, Loss: 0.00034861534368246794\n",
      "Epoch 28/100, Iteration 170/303, Loss: 0.00027538673020899296\n",
      "Epoch 28/100, Iteration 171/303, Loss: 0.00023037480423226953\n",
      "Epoch 28/100, Iteration 172/303, Loss: 6.157175084808841e-05\n",
      "Epoch 28/100, Iteration 173/303, Loss: 6.54194809612818e-05\n",
      "Epoch 28/100, Iteration 174/303, Loss: 5.421973764896393e-05\n",
      "Epoch 28/100, Iteration 175/303, Loss: 9.575614967616275e-05\n",
      "Epoch 28/100, Iteration 176/303, Loss: 0.00024598391610197723\n",
      "Epoch 28/100, Iteration 177/303, Loss: 0.0001562322722747922\n",
      "Epoch 28/100, Iteration 178/303, Loss: 0.00013417340232990682\n",
      "Epoch 28/100, Iteration 179/303, Loss: 0.00012893100210931152\n",
      "Epoch 28/100, Iteration 180/303, Loss: 0.00024349283194169402\n",
      "Epoch 28/100, Iteration 181/303, Loss: 0.00017141758871730417\n",
      "Epoch 28/100, Iteration 182/303, Loss: 0.00031489835237152874\n",
      "Epoch 28/100, Iteration 183/303, Loss: 0.0001874834269983694\n",
      "Epoch 28/100, Iteration 184/303, Loss: 0.00030927546322345734\n",
      "Epoch 28/100, Iteration 185/303, Loss: 4.5724511437583715e-05\n",
      "Epoch 28/100, Iteration 186/303, Loss: 0.000418662850279361\n",
      "Epoch 28/100, Iteration 187/303, Loss: 0.00031014723936095834\n",
      "Epoch 28/100, Iteration 188/303, Loss: 8.851776510709897e-05\n",
      "Epoch 28/100, Iteration 189/303, Loss: 9.340843826066703e-05\n",
      "Epoch 28/100, Iteration 190/303, Loss: 0.00014044650015421212\n",
      "Epoch 28/100, Iteration 191/303, Loss: 0.00038182432763278484\n",
      "Epoch 28/100, Iteration 192/303, Loss: 0.0001035561363096349\n",
      "Epoch 28/100, Iteration 193/303, Loss: 8.459266973659396e-05\n",
      "Epoch 28/100, Iteration 194/303, Loss: 7.951872248668224e-05\n",
      "Epoch 28/100, Iteration 195/303, Loss: 0.00015570237883366644\n",
      "Epoch 28/100, Iteration 196/303, Loss: 3.27245143125765e-05\n",
      "Epoch 28/100, Iteration 197/303, Loss: 0.0001172069096355699\n",
      "Epoch 28/100, Iteration 198/303, Loss: 0.00017846499395091087\n",
      "Epoch 28/100, Iteration 199/303, Loss: 2.8156418920843862e-05\n",
      "Epoch 28/100, Iteration 200/303, Loss: 5.171849988983013e-05\n",
      "Epoch 28/100, Iteration 201/303, Loss: 8.510852057952434e-05\n",
      "Epoch 28/100, Iteration 202/303, Loss: 0.00014109647599980235\n",
      "Epoch 28/100, Iteration 203/303, Loss: 2.1496432964340784e-05\n",
      "Epoch 28/100, Iteration 204/303, Loss: 2.262477937620133e-05\n",
      "Epoch 28/100, Iteration 205/303, Loss: 0.00017218275752384216\n",
      "Epoch 28/100, Iteration 206/303, Loss: 0.0001363117917208001\n",
      "Epoch 28/100, Iteration 207/303, Loss: 0.00018064225150737911\n",
      "Epoch 28/100, Iteration 208/303, Loss: 0.00014260369061958045\n",
      "Epoch 28/100, Iteration 209/303, Loss: 1.5693593013565987e-05\n",
      "Epoch 28/100, Iteration 210/303, Loss: 0.000164849276188761\n",
      "Epoch 28/100, Iteration 211/303, Loss: 0.00039606759673915803\n",
      "Epoch 28/100, Iteration 212/303, Loss: 3.046890560653992e-05\n",
      "Epoch 28/100, Iteration 213/303, Loss: 8.514468936482444e-05\n",
      "Epoch 28/100, Iteration 214/303, Loss: 0.0001594258937984705\n",
      "Epoch 28/100, Iteration 215/303, Loss: 3.442747765802778e-05\n",
      "Epoch 28/100, Iteration 216/303, Loss: 0.0001445714005967602\n",
      "Epoch 28/100, Iteration 217/303, Loss: 3.748579911189154e-05\n",
      "Epoch 28/100, Iteration 218/303, Loss: 0.00017423478129785508\n",
      "Epoch 28/100, Iteration 219/303, Loss: 8.409414294874296e-05\n",
      "Epoch 28/100, Iteration 220/303, Loss: 6.573184509761631e-05\n",
      "Epoch 28/100, Iteration 221/303, Loss: 0.00011003026156686246\n",
      "Epoch 28/100, Iteration 222/303, Loss: 6.204828241607174e-05\n",
      "Epoch 28/100, Iteration 223/303, Loss: 2.049142676696647e-05\n",
      "Epoch 28/100, Iteration 224/303, Loss: 0.00020475787459872663\n",
      "Epoch 28/100, Iteration 225/303, Loss: 0.00016368183423765004\n",
      "Epoch 28/100, Iteration 226/303, Loss: 0.000163114134920761\n",
      "Epoch 28/100, Iteration 227/303, Loss: 6.062033571652137e-05\n",
      "Epoch 28/100, Iteration 228/303, Loss: 4.9433409003540874e-05\n",
      "Epoch 28/100, Iteration 229/303, Loss: 0.0001613083150004968\n",
      "Epoch 28/100, Iteration 230/303, Loss: 7.759635627735406e-05\n",
      "Epoch 28/100, Iteration 231/303, Loss: 0.000402798323193565\n",
      "Epoch 28/100, Iteration 232/303, Loss: 7.980360533110797e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Iteration 233/303, Loss: 0.00011921527766389772\n",
      "Epoch 28/100, Iteration 234/303, Loss: 0.0001436827442375943\n",
      "Epoch 28/100, Iteration 235/303, Loss: 0.00022317351249512285\n",
      "Epoch 28/100, Iteration 236/303, Loss: 8.699878526385874e-05\n",
      "Epoch 28/100, Iteration 237/303, Loss: 5.685166615876369e-05\n",
      "Epoch 28/100, Iteration 238/303, Loss: 6.694879994029179e-05\n",
      "Epoch 28/100, Iteration 239/303, Loss: 0.00025234525674022734\n",
      "Epoch 28/100, Iteration 240/303, Loss: 8.024447743082419e-05\n",
      "Epoch 28/100, Iteration 241/303, Loss: 9.115750435739756e-05\n",
      "Epoch 28/100, Iteration 242/303, Loss: 0.0002991585060954094\n",
      "Epoch 28/100, Iteration 243/303, Loss: 0.0009614748414605856\n",
      "Epoch 28/100, Iteration 244/303, Loss: 4.263862138031982e-05\n",
      "Epoch 28/100, Iteration 245/303, Loss: 9.477201092522591e-05\n",
      "Epoch 28/100, Iteration 246/303, Loss: 8.060053369263187e-05\n",
      "Epoch 28/100, Iteration 247/303, Loss: 0.00036778009962290525\n",
      "Epoch 28/100, Iteration 248/303, Loss: 0.00013935558672528714\n",
      "Epoch 28/100, Iteration 249/303, Loss: 0.00039682764327153563\n",
      "Epoch 28/100, Iteration 250/303, Loss: 3.000803553732112e-05\n",
      "Epoch 28/100, Iteration 251/303, Loss: 3.2800628105178475e-05\n",
      "Epoch 28/100, Iteration 252/303, Loss: 0.00010240272240480408\n",
      "Epoch 28/100, Iteration 253/303, Loss: 0.0001204337168019265\n",
      "Epoch 28/100, Iteration 254/303, Loss: 3.887006459990516e-05\n",
      "Epoch 28/100, Iteration 255/303, Loss: 0.00011917544907191768\n",
      "Epoch 28/100, Iteration 256/303, Loss: 0.00016137656348291785\n",
      "Epoch 28/100, Iteration 257/303, Loss: 7.324238686123863e-05\n",
      "Epoch 28/100, Iteration 258/303, Loss: 7.17586517566815e-05\n",
      "Epoch 28/100, Iteration 259/303, Loss: 5.7857010688167065e-05\n",
      "Epoch 28/100, Iteration 260/303, Loss: 0.00010693183139665052\n",
      "Epoch 28/100, Iteration 261/303, Loss: 0.00011017767974408343\n",
      "Epoch 28/100, Iteration 262/303, Loss: 3.150303746224381e-05\n",
      "Epoch 28/100, Iteration 263/303, Loss: 5.919363320572302e-05\n",
      "Epoch 28/100, Iteration 264/303, Loss: 6.064577610231936e-05\n",
      "Epoch 28/100, Iteration 265/303, Loss: 2.0498853700701147e-05\n",
      "Epoch 28/100, Iteration 266/303, Loss: 3.65692212653812e-05\n",
      "Epoch 28/100, Iteration 267/303, Loss: 0.00047542829997837543\n",
      "Epoch 28/100, Iteration 268/303, Loss: 2.772567495412659e-05\n",
      "Epoch 28/100, Iteration 269/303, Loss: 0.00011347942927386612\n",
      "Epoch 28/100, Iteration 270/303, Loss: 0.00022287917090579867\n",
      "Epoch 28/100, Iteration 271/303, Loss: 6.954364653211087e-05\n",
      "Epoch 28/100, Iteration 272/303, Loss: 0.0001109949589590542\n",
      "Epoch 28/100, Iteration 273/303, Loss: 0.00014111680502537638\n",
      "Epoch 28/100, Iteration 274/303, Loss: 0.00039725308306515217\n",
      "Epoch 28/100, Iteration 275/303, Loss: 5.565901301451959e-05\n",
      "Epoch 28/100, Iteration 276/303, Loss: 7.514034950872883e-05\n",
      "Epoch 28/100, Iteration 277/303, Loss: 0.0004078407655470073\n",
      "Epoch 28/100, Iteration 278/303, Loss: 7.019648182904348e-05\n",
      "Epoch 28/100, Iteration 279/303, Loss: 7.314025424420834e-05\n",
      "Epoch 28/100, Iteration 280/303, Loss: 3.0945753678679466e-05\n",
      "Epoch 28/100, Iteration 281/303, Loss: 0.00010862665658351034\n",
      "Epoch 28/100, Iteration 282/303, Loss: 0.00010785220365505666\n",
      "Epoch 28/100, Iteration 283/303, Loss: 6.304276030277833e-05\n",
      "Epoch 28/100, Iteration 284/303, Loss: 0.00022345759498421103\n",
      "Epoch 28/100, Iteration 285/303, Loss: 5.244859858066775e-05\n",
      "Epoch 28/100, Iteration 286/303, Loss: 0.00018799383542500436\n",
      "Epoch 28/100, Iteration 287/303, Loss: 7.787001231918111e-05\n",
      "Epoch 28/100, Iteration 288/303, Loss: 0.00011560293205548078\n",
      "Epoch 28/100, Iteration 289/303, Loss: 9.568961104378104e-05\n",
      "Epoch 28/100, Iteration 290/303, Loss: 7.927501428639516e-05\n",
      "Epoch 28/100, Iteration 291/303, Loss: 0.00022100965725257993\n",
      "Epoch 28/100, Iteration 292/303, Loss: 0.00025813389220274985\n",
      "Epoch 28/100, Iteration 293/303, Loss: 3.277077485108748e-05\n",
      "Epoch 28/100, Iteration 294/303, Loss: 4.6780871343798935e-05\n",
      "Epoch 28/100, Iteration 295/303, Loss: 7.396196451736614e-05\n",
      "Epoch 28/100, Iteration 296/303, Loss: 9.431038779439405e-05\n",
      "Epoch 28/100, Iteration 297/303, Loss: 2.798748937493656e-05\n",
      "Epoch 28/100, Iteration 298/303, Loss: 0.0001240819547092542\n",
      "Epoch 28/100, Iteration 299/303, Loss: 6.48272834951058e-05\n",
      "Epoch 28/100, Iteration 300/303, Loss: 4.0244776755571365e-05\n",
      "Epoch 28/100, Iteration 301/303, Loss: 0.00021715584443882108\n",
      "Epoch 28/100, Iteration 302/303, Loss: 1.3878652680432424e-05\n",
      "Epoch 28/100, Iteration 303/303, Loss: 0.00018897819973062724\n",
      "Epoch 29/100, Iteration 1/303, Loss: 4.5044482249068096e-05\n",
      "Epoch 29/100, Iteration 2/303, Loss: 0.00018395371444057673\n",
      "Epoch 29/100, Iteration 3/303, Loss: 9.453985694563016e-05\n",
      "Epoch 29/100, Iteration 4/303, Loss: 0.00015205808449536562\n",
      "Epoch 29/100, Iteration 5/303, Loss: 0.00016437479644082487\n",
      "Epoch 29/100, Iteration 6/303, Loss: 6.928067887201905e-05\n",
      "Epoch 29/100, Iteration 7/303, Loss: 8.25078968773596e-05\n",
      "Epoch 29/100, Iteration 8/303, Loss: 0.00012517751019913703\n",
      "Epoch 29/100, Iteration 9/303, Loss: 8.816250920062885e-05\n",
      "Epoch 29/100, Iteration 10/303, Loss: 0.00016002576739992946\n",
      "Epoch 29/100, Iteration 11/303, Loss: 0.00020009350555483252\n",
      "Epoch 29/100, Iteration 12/303, Loss: 0.00019447416707407683\n",
      "Epoch 29/100, Iteration 13/303, Loss: 4.302124580135569e-05\n",
      "Epoch 29/100, Iteration 14/303, Loss: 0.00012022519513266161\n",
      "Epoch 29/100, Iteration 15/303, Loss: 0.00023588159820064902\n",
      "Epoch 29/100, Iteration 16/303, Loss: 0.00016929370758589357\n",
      "Epoch 29/100, Iteration 17/303, Loss: 0.0001603195705683902\n",
      "Epoch 29/100, Iteration 18/303, Loss: 3.3270152925979346e-05\n",
      "Epoch 29/100, Iteration 19/303, Loss: 7.0866612077225e-05\n",
      "Epoch 29/100, Iteration 20/303, Loss: 6.967144145164639e-05\n",
      "Epoch 29/100, Iteration 21/303, Loss: 9.776790102478117e-05\n",
      "Epoch 29/100, Iteration 22/303, Loss: 3.6491997889243066e-05\n",
      "Epoch 29/100, Iteration 23/303, Loss: 0.0001382166228722781\n",
      "Epoch 29/100, Iteration 24/303, Loss: 0.00013638388190884143\n",
      "Epoch 29/100, Iteration 25/303, Loss: 2.542105721659027e-05\n",
      "Epoch 29/100, Iteration 26/303, Loss: 4.405899017001502e-05\n",
      "Epoch 29/100, Iteration 27/303, Loss: 7.21831529517658e-05\n",
      "Epoch 29/100, Iteration 28/303, Loss: 2.907226371462457e-05\n",
      "Epoch 29/100, Iteration 29/303, Loss: 6.72232563374564e-05\n",
      "Epoch 29/100, Iteration 30/303, Loss: 5.497827805811539e-05\n",
      "Epoch 29/100, Iteration 31/303, Loss: 9.088848310057074e-05\n",
      "Epoch 29/100, Iteration 32/303, Loss: 8.153606177074835e-05\n",
      "Epoch 29/100, Iteration 33/303, Loss: 0.00018662828369997442\n",
      "Epoch 29/100, Iteration 34/303, Loss: 2.2621621610596776e-05\n",
      "Epoch 29/100, Iteration 35/303, Loss: 0.0001246104802703485\n",
      "Epoch 29/100, Iteration 36/303, Loss: 6.173089059302583e-05\n",
      "Epoch 29/100, Iteration 37/303, Loss: 0.00020969628531020135\n",
      "Epoch 29/100, Iteration 38/303, Loss: 5.759656414738856e-05\n",
      "Epoch 29/100, Iteration 39/303, Loss: 0.00010998521611327305\n",
      "Epoch 29/100, Iteration 40/303, Loss: 2.9075954444124363e-05\n",
      "Epoch 29/100, Iteration 41/303, Loss: 0.0002520475536584854\n",
      "Epoch 29/100, Iteration 42/303, Loss: 0.00025265131262131035\n",
      "Epoch 29/100, Iteration 43/303, Loss: 8.3825463661924e-05\n",
      "Epoch 29/100, Iteration 44/303, Loss: 9.461842637392692e-06\n",
      "Epoch 29/100, Iteration 45/303, Loss: 6.772833876311779e-05\n",
      "Epoch 29/100, Iteration 46/303, Loss: 0.0001865514350356534\n",
      "Epoch 29/100, Iteration 47/303, Loss: 4.9163289077114314e-05\n",
      "Epoch 29/100, Iteration 48/303, Loss: 0.00015197467291727662\n",
      "Epoch 29/100, Iteration 49/303, Loss: 1.1272064512013458e-05\n",
      "Epoch 29/100, Iteration 50/303, Loss: 8.069999603321776e-05\n",
      "Epoch 29/100, Iteration 51/303, Loss: 0.00011808231647592038\n",
      "Epoch 29/100, Iteration 52/303, Loss: 8.247374353231862e-06\n",
      "Epoch 29/100, Iteration 53/303, Loss: 0.00010079472122015432\n",
      "Epoch 29/100, Iteration 54/303, Loss: 5.236254946794361e-05\n",
      "Epoch 29/100, Iteration 55/303, Loss: 0.00013546358968596905\n",
      "Epoch 29/100, Iteration 56/303, Loss: 0.00012616293679457158\n",
      "Epoch 29/100, Iteration 57/303, Loss: 5.9409478126326576e-05\n",
      "Epoch 29/100, Iteration 58/303, Loss: 0.00010737722914200276\n",
      "Epoch 29/100, Iteration 59/303, Loss: 0.00010196387302130461\n",
      "Epoch 29/100, Iteration 60/303, Loss: 0.00021401187404990196\n",
      "Epoch 29/100, Iteration 61/303, Loss: 2.369999492657371e-05\n",
      "Epoch 29/100, Iteration 62/303, Loss: 6.460162694565952e-05\n",
      "Epoch 29/100, Iteration 63/303, Loss: 7.450697739841416e-05\n",
      "Epoch 29/100, Iteration 64/303, Loss: 8.834007167024538e-05\n",
      "Epoch 29/100, Iteration 65/303, Loss: 3.53281939169392e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100, Iteration 66/303, Loss: 5.827138738823123e-05\n",
      "Epoch 29/100, Iteration 67/303, Loss: 0.00025604356778785586\n",
      "Epoch 29/100, Iteration 68/303, Loss: 0.0004275670216884464\n",
      "Epoch 29/100, Iteration 69/303, Loss: 8.29786149552092e-05\n",
      "Epoch 29/100, Iteration 70/303, Loss: 6.953207775950432e-05\n",
      "Epoch 29/100, Iteration 71/303, Loss: 3.3805750717874616e-05\n",
      "Epoch 29/100, Iteration 72/303, Loss: 8.89850634848699e-05\n",
      "Epoch 29/100, Iteration 73/303, Loss: 0.00029416970210149884\n",
      "Epoch 29/100, Iteration 74/303, Loss: 0.0004599077219609171\n",
      "Epoch 29/100, Iteration 75/303, Loss: 0.00022558873752132058\n",
      "Epoch 29/100, Iteration 76/303, Loss: 0.0001047491459758021\n",
      "Epoch 29/100, Iteration 77/303, Loss: 6.359197141136974e-05\n",
      "Epoch 29/100, Iteration 78/303, Loss: 1.0623663001751993e-05\n",
      "Epoch 29/100, Iteration 79/303, Loss: 7.483537046937272e-05\n",
      "Epoch 29/100, Iteration 80/303, Loss: 0.00010890187695622444\n",
      "Epoch 29/100, Iteration 81/303, Loss: 0.00015259279462043196\n",
      "Epoch 29/100, Iteration 82/303, Loss: 0.0001245110179297626\n",
      "Epoch 29/100, Iteration 83/303, Loss: 8.351308679266367e-06\n",
      "Epoch 29/100, Iteration 84/303, Loss: 9.84411672106944e-05\n",
      "Epoch 29/100, Iteration 85/303, Loss: 4.740975418826565e-05\n",
      "Epoch 29/100, Iteration 86/303, Loss: 3.1479750759899616e-05\n",
      "Epoch 29/100, Iteration 87/303, Loss: 6.214038876350969e-05\n",
      "Epoch 29/100, Iteration 88/303, Loss: 1.1066944352933206e-05\n",
      "Epoch 29/100, Iteration 89/303, Loss: 8.755718590691686e-05\n",
      "Epoch 29/100, Iteration 90/303, Loss: 0.00034473196137696505\n",
      "Epoch 29/100, Iteration 91/303, Loss: 4.445597733138129e-05\n",
      "Epoch 29/100, Iteration 92/303, Loss: 0.00012386427260935307\n",
      "Epoch 29/100, Iteration 93/303, Loss: 8.284822251880541e-05\n",
      "Epoch 29/100, Iteration 94/303, Loss: 0.00022392682149074972\n",
      "Epoch 29/100, Iteration 95/303, Loss: 6.628584378631786e-05\n",
      "Epoch 29/100, Iteration 96/303, Loss: 1.4904322597431019e-05\n",
      "Epoch 29/100, Iteration 97/303, Loss: 0.0003033385146409273\n",
      "Epoch 29/100, Iteration 98/303, Loss: 0.00016414839774370193\n",
      "Epoch 29/100, Iteration 99/303, Loss: 3.3796306524891406e-05\n",
      "Epoch 29/100, Iteration 100/303, Loss: 1.145827081927564e-05\n",
      "Epoch 29/100, Iteration 101/303, Loss: 3.540658872225322e-05\n",
      "Epoch 29/100, Iteration 102/303, Loss: 7.88959368946962e-05\n",
      "Epoch 29/100, Iteration 103/303, Loss: 0.00027317050262354314\n",
      "Epoch 29/100, Iteration 104/303, Loss: 3.095309511991218e-05\n",
      "Epoch 29/100, Iteration 105/303, Loss: 4.4532502215588465e-05\n",
      "Epoch 29/100, Iteration 106/303, Loss: 8.866163625498302e-07\n",
      "Epoch 29/100, Iteration 107/303, Loss: 5.956019595032558e-05\n",
      "Epoch 29/100, Iteration 108/303, Loss: 3.1243918783729896e-05\n",
      "Epoch 29/100, Iteration 109/303, Loss: 0.00011052429908886552\n",
      "Epoch 29/100, Iteration 110/303, Loss: 0.00011193057434866205\n",
      "Epoch 29/100, Iteration 111/303, Loss: 4.42442178609781e-05\n",
      "Epoch 29/100, Iteration 112/303, Loss: 0.0003439067513681948\n",
      "Epoch 29/100, Iteration 113/303, Loss: 0.00011322366481181234\n",
      "Epoch 29/100, Iteration 114/303, Loss: 0.0002296142774866894\n",
      "Epoch 29/100, Iteration 115/303, Loss: 0.0009144943323917687\n",
      "Epoch 29/100, Iteration 116/303, Loss: 0.00014364536036737263\n",
      "Epoch 29/100, Iteration 117/303, Loss: 9.236713958671317e-05\n",
      "Epoch 29/100, Iteration 118/303, Loss: 3.0746537959203124e-05\n",
      "Epoch 29/100, Iteration 119/303, Loss: 3.373570507392287e-05\n",
      "Epoch 29/100, Iteration 120/303, Loss: 0.00028647753060795367\n",
      "Epoch 29/100, Iteration 121/303, Loss: 5.352096923161298e-05\n",
      "Epoch 29/100, Iteration 122/303, Loss: 1.387582415190991e-05\n",
      "Epoch 29/100, Iteration 123/303, Loss: 0.00012850071652792394\n",
      "Epoch 29/100, Iteration 124/303, Loss: 0.000170273837284185\n",
      "Epoch 29/100, Iteration 125/303, Loss: 1.1655810340016615e-05\n",
      "Epoch 29/100, Iteration 126/303, Loss: 6.264574767556041e-05\n",
      "Epoch 29/100, Iteration 127/303, Loss: 0.00022656854707747698\n",
      "Epoch 29/100, Iteration 128/303, Loss: 0.00012589659309014678\n",
      "Epoch 29/100, Iteration 129/303, Loss: 8.121081918943673e-05\n",
      "Epoch 29/100, Iteration 130/303, Loss: 4.860567787545733e-05\n",
      "Epoch 29/100, Iteration 131/303, Loss: 0.00043210474541410804\n",
      "Epoch 29/100, Iteration 132/303, Loss: 1.385704854328651e-05\n",
      "Epoch 29/100, Iteration 133/303, Loss: 0.00011562507279450074\n",
      "Epoch 29/100, Iteration 134/303, Loss: 7.764919428154826e-05\n",
      "Epoch 29/100, Iteration 135/303, Loss: 6.950307579245418e-05\n",
      "Epoch 29/100, Iteration 136/303, Loss: 2.5276129235862754e-05\n",
      "Epoch 29/100, Iteration 137/303, Loss: 7.051911961752921e-05\n",
      "Epoch 29/100, Iteration 138/303, Loss: 6.355561345117167e-05\n",
      "Epoch 29/100, Iteration 139/303, Loss: 0.00014993976219557226\n",
      "Epoch 29/100, Iteration 140/303, Loss: 4.709209315478802e-05\n",
      "Epoch 29/100, Iteration 141/303, Loss: 4.088765854248777e-05\n",
      "Epoch 29/100, Iteration 142/303, Loss: 5.390652586356737e-05\n",
      "Epoch 29/100, Iteration 143/303, Loss: 4.3169246055185795e-05\n",
      "Epoch 29/100, Iteration 144/303, Loss: 0.00010022443893831223\n",
      "Epoch 29/100, Iteration 145/303, Loss: 0.0002997401461470872\n",
      "Epoch 29/100, Iteration 146/303, Loss: 0.00023301360488403589\n",
      "Epoch 29/100, Iteration 147/303, Loss: 0.00012705623521469533\n",
      "Epoch 29/100, Iteration 148/303, Loss: 3.392041617189534e-05\n",
      "Epoch 29/100, Iteration 149/303, Loss: 2.641895116539672e-05\n",
      "Epoch 29/100, Iteration 150/303, Loss: 5.537686956813559e-05\n",
      "Epoch 29/100, Iteration 151/303, Loss: 1.1997665751550812e-05\n",
      "Epoch 29/100, Iteration 152/303, Loss: 4.605937283486128e-05\n",
      "Epoch 29/100, Iteration 153/303, Loss: 0.0002757315232884139\n",
      "Epoch 29/100, Iteration 154/303, Loss: 7.241885032271966e-05\n",
      "Epoch 29/100, Iteration 155/303, Loss: 0.00018590016406960785\n",
      "Epoch 29/100, Iteration 156/303, Loss: 1.6534711903659627e-05\n",
      "Epoch 29/100, Iteration 157/303, Loss: 0.00010053064033854753\n",
      "Epoch 29/100, Iteration 158/303, Loss: 5.3102350648259744e-05\n",
      "Epoch 29/100, Iteration 159/303, Loss: 4.890365380560979e-05\n",
      "Epoch 29/100, Iteration 160/303, Loss: 0.00014671053213533014\n",
      "Epoch 29/100, Iteration 161/303, Loss: 0.0003148089163005352\n",
      "Epoch 29/100, Iteration 162/303, Loss: 0.00010104375542141497\n",
      "Epoch 29/100, Iteration 163/303, Loss: 0.00017508954624645412\n",
      "Epoch 29/100, Iteration 164/303, Loss: 4.8018187044363e-06\n",
      "Epoch 29/100, Iteration 165/303, Loss: 8.465157588943839e-05\n",
      "Epoch 29/100, Iteration 166/303, Loss: 0.0001081072332453914\n",
      "Epoch 29/100, Iteration 167/303, Loss: 3.980017936555669e-05\n",
      "Epoch 29/100, Iteration 168/303, Loss: 7.704849849687889e-05\n",
      "Epoch 29/100, Iteration 169/303, Loss: 8.419132768722193e-07\n",
      "Epoch 29/100, Iteration 170/303, Loss: 0.00024712123558856547\n",
      "Epoch 29/100, Iteration 171/303, Loss: 0.00013527176633942872\n",
      "Epoch 29/100, Iteration 172/303, Loss: 5.205688648857176e-05\n",
      "Epoch 29/100, Iteration 173/303, Loss: 6.056420534150675e-05\n",
      "Epoch 29/100, Iteration 174/303, Loss: 9.657834016252309e-05\n",
      "Epoch 29/100, Iteration 175/303, Loss: 0.00016990106087177992\n",
      "Epoch 29/100, Iteration 176/303, Loss: 2.7895355742657557e-05\n",
      "Epoch 29/100, Iteration 177/303, Loss: 8.25558599899523e-05\n",
      "Epoch 29/100, Iteration 178/303, Loss: 2.8903354177600704e-05\n",
      "Epoch 29/100, Iteration 179/303, Loss: 5.752619472332299e-05\n",
      "Epoch 29/100, Iteration 180/303, Loss: 0.0002771147119347006\n",
      "Epoch 29/100, Iteration 181/303, Loss: 6.739917444065213e-05\n",
      "Epoch 29/100, Iteration 182/303, Loss: 0.0005793490563519299\n",
      "Epoch 29/100, Iteration 183/303, Loss: 3.350686893099919e-05\n",
      "Epoch 29/100, Iteration 184/303, Loss: 6.404719169950113e-05\n",
      "Epoch 29/100, Iteration 185/303, Loss: 1.528335633338429e-05\n",
      "Epoch 29/100, Iteration 186/303, Loss: 1.6118185158120468e-05\n",
      "Epoch 29/100, Iteration 187/303, Loss: 6.880963337607682e-05\n",
      "Epoch 29/100, Iteration 188/303, Loss: 8.335593156516552e-05\n",
      "Epoch 29/100, Iteration 189/303, Loss: 0.0001199491016450338\n",
      "Epoch 29/100, Iteration 190/303, Loss: 1.0948014278255869e-05\n",
      "Epoch 29/100, Iteration 191/303, Loss: 0.00012541725300252438\n",
      "Epoch 29/100, Iteration 192/303, Loss: 0.00010891213605646044\n",
      "Epoch 29/100, Iteration 193/303, Loss: 0.00011623405589489266\n",
      "Epoch 29/100, Iteration 194/303, Loss: 7.615776848979294e-05\n",
      "Epoch 29/100, Iteration 195/303, Loss: 2.183919605158735e-05\n",
      "Epoch 29/100, Iteration 196/303, Loss: 6.194964953465387e-06\n",
      "Epoch 29/100, Iteration 197/303, Loss: 0.0001067465782398358\n",
      "Epoch 29/100, Iteration 198/303, Loss: 3.2378651667386293e-05\n",
      "Epoch 29/100, Iteration 199/303, Loss: 3.7795038224430755e-05\n",
      "Epoch 29/100, Iteration 200/303, Loss: 0.00020162967848591506\n",
      "Epoch 29/100, Iteration 201/303, Loss: 7.632196502527222e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100, Iteration 202/303, Loss: 1.0612674486765172e-05\n",
      "Epoch 29/100, Iteration 203/303, Loss: 6.961909093661234e-05\n",
      "Epoch 29/100, Iteration 204/303, Loss: 9.702561510493979e-05\n",
      "Epoch 29/100, Iteration 205/303, Loss: 0.00023337433231063187\n",
      "Epoch 29/100, Iteration 206/303, Loss: 0.00011280373291810974\n",
      "Epoch 29/100, Iteration 207/303, Loss: 0.00018230323621537536\n",
      "Epoch 29/100, Iteration 208/303, Loss: 0.0001123604888562113\n",
      "Epoch 29/100, Iteration 209/303, Loss: 0.00010899275366682559\n",
      "Epoch 29/100, Iteration 210/303, Loss: 0.0001487199915573001\n",
      "Epoch 29/100, Iteration 211/303, Loss: 0.00013152864994481206\n",
      "Epoch 29/100, Iteration 212/303, Loss: 0.00017664978804532439\n",
      "Epoch 29/100, Iteration 213/303, Loss: 0.0002472515916451812\n",
      "Epoch 29/100, Iteration 214/303, Loss: 0.00013410465908236802\n",
      "Epoch 29/100, Iteration 215/303, Loss: 8.69376162881963e-05\n",
      "Epoch 29/100, Iteration 216/303, Loss: 4.408169479575008e-05\n",
      "Epoch 29/100, Iteration 217/303, Loss: 0.00028060527984052896\n",
      "Epoch 29/100, Iteration 218/303, Loss: 0.0001991648750845343\n",
      "Epoch 29/100, Iteration 219/303, Loss: 1.4218177057045978e-05\n",
      "Epoch 29/100, Iteration 220/303, Loss: 2.1186961021157913e-05\n",
      "Epoch 29/100, Iteration 221/303, Loss: 7.727776392130181e-05\n",
      "Epoch 29/100, Iteration 222/303, Loss: 8.197403803933412e-05\n",
      "Epoch 29/100, Iteration 223/303, Loss: 2.2643898773822002e-05\n",
      "Epoch 29/100, Iteration 224/303, Loss: 7.273505616467446e-05\n",
      "Epoch 29/100, Iteration 225/303, Loss: 1.3160094567865599e-05\n",
      "Epoch 29/100, Iteration 226/303, Loss: 9.960089664673433e-05\n",
      "Epoch 29/100, Iteration 227/303, Loss: 0.00015636133321095258\n",
      "Epoch 29/100, Iteration 228/303, Loss: 0.00031914428109303117\n",
      "Epoch 29/100, Iteration 229/303, Loss: 9.035891707753763e-05\n",
      "Epoch 29/100, Iteration 230/303, Loss: 0.00011973784421570599\n",
      "Epoch 29/100, Iteration 231/303, Loss: 0.0001311410014750436\n",
      "Epoch 29/100, Iteration 232/303, Loss: 4.80872331536375e-05\n",
      "Epoch 29/100, Iteration 233/303, Loss: 8.620833978056908e-05\n",
      "Epoch 29/100, Iteration 234/303, Loss: 0.00029161700513213873\n",
      "Epoch 29/100, Iteration 235/303, Loss: 5.074407090432942e-05\n",
      "Epoch 29/100, Iteration 236/303, Loss: 0.000754544569645077\n",
      "Epoch 29/100, Iteration 237/303, Loss: 0.00015287852147594094\n",
      "Epoch 29/100, Iteration 238/303, Loss: 2.5735467716003768e-05\n",
      "Epoch 29/100, Iteration 239/303, Loss: 5.630846862914041e-05\n",
      "Epoch 29/100, Iteration 240/303, Loss: 0.00018223293591290712\n",
      "Epoch 29/100, Iteration 241/303, Loss: 0.00011447627912275493\n",
      "Epoch 29/100, Iteration 242/303, Loss: 0.00033944586175493896\n",
      "Epoch 29/100, Iteration 243/303, Loss: 0.00010172352631343529\n",
      "Epoch 29/100, Iteration 244/303, Loss: 0.00014609422942157835\n",
      "Epoch 29/100, Iteration 245/303, Loss: 0.0001148221708717756\n",
      "Epoch 29/100, Iteration 246/303, Loss: 0.0003664113755803555\n",
      "Epoch 29/100, Iteration 247/303, Loss: 0.0001513924653409049\n",
      "Epoch 29/100, Iteration 248/303, Loss: 0.00017690307868178934\n",
      "Epoch 29/100, Iteration 249/303, Loss: 9.529739327263087e-05\n",
      "Epoch 29/100, Iteration 250/303, Loss: 0.00010349156218580902\n",
      "Epoch 29/100, Iteration 251/303, Loss: 0.00012839848932344466\n",
      "Epoch 29/100, Iteration 252/303, Loss: 1.983173206099309e-05\n",
      "Epoch 29/100, Iteration 253/303, Loss: 0.0001330139784840867\n",
      "Epoch 29/100, Iteration 254/303, Loss: 0.0003553112328518182\n",
      "Epoch 29/100, Iteration 255/303, Loss: 0.00018143905617762357\n",
      "Epoch 29/100, Iteration 256/303, Loss: 6.681692320853472e-05\n",
      "Epoch 29/100, Iteration 257/303, Loss: 0.00017400135402567685\n",
      "Epoch 29/100, Iteration 258/303, Loss: 0.0001651233178563416\n",
      "Epoch 29/100, Iteration 259/303, Loss: 0.00034311015042476356\n",
      "Epoch 29/100, Iteration 260/303, Loss: 0.0002605023037176579\n",
      "Epoch 29/100, Iteration 261/303, Loss: 5.650278035318479e-05\n",
      "Epoch 29/100, Iteration 262/303, Loss: 0.00018862217257265002\n",
      "Epoch 29/100, Iteration 263/303, Loss: 5.60316038900055e-05\n",
      "Epoch 29/100, Iteration 264/303, Loss: 5.8969661040464416e-05\n",
      "Epoch 29/100, Iteration 265/303, Loss: 0.00015606656961608678\n",
      "Epoch 29/100, Iteration 266/303, Loss: 5.549273919314146e-05\n",
      "Epoch 29/100, Iteration 267/303, Loss: 0.00016142817912623286\n",
      "Epoch 29/100, Iteration 268/303, Loss: 0.000162929150974378\n",
      "Epoch 29/100, Iteration 269/303, Loss: 5.77472492295783e-05\n",
      "Epoch 29/100, Iteration 270/303, Loss: 8.106265886453912e-05\n",
      "Epoch 29/100, Iteration 271/303, Loss: 3.399842535145581e-05\n",
      "Epoch 29/100, Iteration 272/303, Loss: 0.00024003071303013712\n",
      "Epoch 29/100, Iteration 273/303, Loss: 0.00020830177527386695\n",
      "Epoch 29/100, Iteration 274/303, Loss: 0.0005047352751716971\n",
      "Epoch 29/100, Iteration 275/303, Loss: 0.00013224835856817663\n",
      "Epoch 29/100, Iteration 276/303, Loss: 0.00011399618961149827\n",
      "Epoch 29/100, Iteration 277/303, Loss: 0.00011162007285747677\n",
      "Epoch 29/100, Iteration 278/303, Loss: 4.999269003747031e-05\n",
      "Epoch 29/100, Iteration 279/303, Loss: 0.00014472973998636007\n",
      "Epoch 29/100, Iteration 280/303, Loss: 0.00018661121430341154\n",
      "Epoch 29/100, Iteration 281/303, Loss: 6.324745481833816e-05\n",
      "Epoch 29/100, Iteration 282/303, Loss: 0.00010012170241679996\n",
      "Epoch 29/100, Iteration 283/303, Loss: 0.00011093608191004023\n",
      "Epoch 29/100, Iteration 284/303, Loss: 8.814556349534541e-05\n",
      "Epoch 29/100, Iteration 285/303, Loss: 6.323225534288213e-05\n",
      "Epoch 29/100, Iteration 286/303, Loss: 7.995865598786622e-05\n",
      "Epoch 29/100, Iteration 287/303, Loss: 1.7335867596557364e-05\n",
      "Epoch 29/100, Iteration 288/303, Loss: 5.442019028123468e-05\n",
      "Epoch 29/100, Iteration 289/303, Loss: 0.00016360802692361176\n",
      "Epoch 29/100, Iteration 290/303, Loss: 9.166830568574369e-05\n",
      "Epoch 29/100, Iteration 291/303, Loss: 0.00011670965614030138\n",
      "Epoch 29/100, Iteration 292/303, Loss: 0.00022873212583363056\n",
      "Epoch 29/100, Iteration 293/303, Loss: 0.00021235342137515545\n",
      "Epoch 29/100, Iteration 294/303, Loss: 3.7214867916190997e-06\n",
      "Epoch 29/100, Iteration 295/303, Loss: 9.405919627170078e-06\n",
      "Epoch 29/100, Iteration 296/303, Loss: 0.0001238866534549743\n",
      "Epoch 29/100, Iteration 297/303, Loss: 9.251167648471892e-05\n",
      "Epoch 29/100, Iteration 298/303, Loss: 0.00011376882321201265\n",
      "Epoch 29/100, Iteration 299/303, Loss: 0.00017528027819935232\n",
      "Epoch 29/100, Iteration 300/303, Loss: 0.000115382150397636\n",
      "Epoch 29/100, Iteration 301/303, Loss: 6.594731530640274e-05\n",
      "Epoch 29/100, Iteration 302/303, Loss: 0.0001429932890459895\n",
      "Epoch 29/100, Iteration 303/303, Loss: 1.9444227291387506e-05\n",
      "Epoch 30/100, Iteration 1/303, Loss: 1.6185467757168226e-05\n",
      "Epoch 30/100, Iteration 2/303, Loss: 0.00039837986696511507\n",
      "Epoch 30/100, Iteration 3/303, Loss: 9.643293742556125e-05\n",
      "Epoch 30/100, Iteration 4/303, Loss: 5.553225491894409e-05\n",
      "Epoch 30/100, Iteration 5/303, Loss: 0.00017817954358179122\n",
      "Epoch 30/100, Iteration 6/303, Loss: 4.7784633352421224e-05\n",
      "Epoch 30/100, Iteration 7/303, Loss: 0.00012459189747460186\n",
      "Epoch 30/100, Iteration 8/303, Loss: 8.956932288128883e-05\n",
      "Epoch 30/100, Iteration 9/303, Loss: 0.0001563649857416749\n",
      "Epoch 30/100, Iteration 10/303, Loss: 0.00014011729217600077\n",
      "Epoch 30/100, Iteration 11/303, Loss: 0.00015572994016110897\n",
      "Epoch 30/100, Iteration 12/303, Loss: 7.118137727957219e-05\n",
      "Epoch 30/100, Iteration 13/303, Loss: 1.1316959898977075e-05\n",
      "Epoch 30/100, Iteration 14/303, Loss: 5.172559758648276e-05\n",
      "Epoch 30/100, Iteration 15/303, Loss: 0.0006947558140382171\n",
      "Epoch 30/100, Iteration 16/303, Loss: 5.975090061838273e-06\n",
      "Epoch 30/100, Iteration 17/303, Loss: 0.00014427992573473603\n",
      "Epoch 30/100, Iteration 18/303, Loss: 0.00024224015942309052\n",
      "Epoch 30/100, Iteration 19/303, Loss: 9.748376760398969e-05\n",
      "Epoch 30/100, Iteration 20/303, Loss: 0.00015904991596471518\n",
      "Epoch 30/100, Iteration 21/303, Loss: 8.02952708909288e-05\n",
      "Epoch 30/100, Iteration 22/303, Loss: 0.00018404697766527534\n",
      "Epoch 30/100, Iteration 23/303, Loss: 5.491073170560412e-05\n",
      "Epoch 30/100, Iteration 24/303, Loss: 9.523585322313011e-05\n",
      "Epoch 30/100, Iteration 25/303, Loss: 0.00013759455760009587\n",
      "Epoch 30/100, Iteration 26/303, Loss: 8.250613973359577e-06\n",
      "Epoch 30/100, Iteration 27/303, Loss: 0.0001798721496015787\n",
      "Epoch 30/100, Iteration 28/303, Loss: 8.263136260211468e-05\n",
      "Epoch 30/100, Iteration 29/303, Loss: 1.8960025045089424e-05\n",
      "Epoch 30/100, Iteration 30/303, Loss: 9.55356445047073e-05\n",
      "Epoch 30/100, Iteration 31/303, Loss: 7.419110625050962e-05\n",
      "Epoch 30/100, Iteration 32/303, Loss: 0.00025099984486587346\n",
      "Epoch 30/100, Iteration 33/303, Loss: 0.0001495520700700581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Iteration 34/303, Loss: 0.000144294070196338\n",
      "Epoch 30/100, Iteration 35/303, Loss: 5.983037408441305e-05\n",
      "Epoch 30/100, Iteration 36/303, Loss: 8.33147787488997e-05\n",
      "Epoch 30/100, Iteration 37/303, Loss: 0.00019399433222133666\n",
      "Epoch 30/100, Iteration 38/303, Loss: 5.893228080822155e-05\n",
      "Epoch 30/100, Iteration 39/303, Loss: 0.00027838684036396444\n",
      "Epoch 30/100, Iteration 40/303, Loss: 2.1876188839087263e-05\n",
      "Epoch 30/100, Iteration 41/303, Loss: 0.00012636320025194436\n",
      "Epoch 30/100, Iteration 42/303, Loss: 8.03285583970137e-05\n",
      "Epoch 30/100, Iteration 43/303, Loss: 7.397337321890518e-05\n",
      "Epoch 30/100, Iteration 44/303, Loss: 0.00013054329610895365\n",
      "Epoch 30/100, Iteration 45/303, Loss: 3.426941475481726e-05\n",
      "Epoch 30/100, Iteration 46/303, Loss: 5.15443753101863e-05\n",
      "Epoch 30/100, Iteration 47/303, Loss: 1.1786058166762814e-05\n",
      "Epoch 30/100, Iteration 48/303, Loss: 4.334713230491616e-05\n",
      "Epoch 30/100, Iteration 49/303, Loss: 8.572959632147104e-05\n",
      "Epoch 30/100, Iteration 50/303, Loss: 5.968417463009246e-05\n",
      "Epoch 30/100, Iteration 51/303, Loss: 0.0001310360967181623\n",
      "Epoch 30/100, Iteration 52/303, Loss: 3.510815076879226e-05\n",
      "Epoch 30/100, Iteration 53/303, Loss: 6.368493632180616e-05\n",
      "Epoch 30/100, Iteration 54/303, Loss: 3.167304384987801e-05\n",
      "Epoch 30/100, Iteration 55/303, Loss: 2.4216706151491962e-05\n",
      "Epoch 30/100, Iteration 56/303, Loss: 0.00018858756811823696\n",
      "Epoch 30/100, Iteration 57/303, Loss: 0.00015399987751152366\n",
      "Epoch 30/100, Iteration 58/303, Loss: 1.4117495993559714e-05\n",
      "Epoch 30/100, Iteration 59/303, Loss: 9.752767073223367e-05\n",
      "Epoch 30/100, Iteration 60/303, Loss: 5.0615199143067e-05\n",
      "Epoch 30/100, Iteration 61/303, Loss: 6.052115713828243e-05\n",
      "Epoch 30/100, Iteration 62/303, Loss: 0.0007425696239806712\n",
      "Epoch 30/100, Iteration 63/303, Loss: 0.00014012865722179413\n",
      "Epoch 30/100, Iteration 64/303, Loss: 9.130302350968122e-05\n",
      "Epoch 30/100, Iteration 65/303, Loss: 8.233312837546691e-05\n",
      "Epoch 30/100, Iteration 66/303, Loss: 1.5570274626952596e-05\n",
      "Epoch 30/100, Iteration 67/303, Loss: 4.6437387936748564e-05\n",
      "Epoch 30/100, Iteration 68/303, Loss: 8.107838220894337e-05\n",
      "Epoch 30/100, Iteration 69/303, Loss: 7.833600102458149e-05\n",
      "Epoch 30/100, Iteration 70/303, Loss: 0.0002184186305385083\n",
      "Epoch 30/100, Iteration 71/303, Loss: 0.0001494484895374626\n",
      "Epoch 30/100, Iteration 72/303, Loss: 5.998847336741164e-05\n",
      "Epoch 30/100, Iteration 73/303, Loss: 5.742010398535058e-05\n",
      "Epoch 30/100, Iteration 74/303, Loss: 3.443918831180781e-05\n",
      "Epoch 30/100, Iteration 75/303, Loss: 1.297447488468606e-05\n",
      "Epoch 30/100, Iteration 76/303, Loss: 0.00014844106044620275\n",
      "Epoch 30/100, Iteration 77/303, Loss: 4.925494795315899e-05\n",
      "Epoch 30/100, Iteration 78/303, Loss: 4.245412492309697e-05\n",
      "Epoch 30/100, Iteration 79/303, Loss: 8.460424578515813e-05\n",
      "Epoch 30/100, Iteration 80/303, Loss: 8.120594429783523e-05\n",
      "Epoch 30/100, Iteration 81/303, Loss: 4.0097846067510545e-05\n",
      "Epoch 30/100, Iteration 82/303, Loss: 0.00018486786575522274\n",
      "Epoch 30/100, Iteration 83/303, Loss: 4.677323886426166e-05\n",
      "Epoch 30/100, Iteration 84/303, Loss: 0.00019228411838412285\n",
      "Epoch 30/100, Iteration 85/303, Loss: 0.00013748144556302577\n",
      "Epoch 30/100, Iteration 86/303, Loss: 4.518894638749771e-05\n",
      "Epoch 30/100, Iteration 87/303, Loss: 2.4077420675894246e-05\n",
      "Epoch 30/100, Iteration 88/303, Loss: 5.119728302815929e-05\n",
      "Epoch 30/100, Iteration 89/303, Loss: 2.780496288323775e-05\n",
      "Epoch 30/100, Iteration 90/303, Loss: 0.00013396141002885997\n",
      "Epoch 30/100, Iteration 91/303, Loss: 6.581503839697689e-05\n",
      "Epoch 30/100, Iteration 92/303, Loss: 6.945298810023814e-05\n",
      "Epoch 30/100, Iteration 93/303, Loss: 0.00010146215936401859\n",
      "Epoch 30/100, Iteration 94/303, Loss: 0.00010947417467832565\n",
      "Epoch 30/100, Iteration 95/303, Loss: 5.43911628483329e-05\n",
      "Epoch 30/100, Iteration 96/303, Loss: 9.712493192637339e-05\n",
      "Epoch 30/100, Iteration 97/303, Loss: 4.849890319746919e-05\n",
      "Epoch 30/100, Iteration 98/303, Loss: 0.00012709113070741296\n",
      "Epoch 30/100, Iteration 99/303, Loss: 4.880849155597389e-05\n",
      "Epoch 30/100, Iteration 100/303, Loss: 7.44680583011359e-05\n",
      "Epoch 30/100, Iteration 101/303, Loss: 3.5161883715773e-05\n",
      "Epoch 30/100, Iteration 102/303, Loss: 4.2303261579945683e-05\n",
      "Epoch 30/100, Iteration 103/303, Loss: 0.00016085038078017533\n",
      "Epoch 30/100, Iteration 104/303, Loss: 0.00012401209096424282\n",
      "Epoch 30/100, Iteration 105/303, Loss: 0.0001484367239754647\n",
      "Epoch 30/100, Iteration 106/303, Loss: 0.00019932964642066509\n",
      "Epoch 30/100, Iteration 107/303, Loss: 6.32543515166617e-06\n",
      "Epoch 30/100, Iteration 108/303, Loss: 0.0002085812302539125\n",
      "Epoch 30/100, Iteration 109/303, Loss: 7.290945359272882e-05\n",
      "Epoch 30/100, Iteration 110/303, Loss: 2.6592830181471072e-05\n",
      "Epoch 30/100, Iteration 111/303, Loss: 7.105348049663007e-05\n",
      "Epoch 30/100, Iteration 112/303, Loss: 1.582391450938303e-05\n",
      "Epoch 30/100, Iteration 113/303, Loss: 4.866502058575861e-05\n",
      "Epoch 30/100, Iteration 114/303, Loss: 0.00014978781109675765\n",
      "Epoch 30/100, Iteration 115/303, Loss: 5.381861046771519e-05\n",
      "Epoch 30/100, Iteration 116/303, Loss: 5.495281220646575e-05\n",
      "Epoch 30/100, Iteration 117/303, Loss: 4.3539337639231235e-05\n",
      "Epoch 30/100, Iteration 118/303, Loss: 7.950414874358103e-05\n",
      "Epoch 30/100, Iteration 119/303, Loss: 0.0006680777296423912\n",
      "Epoch 30/100, Iteration 120/303, Loss: 2.2828355213277973e-05\n",
      "Epoch 30/100, Iteration 121/303, Loss: 0.00014811514120083302\n",
      "Epoch 30/100, Iteration 122/303, Loss: 8.439114026259631e-05\n",
      "Epoch 30/100, Iteration 123/303, Loss: 0.0001552976027596742\n",
      "Epoch 30/100, Iteration 124/303, Loss: 2.7820233299280517e-05\n",
      "Epoch 30/100, Iteration 125/303, Loss: 1.5934823750285432e-05\n",
      "Epoch 30/100, Iteration 126/303, Loss: 5.479077299241908e-05\n",
      "Epoch 30/100, Iteration 127/303, Loss: 9.534016135148704e-05\n",
      "Epoch 30/100, Iteration 128/303, Loss: 7.11560423951596e-05\n",
      "Epoch 30/100, Iteration 129/303, Loss: 6.64432009216398e-05\n",
      "Epoch 30/100, Iteration 130/303, Loss: 0.00020436252816580236\n",
      "Epoch 30/100, Iteration 131/303, Loss: 8.63816385390237e-05\n",
      "Epoch 30/100, Iteration 132/303, Loss: 7.958008791320026e-05\n",
      "Epoch 30/100, Iteration 133/303, Loss: 9.391250205226243e-05\n",
      "Epoch 30/100, Iteration 134/303, Loss: 0.00020536407828330994\n",
      "Epoch 30/100, Iteration 135/303, Loss: 0.00018928232020698488\n",
      "Epoch 30/100, Iteration 136/303, Loss: 0.0001366814540233463\n",
      "Epoch 30/100, Iteration 137/303, Loss: 0.00021751655731350183\n",
      "Epoch 30/100, Iteration 138/303, Loss: 4.4845226511824876e-05\n",
      "Epoch 30/100, Iteration 139/303, Loss: 5.8980382164008915e-05\n",
      "Epoch 30/100, Iteration 140/303, Loss: 0.00021482794545590878\n",
      "Epoch 30/100, Iteration 141/303, Loss: 4.2392275645397604e-05\n",
      "Epoch 30/100, Iteration 142/303, Loss: 0.00012576268636621535\n",
      "Epoch 30/100, Iteration 143/303, Loss: 5.039659299654886e-05\n",
      "Epoch 30/100, Iteration 144/303, Loss: 7.440306944772601e-05\n",
      "Epoch 30/100, Iteration 145/303, Loss: 0.00010252716310787946\n",
      "Epoch 30/100, Iteration 146/303, Loss: 3.40201222570613e-05\n",
      "Epoch 30/100, Iteration 147/303, Loss: 5.165153197594918e-05\n",
      "Epoch 30/100, Iteration 148/303, Loss: 9.107326332014054e-05\n",
      "Epoch 30/100, Iteration 149/303, Loss: 3.030452899110969e-05\n",
      "Epoch 30/100, Iteration 150/303, Loss: 0.00027650463744066656\n",
      "Epoch 30/100, Iteration 151/303, Loss: 4.7323148464784026e-05\n",
      "Epoch 30/100, Iteration 152/303, Loss: 0.00010578747605904937\n",
      "Epoch 30/100, Iteration 153/303, Loss: 6.081371248001233e-05\n",
      "Epoch 30/100, Iteration 154/303, Loss: 2.9382914362940937e-05\n",
      "Epoch 30/100, Iteration 155/303, Loss: 8.343961962964386e-05\n",
      "Epoch 30/100, Iteration 156/303, Loss: 0.00014441962412092835\n",
      "Epoch 30/100, Iteration 157/303, Loss: 0.00011582314618863165\n",
      "Epoch 30/100, Iteration 158/303, Loss: 0.00043653868488036096\n",
      "Epoch 30/100, Iteration 159/303, Loss: 0.0001888341357698664\n",
      "Epoch 30/100, Iteration 160/303, Loss: 8.470651664538309e-05\n",
      "Epoch 30/100, Iteration 161/303, Loss: 6.707548163831234e-05\n",
      "Epoch 30/100, Iteration 162/303, Loss: 5.228537702350877e-05\n",
      "Epoch 30/100, Iteration 163/303, Loss: 6.777590169804171e-05\n",
      "Epoch 30/100, Iteration 164/303, Loss: 0.00020535234943963587\n",
      "Epoch 30/100, Iteration 165/303, Loss: 4.99314337503165e-05\n",
      "Epoch 30/100, Iteration 166/303, Loss: 0.00014088107855059206\n",
      "Epoch 30/100, Iteration 167/303, Loss: 3.30243055941537e-05\n",
      "Epoch 30/100, Iteration 168/303, Loss: 4.5652159315068275e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Iteration 169/303, Loss: 7.969645957928151e-05\n",
      "Epoch 30/100, Iteration 170/303, Loss: 3.435764301684685e-05\n",
      "Epoch 30/100, Iteration 171/303, Loss: 1.6423531633336097e-05\n",
      "Epoch 30/100, Iteration 172/303, Loss: 2.6603844162309542e-05\n",
      "Epoch 30/100, Iteration 173/303, Loss: 0.00015635059389751405\n",
      "Epoch 30/100, Iteration 174/303, Loss: 3.306891449028626e-05\n",
      "Epoch 30/100, Iteration 175/303, Loss: 3.7952937418594956e-05\n",
      "Epoch 30/100, Iteration 176/303, Loss: 7.398014713544399e-05\n",
      "Epoch 30/100, Iteration 177/303, Loss: 0.0002590624208096415\n",
      "Epoch 30/100, Iteration 178/303, Loss: 0.00010991914314217865\n",
      "Epoch 30/100, Iteration 179/303, Loss: 0.0002159853611374274\n",
      "Epoch 30/100, Iteration 180/303, Loss: 7.702433504164219e-05\n",
      "Epoch 30/100, Iteration 181/303, Loss: 0.00034308593603782356\n",
      "Epoch 30/100, Iteration 182/303, Loss: 7.347072823904455e-05\n",
      "Epoch 30/100, Iteration 183/303, Loss: 0.00015535832790192217\n",
      "Epoch 30/100, Iteration 184/303, Loss: 4.1383333154954016e-05\n",
      "Epoch 30/100, Iteration 185/303, Loss: 5.932581552769989e-05\n",
      "Epoch 30/100, Iteration 186/303, Loss: 1.881112802948337e-05\n",
      "Epoch 30/100, Iteration 187/303, Loss: 1.1812380762421526e-05\n",
      "Epoch 30/100, Iteration 188/303, Loss: 3.88888074667193e-05\n",
      "Epoch 30/100, Iteration 189/303, Loss: 9.344312275061384e-05\n",
      "Epoch 30/100, Iteration 190/303, Loss: 0.0001612971245776862\n",
      "Epoch 30/100, Iteration 191/303, Loss: 8.09177799965255e-05\n",
      "Epoch 30/100, Iteration 192/303, Loss: 9.076255082618445e-05\n",
      "Epoch 30/100, Iteration 193/303, Loss: 0.00016129342839121819\n",
      "Epoch 30/100, Iteration 194/303, Loss: 0.00018080620793625712\n",
      "Epoch 30/100, Iteration 195/303, Loss: 7.323706813622266e-05\n",
      "Epoch 30/100, Iteration 196/303, Loss: 0.00017823948292061687\n",
      "Epoch 30/100, Iteration 197/303, Loss: 0.00010746849147835746\n",
      "Epoch 30/100, Iteration 198/303, Loss: 7.408173405565321e-05\n",
      "Epoch 30/100, Iteration 199/303, Loss: 8.132604125421494e-05\n",
      "Epoch 30/100, Iteration 200/303, Loss: 7.632563210790977e-05\n",
      "Epoch 30/100, Iteration 201/303, Loss: 7.95874948380515e-05\n",
      "Epoch 30/100, Iteration 202/303, Loss: 0.00022645198623649776\n",
      "Epoch 30/100, Iteration 203/303, Loss: 3.639440183178522e-05\n",
      "Epoch 30/100, Iteration 204/303, Loss: 4.901812280877493e-05\n",
      "Epoch 30/100, Iteration 205/303, Loss: 4.4953842007089406e-05\n",
      "Epoch 30/100, Iteration 206/303, Loss: 6.466892500611721e-06\n",
      "Epoch 30/100, Iteration 207/303, Loss: 0.0002535079838708043\n",
      "Epoch 30/100, Iteration 208/303, Loss: 4.352555697550997e-05\n",
      "Epoch 30/100, Iteration 209/303, Loss: 0.0001432102726539597\n",
      "Epoch 30/100, Iteration 210/303, Loss: 0.00019939447520300746\n",
      "Epoch 30/100, Iteration 211/303, Loss: 0.00011168092169100419\n",
      "Epoch 30/100, Iteration 212/303, Loss: 4.448783511179499e-05\n",
      "Epoch 30/100, Iteration 213/303, Loss: 1.4836507943982724e-05\n",
      "Epoch 30/100, Iteration 214/303, Loss: 1.2128722119086888e-05\n",
      "Epoch 30/100, Iteration 215/303, Loss: 8.854111365508288e-05\n",
      "Epoch 30/100, Iteration 216/303, Loss: 8.313681610161439e-05\n",
      "Epoch 30/100, Iteration 217/303, Loss: 9.715898340800777e-05\n",
      "Epoch 30/100, Iteration 218/303, Loss: 7.153609476517886e-05\n",
      "Epoch 30/100, Iteration 219/303, Loss: 0.00019681452249642462\n",
      "Epoch 30/100, Iteration 220/303, Loss: 0.00010382139589637518\n",
      "Epoch 30/100, Iteration 221/303, Loss: 0.00014972506323829293\n",
      "Epoch 30/100, Iteration 222/303, Loss: 3.638537600636482e-05\n",
      "Epoch 30/100, Iteration 223/303, Loss: 5.8266130508854985e-05\n",
      "Epoch 30/100, Iteration 224/303, Loss: 8.759743650443852e-05\n",
      "Epoch 30/100, Iteration 225/303, Loss: 8.294727740576491e-05\n",
      "Epoch 30/100, Iteration 226/303, Loss: 2.07487064471934e-05\n",
      "Epoch 30/100, Iteration 227/303, Loss: 0.00010455075243953615\n",
      "Epoch 30/100, Iteration 228/303, Loss: 0.00032392313005402684\n",
      "Epoch 30/100, Iteration 229/303, Loss: 6.638479680987075e-05\n",
      "Epoch 30/100, Iteration 230/303, Loss: 0.0002188269281759858\n",
      "Epoch 30/100, Iteration 231/303, Loss: 0.00021106198255438358\n",
      "Epoch 30/100, Iteration 232/303, Loss: 2.2617616195930168e-05\n",
      "Epoch 30/100, Iteration 233/303, Loss: 5.974128362140618e-05\n",
      "Epoch 30/100, Iteration 234/303, Loss: 0.00017350069538224488\n",
      "Epoch 30/100, Iteration 235/303, Loss: 4.423740028869361e-05\n",
      "Epoch 30/100, Iteration 236/303, Loss: 0.00011054294736823067\n",
      "Epoch 30/100, Iteration 237/303, Loss: 6.063504406483844e-05\n",
      "Epoch 30/100, Iteration 238/303, Loss: 4.906982576358132e-05\n",
      "Epoch 30/100, Iteration 239/303, Loss: 0.0002574841200839728\n",
      "Epoch 30/100, Iteration 240/303, Loss: 0.0001084179020836018\n",
      "Epoch 30/100, Iteration 241/303, Loss: 3.427722185733728e-05\n",
      "Epoch 30/100, Iteration 242/303, Loss: 3.673716855701059e-05\n",
      "Epoch 30/100, Iteration 243/303, Loss: 8.019099186640233e-05\n",
      "Epoch 30/100, Iteration 244/303, Loss: 0.00010946769907604903\n",
      "Epoch 30/100, Iteration 245/303, Loss: 0.00020953145576640964\n",
      "Epoch 30/100, Iteration 246/303, Loss: 0.00020584787125699222\n",
      "Epoch 30/100, Iteration 247/303, Loss: 5.285266161081381e-05\n",
      "Epoch 30/100, Iteration 248/303, Loss: 4.090450602234341e-05\n",
      "Epoch 30/100, Iteration 249/303, Loss: 7.868606189731508e-05\n",
      "Epoch 30/100, Iteration 250/303, Loss: 0.00020987259631510824\n",
      "Epoch 30/100, Iteration 251/303, Loss: 0.00023702923499513417\n",
      "Epoch 30/100, Iteration 252/303, Loss: 0.00012206235260237008\n",
      "Epoch 30/100, Iteration 253/303, Loss: 0.00029529668972827494\n",
      "Epoch 30/100, Iteration 254/303, Loss: 3.471766467555426e-05\n",
      "Epoch 30/100, Iteration 255/303, Loss: 0.00014982391439843923\n",
      "Epoch 30/100, Iteration 256/303, Loss: 0.00030405173311010003\n",
      "Epoch 30/100, Iteration 257/303, Loss: 5.5083513871068135e-05\n",
      "Epoch 30/100, Iteration 258/303, Loss: 3.0762759706703946e-05\n",
      "Epoch 30/100, Iteration 259/303, Loss: 0.00010920685599558055\n",
      "Epoch 30/100, Iteration 260/303, Loss: 0.00010968674905598164\n",
      "Epoch 30/100, Iteration 261/303, Loss: 0.0002393322210991755\n",
      "Epoch 30/100, Iteration 262/303, Loss: 0.00015868376067373902\n",
      "Epoch 30/100, Iteration 263/303, Loss: 0.00017340188787784427\n",
      "Epoch 30/100, Iteration 264/303, Loss: 7.617862866027281e-05\n",
      "Epoch 30/100, Iteration 265/303, Loss: 7.160727545851842e-05\n",
      "Epoch 30/100, Iteration 266/303, Loss: 0.00017797492910176516\n",
      "Epoch 30/100, Iteration 267/303, Loss: 1.9507462639012374e-05\n",
      "Epoch 30/100, Iteration 268/303, Loss: 0.0001484785316279158\n",
      "Epoch 30/100, Iteration 269/303, Loss: 9.029227658174932e-05\n",
      "Epoch 30/100, Iteration 270/303, Loss: 0.0001671039790380746\n",
      "Epoch 30/100, Iteration 271/303, Loss: 2.6043508114526048e-05\n",
      "Epoch 30/100, Iteration 272/303, Loss: 6.905592454131693e-05\n",
      "Epoch 30/100, Iteration 273/303, Loss: 0.00019226293079555035\n",
      "Epoch 30/100, Iteration 274/303, Loss: 0.0001007969185593538\n",
      "Epoch 30/100, Iteration 275/303, Loss: 0.00010813624976435676\n",
      "Epoch 30/100, Iteration 276/303, Loss: 3.688591095851734e-05\n",
      "Epoch 30/100, Iteration 277/303, Loss: 0.0001897306792670861\n",
      "Epoch 30/100, Iteration 278/303, Loss: 0.00014521757839247584\n",
      "Epoch 30/100, Iteration 279/303, Loss: 9.710081212688237e-05\n",
      "Epoch 30/100, Iteration 280/303, Loss: 5.492270793183707e-05\n",
      "Epoch 30/100, Iteration 281/303, Loss: 9.54582283156924e-05\n",
      "Epoch 30/100, Iteration 282/303, Loss: 4.630627518054098e-05\n",
      "Epoch 30/100, Iteration 283/303, Loss: 0.00025477001327089965\n",
      "Epoch 30/100, Iteration 284/303, Loss: 6.142936763353646e-05\n",
      "Epoch 30/100, Iteration 285/303, Loss: 0.00023070542374625802\n",
      "Epoch 30/100, Iteration 286/303, Loss: 0.0001546457497170195\n",
      "Epoch 30/100, Iteration 287/303, Loss: 0.00020811827562283725\n",
      "Epoch 30/100, Iteration 288/303, Loss: 8.87236965354532e-05\n",
      "Epoch 30/100, Iteration 289/303, Loss: 0.00029444711981341243\n",
      "Epoch 30/100, Iteration 290/303, Loss: 0.00011633289250312373\n",
      "Epoch 30/100, Iteration 291/303, Loss: 0.00010119008220499381\n",
      "Epoch 30/100, Iteration 292/303, Loss: 6.262605893425643e-05\n",
      "Epoch 30/100, Iteration 293/303, Loss: 5.300945304043125e-06\n",
      "Epoch 30/100, Iteration 294/303, Loss: 0.00014310461119748652\n",
      "Epoch 30/100, Iteration 295/303, Loss: 8.013442857190967e-05\n",
      "Epoch 30/100, Iteration 296/303, Loss: 6.041563756298274e-05\n",
      "Epoch 30/100, Iteration 297/303, Loss: 8.600363798905164e-05\n",
      "Epoch 30/100, Iteration 298/303, Loss: 3.647947232821025e-05\n",
      "Epoch 30/100, Iteration 299/303, Loss: 6.667928391834721e-05\n",
      "Epoch 30/100, Iteration 300/303, Loss: 9.023194434121251e-05\n",
      "Epoch 30/100, Iteration 301/303, Loss: 0.00014155609824229032\n",
      "Epoch 30/100, Iteration 302/303, Loss: 4.160109529038891e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Iteration 303/303, Loss: 3.639374699559994e-05\n",
      "Epoch 31/100, Iteration 1/303, Loss: 1.6334070096490905e-05\n",
      "Epoch 31/100, Iteration 2/303, Loss: 3.550577093847096e-05\n",
      "Epoch 31/100, Iteration 3/303, Loss: 7.577887299703434e-05\n",
      "Epoch 31/100, Iteration 4/303, Loss: 3.1543797376798466e-05\n",
      "Epoch 31/100, Iteration 5/303, Loss: 2.010185744438786e-05\n",
      "Epoch 31/100, Iteration 6/303, Loss: 3.159927291562781e-05\n",
      "Epoch 31/100, Iteration 7/303, Loss: 8.803855598671362e-05\n",
      "Epoch 31/100, Iteration 8/303, Loss: 7.225796434795484e-05\n",
      "Epoch 31/100, Iteration 9/303, Loss: 7.815629214746878e-05\n",
      "Epoch 31/100, Iteration 10/303, Loss: 6.81866513332352e-05\n",
      "Epoch 31/100, Iteration 11/303, Loss: 0.000208154262509197\n",
      "Epoch 31/100, Iteration 12/303, Loss: 0.00012366256851237267\n",
      "Epoch 31/100, Iteration 13/303, Loss: 8.780369535088539e-05\n",
      "Epoch 31/100, Iteration 14/303, Loss: 2.8514101359178312e-05\n",
      "Epoch 31/100, Iteration 15/303, Loss: 1.1014223673555534e-05\n",
      "Epoch 31/100, Iteration 16/303, Loss: 0.00010750823275884613\n",
      "Epoch 31/100, Iteration 17/303, Loss: 0.00014492035552393645\n",
      "Epoch 31/100, Iteration 18/303, Loss: 1.9190589227946475e-05\n",
      "Epoch 31/100, Iteration 19/303, Loss: 9.744166163727641e-05\n",
      "Epoch 31/100, Iteration 20/303, Loss: 0.0001409687101840973\n",
      "Epoch 31/100, Iteration 21/303, Loss: 1.4493516573566012e-05\n",
      "Epoch 31/100, Iteration 22/303, Loss: 7.92037826613523e-05\n",
      "Epoch 31/100, Iteration 23/303, Loss: 3.818254845100455e-05\n",
      "Epoch 31/100, Iteration 24/303, Loss: 0.000173041524249129\n",
      "Epoch 31/100, Iteration 25/303, Loss: 1.1554966476978734e-05\n",
      "Epoch 31/100, Iteration 26/303, Loss: 4.643048669095151e-05\n",
      "Epoch 31/100, Iteration 27/303, Loss: 3.963468407164328e-05\n",
      "Epoch 31/100, Iteration 28/303, Loss: 0.00019705349404830486\n",
      "Epoch 31/100, Iteration 29/303, Loss: 1.715279540803749e-05\n",
      "Epoch 31/100, Iteration 30/303, Loss: 6.597932951990515e-05\n",
      "Epoch 31/100, Iteration 31/303, Loss: 0.00012273206084500998\n",
      "Epoch 31/100, Iteration 32/303, Loss: 9.897579730022699e-05\n",
      "Epoch 31/100, Iteration 33/303, Loss: 7.334873953368515e-05\n",
      "Epoch 31/100, Iteration 34/303, Loss: 0.00011697207082761452\n",
      "Epoch 31/100, Iteration 35/303, Loss: 0.0001495934702688828\n",
      "Epoch 31/100, Iteration 36/303, Loss: 0.00010033063881564885\n",
      "Epoch 31/100, Iteration 37/303, Loss: 8.140082354657352e-05\n",
      "Epoch 31/100, Iteration 38/303, Loss: 0.00012486176274251193\n",
      "Epoch 31/100, Iteration 39/303, Loss: 4.366114444565028e-05\n",
      "Epoch 31/100, Iteration 40/303, Loss: 0.0003042557218577713\n",
      "Epoch 31/100, Iteration 41/303, Loss: 1.8090711819240823e-05\n",
      "Epoch 31/100, Iteration 42/303, Loss: 4.176754009677097e-05\n",
      "Epoch 31/100, Iteration 43/303, Loss: 0.00026463871472515166\n",
      "Epoch 31/100, Iteration 44/303, Loss: 8.77418351592496e-05\n",
      "Epoch 31/100, Iteration 45/303, Loss: 5.808554487884976e-05\n",
      "Epoch 31/100, Iteration 46/303, Loss: 8.484602585667744e-05\n",
      "Epoch 31/100, Iteration 47/303, Loss: 2.879273051803466e-05\n",
      "Epoch 31/100, Iteration 48/303, Loss: 0.00010910131823038682\n",
      "Epoch 31/100, Iteration 49/303, Loss: 6.894001853652298e-05\n",
      "Epoch 31/100, Iteration 50/303, Loss: 0.0001953603932633996\n",
      "Epoch 31/100, Iteration 51/303, Loss: 6.86933781253174e-05\n",
      "Epoch 31/100, Iteration 52/303, Loss: 2.5711746275192127e-05\n",
      "Epoch 31/100, Iteration 53/303, Loss: 4.172831540927291e-05\n",
      "Epoch 31/100, Iteration 54/303, Loss: 0.00011248335795244202\n",
      "Epoch 31/100, Iteration 55/303, Loss: 4.2257714085280895e-05\n",
      "Epoch 31/100, Iteration 56/303, Loss: 3.667597775347531e-05\n",
      "Epoch 31/100, Iteration 57/303, Loss: 0.00010140315862372518\n",
      "Epoch 31/100, Iteration 58/303, Loss: 8.975800301413983e-05\n",
      "Epoch 31/100, Iteration 59/303, Loss: 0.00012173601135145873\n",
      "Epoch 31/100, Iteration 60/303, Loss: 0.00010619848762871698\n",
      "Epoch 31/100, Iteration 61/303, Loss: 4.5721884816884995e-05\n",
      "Epoch 31/100, Iteration 62/303, Loss: 7.81427079346031e-05\n",
      "Epoch 31/100, Iteration 63/303, Loss: 1.9190851162420586e-05\n",
      "Epoch 31/100, Iteration 64/303, Loss: 0.0002012159238802269\n",
      "Epoch 31/100, Iteration 65/303, Loss: 5.704318391508423e-05\n",
      "Epoch 31/100, Iteration 66/303, Loss: 0.0002372146991547197\n",
      "Epoch 31/100, Iteration 67/303, Loss: 5.4667489166604355e-05\n",
      "Epoch 31/100, Iteration 68/303, Loss: 1.0013171959144529e-05\n",
      "Epoch 31/100, Iteration 69/303, Loss: 6.0926045989617705e-05\n",
      "Epoch 31/100, Iteration 70/303, Loss: 4.371464819996618e-05\n",
      "Epoch 31/100, Iteration 71/303, Loss: 0.0001423671783413738\n",
      "Epoch 31/100, Iteration 72/303, Loss: 1.2497254829213489e-05\n",
      "Epoch 31/100, Iteration 73/303, Loss: 6.100223254179582e-05\n",
      "Epoch 31/100, Iteration 74/303, Loss: 0.00019572816381696612\n",
      "Epoch 31/100, Iteration 75/303, Loss: 9.21840692171827e-05\n",
      "Epoch 31/100, Iteration 76/303, Loss: 3.992943311459385e-05\n",
      "Epoch 31/100, Iteration 77/303, Loss: 0.000142349730595015\n",
      "Epoch 31/100, Iteration 78/303, Loss: 0.0002917414531111717\n",
      "Epoch 31/100, Iteration 79/303, Loss: 9.550659160595387e-05\n",
      "Epoch 31/100, Iteration 80/303, Loss: 0.00021960058074910194\n",
      "Epoch 31/100, Iteration 81/303, Loss: 7.74748477851972e-05\n",
      "Epoch 31/100, Iteration 82/303, Loss: 1.8013128283200786e-05\n",
      "Epoch 31/100, Iteration 83/303, Loss: 0.00022337518748827279\n",
      "Epoch 31/100, Iteration 84/303, Loss: 6.930431845830753e-05\n",
      "Epoch 31/100, Iteration 85/303, Loss: 2.0074676285730675e-05\n",
      "Epoch 31/100, Iteration 86/303, Loss: 1.1249872841290198e-05\n",
      "Epoch 31/100, Iteration 87/303, Loss: 4.224002259434201e-05\n",
      "Epoch 31/100, Iteration 88/303, Loss: 2.0960707843187265e-05\n",
      "Epoch 31/100, Iteration 89/303, Loss: 0.00015435331442859024\n",
      "Epoch 31/100, Iteration 90/303, Loss: 2.958790173579473e-05\n",
      "Epoch 31/100, Iteration 91/303, Loss: 0.00011715917935362086\n",
      "Epoch 31/100, Iteration 92/303, Loss: 0.00016111638979054987\n",
      "Epoch 31/100, Iteration 93/303, Loss: 0.00021153604029677808\n",
      "Epoch 31/100, Iteration 94/303, Loss: 0.00010638884850777686\n",
      "Epoch 31/100, Iteration 95/303, Loss: 8.501078264089301e-05\n",
      "Epoch 31/100, Iteration 96/303, Loss: 3.73971852241084e-05\n",
      "Epoch 31/100, Iteration 97/303, Loss: 6.960622704355046e-05\n",
      "Epoch 31/100, Iteration 98/303, Loss: 3.70765155821573e-05\n",
      "Epoch 31/100, Iteration 99/303, Loss: 5.571742804022506e-05\n",
      "Epoch 31/100, Iteration 100/303, Loss: 0.00021116041170898825\n",
      "Epoch 31/100, Iteration 101/303, Loss: 2.2088377590989694e-05\n",
      "Epoch 31/100, Iteration 102/303, Loss: 3.7675265048164874e-05\n",
      "Epoch 31/100, Iteration 103/303, Loss: 8.113546937238425e-05\n",
      "Epoch 31/100, Iteration 104/303, Loss: 0.00021247768017929047\n",
      "Epoch 31/100, Iteration 105/303, Loss: 9.202639193972573e-05\n",
      "Epoch 31/100, Iteration 106/303, Loss: 2.9199278287705965e-05\n",
      "Epoch 31/100, Iteration 107/303, Loss: 2.8089409170206636e-05\n",
      "Epoch 31/100, Iteration 108/303, Loss: 8.575855463277549e-05\n",
      "Epoch 31/100, Iteration 109/303, Loss: 4.1784598579397425e-05\n",
      "Epoch 31/100, Iteration 110/303, Loss: 9.236596088157967e-05\n",
      "Epoch 31/100, Iteration 111/303, Loss: 5.94401171838399e-05\n",
      "Epoch 31/100, Iteration 112/303, Loss: 4.793355765286833e-05\n",
      "Epoch 31/100, Iteration 113/303, Loss: 0.0002045295259449631\n",
      "Epoch 31/100, Iteration 114/303, Loss: 7.533741882070899e-05\n",
      "Epoch 31/100, Iteration 115/303, Loss: 8.844537660479546e-05\n",
      "Epoch 31/100, Iteration 116/303, Loss: 5.4379856010200456e-05\n",
      "Epoch 31/100, Iteration 117/303, Loss: 3.4165848774136975e-05\n",
      "Epoch 31/100, Iteration 118/303, Loss: 6.192622822709382e-05\n",
      "Epoch 31/100, Iteration 119/303, Loss: 3.693142207339406e-05\n",
      "Epoch 31/100, Iteration 120/303, Loss: 0.00012515648268163204\n",
      "Epoch 31/100, Iteration 121/303, Loss: 3.544266292010434e-05\n",
      "Epoch 31/100, Iteration 122/303, Loss: 8.073604840319604e-05\n",
      "Epoch 31/100, Iteration 123/303, Loss: 0.00022569342399947345\n",
      "Epoch 31/100, Iteration 124/303, Loss: 9.018519449455198e-06\n",
      "Epoch 31/100, Iteration 125/303, Loss: 2.97116712317802e-05\n",
      "Epoch 31/100, Iteration 126/303, Loss: 2.831981510098558e-05\n",
      "Epoch 31/100, Iteration 127/303, Loss: 5.452168988995254e-05\n",
      "Epoch 31/100, Iteration 128/303, Loss: 9.410618804395199e-05\n",
      "Epoch 31/100, Iteration 129/303, Loss: 0.0002293812285643071\n",
      "Epoch 31/100, Iteration 130/303, Loss: 2.547282201703638e-05\n",
      "Epoch 31/100, Iteration 131/303, Loss: 0.00029988092137500644\n",
      "Epoch 31/100, Iteration 132/303, Loss: 9.454269275011029e-06\n",
      "Epoch 31/100, Iteration 133/303, Loss: 0.0001197451347252354\n",
      "Epoch 31/100, Iteration 134/303, Loss: 0.00013238523388281465\n",
      "Epoch 31/100, Iteration 135/303, Loss: 4.9512527766637504e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100, Iteration 136/303, Loss: 6.240974471438676e-05\n",
      "Epoch 31/100, Iteration 137/303, Loss: 4.589077434502542e-05\n",
      "Epoch 31/100, Iteration 138/303, Loss: 5.504504224518314e-05\n",
      "Epoch 31/100, Iteration 139/303, Loss: 0.00016757030971348286\n",
      "Epoch 31/100, Iteration 140/303, Loss: 1.675498606346082e-05\n",
      "Epoch 31/100, Iteration 141/303, Loss: 8.634659025119618e-06\n",
      "Epoch 31/100, Iteration 142/303, Loss: 0.00013959358329884708\n",
      "Epoch 31/100, Iteration 143/303, Loss: 6.132557609817013e-05\n",
      "Epoch 31/100, Iteration 144/303, Loss: 5.436065839603543e-05\n",
      "Epoch 31/100, Iteration 145/303, Loss: 2.9394264856819063e-05\n",
      "Epoch 31/100, Iteration 146/303, Loss: 5.706384763470851e-05\n",
      "Epoch 31/100, Iteration 147/303, Loss: 0.00010075883619720116\n",
      "Epoch 31/100, Iteration 148/303, Loss: 0.00014873594045639038\n",
      "Epoch 31/100, Iteration 149/303, Loss: 0.00012236159818712622\n",
      "Epoch 31/100, Iteration 150/303, Loss: 0.00026853036251850426\n",
      "Epoch 31/100, Iteration 151/303, Loss: 1.2654294550884515e-05\n",
      "Epoch 31/100, Iteration 152/303, Loss: 0.0001606346049811691\n",
      "Epoch 31/100, Iteration 153/303, Loss: 0.00011164157331222668\n",
      "Epoch 31/100, Iteration 154/303, Loss: 6.503131589852273e-05\n",
      "Epoch 31/100, Iteration 155/303, Loss: 4.688157787313685e-05\n",
      "Epoch 31/100, Iteration 156/303, Loss: 8.00527777755633e-05\n",
      "Epoch 31/100, Iteration 157/303, Loss: 8.832849562168121e-05\n",
      "Epoch 31/100, Iteration 158/303, Loss: 9.43516060942784e-05\n",
      "Epoch 31/100, Iteration 159/303, Loss: 0.0007362753967754543\n",
      "Epoch 31/100, Iteration 160/303, Loss: 0.00023646437330171466\n",
      "Epoch 31/100, Iteration 161/303, Loss: 0.00011477305088192225\n",
      "Epoch 31/100, Iteration 162/303, Loss: 0.0002060779370367527\n",
      "Epoch 31/100, Iteration 163/303, Loss: 6.360127736115828e-05\n",
      "Epoch 31/100, Iteration 164/303, Loss: 9.847540786722675e-05\n",
      "Epoch 31/100, Iteration 165/303, Loss: 4.926472684019245e-05\n",
      "Epoch 31/100, Iteration 166/303, Loss: 0.00011748779070330784\n",
      "Epoch 31/100, Iteration 167/303, Loss: 2.7488753403304145e-05\n",
      "Epoch 31/100, Iteration 168/303, Loss: 4.2106315959244967e-05\n",
      "Epoch 31/100, Iteration 169/303, Loss: 3.432079392950982e-05\n",
      "Epoch 31/100, Iteration 170/303, Loss: 0.0003346080775372684\n",
      "Epoch 31/100, Iteration 171/303, Loss: 0.0001514033938292414\n",
      "Epoch 31/100, Iteration 172/303, Loss: 7.308142085094005e-05\n",
      "Epoch 31/100, Iteration 173/303, Loss: 0.00010014423605753109\n",
      "Epoch 31/100, Iteration 174/303, Loss: 0.00021360920800361782\n",
      "Epoch 31/100, Iteration 175/303, Loss: 0.0001140731037594378\n",
      "Epoch 31/100, Iteration 176/303, Loss: 0.00011272107803961262\n",
      "Epoch 31/100, Iteration 177/303, Loss: 0.00013069472333882004\n",
      "Epoch 31/100, Iteration 178/303, Loss: 7.560614176327363e-05\n",
      "Epoch 31/100, Iteration 179/303, Loss: 5.1521397836040705e-05\n",
      "Epoch 31/100, Iteration 180/303, Loss: 0.00019896161393262446\n",
      "Epoch 31/100, Iteration 181/303, Loss: 3.0558425351046026e-05\n",
      "Epoch 31/100, Iteration 182/303, Loss: 3.893042594427243e-05\n",
      "Epoch 31/100, Iteration 183/303, Loss: 5.5280292144743726e-05\n",
      "Epoch 31/100, Iteration 184/303, Loss: 0.00010227932943962514\n",
      "Epoch 31/100, Iteration 185/303, Loss: 0.00017759599722921848\n",
      "Epoch 31/100, Iteration 186/303, Loss: 0.00014641440066043288\n",
      "Epoch 31/100, Iteration 187/303, Loss: 0.000102444231742993\n",
      "Epoch 31/100, Iteration 188/303, Loss: 0.00017691477842163295\n",
      "Epoch 31/100, Iteration 189/303, Loss: 7.901378558017313e-05\n",
      "Epoch 31/100, Iteration 190/303, Loss: 0.00023441592929884791\n",
      "Epoch 31/100, Iteration 191/303, Loss: 6.75334595143795e-05\n",
      "Epoch 31/100, Iteration 192/303, Loss: 0.00013924780068919063\n",
      "Epoch 31/100, Iteration 193/303, Loss: 8.691679977346212e-05\n",
      "Epoch 31/100, Iteration 194/303, Loss: 0.00016342842718586326\n",
      "Epoch 31/100, Iteration 195/303, Loss: 2.156776827177964e-05\n",
      "Epoch 31/100, Iteration 196/303, Loss: 0.00017956247029360384\n",
      "Epoch 31/100, Iteration 197/303, Loss: 5.772090662503615e-05\n",
      "Epoch 31/100, Iteration 198/303, Loss: 3.1477789889322594e-05\n",
      "Epoch 31/100, Iteration 199/303, Loss: 6.91541499691084e-05\n",
      "Epoch 31/100, Iteration 200/303, Loss: 0.0001022762298816815\n",
      "Epoch 31/100, Iteration 201/303, Loss: 7.617921801283956e-05\n",
      "Epoch 31/100, Iteration 202/303, Loss: 1.7405101971235126e-05\n",
      "Epoch 31/100, Iteration 203/303, Loss: 4.557985084829852e-05\n",
      "Epoch 31/100, Iteration 204/303, Loss: 0.0003040252486243844\n",
      "Epoch 31/100, Iteration 205/303, Loss: 0.00010417269368190318\n",
      "Epoch 31/100, Iteration 206/303, Loss: 2.439418858557474e-05\n",
      "Epoch 31/100, Iteration 207/303, Loss: 6.605309317819774e-05\n",
      "Epoch 31/100, Iteration 208/303, Loss: 1.177501144411508e-05\n",
      "Epoch 31/100, Iteration 209/303, Loss: 2.696243791433517e-05\n",
      "Epoch 31/100, Iteration 210/303, Loss: 0.00022401942987926304\n",
      "Epoch 31/100, Iteration 211/303, Loss: 0.00012691660958807915\n",
      "Epoch 31/100, Iteration 212/303, Loss: 8.087816968327388e-05\n",
      "Epoch 31/100, Iteration 213/303, Loss: 3.915448178304359e-05\n",
      "Epoch 31/100, Iteration 214/303, Loss: 7.741460285615176e-05\n",
      "Epoch 31/100, Iteration 215/303, Loss: 0.00014054491475690156\n",
      "Epoch 31/100, Iteration 216/303, Loss: 0.0001280622382182628\n",
      "Epoch 31/100, Iteration 217/303, Loss: 0.00011175452527822927\n",
      "Epoch 31/100, Iteration 218/303, Loss: 0.00012955229612998664\n",
      "Epoch 31/100, Iteration 219/303, Loss: 5.795893230242655e-05\n",
      "Epoch 31/100, Iteration 220/303, Loss: 0.00014044881390873343\n",
      "Epoch 31/100, Iteration 221/303, Loss: 0.00011967390310019255\n",
      "Epoch 31/100, Iteration 222/303, Loss: 7.650696352357045e-05\n",
      "Epoch 31/100, Iteration 223/303, Loss: 0.0001411630364600569\n",
      "Epoch 31/100, Iteration 224/303, Loss: 8.735486517252866e-06\n",
      "Epoch 31/100, Iteration 225/303, Loss: 8.451650501228869e-05\n",
      "Epoch 31/100, Iteration 226/303, Loss: 7.837657904019579e-05\n",
      "Epoch 31/100, Iteration 227/303, Loss: 0.00018610118422657251\n",
      "Epoch 31/100, Iteration 228/303, Loss: 0.00011178116255905479\n",
      "Epoch 31/100, Iteration 229/303, Loss: 5.311854329193011e-05\n",
      "Epoch 31/100, Iteration 230/303, Loss: 9.814409713726491e-05\n",
      "Epoch 31/100, Iteration 231/303, Loss: 0.00011614059621933848\n",
      "Epoch 31/100, Iteration 232/303, Loss: 0.00012902557500638068\n",
      "Epoch 31/100, Iteration 233/303, Loss: 8.932051423471421e-05\n",
      "Epoch 31/100, Iteration 234/303, Loss: 8.254031126853079e-05\n",
      "Epoch 31/100, Iteration 235/303, Loss: 5.5194170272443444e-05\n",
      "Epoch 31/100, Iteration 236/303, Loss: 0.00016617719666101038\n",
      "Epoch 31/100, Iteration 237/303, Loss: 7.391420513158664e-05\n",
      "Epoch 31/100, Iteration 238/303, Loss: 2.831183337548282e-06\n",
      "Epoch 31/100, Iteration 239/303, Loss: 3.423931048018858e-05\n",
      "Epoch 31/100, Iteration 240/303, Loss: 6.451702938647941e-05\n",
      "Epoch 31/100, Iteration 241/303, Loss: 0.0001439274928998202\n",
      "Epoch 31/100, Iteration 242/303, Loss: 7.982621173141524e-05\n",
      "Epoch 31/100, Iteration 243/303, Loss: 8.884961425792426e-05\n",
      "Epoch 31/100, Iteration 244/303, Loss: 6.27518747933209e-05\n",
      "Epoch 31/100, Iteration 245/303, Loss: 7.734621613053605e-05\n",
      "Epoch 31/100, Iteration 246/303, Loss: 0.0002973597147502005\n",
      "Epoch 31/100, Iteration 247/303, Loss: 0.00025212785112671554\n",
      "Epoch 31/100, Iteration 248/303, Loss: 0.00036380975507199764\n",
      "Epoch 31/100, Iteration 249/303, Loss: 0.00018932951206807047\n",
      "Epoch 31/100, Iteration 250/303, Loss: 4.821488619199954e-05\n",
      "Epoch 31/100, Iteration 251/303, Loss: 6.57116252114065e-05\n",
      "Epoch 31/100, Iteration 252/303, Loss: 9.681646770332009e-05\n",
      "Epoch 31/100, Iteration 253/303, Loss: 7.793781696818769e-05\n",
      "Epoch 31/100, Iteration 254/303, Loss: 8.202792378142476e-05\n",
      "Epoch 31/100, Iteration 255/303, Loss: 2.756745379883796e-05\n",
      "Epoch 31/100, Iteration 256/303, Loss: 8.51415388751775e-05\n",
      "Epoch 31/100, Iteration 257/303, Loss: 6.87040010234341e-05\n",
      "Epoch 31/100, Iteration 258/303, Loss: 6.381096318364143e-05\n",
      "Epoch 31/100, Iteration 259/303, Loss: 0.0002049838803941384\n",
      "Epoch 31/100, Iteration 260/303, Loss: 0.00011596472177188843\n",
      "Epoch 31/100, Iteration 261/303, Loss: 0.0006353671196848154\n",
      "Epoch 31/100, Iteration 262/303, Loss: 7.684817319386639e-06\n",
      "Epoch 31/100, Iteration 263/303, Loss: 2.006903014262207e-05\n",
      "Epoch 31/100, Iteration 264/303, Loss: 6.053244578652084e-05\n",
      "Epoch 31/100, Iteration 265/303, Loss: 2.0463687178562395e-05\n",
      "Epoch 31/100, Iteration 266/303, Loss: 0.0004801867762580514\n",
      "Epoch 31/100, Iteration 267/303, Loss: 0.00015148766397032887\n",
      "Epoch 31/100, Iteration 268/303, Loss: 0.00013886031229048967\n",
      "Epoch 31/100, Iteration 269/303, Loss: 2.9689901566598564e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100, Iteration 270/303, Loss: 9.02307583601214e-05\n",
      "Epoch 31/100, Iteration 271/303, Loss: 9.900923760142177e-05\n",
      "Epoch 31/100, Iteration 272/303, Loss: 0.000273957964964211\n",
      "Epoch 31/100, Iteration 273/303, Loss: 7.928164268378168e-05\n",
      "Epoch 31/100, Iteration 274/303, Loss: 4.6651792217744514e-05\n",
      "Epoch 31/100, Iteration 275/303, Loss: 9.240178042091429e-05\n",
      "Epoch 31/100, Iteration 276/303, Loss: 1.5399366020574234e-05\n",
      "Epoch 31/100, Iteration 277/303, Loss: 4.645949957193807e-05\n",
      "Epoch 31/100, Iteration 278/303, Loss: 4.064650056534447e-05\n",
      "Epoch 31/100, Iteration 279/303, Loss: 9.226072143064812e-05\n",
      "Epoch 31/100, Iteration 280/303, Loss: 0.00012221929500810802\n",
      "Epoch 31/100, Iteration 281/303, Loss: 9.9146731372457e-05\n",
      "Epoch 31/100, Iteration 282/303, Loss: 3.461455708020367e-05\n",
      "Epoch 31/100, Iteration 283/303, Loss: 2.986242361657787e-05\n",
      "Epoch 31/100, Iteration 284/303, Loss: 3.553707210812718e-05\n",
      "Epoch 31/100, Iteration 285/303, Loss: 0.00017234022379852831\n",
      "Epoch 31/100, Iteration 286/303, Loss: 2.5871075195027515e-05\n",
      "Epoch 31/100, Iteration 287/303, Loss: 0.00019028437964152545\n",
      "Epoch 31/100, Iteration 288/303, Loss: 8.999390411190689e-05\n",
      "Epoch 31/100, Iteration 289/303, Loss: 0.0004053053562529385\n",
      "Epoch 31/100, Iteration 290/303, Loss: 4.3960728362435475e-05\n",
      "Epoch 31/100, Iteration 291/303, Loss: 3.476758502074517e-05\n",
      "Epoch 31/100, Iteration 292/303, Loss: 0.00010912585275946185\n",
      "Epoch 31/100, Iteration 293/303, Loss: 0.00012294662883505225\n",
      "Epoch 31/100, Iteration 294/303, Loss: 0.00012447753397282213\n",
      "Epoch 31/100, Iteration 295/303, Loss: 0.00011566738976398483\n",
      "Epoch 31/100, Iteration 296/303, Loss: 7.081661169650033e-05\n",
      "Epoch 31/100, Iteration 297/303, Loss: 6.525756907649338e-05\n",
      "Epoch 31/100, Iteration 298/303, Loss: 7.67091623856686e-05\n",
      "Epoch 31/100, Iteration 299/303, Loss: 3.801750062848441e-05\n",
      "Epoch 31/100, Iteration 300/303, Loss: 4.027175236842595e-05\n",
      "Epoch 31/100, Iteration 301/303, Loss: 0.00010474805458215997\n",
      "Epoch 31/100, Iteration 302/303, Loss: 2.1560212189797312e-05\n",
      "Epoch 31/100, Iteration 303/303, Loss: 4.7892531256366055e-06\n",
      "Epoch 32/100, Iteration 1/303, Loss: 7.587410800624639e-05\n",
      "Epoch 32/100, Iteration 2/303, Loss: 9.171183046419173e-05\n",
      "Epoch 32/100, Iteration 3/303, Loss: 0.00011652067041723058\n",
      "Epoch 32/100, Iteration 4/303, Loss: 0.000196613633306697\n",
      "Epoch 32/100, Iteration 5/303, Loss: 8.821061055641621e-05\n",
      "Epoch 32/100, Iteration 6/303, Loss: 0.0002688977401703596\n",
      "Epoch 32/100, Iteration 7/303, Loss: 2.1765768906334415e-05\n",
      "Epoch 32/100, Iteration 8/303, Loss: 3.4123120258300332e-06\n",
      "Epoch 32/100, Iteration 9/303, Loss: 8.460215030936524e-05\n",
      "Epoch 32/100, Iteration 10/303, Loss: 0.00012458558194339275\n",
      "Epoch 32/100, Iteration 11/303, Loss: 3.378943438292481e-05\n",
      "Epoch 32/100, Iteration 12/303, Loss: 0.00010141149687115103\n",
      "Epoch 32/100, Iteration 13/303, Loss: 0.00023922788386698812\n",
      "Epoch 32/100, Iteration 14/303, Loss: 9.179439075523987e-05\n",
      "Epoch 32/100, Iteration 15/303, Loss: 0.00013626282452605665\n",
      "Epoch 32/100, Iteration 16/303, Loss: 4.2083600419573486e-05\n",
      "Epoch 32/100, Iteration 17/303, Loss: 1.324881122855004e-05\n",
      "Epoch 32/100, Iteration 18/303, Loss: 2.643451080075465e-05\n",
      "Epoch 32/100, Iteration 19/303, Loss: 4.799378075404093e-05\n",
      "Epoch 32/100, Iteration 20/303, Loss: 0.00030261778738349676\n",
      "Epoch 32/100, Iteration 21/303, Loss: 4.6863631723681465e-05\n",
      "Epoch 32/100, Iteration 22/303, Loss: 9.269058500649408e-05\n",
      "Epoch 32/100, Iteration 23/303, Loss: 0.00010819350427482277\n",
      "Epoch 32/100, Iteration 24/303, Loss: 1.64044504344929e-05\n",
      "Epoch 32/100, Iteration 25/303, Loss: 0.00011456019274191931\n",
      "Epoch 32/100, Iteration 26/303, Loss: 3.9934443520905916e-06\n",
      "Epoch 32/100, Iteration 27/303, Loss: 0.0001386377844028175\n",
      "Epoch 32/100, Iteration 28/303, Loss: 0.00010777243005577475\n",
      "Epoch 32/100, Iteration 29/303, Loss: 8.43157249619253e-05\n",
      "Epoch 32/100, Iteration 30/303, Loss: 0.00013296623365022242\n",
      "Epoch 32/100, Iteration 31/303, Loss: 9.942458564182743e-05\n",
      "Epoch 32/100, Iteration 32/303, Loss: 6.237624620553106e-05\n",
      "Epoch 32/100, Iteration 33/303, Loss: 5.680135654984042e-05\n",
      "Epoch 32/100, Iteration 34/303, Loss: 9.027888881973922e-05\n",
      "Epoch 32/100, Iteration 35/303, Loss: 6.055464837118052e-05\n",
      "Epoch 32/100, Iteration 36/303, Loss: 3.2084386475617066e-05\n",
      "Epoch 32/100, Iteration 37/303, Loss: 0.00024961261078715324\n",
      "Epoch 32/100, Iteration 38/303, Loss: 4.275622995919548e-05\n",
      "Epoch 32/100, Iteration 39/303, Loss: 0.0001285817415919155\n",
      "Epoch 32/100, Iteration 40/303, Loss: 9.116586443269625e-05\n",
      "Epoch 32/100, Iteration 41/303, Loss: 2.819115798047278e-05\n",
      "Epoch 32/100, Iteration 42/303, Loss: 2.931701146735577e-06\n",
      "Epoch 32/100, Iteration 43/303, Loss: 8.944236469687894e-05\n",
      "Epoch 32/100, Iteration 44/303, Loss: 0.00013811333337798715\n",
      "Epoch 32/100, Iteration 45/303, Loss: 4.4008025724906474e-05\n",
      "Epoch 32/100, Iteration 46/303, Loss: 4.0256309148389846e-05\n",
      "Epoch 32/100, Iteration 47/303, Loss: 0.00012316522770561278\n",
      "Epoch 32/100, Iteration 48/303, Loss: 0.00011833572352770716\n",
      "Epoch 32/100, Iteration 49/303, Loss: 3.786366869462654e-05\n",
      "Epoch 32/100, Iteration 50/303, Loss: 7.59404429118149e-05\n",
      "Epoch 32/100, Iteration 51/303, Loss: 0.000133854104205966\n",
      "Epoch 32/100, Iteration 52/303, Loss: 0.0001351160171907395\n",
      "Epoch 32/100, Iteration 53/303, Loss: 0.0001612122287042439\n",
      "Epoch 32/100, Iteration 54/303, Loss: 8.875672938302159e-05\n",
      "Epoch 32/100, Iteration 55/303, Loss: 0.0007791701355017722\n",
      "Epoch 32/100, Iteration 56/303, Loss: 6.882143497932702e-05\n",
      "Epoch 32/100, Iteration 57/303, Loss: 8.586643525632098e-05\n",
      "Epoch 32/100, Iteration 58/303, Loss: 6.198036135174334e-05\n",
      "Epoch 32/100, Iteration 59/303, Loss: 0.0001619525719434023\n",
      "Epoch 32/100, Iteration 60/303, Loss: 6.94609188940376e-05\n",
      "Epoch 32/100, Iteration 61/303, Loss: 2.4553710318286903e-05\n",
      "Epoch 32/100, Iteration 62/303, Loss: 2.844661685230676e-05\n",
      "Epoch 32/100, Iteration 63/303, Loss: 0.0004743803001474589\n",
      "Epoch 32/100, Iteration 64/303, Loss: 7.187906157923862e-05\n",
      "Epoch 32/100, Iteration 65/303, Loss: 0.00015049189096316695\n",
      "Epoch 32/100, Iteration 66/303, Loss: 9.717186185298488e-05\n",
      "Epoch 32/100, Iteration 67/303, Loss: 1.8187625755672343e-05\n",
      "Epoch 32/100, Iteration 68/303, Loss: 0.00022353127133101225\n",
      "Epoch 32/100, Iteration 69/303, Loss: 7.656621892238036e-05\n",
      "Epoch 32/100, Iteration 70/303, Loss: 0.00020397012121975422\n",
      "Epoch 32/100, Iteration 71/303, Loss: 0.00018580326286610216\n",
      "Epoch 32/100, Iteration 72/303, Loss: 4.651432391256094e-05\n",
      "Epoch 32/100, Iteration 73/303, Loss: 1.561176759423688e-05\n",
      "Epoch 32/100, Iteration 74/303, Loss: 0.00013417715672403574\n",
      "Epoch 32/100, Iteration 75/303, Loss: 2.851053068297915e-05\n",
      "Epoch 32/100, Iteration 76/303, Loss: 4.771187377627939e-05\n",
      "Epoch 32/100, Iteration 77/303, Loss: 4.833241837332025e-05\n",
      "Epoch 32/100, Iteration 78/303, Loss: 0.00031942533678375185\n",
      "Epoch 32/100, Iteration 79/303, Loss: 0.00016643249546177685\n",
      "Epoch 32/100, Iteration 80/303, Loss: 6.883939477120293e-06\n",
      "Epoch 32/100, Iteration 81/303, Loss: 0.00013203702110331506\n",
      "Epoch 32/100, Iteration 82/303, Loss: 0.00016074649465736002\n",
      "Epoch 32/100, Iteration 83/303, Loss: 0.00026705212076194584\n",
      "Epoch 32/100, Iteration 84/303, Loss: 0.00011187240306753665\n",
      "Epoch 32/100, Iteration 85/303, Loss: 0.00016328190395142883\n",
      "Epoch 32/100, Iteration 86/303, Loss: 7.046370592433959e-05\n",
      "Epoch 32/100, Iteration 87/303, Loss: 0.00013207635493017733\n",
      "Epoch 32/100, Iteration 88/303, Loss: 4.751237065647729e-05\n",
      "Epoch 32/100, Iteration 89/303, Loss: 7.617718438268639e-06\n",
      "Epoch 32/100, Iteration 90/303, Loss: 1.4229173757485114e-05\n",
      "Epoch 32/100, Iteration 91/303, Loss: 0.00012132873962400481\n",
      "Epoch 32/100, Iteration 92/303, Loss: 9.753982885740697e-05\n",
      "Epoch 32/100, Iteration 93/303, Loss: 5.2838084229733795e-05\n",
      "Epoch 32/100, Iteration 94/303, Loss: 6.368443428073078e-05\n",
      "Epoch 32/100, Iteration 95/303, Loss: 0.0002177186106564477\n",
      "Epoch 32/100, Iteration 96/303, Loss: 3.5895307519240305e-05\n",
      "Epoch 32/100, Iteration 97/303, Loss: 0.00032114831265062094\n",
      "Epoch 32/100, Iteration 98/303, Loss: 0.0002589586947578937\n",
      "Epoch 32/100, Iteration 99/303, Loss: 0.00013278810365591198\n",
      "Epoch 32/100, Iteration 100/303, Loss: 7.158692460507154e-05\n",
      "Epoch 32/100, Iteration 101/303, Loss: 0.0006009333883412182\n",
      "Epoch 32/100, Iteration 102/303, Loss: 3.6951205402147025e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100, Iteration 103/303, Loss: 4.5937238610349596e-05\n",
      "Epoch 32/100, Iteration 104/303, Loss: 6.36572003713809e-05\n",
      "Epoch 32/100, Iteration 105/303, Loss: 1.8390353943686932e-05\n",
      "Epoch 32/100, Iteration 106/303, Loss: 3.3390228054486215e-05\n",
      "Epoch 32/100, Iteration 107/303, Loss: 2.988697997352574e-05\n",
      "Epoch 32/100, Iteration 108/303, Loss: 0.0001471220894018188\n",
      "Epoch 32/100, Iteration 109/303, Loss: 3.7430661905091256e-05\n",
      "Epoch 32/100, Iteration 110/303, Loss: 0.0002658520534168929\n",
      "Epoch 32/100, Iteration 111/303, Loss: 0.00020000374934170395\n",
      "Epoch 32/100, Iteration 112/303, Loss: 0.00013496774772647768\n",
      "Epoch 32/100, Iteration 113/303, Loss: 8.542087743990123e-05\n",
      "Epoch 32/100, Iteration 114/303, Loss: 8.282929775305092e-05\n",
      "Epoch 32/100, Iteration 115/303, Loss: 9.857564873527735e-05\n",
      "Epoch 32/100, Iteration 116/303, Loss: 5.381083974498324e-05\n",
      "Epoch 32/100, Iteration 117/303, Loss: 8.246776997111738e-05\n",
      "Epoch 32/100, Iteration 118/303, Loss: 0.00011127402103738859\n",
      "Epoch 32/100, Iteration 119/303, Loss: 8.001416426850483e-05\n",
      "Epoch 32/100, Iteration 120/303, Loss: 3.77226278942544e-05\n",
      "Epoch 32/100, Iteration 121/303, Loss: 7.773490506224334e-05\n",
      "Epoch 32/100, Iteration 122/303, Loss: 9.836853860178962e-05\n",
      "Epoch 32/100, Iteration 123/303, Loss: 4.182672273600474e-05\n",
      "Epoch 32/100, Iteration 124/303, Loss: 0.00010270631173625588\n",
      "Epoch 32/100, Iteration 125/303, Loss: 6.85698541929014e-05\n",
      "Epoch 32/100, Iteration 126/303, Loss: 2.431081884424202e-05\n",
      "Epoch 32/100, Iteration 127/303, Loss: 3.818379627773538e-05\n",
      "Epoch 32/100, Iteration 128/303, Loss: 4.2011888581328094e-05\n",
      "Epoch 32/100, Iteration 129/303, Loss: 5.1391831220826134e-05\n",
      "Epoch 32/100, Iteration 130/303, Loss: 0.00011867140710819513\n",
      "Epoch 32/100, Iteration 131/303, Loss: 8.059468382271007e-05\n",
      "Epoch 32/100, Iteration 132/303, Loss: 4.9943748308578506e-05\n",
      "Epoch 32/100, Iteration 133/303, Loss: 8.89417715370655e-05\n",
      "Epoch 32/100, Iteration 134/303, Loss: 7.59081231080927e-05\n",
      "Epoch 32/100, Iteration 135/303, Loss: 0.0001533337781438604\n",
      "Epoch 32/100, Iteration 136/303, Loss: 5.166755727259442e-05\n",
      "Epoch 32/100, Iteration 137/303, Loss: 2.1679406927432865e-05\n",
      "Epoch 32/100, Iteration 138/303, Loss: 0.0001453938166378066\n",
      "Epoch 32/100, Iteration 139/303, Loss: 7.175630162237212e-05\n",
      "Epoch 32/100, Iteration 140/303, Loss: 8.815337059786543e-05\n",
      "Epoch 32/100, Iteration 141/303, Loss: 0.00011108528269687667\n",
      "Epoch 32/100, Iteration 142/303, Loss: 1.3685959856957197e-05\n",
      "Epoch 32/100, Iteration 143/303, Loss: 4.488662671064958e-05\n",
      "Epoch 32/100, Iteration 144/303, Loss: 3.294937778264284e-05\n",
      "Epoch 32/100, Iteration 145/303, Loss: 6.474550900748e-05\n",
      "Epoch 32/100, Iteration 146/303, Loss: 1.4564664525096305e-05\n",
      "Epoch 32/100, Iteration 147/303, Loss: 0.00031494616996496916\n",
      "Epoch 32/100, Iteration 148/303, Loss: 1.8185888620791957e-05\n",
      "Epoch 32/100, Iteration 149/303, Loss: 8.990864444058388e-05\n",
      "Epoch 32/100, Iteration 150/303, Loss: 8.005213749129325e-05\n",
      "Epoch 32/100, Iteration 151/303, Loss: 0.00010488517727935687\n",
      "Epoch 32/100, Iteration 152/303, Loss: 6.677220517303795e-05\n",
      "Epoch 32/100, Iteration 153/303, Loss: 0.00011888699373230338\n",
      "Epoch 32/100, Iteration 154/303, Loss: 0.00021983426995575428\n",
      "Epoch 32/100, Iteration 155/303, Loss: 8.354120654985309e-05\n",
      "Epoch 32/100, Iteration 156/303, Loss: 0.00010970461880788207\n",
      "Epoch 32/100, Iteration 157/303, Loss: 5.464603236760013e-05\n",
      "Epoch 32/100, Iteration 158/303, Loss: 0.00019878512830473483\n",
      "Epoch 32/100, Iteration 159/303, Loss: 1.8449994968250394e-05\n",
      "Epoch 32/100, Iteration 160/303, Loss: 8.59080464579165e-05\n",
      "Epoch 32/100, Iteration 161/303, Loss: 0.0001229438785230741\n",
      "Epoch 32/100, Iteration 162/303, Loss: 0.00021851705969311297\n",
      "Epoch 32/100, Iteration 163/303, Loss: 1.1577594705158845e-05\n",
      "Epoch 32/100, Iteration 164/303, Loss: 0.00023632109514437616\n",
      "Epoch 32/100, Iteration 165/303, Loss: 3.559486867743544e-05\n",
      "Epoch 32/100, Iteration 166/303, Loss: 5.353233791538514e-05\n",
      "Epoch 32/100, Iteration 167/303, Loss: 0.00011413305765017867\n",
      "Epoch 32/100, Iteration 168/303, Loss: 0.0001560032251290977\n",
      "Epoch 32/100, Iteration 169/303, Loss: 8.757901377975941e-05\n",
      "Epoch 32/100, Iteration 170/303, Loss: 0.000160328607307747\n",
      "Epoch 32/100, Iteration 171/303, Loss: 5.0319507863605395e-05\n",
      "Epoch 32/100, Iteration 172/303, Loss: 0.00010136955097550526\n",
      "Epoch 32/100, Iteration 173/303, Loss: 1.0229249710391741e-05\n",
      "Epoch 32/100, Iteration 174/303, Loss: 5.5062122555682436e-05\n",
      "Epoch 32/100, Iteration 175/303, Loss: 1.2738500117848162e-05\n",
      "Epoch 32/100, Iteration 176/303, Loss: 6.475031113950536e-05\n",
      "Epoch 32/100, Iteration 177/303, Loss: 2.3954820790095255e-05\n",
      "Epoch 32/100, Iteration 178/303, Loss: 5.083637370262295e-05\n",
      "Epoch 32/100, Iteration 179/303, Loss: 3.800429476541467e-05\n",
      "Epoch 32/100, Iteration 180/303, Loss: 2.3487917133024894e-05\n",
      "Epoch 32/100, Iteration 181/303, Loss: 1.621148840058595e-05\n",
      "Epoch 32/100, Iteration 182/303, Loss: 0.00016335261170752347\n",
      "Epoch 32/100, Iteration 183/303, Loss: 5.138325286679901e-05\n",
      "Epoch 32/100, Iteration 184/303, Loss: 0.00014959453255869448\n",
      "Epoch 32/100, Iteration 185/303, Loss: 7.68881454860093e-06\n",
      "Epoch 32/100, Iteration 186/303, Loss: 3.76984144168091e-06\n",
      "Epoch 32/100, Iteration 187/303, Loss: 9.063509060069919e-05\n",
      "Epoch 32/100, Iteration 188/303, Loss: 2.866917202482e-05\n",
      "Epoch 32/100, Iteration 189/303, Loss: 3.203329470125027e-05\n",
      "Epoch 32/100, Iteration 190/303, Loss: 0.00013391066750045866\n",
      "Epoch 32/100, Iteration 191/303, Loss: 5.864926424692385e-05\n",
      "Epoch 32/100, Iteration 192/303, Loss: 2.480468356225174e-05\n",
      "Epoch 32/100, Iteration 193/303, Loss: 0.00010049372940557078\n",
      "Epoch 32/100, Iteration 194/303, Loss: 2.1082378225401044e-05\n",
      "Epoch 32/100, Iteration 195/303, Loss: 3.5473371099215e-05\n",
      "Epoch 32/100, Iteration 196/303, Loss: 0.0001476031611673534\n",
      "Epoch 32/100, Iteration 197/303, Loss: 2.3239861548063345e-05\n",
      "Epoch 32/100, Iteration 198/303, Loss: 3.211904186173342e-05\n",
      "Epoch 32/100, Iteration 199/303, Loss: 4.475519745028578e-05\n",
      "Epoch 32/100, Iteration 200/303, Loss: 7.232505595311522e-05\n",
      "Epoch 32/100, Iteration 201/303, Loss: 6.329547613859177e-05\n",
      "Epoch 32/100, Iteration 202/303, Loss: 6.543014023918658e-05\n",
      "Epoch 32/100, Iteration 203/303, Loss: 7.520983217546018e-06\n",
      "Epoch 32/100, Iteration 204/303, Loss: 8.818058995530009e-05\n",
      "Epoch 32/100, Iteration 205/303, Loss: 0.00015805460861884058\n",
      "Epoch 32/100, Iteration 206/303, Loss: 6.7686937654798385e-06\n",
      "Epoch 32/100, Iteration 207/303, Loss: 7.025546801742166e-05\n",
      "Epoch 32/100, Iteration 208/303, Loss: 0.0001692496007308364\n",
      "Epoch 32/100, Iteration 209/303, Loss: 0.000149554165545851\n",
      "Epoch 32/100, Iteration 210/303, Loss: 0.00010353959805797786\n",
      "Epoch 32/100, Iteration 211/303, Loss: 5.35186190973036e-05\n",
      "Epoch 32/100, Iteration 212/303, Loss: 3.525811553117819e-05\n",
      "Epoch 32/100, Iteration 213/303, Loss: 6.492390821222216e-05\n",
      "Epoch 32/100, Iteration 214/303, Loss: 0.00011507451563375071\n",
      "Epoch 32/100, Iteration 215/303, Loss: 6.075525743653998e-05\n",
      "Epoch 32/100, Iteration 216/303, Loss: 8.35169521451462e-06\n",
      "Epoch 32/100, Iteration 217/303, Loss: 5.969134872430004e-05\n",
      "Epoch 32/100, Iteration 218/303, Loss: 2.7939136998611502e-05\n",
      "Epoch 32/100, Iteration 219/303, Loss: 0.00019028192036785185\n",
      "Epoch 32/100, Iteration 220/303, Loss: 5.876079012523405e-05\n",
      "Epoch 32/100, Iteration 221/303, Loss: 0.00015655893366783857\n",
      "Epoch 32/100, Iteration 222/303, Loss: 4.473516310099512e-05\n",
      "Epoch 32/100, Iteration 223/303, Loss: 0.00010231492342427373\n",
      "Epoch 32/100, Iteration 224/303, Loss: 4.32360902777873e-05\n",
      "Epoch 32/100, Iteration 225/303, Loss: 2.1904246750636958e-05\n",
      "Epoch 32/100, Iteration 226/303, Loss: 6.172399298520759e-05\n",
      "Epoch 32/100, Iteration 227/303, Loss: 1.8323353287996724e-05\n",
      "Epoch 32/100, Iteration 228/303, Loss: 6.791015948692802e-06\n",
      "Epoch 32/100, Iteration 229/303, Loss: 4.6590972488047555e-05\n",
      "Epoch 32/100, Iteration 230/303, Loss: 1.2683701243076939e-05\n",
      "Epoch 32/100, Iteration 231/303, Loss: 4.196629743091762e-05\n",
      "Epoch 32/100, Iteration 232/303, Loss: 3.437284613028169e-05\n",
      "Epoch 32/100, Iteration 233/303, Loss: 7.828520028851926e-05\n",
      "Epoch 32/100, Iteration 234/303, Loss: 0.00011323451326461509\n",
      "Epoch 32/100, Iteration 235/303, Loss: 2.9634515158249997e-05\n",
      "Epoch 32/100, Iteration 236/303, Loss: 2.1332183678168803e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100, Iteration 237/303, Loss: 0.00028598238714039326\n",
      "Epoch 32/100, Iteration 238/303, Loss: 5.336258254828863e-05\n",
      "Epoch 32/100, Iteration 239/303, Loss: 0.00013246510934550315\n",
      "Epoch 32/100, Iteration 240/303, Loss: 4.262064248905517e-05\n",
      "Epoch 32/100, Iteration 241/303, Loss: 9.42045371630229e-05\n",
      "Epoch 32/100, Iteration 242/303, Loss: 0.00010255060624331236\n",
      "Epoch 32/100, Iteration 243/303, Loss: 5.0614195060916245e-05\n",
      "Epoch 32/100, Iteration 244/303, Loss: 0.00012238798080943525\n",
      "Epoch 32/100, Iteration 245/303, Loss: 7.989531877683476e-05\n",
      "Epoch 32/100, Iteration 246/303, Loss: 7.614096102770418e-05\n",
      "Epoch 32/100, Iteration 247/303, Loss: 6.239627691684291e-05\n",
      "Epoch 32/100, Iteration 248/303, Loss: 7.219919643830508e-05\n",
      "Epoch 32/100, Iteration 249/303, Loss: 0.0001058692141668871\n",
      "Epoch 32/100, Iteration 250/303, Loss: 9.704915282782167e-05\n",
      "Epoch 32/100, Iteration 251/303, Loss: 6.263515388127416e-05\n",
      "Epoch 32/100, Iteration 252/303, Loss: 4.741938391816802e-05\n",
      "Epoch 32/100, Iteration 253/303, Loss: 2.292635508638341e-05\n",
      "Epoch 32/100, Iteration 254/303, Loss: 3.3999553124886006e-05\n",
      "Epoch 32/100, Iteration 255/303, Loss: 2.4645049052196555e-05\n",
      "Epoch 32/100, Iteration 256/303, Loss: 4.723194433609024e-05\n",
      "Epoch 32/100, Iteration 257/303, Loss: 6.038440915290266e-05\n",
      "Epoch 32/100, Iteration 258/303, Loss: 0.0002293869765708223\n",
      "Epoch 32/100, Iteration 259/303, Loss: 3.494162956485525e-05\n",
      "Epoch 32/100, Iteration 260/303, Loss: 3.049750921491068e-05\n",
      "Epoch 32/100, Iteration 261/303, Loss: 3.421063593123108e-05\n",
      "Epoch 32/100, Iteration 262/303, Loss: 4.174938294454478e-05\n",
      "Epoch 32/100, Iteration 263/303, Loss: 2.0110986952204257e-05\n",
      "Epoch 32/100, Iteration 264/303, Loss: 7.061421638354659e-05\n",
      "Epoch 32/100, Iteration 265/303, Loss: 5.93891236349009e-05\n",
      "Epoch 32/100, Iteration 266/303, Loss: 0.00017288789968006313\n",
      "Epoch 32/100, Iteration 267/303, Loss: 6.31047623755876e-06\n",
      "Epoch 32/100, Iteration 268/303, Loss: 2.0248060536687262e-05\n",
      "Epoch 32/100, Iteration 269/303, Loss: 4.856920713791624e-05\n",
      "Epoch 32/100, Iteration 270/303, Loss: 0.00013534016034100205\n",
      "Epoch 32/100, Iteration 271/303, Loss: 0.00018889951752498746\n",
      "Epoch 32/100, Iteration 272/303, Loss: 7.136054045986384e-05\n",
      "Epoch 32/100, Iteration 273/303, Loss: 0.00017316531739197671\n",
      "Epoch 32/100, Iteration 274/303, Loss: 0.00012841566058341414\n",
      "Epoch 32/100, Iteration 275/303, Loss: 0.00013459176989272237\n",
      "Epoch 32/100, Iteration 276/303, Loss: 1.4825742255197838e-05\n",
      "Epoch 32/100, Iteration 277/303, Loss: 6.650734576396644e-05\n",
      "Epoch 32/100, Iteration 278/303, Loss: 5.9899157349718735e-05\n",
      "Epoch 32/100, Iteration 279/303, Loss: 3.269257285865024e-05\n",
      "Epoch 32/100, Iteration 280/303, Loss: 0.00016618940571788698\n",
      "Epoch 32/100, Iteration 281/303, Loss: 0.0002293688739882782\n",
      "Epoch 32/100, Iteration 282/303, Loss: 8.051362237893045e-05\n",
      "Epoch 32/100, Iteration 283/303, Loss: 5.1641960453707725e-05\n",
      "Epoch 32/100, Iteration 284/303, Loss: 0.00012398225953802466\n",
      "Epoch 32/100, Iteration 285/303, Loss: 0.00023593826335854828\n",
      "Epoch 32/100, Iteration 286/303, Loss: 6.735920032951981e-05\n",
      "Epoch 32/100, Iteration 287/303, Loss: 2.6929092200589366e-05\n",
      "Epoch 32/100, Iteration 288/303, Loss: 1.5991170585039072e-05\n",
      "Epoch 32/100, Iteration 289/303, Loss: 7.190687028924003e-05\n",
      "Epoch 32/100, Iteration 290/303, Loss: 9.203048830386251e-05\n",
      "Epoch 32/100, Iteration 291/303, Loss: 3.99118653149344e-05\n",
      "Epoch 32/100, Iteration 292/303, Loss: 0.00018553697736933827\n",
      "Epoch 32/100, Iteration 293/303, Loss: 7.709252531640232e-05\n",
      "Epoch 32/100, Iteration 294/303, Loss: 5.4849719163030386e-05\n",
      "Epoch 32/100, Iteration 295/303, Loss: 0.00018024625023826957\n",
      "Epoch 32/100, Iteration 296/303, Loss: 6.982631020946428e-05\n",
      "Epoch 32/100, Iteration 297/303, Loss: 5.824419713462703e-05\n",
      "Epoch 32/100, Iteration 298/303, Loss: 1.653164508752525e-05\n",
      "Epoch 32/100, Iteration 299/303, Loss: 0.00016780485748313367\n",
      "Epoch 32/100, Iteration 300/303, Loss: 0.000172498170286417\n",
      "Epoch 32/100, Iteration 301/303, Loss: 4.9089136155089363e-05\n",
      "Epoch 32/100, Iteration 302/303, Loss: 5.1956325478386134e-05\n",
      "Epoch 32/100, Iteration 303/303, Loss: 3.464422115939669e-05\n",
      "Epoch 33/100, Iteration 1/303, Loss: 0.00012245996913406998\n",
      "Epoch 33/100, Iteration 2/303, Loss: 0.00012757605873048306\n",
      "Epoch 33/100, Iteration 3/303, Loss: 0.00012134455755585805\n",
      "Epoch 33/100, Iteration 4/303, Loss: 5.2062663598917425e-05\n",
      "Epoch 33/100, Iteration 5/303, Loss: 3.676951746456325e-05\n",
      "Epoch 33/100, Iteration 6/303, Loss: 6.378054968081415e-05\n",
      "Epoch 33/100, Iteration 7/303, Loss: 4.797785004484467e-05\n",
      "Epoch 33/100, Iteration 8/303, Loss: 0.00021450294298119843\n",
      "Epoch 33/100, Iteration 9/303, Loss: 2.9896436899434775e-05\n",
      "Epoch 33/100, Iteration 10/303, Loss: 8.827068086247891e-05\n",
      "Epoch 33/100, Iteration 11/303, Loss: 3.075949280173518e-05\n",
      "Epoch 33/100, Iteration 12/303, Loss: 8.522348798578605e-05\n",
      "Epoch 33/100, Iteration 13/303, Loss: 5.89133269386366e-05\n",
      "Epoch 33/100, Iteration 14/303, Loss: 8.522999451088253e-06\n",
      "Epoch 33/100, Iteration 15/303, Loss: 7.879755867179483e-05\n",
      "Epoch 33/100, Iteration 16/303, Loss: 3.2543219276703894e-05\n",
      "Epoch 33/100, Iteration 17/303, Loss: 0.000131433509523049\n",
      "Epoch 33/100, Iteration 18/303, Loss: 7.714792445767671e-05\n",
      "Epoch 33/100, Iteration 19/303, Loss: 0.0001365748466923833\n",
      "Epoch 33/100, Iteration 20/303, Loss: 7.524869579356164e-05\n",
      "Epoch 33/100, Iteration 21/303, Loss: 7.430072582792491e-05\n",
      "Epoch 33/100, Iteration 22/303, Loss: 7.088683105394011e-06\n",
      "Epoch 33/100, Iteration 23/303, Loss: 6.092053445172496e-05\n",
      "Epoch 33/100, Iteration 24/303, Loss: 6.183014193084091e-05\n",
      "Epoch 33/100, Iteration 25/303, Loss: 1.4017021385370754e-05\n",
      "Epoch 33/100, Iteration 26/303, Loss: 6.942779873497784e-05\n",
      "Epoch 33/100, Iteration 27/303, Loss: 0.00012138103193137795\n",
      "Epoch 33/100, Iteration 28/303, Loss: 5.425772542366758e-05\n",
      "Epoch 33/100, Iteration 29/303, Loss: 0.00013815872080158442\n",
      "Epoch 33/100, Iteration 30/303, Loss: 2.6673473257687874e-05\n",
      "Epoch 33/100, Iteration 31/303, Loss: 9.8359290859662e-05\n",
      "Epoch 33/100, Iteration 32/303, Loss: 7.19853924238123e-05\n",
      "Epoch 33/100, Iteration 33/303, Loss: 3.6059263948118314e-05\n",
      "Epoch 33/100, Iteration 34/303, Loss: 8.963674918049946e-05\n",
      "Epoch 33/100, Iteration 35/303, Loss: 4.8074616643134505e-05\n",
      "Epoch 33/100, Iteration 36/303, Loss: 5.5707227147649974e-05\n",
      "Epoch 33/100, Iteration 37/303, Loss: 6.052423850633204e-05\n",
      "Epoch 33/100, Iteration 38/303, Loss: 0.00017412156739737839\n",
      "Epoch 33/100, Iteration 39/303, Loss: 7.728936907369643e-05\n",
      "Epoch 33/100, Iteration 40/303, Loss: 3.281090539530851e-05\n",
      "Epoch 33/100, Iteration 41/303, Loss: 9.699221118353307e-05\n",
      "Epoch 33/100, Iteration 42/303, Loss: 7.843998173484579e-05\n",
      "Epoch 33/100, Iteration 43/303, Loss: 3.730362732312642e-05\n",
      "Epoch 33/100, Iteration 44/303, Loss: 9.359082469018176e-05\n",
      "Epoch 33/100, Iteration 45/303, Loss: 0.00010450553963892162\n",
      "Epoch 33/100, Iteration 46/303, Loss: 8.42372392071411e-05\n",
      "Epoch 33/100, Iteration 47/303, Loss: 5.5004493333399296e-05\n",
      "Epoch 33/100, Iteration 48/303, Loss: 8.073443314060569e-05\n",
      "Epoch 33/100, Iteration 49/303, Loss: 2.6238580176141113e-05\n",
      "Epoch 33/100, Iteration 50/303, Loss: 1.793195951904636e-05\n",
      "Epoch 33/100, Iteration 51/303, Loss: 6.635933095822111e-05\n",
      "Epoch 33/100, Iteration 52/303, Loss: 0.0001303218596149236\n",
      "Epoch 33/100, Iteration 53/303, Loss: 0.00011005999840563163\n",
      "Epoch 33/100, Iteration 54/303, Loss: 4.376110155135393e-05\n",
      "Epoch 33/100, Iteration 55/303, Loss: 5.279371907818131e-05\n",
      "Epoch 33/100, Iteration 56/303, Loss: 2.270246113766916e-05\n",
      "Epoch 33/100, Iteration 57/303, Loss: 0.00010143853432964534\n",
      "Epoch 33/100, Iteration 58/303, Loss: 2.3953446088853525e-06\n",
      "Epoch 33/100, Iteration 59/303, Loss: 9.685466648079455e-05\n",
      "Epoch 33/100, Iteration 60/303, Loss: 7.962215022416785e-05\n",
      "Epoch 33/100, Iteration 61/303, Loss: 8.616424020146951e-05\n",
      "Epoch 33/100, Iteration 62/303, Loss: 7.035884482320398e-05\n",
      "Epoch 33/100, Iteration 63/303, Loss: 1.8047037883661687e-05\n",
      "Epoch 33/100, Iteration 64/303, Loss: 1.1529120456543751e-05\n",
      "Epoch 33/100, Iteration 65/303, Loss: 0.00020364431838970631\n",
      "Epoch 33/100, Iteration 66/303, Loss: 0.00021444607409648597\n",
      "Epoch 33/100, Iteration 67/303, Loss: 0.00012039121065754443\n",
      "Epoch 33/100, Iteration 68/303, Loss: 9.527023939881474e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100, Iteration 69/303, Loss: 7.064184319460765e-05\n",
      "Epoch 33/100, Iteration 70/303, Loss: 0.00013014099386055022\n",
      "Epoch 33/100, Iteration 71/303, Loss: 6.23953528702259e-05\n",
      "Epoch 33/100, Iteration 72/303, Loss: 0.0001599636161699891\n",
      "Epoch 33/100, Iteration 73/303, Loss: 6.555815343745053e-05\n",
      "Epoch 33/100, Iteration 74/303, Loss: 9.189450793201104e-05\n",
      "Epoch 33/100, Iteration 75/303, Loss: 5.784869063063525e-05\n",
      "Epoch 33/100, Iteration 76/303, Loss: 7.951341103762388e-05\n",
      "Epoch 33/100, Iteration 77/303, Loss: 7.167786679929122e-05\n",
      "Epoch 33/100, Iteration 78/303, Loss: 0.00011590593931032345\n",
      "Epoch 33/100, Iteration 79/303, Loss: 7.182727858889848e-05\n",
      "Epoch 33/100, Iteration 80/303, Loss: 8.46434268169105e-05\n",
      "Epoch 33/100, Iteration 81/303, Loss: 0.00024271622532978654\n",
      "Epoch 33/100, Iteration 82/303, Loss: 2.1305897462298162e-05\n",
      "Epoch 33/100, Iteration 83/303, Loss: 8.876710126060061e-06\n",
      "Epoch 33/100, Iteration 84/303, Loss: 0.00010770914377644658\n",
      "Epoch 33/100, Iteration 85/303, Loss: 5.015245915274136e-05\n",
      "Epoch 33/100, Iteration 86/303, Loss: 5.5637563491472974e-05\n",
      "Epoch 33/100, Iteration 87/303, Loss: 0.00017052404291462153\n",
      "Epoch 33/100, Iteration 88/303, Loss: 0.0002380926307523623\n",
      "Epoch 33/100, Iteration 89/303, Loss: 0.00015839166007936\n",
      "Epoch 33/100, Iteration 90/303, Loss: 7.15547357685864e-05\n",
      "Epoch 33/100, Iteration 91/303, Loss: 0.00010537142225075513\n",
      "Epoch 33/100, Iteration 92/303, Loss: 3.691700612762361e-06\n",
      "Epoch 33/100, Iteration 93/303, Loss: 4.986360727343708e-05\n",
      "Epoch 33/100, Iteration 94/303, Loss: 3.5941004171036184e-05\n",
      "Epoch 33/100, Iteration 95/303, Loss: 3.900907904608175e-05\n",
      "Epoch 33/100, Iteration 96/303, Loss: 6.046082125976682e-05\n",
      "Epoch 33/100, Iteration 97/303, Loss: 7.781780732329935e-05\n",
      "Epoch 33/100, Iteration 98/303, Loss: 0.00011782888032030314\n",
      "Epoch 33/100, Iteration 99/303, Loss: 2.6114592401427217e-05\n",
      "Epoch 33/100, Iteration 100/303, Loss: 8.440963574685156e-05\n",
      "Epoch 33/100, Iteration 101/303, Loss: 0.00012359175889287144\n",
      "Epoch 33/100, Iteration 102/303, Loss: 1.2493777830968611e-05\n",
      "Epoch 33/100, Iteration 103/303, Loss: 0.00011318818724248558\n",
      "Epoch 33/100, Iteration 104/303, Loss: 6.580276385648176e-05\n",
      "Epoch 33/100, Iteration 105/303, Loss: 5.857124779140577e-05\n",
      "Epoch 33/100, Iteration 106/303, Loss: 1.8665887182578444e-05\n",
      "Epoch 33/100, Iteration 107/303, Loss: 5.1366812840569764e-05\n",
      "Epoch 33/100, Iteration 108/303, Loss: 8.70393923833035e-05\n",
      "Epoch 33/100, Iteration 109/303, Loss: 8.231279207393527e-05\n",
      "Epoch 33/100, Iteration 110/303, Loss: 0.00016038850299082696\n",
      "Epoch 33/100, Iteration 111/303, Loss: 0.0001306825433857739\n",
      "Epoch 33/100, Iteration 112/303, Loss: 5.1421149692032486e-05\n",
      "Epoch 33/100, Iteration 113/303, Loss: 0.00012809726467821747\n",
      "Epoch 33/100, Iteration 114/303, Loss: 7.284784078365192e-05\n",
      "Epoch 33/100, Iteration 115/303, Loss: 2.050918737950269e-05\n",
      "Epoch 33/100, Iteration 116/303, Loss: 0.00010128285794053227\n",
      "Epoch 33/100, Iteration 117/303, Loss: 6.023814421496354e-05\n",
      "Epoch 33/100, Iteration 118/303, Loss: 6.738179945386946e-05\n",
      "Epoch 33/100, Iteration 119/303, Loss: 0.00013990869047120214\n",
      "Epoch 33/100, Iteration 120/303, Loss: 3.037690657947678e-05\n",
      "Epoch 33/100, Iteration 121/303, Loss: 7.34935310902074e-05\n",
      "Epoch 33/100, Iteration 122/303, Loss: 3.721495204445091e-06\n",
      "Epoch 33/100, Iteration 123/303, Loss: 4.560699744615704e-05\n",
      "Epoch 33/100, Iteration 124/303, Loss: 1.6069032426457852e-05\n",
      "Epoch 33/100, Iteration 125/303, Loss: 1.9013186829397455e-05\n",
      "Epoch 33/100, Iteration 126/303, Loss: 3.42716411978472e-05\n",
      "Epoch 33/100, Iteration 127/303, Loss: 6.361037230817601e-05\n",
      "Epoch 33/100, Iteration 128/303, Loss: 0.00014037993969395757\n",
      "Epoch 33/100, Iteration 129/303, Loss: 6.418515113182366e-05\n",
      "Epoch 33/100, Iteration 130/303, Loss: 0.00012657945626415312\n",
      "Epoch 33/100, Iteration 131/303, Loss: 6.36647964711301e-05\n",
      "Epoch 33/100, Iteration 132/303, Loss: 2.1685409592464566e-05\n",
      "Epoch 33/100, Iteration 133/303, Loss: 5.466588117997162e-05\n",
      "Epoch 33/100, Iteration 134/303, Loss: 7.502025255234912e-05\n",
      "Epoch 33/100, Iteration 135/303, Loss: 8.579457789892331e-05\n",
      "Epoch 33/100, Iteration 136/303, Loss: 0.000339933845680207\n",
      "Epoch 33/100, Iteration 137/303, Loss: 0.00015458601410500705\n",
      "Epoch 33/100, Iteration 138/303, Loss: 6.412627408280969e-05\n",
      "Epoch 33/100, Iteration 139/303, Loss: 4.676689059124328e-05\n",
      "Epoch 33/100, Iteration 140/303, Loss: 8.798856470093597e-06\n",
      "Epoch 33/100, Iteration 141/303, Loss: 0.00011829807772301137\n",
      "Epoch 33/100, Iteration 142/303, Loss: 5.530142880161293e-05\n",
      "Epoch 33/100, Iteration 143/303, Loss: 8.550191705580801e-05\n",
      "Epoch 33/100, Iteration 144/303, Loss: 7.3592433182057e-05\n",
      "Epoch 33/100, Iteration 145/303, Loss: 6.90567831043154e-05\n",
      "Epoch 33/100, Iteration 146/303, Loss: 3.492923860903829e-05\n",
      "Epoch 33/100, Iteration 147/303, Loss: 8.394579344894737e-05\n",
      "Epoch 33/100, Iteration 148/303, Loss: 0.0002682269550859928\n",
      "Epoch 33/100, Iteration 149/303, Loss: 0.00013330124784260988\n",
      "Epoch 33/100, Iteration 150/303, Loss: 3.956332875532098e-05\n",
      "Epoch 33/100, Iteration 151/303, Loss: 1.9577189959818497e-05\n",
      "Epoch 33/100, Iteration 152/303, Loss: 0.0001225536980200559\n",
      "Epoch 33/100, Iteration 153/303, Loss: 3.815840682364069e-05\n",
      "Epoch 33/100, Iteration 154/303, Loss: 3.220477083232254e-05\n",
      "Epoch 33/100, Iteration 155/303, Loss: 5.468984818435274e-05\n",
      "Epoch 33/100, Iteration 156/303, Loss: 7.564951374661177e-05\n",
      "Epoch 33/100, Iteration 157/303, Loss: 2.3417709599016234e-05\n",
      "Epoch 33/100, Iteration 158/303, Loss: 0.00021117772848811\n",
      "Epoch 33/100, Iteration 159/303, Loss: 2.6631107175489888e-05\n",
      "Epoch 33/100, Iteration 160/303, Loss: 4.12694935221225e-05\n",
      "Epoch 33/100, Iteration 161/303, Loss: 0.00014631618978455663\n",
      "Epoch 33/100, Iteration 162/303, Loss: 0.00012644351227208972\n",
      "Epoch 33/100, Iteration 163/303, Loss: 8.625850023236126e-05\n",
      "Epoch 33/100, Iteration 164/303, Loss: 0.0001193767529912293\n",
      "Epoch 33/100, Iteration 165/303, Loss: 9.617956675356254e-05\n",
      "Epoch 33/100, Iteration 166/303, Loss: 8.579059067415074e-05\n",
      "Epoch 33/100, Iteration 167/303, Loss: 7.473414007108659e-05\n",
      "Epoch 33/100, Iteration 168/303, Loss: 1.9718687326530926e-05\n",
      "Epoch 33/100, Iteration 169/303, Loss: 3.5691624361788854e-05\n",
      "Epoch 33/100, Iteration 170/303, Loss: 8.529978367732838e-05\n",
      "Epoch 33/100, Iteration 171/303, Loss: 7.5780444603879e-05\n",
      "Epoch 33/100, Iteration 172/303, Loss: 4.345300840213895e-05\n",
      "Epoch 33/100, Iteration 173/303, Loss: 1.3630067769554444e-05\n",
      "Epoch 33/100, Iteration 174/303, Loss: 0.00019257204257883132\n",
      "Epoch 33/100, Iteration 175/303, Loss: 3.7343063013395295e-05\n",
      "Epoch 33/100, Iteration 176/303, Loss: 0.00012415875971782953\n",
      "Epoch 33/100, Iteration 177/303, Loss: 5.9619731473503634e-05\n",
      "Epoch 33/100, Iteration 178/303, Loss: 2.637386933201924e-05\n",
      "Epoch 33/100, Iteration 179/303, Loss: 8.650674135424197e-05\n",
      "Epoch 33/100, Iteration 180/303, Loss: 6.583103095181286e-05\n",
      "Epoch 33/100, Iteration 181/303, Loss: 4.5680681068915874e-05\n",
      "Epoch 33/100, Iteration 182/303, Loss: 2.8404538170434535e-05\n",
      "Epoch 33/100, Iteration 183/303, Loss: 3.778414611588232e-05\n",
      "Epoch 33/100, Iteration 184/303, Loss: 0.00018334225751459599\n",
      "Epoch 33/100, Iteration 185/303, Loss: 8.434751362074167e-05\n",
      "Epoch 33/100, Iteration 186/303, Loss: 8.608298958279192e-05\n",
      "Epoch 33/100, Iteration 187/303, Loss: 0.0001420124463038519\n",
      "Epoch 33/100, Iteration 188/303, Loss: 4.399214594741352e-05\n",
      "Epoch 33/100, Iteration 189/303, Loss: 0.0001320606970693916\n",
      "Epoch 33/100, Iteration 190/303, Loss: 9.007209882838652e-06\n",
      "Epoch 33/100, Iteration 191/303, Loss: 0.0001934573519974947\n",
      "Epoch 33/100, Iteration 192/303, Loss: 2.3641185180167668e-05\n",
      "Epoch 33/100, Iteration 193/303, Loss: 0.00014707777881994843\n",
      "Epoch 33/100, Iteration 194/303, Loss: 8.90274895937182e-06\n",
      "Epoch 33/100, Iteration 195/303, Loss: 0.00022057382739149034\n",
      "Epoch 33/100, Iteration 196/303, Loss: 2.4863567887223326e-05\n",
      "Epoch 33/100, Iteration 197/303, Loss: 5.349065759219229e-05\n",
      "Epoch 33/100, Iteration 198/303, Loss: 0.0002240849717054516\n",
      "Epoch 33/100, Iteration 199/303, Loss: 0.00011449966405052692\n",
      "Epoch 33/100, Iteration 200/303, Loss: 3.562120764399879e-05\n",
      "Epoch 33/100, Iteration 201/303, Loss: 0.00018978380830958486\n",
      "Epoch 33/100, Iteration 202/303, Loss: 6.227959238458425e-05\n",
      "Epoch 33/100, Iteration 203/303, Loss: 6.514839333249256e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100, Iteration 204/303, Loss: 8.43998568598181e-05\n",
      "Epoch 33/100, Iteration 205/303, Loss: 6.341384869301692e-05\n",
      "Epoch 33/100, Iteration 206/303, Loss: 7.121179078239948e-05\n",
      "Epoch 33/100, Iteration 207/303, Loss: 6.103614578023553e-05\n",
      "Epoch 33/100, Iteration 208/303, Loss: 4.2645544453989714e-05\n",
      "Epoch 33/100, Iteration 209/303, Loss: 1.5954390619299375e-05\n",
      "Epoch 33/100, Iteration 210/303, Loss: 2.799153844534885e-05\n",
      "Epoch 33/100, Iteration 211/303, Loss: 3.5839380871038884e-05\n",
      "Epoch 33/100, Iteration 212/303, Loss: 5.001275712857023e-05\n",
      "Epoch 33/100, Iteration 213/303, Loss: 9.743868577061221e-05\n",
      "Epoch 33/100, Iteration 214/303, Loss: 6.219663919182494e-05\n",
      "Epoch 33/100, Iteration 215/303, Loss: 6.786689482396469e-05\n",
      "Epoch 33/100, Iteration 216/303, Loss: 4.813360283151269e-05\n",
      "Epoch 33/100, Iteration 217/303, Loss: 7.429433753713965e-05\n",
      "Epoch 33/100, Iteration 218/303, Loss: 0.0005659913294948637\n",
      "Epoch 33/100, Iteration 219/303, Loss: 1.8930186342913657e-05\n",
      "Epoch 33/100, Iteration 220/303, Loss: 3.408073098398745e-05\n",
      "Epoch 33/100, Iteration 221/303, Loss: 6.875335384393111e-05\n",
      "Epoch 33/100, Iteration 222/303, Loss: 7.338877185247838e-05\n",
      "Epoch 33/100, Iteration 223/303, Loss: 0.00019212771439924836\n",
      "Epoch 33/100, Iteration 224/303, Loss: 4.483294105739333e-05\n",
      "Epoch 33/100, Iteration 225/303, Loss: 0.0002337652986170724\n",
      "Epoch 33/100, Iteration 226/303, Loss: 0.00018888060003519058\n",
      "Epoch 33/100, Iteration 227/303, Loss: 0.00012004013842670247\n",
      "Epoch 33/100, Iteration 228/303, Loss: 0.00011310421541566029\n",
      "Epoch 33/100, Iteration 229/303, Loss: 0.0003025627520401031\n",
      "Epoch 33/100, Iteration 230/303, Loss: 2.9559781978605315e-05\n",
      "Epoch 33/100, Iteration 231/303, Loss: 0.00011520995758473873\n",
      "Epoch 33/100, Iteration 232/303, Loss: 3.0477835025521927e-05\n",
      "Epoch 33/100, Iteration 233/303, Loss: 0.0002410975139355287\n",
      "Epoch 33/100, Iteration 234/303, Loss: 8.454471389995888e-05\n",
      "Epoch 33/100, Iteration 235/303, Loss: 7.032853318378329e-05\n",
      "Epoch 33/100, Iteration 236/303, Loss: 6.774046778446063e-05\n",
      "Epoch 33/100, Iteration 237/303, Loss: 0.00010628459858708084\n",
      "Epoch 33/100, Iteration 238/303, Loss: 7.381992327282205e-05\n",
      "Epoch 33/100, Iteration 239/303, Loss: 5.820638034492731e-05\n",
      "Epoch 33/100, Iteration 240/303, Loss: 5.7234876294387504e-05\n",
      "Epoch 33/100, Iteration 241/303, Loss: 4.304640242480673e-05\n",
      "Epoch 33/100, Iteration 242/303, Loss: 7.083159289322793e-05\n",
      "Epoch 33/100, Iteration 243/303, Loss: 3.3754902688087896e-05\n",
      "Epoch 33/100, Iteration 244/303, Loss: 9.25973363337107e-05\n",
      "Epoch 33/100, Iteration 245/303, Loss: 1.4121593267191201e-05\n",
      "Epoch 33/100, Iteration 246/303, Loss: 1.6179654267034493e-05\n",
      "Epoch 33/100, Iteration 247/303, Loss: 8.655575948068872e-05\n",
      "Epoch 33/100, Iteration 248/303, Loss: 3.567284147720784e-05\n",
      "Epoch 33/100, Iteration 249/303, Loss: 7.120506052160636e-05\n",
      "Epoch 33/100, Iteration 250/303, Loss: 5.0952075980603695e-05\n",
      "Epoch 33/100, Iteration 251/303, Loss: 1.7529902834212407e-05\n",
      "Epoch 33/100, Iteration 252/303, Loss: 3.107599695795216e-05\n",
      "Epoch 33/100, Iteration 253/303, Loss: 0.0006257566274143755\n",
      "Epoch 33/100, Iteration 254/303, Loss: 0.00016097829211503267\n",
      "Epoch 33/100, Iteration 255/303, Loss: 2.259634857182391e-05\n",
      "Epoch 33/100, Iteration 256/303, Loss: 5.832505485159345e-05\n",
      "Epoch 33/100, Iteration 257/303, Loss: 1.645206066314131e-05\n",
      "Epoch 33/100, Iteration 258/303, Loss: 0.00013707534526474774\n",
      "Epoch 33/100, Iteration 259/303, Loss: 0.00013863280764780939\n",
      "Epoch 33/100, Iteration 260/303, Loss: 0.00015701187658123672\n",
      "Epoch 33/100, Iteration 261/303, Loss: 0.0002530297788325697\n",
      "Epoch 33/100, Iteration 262/303, Loss: 3.260504672653042e-05\n",
      "Epoch 33/100, Iteration 263/303, Loss: 6.411929643945768e-05\n",
      "Epoch 33/100, Iteration 264/303, Loss: 7.99365370767191e-05\n",
      "Epoch 33/100, Iteration 265/303, Loss: 0.00017121901328209788\n",
      "Epoch 33/100, Iteration 266/303, Loss: 4.025374073535204e-05\n",
      "Epoch 33/100, Iteration 267/303, Loss: 2.0757908714585938e-05\n",
      "Epoch 33/100, Iteration 268/303, Loss: 6.986307562328875e-05\n",
      "Epoch 33/100, Iteration 269/303, Loss: 6.376880628522485e-05\n",
      "Epoch 33/100, Iteration 270/303, Loss: 0.00011507413000799716\n",
      "Epoch 33/100, Iteration 271/303, Loss: 9.275277989218011e-06\n",
      "Epoch 33/100, Iteration 272/303, Loss: 5.52697129023727e-05\n",
      "Epoch 33/100, Iteration 273/303, Loss: 0.00010897719766944647\n",
      "Epoch 33/100, Iteration 274/303, Loss: 4.623380664270371e-05\n",
      "Epoch 33/100, Iteration 275/303, Loss: 1.3279841368785128e-05\n",
      "Epoch 33/100, Iteration 276/303, Loss: 0.0002799497451633215\n",
      "Epoch 33/100, Iteration 277/303, Loss: 0.00010499273776076734\n",
      "Epoch 33/100, Iteration 278/303, Loss: 0.00012619465996976942\n",
      "Epoch 33/100, Iteration 279/303, Loss: 2.4331495296792127e-05\n",
      "Epoch 33/100, Iteration 280/303, Loss: 5.878416413906962e-05\n",
      "Epoch 33/100, Iteration 281/303, Loss: 0.00012095153942937031\n",
      "Epoch 33/100, Iteration 282/303, Loss: 0.00018911594816017896\n",
      "Epoch 33/100, Iteration 283/303, Loss: 9.787979070097208e-05\n",
      "Epoch 33/100, Iteration 284/303, Loss: 7.402132905554026e-05\n",
      "Epoch 33/100, Iteration 285/303, Loss: 0.00013470742851495743\n",
      "Epoch 33/100, Iteration 286/303, Loss: 6.618033512495458e-05\n",
      "Epoch 33/100, Iteration 287/303, Loss: 0.00015503884060308337\n",
      "Epoch 33/100, Iteration 288/303, Loss: 2.673026392585598e-05\n",
      "Epoch 33/100, Iteration 289/303, Loss: 8.300486661028117e-05\n",
      "Epoch 33/100, Iteration 290/303, Loss: 6.912610115250573e-05\n",
      "Epoch 33/100, Iteration 291/303, Loss: 0.00015856782556511462\n",
      "Epoch 33/100, Iteration 292/303, Loss: 2.8497728635556996e-05\n",
      "Epoch 33/100, Iteration 293/303, Loss: 0.00012572156265377998\n",
      "Epoch 33/100, Iteration 294/303, Loss: 0.00015613582218065858\n",
      "Epoch 33/100, Iteration 295/303, Loss: 7.766197813907638e-05\n",
      "Epoch 33/100, Iteration 296/303, Loss: 7.32468324713409e-05\n",
      "Epoch 33/100, Iteration 297/303, Loss: 0.00013355269038584083\n",
      "Epoch 33/100, Iteration 298/303, Loss: 0.00012666790280491114\n",
      "Epoch 33/100, Iteration 299/303, Loss: 6.43340399619774e-06\n",
      "Epoch 33/100, Iteration 300/303, Loss: 3.672822640510276e-05\n",
      "Epoch 33/100, Iteration 301/303, Loss: 2.429472988296766e-05\n",
      "Epoch 33/100, Iteration 302/303, Loss: 0.00010778468276839703\n",
      "Epoch 33/100, Iteration 303/303, Loss: 5.1699476898647845e-05\n",
      "Epoch 34/100, Iteration 1/303, Loss: 3.9663460484007373e-05\n",
      "Epoch 34/100, Iteration 2/303, Loss: 0.00020467226568143815\n",
      "Epoch 34/100, Iteration 3/303, Loss: 5.693650746252388e-05\n",
      "Epoch 34/100, Iteration 4/303, Loss: 8.942978456616402e-05\n",
      "Epoch 34/100, Iteration 5/303, Loss: 0.00011028381413780153\n",
      "Epoch 34/100, Iteration 6/303, Loss: 1.0564343938312959e-05\n",
      "Epoch 34/100, Iteration 7/303, Loss: 8.199104740924668e-06\n",
      "Epoch 34/100, Iteration 8/303, Loss: 9.516768477624282e-05\n",
      "Epoch 34/100, Iteration 9/303, Loss: 6.821497663622722e-05\n",
      "Epoch 34/100, Iteration 10/303, Loss: 6.333875353448093e-05\n",
      "Epoch 34/100, Iteration 11/303, Loss: 6.987062079133466e-05\n",
      "Epoch 34/100, Iteration 12/303, Loss: 0.00013021432096138597\n",
      "Epoch 34/100, Iteration 13/303, Loss: 3.2072151952888817e-05\n",
      "Epoch 34/100, Iteration 14/303, Loss: 0.00013452852726913989\n",
      "Epoch 34/100, Iteration 15/303, Loss: 3.539250974426977e-05\n",
      "Epoch 34/100, Iteration 16/303, Loss: 5.5687960411887616e-05\n",
      "Epoch 34/100, Iteration 17/303, Loss: 2.6028947104350664e-05\n",
      "Epoch 34/100, Iteration 18/303, Loss: 0.00011738228204194456\n",
      "Epoch 34/100, Iteration 19/303, Loss: 7.686973549425602e-05\n",
      "Epoch 34/100, Iteration 20/303, Loss: 5.647315629175864e-05\n",
      "Epoch 34/100, Iteration 21/303, Loss: 8.753924339544028e-05\n",
      "Epoch 34/100, Iteration 22/303, Loss: 6.883598689455539e-05\n",
      "Epoch 34/100, Iteration 23/303, Loss: 8.035147402551956e-06\n",
      "Epoch 34/100, Iteration 24/303, Loss: 6.269563164096326e-05\n",
      "Epoch 34/100, Iteration 25/303, Loss: 3.326584555907175e-05\n",
      "Epoch 34/100, Iteration 26/303, Loss: 3.077455039601773e-05\n",
      "Epoch 34/100, Iteration 27/303, Loss: 3.5989010939374566e-05\n",
      "Epoch 34/100, Iteration 28/303, Loss: 9.342265911982395e-06\n",
      "Epoch 34/100, Iteration 29/303, Loss: 9.297870565205812e-05\n",
      "Epoch 34/100, Iteration 30/303, Loss: 3.715846469276585e-05\n",
      "Epoch 34/100, Iteration 31/303, Loss: 7.980292866704985e-05\n",
      "Epoch 34/100, Iteration 32/303, Loss: 2.944036532426253e-05\n",
      "Epoch 34/100, Iteration 33/303, Loss: 0.0001111253586714156\n",
      "Epoch 34/100, Iteration 34/303, Loss: 2.331436007807497e-05\n",
      "Epoch 34/100, Iteration 35/303, Loss: 6.127470260253176e-05\n",
      "Epoch 34/100, Iteration 36/303, Loss: 8.636756683699787e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100, Iteration 37/303, Loss: 1.0310946890967898e-05\n",
      "Epoch 34/100, Iteration 38/303, Loss: 4.438882751855999e-05\n",
      "Epoch 34/100, Iteration 39/303, Loss: 0.00011173733946634457\n",
      "Epoch 34/100, Iteration 40/303, Loss: 2.2204059860087e-05\n",
      "Epoch 34/100, Iteration 41/303, Loss: 7.428137178067118e-05\n",
      "Epoch 34/100, Iteration 42/303, Loss: 6.650272553088143e-05\n",
      "Epoch 34/100, Iteration 43/303, Loss: 9.73160276771523e-05\n",
      "Epoch 34/100, Iteration 44/303, Loss: 4.508391793933697e-05\n",
      "Epoch 34/100, Iteration 45/303, Loss: 7.96302774688229e-05\n",
      "Epoch 34/100, Iteration 46/303, Loss: 0.0002323265071026981\n",
      "Epoch 34/100, Iteration 47/303, Loss: 5.4155796533450484e-05\n",
      "Epoch 34/100, Iteration 48/303, Loss: 4.911768337478861e-05\n",
      "Epoch 34/100, Iteration 49/303, Loss: 0.0001233546790899709\n",
      "Epoch 34/100, Iteration 50/303, Loss: 4.764684126712382e-05\n",
      "Epoch 34/100, Iteration 51/303, Loss: 8.526852616341785e-05\n",
      "Epoch 34/100, Iteration 52/303, Loss: 4.7075260226847604e-05\n",
      "Epoch 34/100, Iteration 53/303, Loss: 6.459344149334356e-05\n",
      "Epoch 34/100, Iteration 54/303, Loss: 4.23183519160375e-05\n",
      "Epoch 34/100, Iteration 55/303, Loss: 3.82914804504253e-05\n",
      "Epoch 34/100, Iteration 56/303, Loss: 1.9264731236035004e-05\n",
      "Epoch 34/100, Iteration 57/303, Loss: 6.569434481207281e-05\n",
      "Epoch 34/100, Iteration 58/303, Loss: 5.160405271453783e-05\n",
      "Epoch 34/100, Iteration 59/303, Loss: 1.2306312783039175e-05\n",
      "Epoch 34/100, Iteration 60/303, Loss: 9.259173384634778e-05\n",
      "Epoch 34/100, Iteration 61/303, Loss: 0.00011932940105907619\n",
      "Epoch 34/100, Iteration 62/303, Loss: 7.64037249609828e-05\n",
      "Epoch 34/100, Iteration 63/303, Loss: 6.038395440555178e-06\n",
      "Epoch 34/100, Iteration 64/303, Loss: 9.096800204133615e-05\n",
      "Epoch 34/100, Iteration 65/303, Loss: 1.5466523109353147e-05\n",
      "Epoch 34/100, Iteration 66/303, Loss: 8.435995550826192e-05\n",
      "Epoch 34/100, Iteration 67/303, Loss: 2.552865589677822e-05\n",
      "Epoch 34/100, Iteration 68/303, Loss: 9.768223389983177e-05\n",
      "Epoch 34/100, Iteration 69/303, Loss: 2.134574970114045e-06\n",
      "Epoch 34/100, Iteration 70/303, Loss: 3.939557063858956e-05\n",
      "Epoch 34/100, Iteration 71/303, Loss: 6.171625864226371e-05\n",
      "Epoch 34/100, Iteration 72/303, Loss: 8.2307007687632e-05\n",
      "Epoch 34/100, Iteration 73/303, Loss: 5.779583443654701e-05\n",
      "Epoch 34/100, Iteration 74/303, Loss: 7.275399548234418e-05\n",
      "Epoch 34/100, Iteration 75/303, Loss: 8.062295819399878e-05\n",
      "Epoch 34/100, Iteration 76/303, Loss: 2.9169990739319474e-05\n",
      "Epoch 34/100, Iteration 77/303, Loss: 9.506538845016621e-06\n",
      "Epoch 34/100, Iteration 78/303, Loss: 0.00020818937628064305\n",
      "Epoch 34/100, Iteration 79/303, Loss: 0.00010313019447494298\n",
      "Epoch 34/100, Iteration 80/303, Loss: 6.17380574112758e-05\n",
      "Epoch 34/100, Iteration 81/303, Loss: 1.2910718396597076e-05\n",
      "Epoch 34/100, Iteration 82/303, Loss: 0.0003277167270425707\n",
      "Epoch 34/100, Iteration 83/303, Loss: 9.118430898524821e-05\n",
      "Epoch 34/100, Iteration 84/303, Loss: 4.66501951450482e-05\n",
      "Epoch 34/100, Iteration 85/303, Loss: 0.00010923328227363527\n",
      "Epoch 34/100, Iteration 86/303, Loss: 0.00012390545452944934\n",
      "Epoch 34/100, Iteration 87/303, Loss: 6.315167411230505e-05\n",
      "Epoch 34/100, Iteration 88/303, Loss: 7.347267091972753e-05\n",
      "Epoch 34/100, Iteration 89/303, Loss: 5.64585134270601e-05\n",
      "Epoch 34/100, Iteration 90/303, Loss: 5.9921647334704176e-05\n",
      "Epoch 34/100, Iteration 91/303, Loss: 0.00012963810877408832\n",
      "Epoch 34/100, Iteration 92/303, Loss: 5.0682956498349085e-05\n",
      "Epoch 34/100, Iteration 93/303, Loss: 2.1186151570873335e-05\n",
      "Epoch 34/100, Iteration 94/303, Loss: 7.025524973869324e-05\n",
      "Epoch 34/100, Iteration 95/303, Loss: 7.638896931894124e-05\n",
      "Epoch 34/100, Iteration 96/303, Loss: 5.044697172706947e-05\n",
      "Epoch 34/100, Iteration 97/303, Loss: 2.9708733563893475e-05\n",
      "Epoch 34/100, Iteration 98/303, Loss: 0.00029376489692367613\n",
      "Epoch 34/100, Iteration 99/303, Loss: 3.7246831197990105e-05\n",
      "Epoch 34/100, Iteration 100/303, Loss: 1.6758005585870706e-05\n",
      "Epoch 34/100, Iteration 101/303, Loss: 0.00010409413516754285\n",
      "Epoch 34/100, Iteration 102/303, Loss: 8.299381443066522e-05\n",
      "Epoch 34/100, Iteration 103/303, Loss: 0.0001958869834197685\n",
      "Epoch 34/100, Iteration 104/303, Loss: 0.0001387691154377535\n",
      "Epoch 34/100, Iteration 105/303, Loss: 5.249526657280512e-05\n",
      "Epoch 34/100, Iteration 106/303, Loss: 7.737957639619708e-05\n",
      "Epoch 34/100, Iteration 107/303, Loss: 8.913382043829188e-05\n",
      "Epoch 34/100, Iteration 108/303, Loss: 1.650153899390716e-05\n",
      "Epoch 34/100, Iteration 109/303, Loss: 6.415008829208091e-05\n",
      "Epoch 34/100, Iteration 110/303, Loss: 6.57753917039372e-05\n",
      "Epoch 34/100, Iteration 111/303, Loss: 1.5499183064093813e-05\n",
      "Epoch 34/100, Iteration 112/303, Loss: 0.00010228667815681547\n",
      "Epoch 34/100, Iteration 113/303, Loss: 6.20275386609137e-05\n",
      "Epoch 34/100, Iteration 114/303, Loss: 4.003930007456802e-05\n",
      "Epoch 34/100, Iteration 115/303, Loss: 0.00011082444689236581\n",
      "Epoch 34/100, Iteration 116/303, Loss: 5.432160833152011e-05\n",
      "Epoch 34/100, Iteration 117/303, Loss: 3.7414451071526855e-05\n",
      "Epoch 34/100, Iteration 118/303, Loss: 0.000165372941410169\n",
      "Epoch 34/100, Iteration 119/303, Loss: 1.8257776901009493e-05\n",
      "Epoch 34/100, Iteration 120/303, Loss: 2.2209511371329427e-05\n",
      "Epoch 34/100, Iteration 121/303, Loss: 0.00012120790779590607\n",
      "Epoch 34/100, Iteration 122/303, Loss: 4.423922291607596e-05\n",
      "Epoch 34/100, Iteration 123/303, Loss: 6.680349179077893e-05\n",
      "Epoch 34/100, Iteration 124/303, Loss: 0.00021904130699113011\n",
      "Epoch 34/100, Iteration 125/303, Loss: 3.9880615076981485e-05\n",
      "Epoch 34/100, Iteration 126/303, Loss: 0.0001544729748275131\n",
      "Epoch 34/100, Iteration 127/303, Loss: 7.77242676122114e-05\n",
      "Epoch 34/100, Iteration 128/303, Loss: 4.9127062084153295e-05\n",
      "Epoch 34/100, Iteration 129/303, Loss: 0.00020657679124269634\n",
      "Epoch 34/100, Iteration 130/303, Loss: 6.635076715610921e-05\n",
      "Epoch 34/100, Iteration 131/303, Loss: 7.429081597365439e-05\n",
      "Epoch 34/100, Iteration 132/303, Loss: 2.7221225536777638e-05\n",
      "Epoch 34/100, Iteration 133/303, Loss: 0.000180577248102054\n",
      "Epoch 34/100, Iteration 134/303, Loss: 1.98086527234409e-05\n",
      "Epoch 34/100, Iteration 135/303, Loss: 1.6494317605975084e-05\n",
      "Epoch 34/100, Iteration 136/303, Loss: 5.401003363658674e-05\n",
      "Epoch 34/100, Iteration 137/303, Loss: 4.8891342885326594e-05\n",
      "Epoch 34/100, Iteration 138/303, Loss: 8.454557246295735e-05\n",
      "Epoch 34/100, Iteration 139/303, Loss: 5.1687104132724926e-05\n",
      "Epoch 34/100, Iteration 140/303, Loss: 5.4637668654322624e-05\n",
      "Epoch 34/100, Iteration 141/303, Loss: 0.00021668468252755702\n",
      "Epoch 34/100, Iteration 142/303, Loss: 0.00021039519924670458\n",
      "Epoch 34/100, Iteration 143/303, Loss: 1.3569711882155389e-05\n",
      "Epoch 34/100, Iteration 144/303, Loss: 4.589792661136016e-05\n",
      "Epoch 34/100, Iteration 145/303, Loss: 0.00016040029004216194\n",
      "Epoch 34/100, Iteration 146/303, Loss: 3.3295658795395866e-05\n",
      "Epoch 34/100, Iteration 147/303, Loss: 0.000105338214780204\n",
      "Epoch 34/100, Iteration 148/303, Loss: 2.474549000908155e-05\n",
      "Epoch 34/100, Iteration 149/303, Loss: 1.5749605154269375e-05\n",
      "Epoch 34/100, Iteration 150/303, Loss: 4.742648889077827e-05\n",
      "Epoch 34/100, Iteration 151/303, Loss: 0.0001261321158381179\n",
      "Epoch 34/100, Iteration 152/303, Loss: 6.263733666855842e-05\n",
      "Epoch 34/100, Iteration 153/303, Loss: 3.9703198126517236e-05\n",
      "Epoch 34/100, Iteration 154/303, Loss: 0.00016970782598946244\n",
      "Epoch 34/100, Iteration 155/303, Loss: 7.979382644407451e-05\n",
      "Epoch 34/100, Iteration 156/303, Loss: 0.0001088764111045748\n",
      "Epoch 34/100, Iteration 157/303, Loss: 4.694409653893672e-05\n",
      "Epoch 34/100, Iteration 158/303, Loss: 8.672592230141163e-05\n",
      "Epoch 34/100, Iteration 159/303, Loss: 2.0973116079403553e-06\n",
      "Epoch 34/100, Iteration 160/303, Loss: 0.00018385742441751063\n",
      "Epoch 34/100, Iteration 161/303, Loss: 8.6829430074431e-05\n",
      "Epoch 34/100, Iteration 162/303, Loss: 0.00019510791753418744\n",
      "Epoch 34/100, Iteration 163/303, Loss: 7.491839642170817e-05\n",
      "Epoch 34/100, Iteration 164/303, Loss: 7.815888966433704e-05\n",
      "Epoch 34/100, Iteration 165/303, Loss: 5.819444777444005e-05\n",
      "Epoch 34/100, Iteration 166/303, Loss: 5.658444933942519e-05\n",
      "Epoch 34/100, Iteration 167/303, Loss: 0.00012077529390808195\n",
      "Epoch 34/100, Iteration 168/303, Loss: 0.0001041723444359377\n",
      "Epoch 34/100, Iteration 169/303, Loss: 5.1668503147084266e-05\n",
      "Epoch 34/100, Iteration 170/303, Loss: 5.042227712692693e-05\n",
      "Epoch 34/100, Iteration 171/303, Loss: 0.0001650775084272027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100, Iteration 172/303, Loss: 2.2327494662022218e-05\n",
      "Epoch 34/100, Iteration 173/303, Loss: 0.00012634530139621347\n",
      "Epoch 34/100, Iteration 174/303, Loss: 3.791526978602633e-05\n",
      "Epoch 34/100, Iteration 175/303, Loss: 6.311936158454046e-05\n",
      "Epoch 34/100, Iteration 176/303, Loss: 1.7999709598370828e-05\n",
      "Epoch 34/100, Iteration 177/303, Loss: 7.940759678604081e-05\n",
      "Epoch 34/100, Iteration 178/303, Loss: 9.722706636239309e-06\n",
      "Epoch 34/100, Iteration 179/303, Loss: 5.384680844144896e-05\n",
      "Epoch 34/100, Iteration 180/303, Loss: 4.598624218488112e-05\n",
      "Epoch 34/100, Iteration 181/303, Loss: 2.317268263141159e-05\n",
      "Epoch 34/100, Iteration 182/303, Loss: 3.2982810807880014e-05\n",
      "Epoch 34/100, Iteration 183/303, Loss: 3.260289304307662e-05\n",
      "Epoch 34/100, Iteration 184/303, Loss: 0.0005236264551058412\n",
      "Epoch 34/100, Iteration 185/303, Loss: 0.0002220595342805609\n",
      "Epoch 34/100, Iteration 186/303, Loss: 0.0003511711838655174\n",
      "Epoch 34/100, Iteration 187/303, Loss: 2.8933845896972343e-05\n",
      "Epoch 34/100, Iteration 188/303, Loss: 0.00010263686999678612\n",
      "Epoch 34/100, Iteration 189/303, Loss: 1.4863342585158534e-05\n",
      "Epoch 34/100, Iteration 190/303, Loss: 2.5124480089289136e-05\n",
      "Epoch 34/100, Iteration 191/303, Loss: 1.705327485979069e-05\n",
      "Epoch 34/100, Iteration 192/303, Loss: 0.00011063212878070772\n",
      "Epoch 34/100, Iteration 193/303, Loss: 2.8806962291128002e-05\n",
      "Epoch 34/100, Iteration 194/303, Loss: 3.841238503810018e-05\n",
      "Epoch 34/100, Iteration 195/303, Loss: 3.882756209350191e-05\n",
      "Epoch 34/100, Iteration 196/303, Loss: 7.720634312136099e-05\n",
      "Epoch 34/100, Iteration 197/303, Loss: 8.638907456770539e-05\n",
      "Epoch 34/100, Iteration 198/303, Loss: 8.01867208792828e-05\n",
      "Epoch 34/100, Iteration 199/303, Loss: 0.00033192645059898496\n",
      "Epoch 34/100, Iteration 200/303, Loss: 0.00012918555876240134\n",
      "Epoch 34/100, Iteration 201/303, Loss: 2.730601408984512e-06\n",
      "Epoch 34/100, Iteration 202/303, Loss: 7.171413017204031e-05\n",
      "Epoch 34/100, Iteration 203/303, Loss: 3.41868435498327e-05\n",
      "Epoch 34/100, Iteration 204/303, Loss: 4.893411460216157e-05\n",
      "Epoch 34/100, Iteration 205/303, Loss: 0.0001297749113291502\n",
      "Epoch 34/100, Iteration 206/303, Loss: 3.7269222957547754e-05\n",
      "Epoch 34/100, Iteration 207/303, Loss: 0.00013334790128283203\n",
      "Epoch 34/100, Iteration 208/303, Loss: 0.00013055028102826327\n",
      "Epoch 34/100, Iteration 209/303, Loss: 6.493187538580969e-05\n",
      "Epoch 34/100, Iteration 210/303, Loss: 5.987151962472126e-05\n",
      "Epoch 34/100, Iteration 211/303, Loss: 4.1934617911465466e-05\n",
      "Epoch 34/100, Iteration 212/303, Loss: 3.28516325680539e-05\n",
      "Epoch 34/100, Iteration 213/303, Loss: 5.6758370192255825e-05\n",
      "Epoch 34/100, Iteration 214/303, Loss: 7.239176920847967e-05\n",
      "Epoch 34/100, Iteration 215/303, Loss: 0.0004919501370750368\n",
      "Epoch 34/100, Iteration 216/303, Loss: 0.0001251895009772852\n",
      "Epoch 34/100, Iteration 217/303, Loss: 2.17029191844631e-05\n",
      "Epoch 34/100, Iteration 218/303, Loss: 4.058931517647579e-05\n",
      "Epoch 34/100, Iteration 219/303, Loss: 5.1066745072603226e-05\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create an instance of the model, an optimizer, and a criterion\n",
    "##########################\n",
    "## change between 3 layers or 5 layers\n",
    "cnn_classifier = Classifier_CNN_3_Layers()\n",
    "#cnn_classifier = Classifier_CNN_5_Layers()\n",
    "\n",
    "cnn_classifier.to(device)\n",
    "## parameters and optimizer\n",
    "optimizer = optim.SGD(cnn_classifier.parameters(), lr=0.1)\n",
    "criterion = nn.BCEWithLogitsLoss()  ## Assuming it's a binary classification problem\n",
    "\n",
    "# Training loop\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    cnn_classifier.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images,  labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_classifier(images)\n",
    "        ##Examine predicted happy or sad\n",
    "        predicted_labels = (outputs >= 0.5).float()\n",
    "        \n",
    "        ## uncomment or comment to control\n",
    "        ## predicted prints\n",
    "        \n",
    "#         print(\"Predictions:\", predicted_labels)\n",
    "#         print(\"True Labels:\", labels)    \n",
    "        \n",
    "        loss = criterion(outputs.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Iteration {i + 1}/{len(train_loader)}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b6a189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8859a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "## evaluate train\n",
    "def evaluate_model(model, train_loader, device):\n",
    "    ## Set the model to evaluation mode\n",
    "    cnn_classifier.eval() \n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    accuracy  = accuracy_score(all_targets, all_predictions)\n",
    "    confmat   = confusion_matrix(y_true=all_targets, y_pred=all_predictions)\n",
    "    precision = precision_score(y_true=all_targets, y_pred=all_predictions, average='weighted', zero_division=1)\n",
    "    recall    = recall_score(y_true=all_targets, y_pred=all_predictions, average='weighted', zero_division=1)\n",
    "    f1 = f1_score(y_true=all_targets, y_pred=all_predictions, average='weighted')\n",
    "    \n",
    "    print(f'Confusion Matrix:\\n{confmat}')\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1-score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c21f4ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[5706    0]\n",
      " [3975    0]]\n",
      "Accuracy: 0.59\n",
      "Precision: 0.76\n",
      "Recall: 0.59\n",
      "F1-score: 0.44\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(cnn_classifier, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b6187e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2ae8e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "## evaluate model based on test data loader\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    ## Set the model to evaluation mode\n",
    "    cnn_classifier.eval() \n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    accuracy  = accuracy_score(all_targets, all_predictions)\n",
    "    confmat   = confusion_matrix(y_true=all_targets, y_pred=all_predictions)\n",
    "    precision = precision_score(y_true=all_targets, y_pred=all_predictions, average='weighted', zero_division=1)\n",
    "    recall    = recall_score(y_true=all_targets, y_pred=all_predictions, average='weighted', zero_division=1)\n",
    "    f1 = f1_score(y_true=all_targets, y_pred=all_predictions, average='weighted')\n",
    "    \n",
    "    print(f'Confusion Matrix:\\n{confmat}')\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1-score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "383273ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1458    0]\n",
      " [ 963    0]]\n",
      "Accuracy: 0.60\n",
      "Precision: 0.76\n",
      "Recall: 0.60\n",
      "F1-score: 0.45\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(cnn_classifier, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c081e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcdd604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23a51a31",
   "metadata": {},
   "source": [
    "## Test based off random image from train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c2b479a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Class: sad, Predicted Class: sad, Correct: True\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###########################\n",
    "## Test on train data\n",
    "cnn_classifier.eval()\n",
    "# Define class names\n",
    "class_names = [\"happy\", \"sad\"] # Add or modify as needed\n",
    "# Get a random index from the test set\n",
    "random_index = random.randint(0, len(train_dataset) - 1)\n",
    "# Get the image and label at the random index\n",
    "image, label = train_dataset[random_index]\n",
    "image = image.to(device)\n",
    "label = label.to(device)\n",
    "\n",
    "\n",
    "output = cnn_classifier(image.unsqueeze(0))  # Unsqueeze to add batch dimension\n",
    "\n",
    "# Apply threshold for binary classification\n",
    "predicted_label = 1 if output > 0.5 else 0\n",
    "\n",
    "# Convert labels to class names\n",
    "actual_class = class_names[int(label)]\n",
    "predicted_class = class_names[predicted_label]\n",
    "\n",
    "# Check if the prediction is correct\n",
    "is_correct = predicted_label == int(label)\n",
    "\n",
    "# Print results\n",
    "print(f\"Actual Class: {actual_class}, Predicted Class: {predicted_class}, Correct: {is_correct}\")\n",
    "\n",
    "# Display the image\n",
    "image = image.cpu().permute(1, 2, 0).numpy()  # Convert to numpy and rearrange dimensions\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Actual: {actual_class}, Predicted: {predicted_class}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60868e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0882736b-3e48-4ba6-9a5e-0f4ef03cf6f7",
   "metadata": {},
   "source": [
    "## Test From an image in the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0035bde5-95f5-41e6-8341-a71f6bd631fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cnn_classifier.eval()\n",
    "random_index = random.randint(0, len(test_dataset) - 1)\n",
    "image, label = test_dataset[random_index]\n",
    "image = image.to(device)\n",
    "label = label.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5abf4fb-954f-44b3-b220-d8327db056c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 48, 48])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbdcd034-6f36-440f-8f7b-575b12459e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c321c37-770a-48c1-8aa3-8a0f822e5b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label: 0, Predicted Label: 0, Correct: True\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Forward pass\n",
    "output = cnn_classifier(image.unsqueeze(0))  # Unsqueeze to add batch dimension\n",
    "\n",
    "# Apply threshold for binary classification\n",
    "predicted_label = 1 if output > 0.5 else 0\n",
    "\n",
    "# Convert labels to numpy arrays for easy comparison\n",
    "actual_label = label.cpu().numpy()\n",
    "\n",
    "# Check if the prediction is correct\n",
    "is_correct = predicted_label == actual_label\n",
    "\n",
    "# Print results\n",
    "print(f\"Actual Label: {actual_label}, Predicted Label: {predicted_label}, Correct: {is_correct}\")\n",
    "\n",
    "# Display the image\n",
    "image = image.cpu().permute(1, 2, 0).numpy()  # Convert to numpy and rearrange dimensions\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Actual: {actual_label}, Predicted: {predicted_label}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c407722-dc6d-411f-beaf-4f7227656abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cnn_classifier.eval()\n",
    "\n",
    "# Define class names\n",
    "class_names = [\"happy\", \"sad\"]  # Add or modify as needed\n",
    "\n",
    "# Get a random index from the test set\n",
    "random_index = random.randint(0, len(test_dataset) - 1)\n",
    "\n",
    "# Get the image and label at the random index\n",
    "image, label = test_dataset[random_index]\n",
    "image = image.to(device)\n",
    "label = label.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4642f9c-a484-4001-8f0e-9068ef4e9249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Class: sad, Predicted Class: sad, Correct: True\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "output = cnn_classifier(image.unsqueeze(0))  # Unsqueeze to add batch dimension\n",
    "\n",
    "# Apply threshold for binary classification\n",
    "predicted_label = 1 if output > 0.5 else 0\n",
    "\n",
    "# Convert labels to class names\n",
    "actual_class = class_names[int(label)]\n",
    "predicted_class = class_names[predicted_label]\n",
    "\n",
    "# Check if the prediction is correct\n",
    "is_correct = predicted_label == int(label)\n",
    "\n",
    "# Print results\n",
    "print(f\"Actual Class: {actual_class}, Predicted Class: {predicted_class}, Correct: {is_correct}\")\n",
    "\n",
    "# Display the image\n",
    "image = image.cpu().permute(1, 2, 0).numpy()  # Convert to numpy and rearrange dimensions\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Actual: {actual_class}, Predicted: {predicted_class}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c4832-21bb-49f1-8355-5d872160791e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7528adea-db7f-440f-9817-544fd87ae85f",
   "metadata": {},
   "source": [
    "## Onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a858af7-e177-43d9-a2b5-e729b42197d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Export the model to ONNX\n",
    "# # Specify the input shape\n",
    "# dimensions = torch.randn(1, 3, 48, 48).to(device)\n",
    "\n",
    "# onnx_path = 'EmotionCnnOnnx.onnx'  # Specify the output path here\n",
    "# torch.onnx.export(cnn_classifier, dimensions, onnx_path, verbose=True, input_names=['input'], output_names=['output'])\n",
    "\n",
    "# # Load the ONNX model\n",
    "# ort_session = onnxruntime.InferenceSession(onnx_path)\n",
    "\n",
    "# # Prepare input data (adjust based on your input type and data)\n",
    "# input_data = np.random.randn(1, 3, 48, 48).astype(np.float32)\n",
    "\n",
    "# # Run inference\n",
    "# ort_inputs = {ort_session.get_inputs()[0].name: input_data}\n",
    "# output_name = ort_session.get_outputs()[0].name  # Get the name of the output\n",
    "# ort_outs = ort_session.run([output_name], ort_inputs)\n",
    "\n",
    "# # Print the output\n",
    "# print(\"EmotionCnnOnnx output:\", ort_outs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "250770ef-55e1-4c37-aaa9-344f68207826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming 'cnn_classifier' is your PyTorch model\n",
    "dummy_input = torch.randn(1, 3, 48, 48)  # Adjust the size according to your input\n",
    "\n",
    "# Provide the filename for the ONNX file\n",
    "onnx_filename = \"emotion_recognition_model.onnx\"\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(cnn_classifier, dummy_input, onnx_filename, opset_version=9, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818fd04c-f151-4831-9ba5-7d58c936a6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f0a927e-1f00-4be0-88b2-50cdaee9451c",
   "metadata": {},
   "source": [
    "## Figuring out the View Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de3c0f-81c2-4a93-a7a8-97d99bbf5d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_tensor_test = torch.randn(1, 3, 48,  48)\n",
    "my_tensor_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfcfb8c-3f48-4fb3-9d42-e6cec62393b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mm_conv_transpose_test = nn.Conv2d(3, 10, kernel_size=5, stride=2)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65d15b-f69e-43fc-bff9-2acbdb7e6535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mm_res_test = mm_conv_transpose_test(my_tensor_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e826ed-765e-4eb5-b560-1e1b1194b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mm_res_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e39e78-fa5d-42b5-b31f-08bcd32657ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ll_conv_transp_test = nn.Conv2d(10, 10, kernel_size=3, stride=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fc5192-27a8-4432-a8d5-d33a0b478b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ll_res_test = ll_conv_transp_test(mm_res_test)\n",
    "ll_res_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e191ccd3-4bec-4e35-b19c-c79b9d36e72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vv_view = View( (1, -1) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676eee7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5bd8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
