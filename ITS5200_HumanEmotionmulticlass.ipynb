{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517155d9-9496-4369-9923-53aa5e74726d",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c3121621-853b-4dcf-87e7-34eecd29b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "## Import Torch Libaries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "###########################\n",
    "## Import standard libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "##########################\n",
    "## Import PIL\n",
    "from PIL import Image\n",
    "\n",
    "#####################\n",
    "## import SK learn libaries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "####################\n",
    "## import matplot\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "365e08c3-dfd3-43ee-9780-9148b02278ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "##Enable CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b725edc-d5e6-477f-b0a5-88a400850ac1",
   "metadata": {},
   "source": [
    "## Figuring out the dimension of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "18ab4fc5-9553-40d7-8be2-85e9ad47af4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dimensions of the image: torch.Size([3, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "folder_path = './Images'\n",
    "\n",
    "# Define a transform without resizing (to maintain original dimensions)\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Create an ImageFolder dataset\n",
    "dataset = ImageFolder(root=folder_path, transform=transform)\n",
    "\n",
    "# Choose an index for the image you want to check\n",
    "index_to_check = 0\n",
    "\n",
    "# Retrieve the image and its dimensions\n",
    "image, label = dataset[index_to_check]\n",
    "original_dimensions = image.shape\n",
    "\n",
    "# Print the original dimensions\n",
    "print(f\"Original dimensions of the image: {original_dimensions}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5935cffa-7569-459e-8c3b-463a7634936e",
   "metadata": {},
   "source": [
    "## Mapping labels with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dc51439e-3a57-4331-b837-d1ae2c05bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "class EmotionDetection(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.classes = os.listdir(data_path)\n",
    "        ## make an array for images and labls\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        ## iterate through emotion class\n",
    "        for i, emotion_class in enumerate(self.classes):\n",
    "            ### grab all images in folders\n",
    "            class_path = os.path.join(data_path, emotion_class)\n",
    "            ## iterate image_name in path\n",
    "            for image_name in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_name)\n",
    "                self.images.append(image_path)\n",
    "                self.labels.append(i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        # Open the image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert label to a single index\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "217f0f19-0f51-46f6-b3cd-25392a6b48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "data_path = './Images'  \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = EmotionDetection(data_path=data_path, transform=transform)\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "10031061-eb67-46f0-9a93-10f11f2a673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "index = 0\n",
    "image, label = dataset[index]\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e326ae2b-f259-4740-af33-420af079eeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 48, 48])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################\n",
    "image.shape\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e6b98869-b15f-48dd-a4dc-5858b9ec92b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## labell are based on the directory name\n",
    "# which means 0 is the first folder name, \n",
    "#1 is the second folder name, etc.\n",
    "label \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdba065",
   "metadata": {},
   "source": [
    "## View Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5a8fd8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "## View Class\n",
    "class View(nn.Module):\n",
    "    \n",
    "    def __init__(self, shape):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.shape = shape,\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b23a19-11f4-41e6-a228-b654ed1c5bf0",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3700b73b-8118-46a4-9d31-d7709c222270",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Classifier_CNN_3_Layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier_CNN_3_Layers, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1= nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 512)\n",
    "        self.fc2 = nn.Linear(512, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        ## flatten and connect all layers\n",
    "        x = x.view(-1, 256 * 6 * 6)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # Softmax activation for multiclass classification\n",
    "        return F.softmax(x, dim=1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960ebc78-ccb6-41c8-b94c-294a1983094b",
   "metadata": {},
   "source": [
    "\n",
    "## Splitting the dataset into training and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "10c2b14d-5b7b-4949-8f54-7fe8936af0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb46db1-ef73-4038-9e46-caa253831aba",
   "metadata": {},
   "source": [
    "## Creating dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b7a0a410-7842-4bf5-a919-1d3de1421663",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "batch_size = 32\n",
    "\n",
    "# Create DataLoader instances for training and testing datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7dc174",
   "metadata": {},
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "96b52100-a9b5-4e66-bb3f-7c191cdf0a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Iteration 1/38, Loss: 1.0987522602081299\n",
      "Epoch 1/100, Iteration 2/38, Loss: 1.0993735790252686\n",
      "Epoch 1/100, Iteration 3/38, Loss: 1.098507285118103\n",
      "Epoch 1/100, Iteration 4/38, Loss: 1.0967859029769897\n",
      "Epoch 1/100, Iteration 5/38, Loss: 1.0966240167617798\n",
      "Epoch 1/100, Iteration 6/38, Loss: 1.0976617336273193\n",
      "Epoch 1/100, Iteration 7/38, Loss: 1.095979928970337\n",
      "Epoch 1/100, Iteration 8/38, Loss: 1.0971640348434448\n",
      "Epoch 1/100, Iteration 9/38, Loss: 1.1010545492172241\n",
      "Epoch 1/100, Iteration 10/38, Loss: 1.0936044454574585\n",
      "Epoch 1/100, Iteration 11/38, Loss: 1.1015779972076416\n",
      "Epoch 1/100, Iteration 12/38, Loss: 1.1061934232711792\n",
      "Epoch 1/100, Iteration 13/38, Loss: 1.0966212749481201\n",
      "Epoch 1/100, Iteration 14/38, Loss: 1.0963484048843384\n",
      "Epoch 1/100, Iteration 15/38, Loss: 1.1000049114227295\n",
      "Epoch 1/100, Iteration 16/38, Loss: 1.0990517139434814\n",
      "Epoch 1/100, Iteration 17/38, Loss: 1.1020615100860596\n",
      "Epoch 1/100, Iteration 18/38, Loss: 1.0989360809326172\n",
      "Epoch 1/100, Iteration 19/38, Loss: 1.1011441946029663\n",
      "Epoch 1/100, Iteration 20/38, Loss: 1.0994408130645752\n",
      "Epoch 1/100, Iteration 21/38, Loss: 1.0978103876113892\n",
      "Epoch 1/100, Iteration 22/38, Loss: 1.099349856376648\n",
      "Epoch 1/100, Iteration 23/38, Loss: 1.0979721546173096\n",
      "Epoch 1/100, Iteration 24/38, Loss: 1.0980442762374878\n",
      "Epoch 1/100, Iteration 25/38, Loss: 1.0992588996887207\n",
      "Epoch 1/100, Iteration 26/38, Loss: 1.0981065034866333\n",
      "Epoch 1/100, Iteration 27/38, Loss: 1.0984206199645996\n",
      "Epoch 1/100, Iteration 28/38, Loss: 1.0979959964752197\n",
      "Epoch 1/100, Iteration 29/38, Loss: 1.0976641178131104\n",
      "Epoch 1/100, Iteration 30/38, Loss: 1.099835753440857\n",
      "Epoch 1/100, Iteration 31/38, Loss: 1.0989458560943604\n",
      "Epoch 1/100, Iteration 32/38, Loss: 1.0987396240234375\n",
      "Epoch 1/100, Iteration 33/38, Loss: 1.0986762046813965\n",
      "Epoch 1/100, Iteration 34/38, Loss: 1.1002252101898193\n",
      "Epoch 1/100, Iteration 35/38, Loss: 1.0983415842056274\n",
      "Epoch 1/100, Iteration 36/38, Loss: 1.0987101793289185\n",
      "Epoch 1/100, Iteration 37/38, Loss: 1.0971262454986572\n",
      "Epoch 1/100, Iteration 38/38, Loss: 1.0995635986328125\n",
      "Epoch 2/100, Iteration 1/38, Loss: 1.097585678100586\n",
      "Epoch 2/100, Iteration 2/38, Loss: 1.0967239141464233\n",
      "Epoch 2/100, Iteration 3/38, Loss: 1.0958001613616943\n",
      "Epoch 2/100, Iteration 4/38, Loss: 1.0967109203338623\n",
      "Epoch 2/100, Iteration 5/38, Loss: 1.1003221273422241\n",
      "Epoch 2/100, Iteration 6/38, Loss: 1.0956798791885376\n",
      "Epoch 2/100, Iteration 7/38, Loss: 1.0949015617370605\n",
      "Epoch 2/100, Iteration 8/38, Loss: 1.106494426727295\n",
      "Epoch 2/100, Iteration 9/38, Loss: 1.095673680305481\n",
      "Epoch 2/100, Iteration 10/38, Loss: 1.0958136320114136\n",
      "Epoch 2/100, Iteration 11/38, Loss: 1.1025387048721313\n",
      "Epoch 2/100, Iteration 12/38, Loss: 1.1012098789215088\n",
      "Epoch 2/100, Iteration 13/38, Loss: 1.096423864364624\n",
      "Epoch 2/100, Iteration 14/38, Loss: 1.1067167520523071\n",
      "Epoch 2/100, Iteration 15/38, Loss: 1.1008363962173462\n",
      "Epoch 2/100, Iteration 16/38, Loss: 1.100726842880249\n",
      "Epoch 2/100, Iteration 17/38, Loss: 1.09859299659729\n",
      "Epoch 2/100, Iteration 18/38, Loss: 1.0994088649749756\n",
      "Epoch 2/100, Iteration 19/38, Loss: 1.0970110893249512\n",
      "Epoch 2/100, Iteration 20/38, Loss: 1.098152995109558\n",
      "Epoch 2/100, Iteration 21/38, Loss: 1.0981229543685913\n",
      "Epoch 2/100, Iteration 22/38, Loss: 1.0948611497879028\n",
      "Epoch 2/100, Iteration 23/38, Loss: 1.1020318269729614\n",
      "Epoch 2/100, Iteration 24/38, Loss: 1.1005830764770508\n",
      "Epoch 2/100, Iteration 25/38, Loss: 1.0987879037857056\n",
      "Epoch 2/100, Iteration 26/38, Loss: 1.0948535203933716\n",
      "Epoch 2/100, Iteration 27/38, Loss: 1.098402976989746\n",
      "Epoch 2/100, Iteration 28/38, Loss: 1.1001533269882202\n",
      "Epoch 2/100, Iteration 29/38, Loss: 1.0971273183822632\n",
      "Epoch 2/100, Iteration 30/38, Loss: 1.0969457626342773\n",
      "Epoch 2/100, Iteration 31/38, Loss: 1.098790168762207\n",
      "Epoch 2/100, Iteration 32/38, Loss: 1.0956755876541138\n",
      "Epoch 2/100, Iteration 33/38, Loss: 1.0993999242782593\n",
      "Epoch 2/100, Iteration 34/38, Loss: 1.0960711240768433\n",
      "Epoch 2/100, Iteration 35/38, Loss: 1.099511981010437\n",
      "Epoch 2/100, Iteration 36/38, Loss: 1.098385214805603\n",
      "Epoch 2/100, Iteration 37/38, Loss: 1.0966731309890747\n",
      "Epoch 2/100, Iteration 38/38, Loss: 1.1004401445388794\n",
      "Epoch 3/100, Iteration 1/38, Loss: 1.0977433919906616\n",
      "Epoch 3/100, Iteration 2/38, Loss: 1.0982402563095093\n",
      "Epoch 3/100, Iteration 3/38, Loss: 1.0968801975250244\n",
      "Epoch 3/100, Iteration 4/38, Loss: 1.097385287284851\n",
      "Epoch 3/100, Iteration 5/38, Loss: 1.094022274017334\n",
      "Epoch 3/100, Iteration 6/38, Loss: 1.0977367162704468\n",
      "Epoch 3/100, Iteration 7/38, Loss: 1.0998544692993164\n",
      "Epoch 3/100, Iteration 8/38, Loss: 1.0969653129577637\n",
      "Epoch 3/100, Iteration 9/38, Loss: 1.093741536140442\n",
      "Epoch 3/100, Iteration 10/38, Loss: 1.0942468643188477\n",
      "Epoch 3/100, Iteration 11/38, Loss: 1.1015554666519165\n",
      "Epoch 3/100, Iteration 12/38, Loss: 1.1061755418777466\n",
      "Epoch 3/100, Iteration 13/38, Loss: 1.0985310077667236\n",
      "Epoch 3/100, Iteration 14/38, Loss: 1.0980364084243774\n",
      "Epoch 3/100, Iteration 15/38, Loss: 1.0945889949798584\n",
      "Epoch 3/100, Iteration 16/38, Loss: 1.0941760540008545\n",
      "Epoch 3/100, Iteration 17/38, Loss: 1.0966395139694214\n",
      "Epoch 3/100, Iteration 18/38, Loss: 1.0943278074264526\n",
      "Epoch 3/100, Iteration 19/38, Loss: 1.0950201749801636\n",
      "Epoch 3/100, Iteration 20/38, Loss: 1.0983734130859375\n",
      "Epoch 3/100, Iteration 21/38, Loss: 1.093381643295288\n",
      "Epoch 3/100, Iteration 22/38, Loss: 1.0933271646499634\n",
      "Epoch 3/100, Iteration 23/38, Loss: 1.0955889225006104\n",
      "Epoch 3/100, Iteration 24/38, Loss: 1.1023037433624268\n",
      "Epoch 3/100, Iteration 25/38, Loss: 1.1006170511245728\n",
      "Epoch 3/100, Iteration 26/38, Loss: 1.0924649238586426\n",
      "Epoch 3/100, Iteration 27/38, Loss: 1.0997871160507202\n",
      "Epoch 3/100, Iteration 28/38, Loss: 1.1003825664520264\n",
      "Epoch 3/100, Iteration 29/38, Loss: 1.097082257270813\n",
      "Epoch 3/100, Iteration 30/38, Loss: 1.0987004041671753\n",
      "Epoch 3/100, Iteration 31/38, Loss: 1.0968562364578247\n",
      "Epoch 3/100, Iteration 32/38, Loss: 1.1127119064331055\n",
      "Epoch 3/100, Iteration 33/38, Loss: 1.100188970565796\n",
      "Epoch 3/100, Iteration 34/38, Loss: 1.0992460250854492\n",
      "Epoch 3/100, Iteration 35/38, Loss: 1.0968691110610962\n",
      "Epoch 3/100, Iteration 36/38, Loss: 1.0953742265701294\n",
      "Epoch 3/100, Iteration 37/38, Loss: 1.0980814695358276\n",
      "Epoch 3/100, Iteration 38/38, Loss: 1.0975261926651\n",
      "Epoch 4/100, Iteration 1/38, Loss: 1.0994709730148315\n",
      "Epoch 4/100, Iteration 2/38, Loss: 1.0979952812194824\n",
      "Epoch 4/100, Iteration 3/38, Loss: 1.10069739818573\n",
      "Epoch 4/100, Iteration 4/38, Loss: 1.096800446510315\n",
      "Epoch 4/100, Iteration 5/38, Loss: 1.0973749160766602\n",
      "Epoch 4/100, Iteration 6/38, Loss: 1.0991216897964478\n",
      "Epoch 4/100, Iteration 7/38, Loss: 1.095967173576355\n",
      "Epoch 4/100, Iteration 8/38, Loss: 1.0978368520736694\n",
      "Epoch 4/100, Iteration 9/38, Loss: 1.0977904796600342\n",
      "Epoch 4/100, Iteration 10/38, Loss: 1.0987162590026855\n",
      "Epoch 4/100, Iteration 11/38, Loss: 1.0945414304733276\n",
      "Epoch 4/100, Iteration 12/38, Loss: 1.095848560333252\n",
      "Epoch 4/100, Iteration 13/38, Loss: 1.0927033424377441\n",
      "Epoch 4/100, Iteration 14/38, Loss: 1.0975148677825928\n",
      "Epoch 4/100, Iteration 15/38, Loss: 1.0982249975204468\n",
      "Epoch 4/100, Iteration 16/38, Loss: 1.0920172929763794\n",
      "Epoch 4/100, Iteration 17/38, Loss: 1.0935360193252563\n",
      "Epoch 4/100, Iteration 18/38, Loss: 1.1046065092086792\n",
      "Epoch 4/100, Iteration 19/38, Loss: 1.095823049545288\n",
      "Epoch 4/100, Iteration 20/38, Loss: 1.1039011478424072\n",
      "Epoch 4/100, Iteration 21/38, Loss: 1.0963140726089478\n",
      "Epoch 4/100, Iteration 22/38, Loss: 1.098575472831726\n",
      "Epoch 4/100, Iteration 23/38, Loss: 1.0954334735870361\n",
      "Epoch 4/100, Iteration 24/38, Loss: 1.099174976348877\n",
      "Epoch 4/100, Iteration 25/38, Loss: 1.096670389175415\n",
      "Epoch 4/100, Iteration 26/38, Loss: 1.0995863676071167\n",
      "Epoch 4/100, Iteration 27/38, Loss: 1.101456642150879\n",
      "Epoch 4/100, Iteration 28/38, Loss: 1.1001255512237549\n",
      "Epoch 4/100, Iteration 29/38, Loss: 1.0989190340042114\n",
      "Epoch 4/100, Iteration 30/38, Loss: 1.0953717231750488\n",
      "Epoch 4/100, Iteration 31/38, Loss: 1.0981653928756714\n",
      "Epoch 4/100, Iteration 32/38, Loss: 1.098231554031372\n",
      "Epoch 4/100, Iteration 33/38, Loss: 1.0956132411956787\n",
      "Epoch 4/100, Iteration 34/38, Loss: 1.0956604480743408\n",
      "Epoch 4/100, Iteration 35/38, Loss: 1.0974433422088623\n",
      "Epoch 4/100, Iteration 36/38, Loss: 1.088356852531433\n",
      "Epoch 4/100, Iteration 37/38, Loss: 1.107908844947815\n",
      "Epoch 4/100, Iteration 38/38, Loss: 1.0974485874176025\n",
      "Epoch 5/100, Iteration 1/38, Loss: 1.092029333114624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Iteration 2/38, Loss: 1.1036568880081177\n",
      "Epoch 5/100, Iteration 3/38, Loss: 1.0927575826644897\n",
      "Epoch 5/100, Iteration 4/38, Loss: 1.0969583988189697\n",
      "Epoch 5/100, Iteration 5/38, Loss: 1.0926498174667358\n",
      "Epoch 5/100, Iteration 6/38, Loss: 1.1022340059280396\n",
      "Epoch 5/100, Iteration 7/38, Loss: 1.0959668159484863\n",
      "Epoch 5/100, Iteration 8/38, Loss: 1.10128915309906\n",
      "Epoch 5/100, Iteration 9/38, Loss: 1.0965665578842163\n",
      "Epoch 5/100, Iteration 10/38, Loss: 1.0971121788024902\n",
      "Epoch 5/100, Iteration 11/38, Loss: 1.091583251953125\n",
      "Epoch 5/100, Iteration 12/38, Loss: 1.1013338565826416\n",
      "Epoch 5/100, Iteration 13/38, Loss: 1.1002355813980103\n",
      "Epoch 5/100, Iteration 14/38, Loss: 1.094670295715332\n",
      "Epoch 5/100, Iteration 15/38, Loss: 1.1022403240203857\n",
      "Epoch 5/100, Iteration 16/38, Loss: 1.0987299680709839\n",
      "Epoch 5/100, Iteration 17/38, Loss: 1.0938986539840698\n",
      "Epoch 5/100, Iteration 18/38, Loss: 1.0940907001495361\n",
      "Epoch 5/100, Iteration 19/38, Loss: 1.0979127883911133\n",
      "Epoch 5/100, Iteration 20/38, Loss: 1.0941951274871826\n",
      "Epoch 5/100, Iteration 21/38, Loss: 1.0954653024673462\n",
      "Epoch 5/100, Iteration 22/38, Loss: 1.096062183380127\n",
      "Epoch 5/100, Iteration 23/38, Loss: 1.0990585088729858\n",
      "Epoch 5/100, Iteration 24/38, Loss: 1.0949196815490723\n",
      "Epoch 5/100, Iteration 25/38, Loss: 1.1004468202590942\n",
      "Epoch 5/100, Iteration 26/38, Loss: 1.1011261940002441\n",
      "Epoch 5/100, Iteration 27/38, Loss: 1.1019363403320312\n",
      "Epoch 5/100, Iteration 28/38, Loss: 1.0976184606552124\n",
      "Epoch 5/100, Iteration 29/38, Loss: 1.095489501953125\n",
      "Epoch 5/100, Iteration 30/38, Loss: 1.0936940908432007\n",
      "Epoch 5/100, Iteration 31/38, Loss: 1.1020784378051758\n",
      "Epoch 5/100, Iteration 32/38, Loss: 1.0950437784194946\n",
      "Epoch 5/100, Iteration 33/38, Loss: 1.0923820734024048\n",
      "Epoch 5/100, Iteration 34/38, Loss: 1.1036709547042847\n",
      "Epoch 5/100, Iteration 35/38, Loss: 1.0987051725387573\n",
      "Epoch 5/100, Iteration 36/38, Loss: 1.0936251878738403\n",
      "Epoch 5/100, Iteration 37/38, Loss: 1.0939407348632812\n",
      "Epoch 5/100, Iteration 38/38, Loss: 1.0930652618408203\n",
      "Epoch 6/100, Iteration 1/38, Loss: 1.1100269556045532\n",
      "Epoch 6/100, Iteration 2/38, Loss: 1.0980995893478394\n",
      "Epoch 6/100, Iteration 3/38, Loss: 1.0968761444091797\n",
      "Epoch 6/100, Iteration 4/38, Loss: 1.0949492454528809\n",
      "Epoch 6/100, Iteration 5/38, Loss: 1.0951311588287354\n",
      "Epoch 6/100, Iteration 6/38, Loss: 1.099565029144287\n",
      "Epoch 6/100, Iteration 7/38, Loss: 1.0951242446899414\n",
      "Epoch 6/100, Iteration 8/38, Loss: 1.0962762832641602\n",
      "Epoch 6/100, Iteration 9/38, Loss: 1.0914909839630127\n",
      "Epoch 6/100, Iteration 10/38, Loss: 1.0915918350219727\n",
      "Epoch 6/100, Iteration 11/38, Loss: 1.0916420221328735\n",
      "Epoch 6/100, Iteration 12/38, Loss: 1.0863935947418213\n",
      "Epoch 6/100, Iteration 13/38, Loss: 1.0995084047317505\n",
      "Epoch 6/100, Iteration 14/38, Loss: 1.0943658351898193\n",
      "Epoch 6/100, Iteration 15/38, Loss: 1.0905256271362305\n",
      "Epoch 6/100, Iteration 16/38, Loss: 1.093987226486206\n",
      "Epoch 6/100, Iteration 17/38, Loss: 1.1132161617279053\n",
      "Epoch 6/100, Iteration 18/38, Loss: 1.0959653854370117\n",
      "Epoch 6/100, Iteration 19/38, Loss: 1.0933561325073242\n",
      "Epoch 6/100, Iteration 20/38, Loss: 1.1079235076904297\n",
      "Epoch 6/100, Iteration 21/38, Loss: 1.1028305292129517\n",
      "Epoch 6/100, Iteration 22/38, Loss: 1.100404977798462\n",
      "Epoch 6/100, Iteration 23/38, Loss: 1.0941874980926514\n",
      "Epoch 6/100, Iteration 24/38, Loss: 1.0951528549194336\n",
      "Epoch 6/100, Iteration 25/38, Loss: 1.102688193321228\n",
      "Epoch 6/100, Iteration 26/38, Loss: 1.0953906774520874\n",
      "Epoch 6/100, Iteration 27/38, Loss: 1.0971055030822754\n",
      "Epoch 6/100, Iteration 28/38, Loss: 1.088213324546814\n",
      "Epoch 6/100, Iteration 29/38, Loss: 1.092319369316101\n",
      "Epoch 6/100, Iteration 30/38, Loss: 1.0988355875015259\n",
      "Epoch 6/100, Iteration 31/38, Loss: 1.1036595106124878\n",
      "Epoch 6/100, Iteration 32/38, Loss: 1.0903759002685547\n",
      "Epoch 6/100, Iteration 33/38, Loss: 1.0990005731582642\n",
      "Epoch 6/100, Iteration 34/38, Loss: 1.0953285694122314\n",
      "Epoch 6/100, Iteration 35/38, Loss: 1.097798466682434\n",
      "Epoch 6/100, Iteration 36/38, Loss: 1.1051995754241943\n",
      "Epoch 6/100, Iteration 37/38, Loss: 1.089943528175354\n",
      "Epoch 6/100, Iteration 38/38, Loss: 1.1029821634292603\n",
      "Epoch 7/100, Iteration 1/38, Loss: 1.0943801403045654\n",
      "Epoch 7/100, Iteration 2/38, Loss: 1.0955007076263428\n",
      "Epoch 7/100, Iteration 3/38, Loss: 1.0957272052764893\n",
      "Epoch 7/100, Iteration 4/38, Loss: 1.106676697731018\n",
      "Epoch 7/100, Iteration 5/38, Loss: 1.0952106714248657\n",
      "Epoch 7/100, Iteration 6/38, Loss: 1.088087558746338\n",
      "Epoch 7/100, Iteration 7/38, Loss: 1.1044501066207886\n",
      "Epoch 7/100, Iteration 8/38, Loss: 1.0957096815109253\n",
      "Epoch 7/100, Iteration 9/38, Loss: 1.1045457124710083\n",
      "Epoch 7/100, Iteration 10/38, Loss: 1.088065505027771\n",
      "Epoch 7/100, Iteration 11/38, Loss: 1.0948373079299927\n",
      "Epoch 7/100, Iteration 12/38, Loss: 1.0890520811080933\n",
      "Epoch 7/100, Iteration 13/38, Loss: 1.1065696477890015\n",
      "Epoch 7/100, Iteration 14/38, Loss: 1.0950747728347778\n",
      "Epoch 7/100, Iteration 15/38, Loss: 1.1084301471710205\n",
      "Epoch 7/100, Iteration 16/38, Loss: 1.0972102880477905\n",
      "Epoch 7/100, Iteration 17/38, Loss: 1.1075776815414429\n",
      "Epoch 7/100, Iteration 18/38, Loss: 1.0945183038711548\n",
      "Epoch 7/100, Iteration 19/38, Loss: 1.0952118635177612\n",
      "Epoch 7/100, Iteration 20/38, Loss: 1.0958038568496704\n",
      "Epoch 7/100, Iteration 21/38, Loss: 1.0892497301101685\n",
      "Epoch 7/100, Iteration 22/38, Loss: 1.0969923734664917\n",
      "Epoch 7/100, Iteration 23/38, Loss: 1.0909799337387085\n",
      "Epoch 7/100, Iteration 24/38, Loss: 1.0946621894836426\n",
      "Epoch 7/100, Iteration 25/38, Loss: 1.0907683372497559\n",
      "Epoch 7/100, Iteration 26/38, Loss: 1.1030044555664062\n",
      "Epoch 7/100, Iteration 27/38, Loss: 1.0984160900115967\n",
      "Epoch 7/100, Iteration 28/38, Loss: 1.0996372699737549\n",
      "Epoch 7/100, Iteration 29/38, Loss: 1.0973572731018066\n",
      "Epoch 7/100, Iteration 30/38, Loss: 1.0904587507247925\n",
      "Epoch 7/100, Iteration 31/38, Loss: 1.097218632698059\n",
      "Epoch 7/100, Iteration 32/38, Loss: 1.092577576637268\n",
      "Epoch 7/100, Iteration 33/38, Loss: 1.096099853515625\n",
      "Epoch 7/100, Iteration 34/38, Loss: 1.098048210144043\n",
      "Epoch 7/100, Iteration 35/38, Loss: 1.09473717212677\n",
      "Epoch 7/100, Iteration 36/38, Loss: 1.0975236892700195\n",
      "Epoch 7/100, Iteration 37/38, Loss: 1.0912529230117798\n",
      "Epoch 7/100, Iteration 38/38, Loss: 1.0880626440048218\n",
      "Epoch 8/100, Iteration 1/38, Loss: 1.0927422046661377\n",
      "Epoch 8/100, Iteration 2/38, Loss: 1.0920236110687256\n",
      "Epoch 8/100, Iteration 3/38, Loss: 1.0953043699264526\n",
      "Epoch 8/100, Iteration 4/38, Loss: 1.1000943183898926\n",
      "Epoch 8/100, Iteration 5/38, Loss: 1.0990231037139893\n",
      "Epoch 8/100, Iteration 6/38, Loss: 1.0874398946762085\n",
      "Epoch 8/100, Iteration 7/38, Loss: 1.097233533859253\n",
      "Epoch 8/100, Iteration 8/38, Loss: 1.0980571508407593\n",
      "Epoch 8/100, Iteration 9/38, Loss: 1.0953967571258545\n",
      "Epoch 8/100, Iteration 10/38, Loss: 1.1048996448516846\n",
      "Epoch 8/100, Iteration 11/38, Loss: 1.081190824508667\n",
      "Epoch 8/100, Iteration 12/38, Loss: 1.088793396949768\n",
      "Epoch 8/100, Iteration 13/38, Loss: 1.0890183448791504\n",
      "Epoch 8/100, Iteration 14/38, Loss: 1.1135926246643066\n",
      "Epoch 8/100, Iteration 15/38, Loss: 1.0875000953674316\n",
      "Epoch 8/100, Iteration 16/38, Loss: 1.0977219343185425\n",
      "Epoch 8/100, Iteration 17/38, Loss: 1.0949689149856567\n",
      "Epoch 8/100, Iteration 18/38, Loss: 1.1008371114730835\n",
      "Epoch 8/100, Iteration 19/38, Loss: 1.0933723449707031\n",
      "Epoch 8/100, Iteration 20/38, Loss: 1.103637933731079\n",
      "Epoch 8/100, Iteration 21/38, Loss: 1.098264217376709\n",
      "Epoch 8/100, Iteration 22/38, Loss: 1.0930620431900024\n",
      "Epoch 8/100, Iteration 23/38, Loss: 1.0935168266296387\n",
      "Epoch 8/100, Iteration 24/38, Loss: 1.099597454071045\n",
      "Epoch 8/100, Iteration 25/38, Loss: 1.0930684804916382\n",
      "Epoch 8/100, Iteration 26/38, Loss: 1.0916528701782227\n",
      "Epoch 8/100, Iteration 27/38, Loss: 1.094768762588501\n",
      "Epoch 8/100, Iteration 28/38, Loss: 1.092273473739624\n",
      "Epoch 8/100, Iteration 29/38, Loss: 1.105331540107727\n",
      "Epoch 8/100, Iteration 30/38, Loss: 1.0971790552139282\n",
      "Epoch 8/100, Iteration 31/38, Loss: 1.0921506881713867\n",
      "Epoch 8/100, Iteration 32/38, Loss: 1.0916593074798584\n",
      "Epoch 8/100, Iteration 33/38, Loss: 1.0975145101547241\n",
      "Epoch 8/100, Iteration 34/38, Loss: 1.0904375314712524\n",
      "Epoch 8/100, Iteration 35/38, Loss: 1.091126561164856\n",
      "Epoch 8/100, Iteration 36/38, Loss: 1.0991668701171875\n",
      "Epoch 8/100, Iteration 37/38, Loss: 1.0913403034210205\n",
      "Epoch 8/100, Iteration 38/38, Loss: 1.0908050537109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Iteration 1/38, Loss: 1.1033086776733398\n",
      "Epoch 9/100, Iteration 2/38, Loss: 1.0934325456619263\n",
      "Epoch 9/100, Iteration 3/38, Loss: 1.0998625755310059\n",
      "Epoch 9/100, Iteration 4/38, Loss: 1.0838370323181152\n",
      "Epoch 9/100, Iteration 5/38, Loss: 1.0857588052749634\n",
      "Epoch 9/100, Iteration 6/38, Loss: 1.0820995569229126\n",
      "Epoch 9/100, Iteration 7/38, Loss: 1.099389910697937\n",
      "Epoch 9/100, Iteration 8/38, Loss: 1.1124494075775146\n",
      "Epoch 9/100, Iteration 9/38, Loss: 1.1023406982421875\n",
      "Epoch 9/100, Iteration 10/38, Loss: 1.092738151550293\n",
      "Epoch 9/100, Iteration 11/38, Loss: 1.0906915664672852\n",
      "Epoch 9/100, Iteration 12/38, Loss: 1.0891541242599487\n",
      "Epoch 9/100, Iteration 13/38, Loss: 1.092386245727539\n",
      "Epoch 9/100, Iteration 14/38, Loss: 1.0881762504577637\n",
      "Epoch 9/100, Iteration 15/38, Loss: 1.0910083055496216\n",
      "Epoch 9/100, Iteration 16/38, Loss: 1.0954043865203857\n",
      "Epoch 9/100, Iteration 17/38, Loss: 1.0981124639511108\n",
      "Epoch 9/100, Iteration 18/38, Loss: 1.0966637134552002\n",
      "Epoch 9/100, Iteration 19/38, Loss: 1.0833368301391602\n",
      "Epoch 9/100, Iteration 20/38, Loss: 1.102782130241394\n",
      "Epoch 9/100, Iteration 21/38, Loss: 1.108347773551941\n",
      "Epoch 9/100, Iteration 22/38, Loss: 1.0861603021621704\n",
      "Epoch 9/100, Iteration 23/38, Loss: 1.1042146682739258\n",
      "Epoch 9/100, Iteration 24/38, Loss: 1.0971862077713013\n",
      "Epoch 9/100, Iteration 25/38, Loss: 1.0944122076034546\n",
      "Epoch 9/100, Iteration 26/38, Loss: 1.0941531658172607\n",
      "Epoch 9/100, Iteration 27/38, Loss: 1.1039847135543823\n",
      "Epoch 9/100, Iteration 28/38, Loss: 1.0956825017929077\n",
      "Epoch 9/100, Iteration 29/38, Loss: 1.09389328956604\n",
      "Epoch 9/100, Iteration 30/38, Loss: 1.08620023727417\n",
      "Epoch 9/100, Iteration 31/38, Loss: 1.098259687423706\n",
      "Epoch 9/100, Iteration 32/38, Loss: 1.0988470315933228\n",
      "Epoch 9/100, Iteration 33/38, Loss: 1.0980942249298096\n",
      "Epoch 9/100, Iteration 34/38, Loss: 1.0898813009262085\n",
      "Epoch 9/100, Iteration 35/38, Loss: 1.0976418256759644\n",
      "Epoch 9/100, Iteration 36/38, Loss: 1.099358320236206\n",
      "Epoch 9/100, Iteration 37/38, Loss: 1.0994967222213745\n",
      "Epoch 9/100, Iteration 38/38, Loss: 1.0897496938705444\n",
      "Epoch 10/100, Iteration 1/38, Loss: 1.094001293182373\n",
      "Epoch 10/100, Iteration 2/38, Loss: 1.0946097373962402\n",
      "Epoch 10/100, Iteration 3/38, Loss: 1.0831149816513062\n",
      "Epoch 10/100, Iteration 4/38, Loss: 1.091599464416504\n",
      "Epoch 10/100, Iteration 5/38, Loss: 1.0983785390853882\n",
      "Epoch 10/100, Iteration 6/38, Loss: 1.086243748664856\n",
      "Epoch 10/100, Iteration 7/38, Loss: 1.0948660373687744\n",
      "Epoch 10/100, Iteration 8/38, Loss: 1.094750165939331\n",
      "Epoch 10/100, Iteration 9/38, Loss: 1.1003236770629883\n",
      "Epoch 10/100, Iteration 10/38, Loss: 1.096890926361084\n",
      "Epoch 10/100, Iteration 11/38, Loss: 1.1011230945587158\n",
      "Epoch 10/100, Iteration 12/38, Loss: 1.0849382877349854\n",
      "Epoch 10/100, Iteration 13/38, Loss: 1.091102957725525\n",
      "Epoch 10/100, Iteration 14/38, Loss: 1.0880240201950073\n",
      "Epoch 10/100, Iteration 15/38, Loss: 1.1088773012161255\n",
      "Epoch 10/100, Iteration 16/38, Loss: 1.0727254152297974\n",
      "Epoch 10/100, Iteration 17/38, Loss: 1.0896341800689697\n",
      "Epoch 10/100, Iteration 18/38, Loss: 1.0855814218521118\n",
      "Epoch 10/100, Iteration 19/38, Loss: 1.095471978187561\n",
      "Epoch 10/100, Iteration 20/38, Loss: 1.1162104606628418\n",
      "Epoch 10/100, Iteration 21/38, Loss: 1.092137336730957\n",
      "Epoch 10/100, Iteration 22/38, Loss: 1.0816080570220947\n",
      "Epoch 10/100, Iteration 23/38, Loss: 1.1088840961456299\n",
      "Epoch 10/100, Iteration 24/38, Loss: 1.0830340385437012\n",
      "Epoch 10/100, Iteration 25/38, Loss: 1.095956802368164\n",
      "Epoch 10/100, Iteration 26/38, Loss: 1.093454360961914\n",
      "Epoch 10/100, Iteration 27/38, Loss: 1.0970630645751953\n",
      "Epoch 10/100, Iteration 28/38, Loss: 1.08487069606781\n",
      "Epoch 10/100, Iteration 29/38, Loss: 1.0908344984054565\n",
      "Epoch 10/100, Iteration 30/38, Loss: 1.0962860584259033\n",
      "Epoch 10/100, Iteration 31/38, Loss: 1.0744891166687012\n",
      "Epoch 10/100, Iteration 32/38, Loss: 1.1008869409561157\n",
      "Epoch 10/100, Iteration 33/38, Loss: 1.09511399269104\n",
      "Epoch 10/100, Iteration 34/38, Loss: 1.0914438962936401\n",
      "Epoch 10/100, Iteration 35/38, Loss: 1.0991301536560059\n",
      "Epoch 10/100, Iteration 36/38, Loss: 1.0905174016952515\n",
      "Epoch 10/100, Iteration 37/38, Loss: 1.0864214897155762\n",
      "Epoch 10/100, Iteration 38/38, Loss: 1.1071879863739014\n",
      "Epoch 11/100, Iteration 1/38, Loss: 1.0939435958862305\n",
      "Epoch 11/100, Iteration 2/38, Loss: 1.0822510719299316\n",
      "Epoch 11/100, Iteration 3/38, Loss: 1.099782109260559\n",
      "Epoch 11/100, Iteration 4/38, Loss: 1.091447353363037\n",
      "Epoch 11/100, Iteration 5/38, Loss: 1.1027660369873047\n",
      "Epoch 11/100, Iteration 6/38, Loss: 1.0922009944915771\n",
      "Epoch 11/100, Iteration 7/38, Loss: 1.1010093688964844\n",
      "Epoch 11/100, Iteration 8/38, Loss: 1.0902504920959473\n",
      "Epoch 11/100, Iteration 9/38, Loss: 1.102632761001587\n",
      "Epoch 11/100, Iteration 10/38, Loss: 1.0906997919082642\n",
      "Epoch 11/100, Iteration 11/38, Loss: 1.1036920547485352\n",
      "Epoch 11/100, Iteration 12/38, Loss: 1.0939381122589111\n",
      "Epoch 11/100, Iteration 13/38, Loss: 1.0900788307189941\n",
      "Epoch 11/100, Iteration 14/38, Loss: 1.0860729217529297\n",
      "Epoch 11/100, Iteration 15/38, Loss: 1.0852060317993164\n",
      "Epoch 11/100, Iteration 16/38, Loss: 1.101969599723816\n",
      "Epoch 11/100, Iteration 17/38, Loss: 1.0894675254821777\n",
      "Epoch 11/100, Iteration 18/38, Loss: 1.0771881341934204\n",
      "Epoch 11/100, Iteration 19/38, Loss: 1.1024457216262817\n",
      "Epoch 11/100, Iteration 20/38, Loss: 1.0828028917312622\n",
      "Epoch 11/100, Iteration 21/38, Loss: 1.115251064300537\n",
      "Epoch 11/100, Iteration 22/38, Loss: 1.0957282781600952\n",
      "Epoch 11/100, Iteration 23/38, Loss: 1.071089267730713\n",
      "Epoch 11/100, Iteration 24/38, Loss: 1.0958459377288818\n",
      "Epoch 11/100, Iteration 25/38, Loss: 1.1107481718063354\n",
      "Epoch 11/100, Iteration 26/38, Loss: 1.0882320404052734\n",
      "Epoch 11/100, Iteration 27/38, Loss: 1.094940185546875\n",
      "Epoch 11/100, Iteration 28/38, Loss: 1.096767783164978\n",
      "Epoch 11/100, Iteration 29/38, Loss: 1.0819405317306519\n",
      "Epoch 11/100, Iteration 30/38, Loss: 1.0897990465164185\n",
      "Epoch 11/100, Iteration 31/38, Loss: 1.0986272096633911\n",
      "Epoch 11/100, Iteration 32/38, Loss: 1.0916688442230225\n",
      "Epoch 11/100, Iteration 33/38, Loss: 1.1048256158828735\n",
      "Epoch 11/100, Iteration 34/38, Loss: 1.086194396018982\n",
      "Epoch 11/100, Iteration 35/38, Loss: 1.0917820930480957\n",
      "Epoch 11/100, Iteration 36/38, Loss: 1.087557077407837\n",
      "Epoch 11/100, Iteration 37/38, Loss: 1.086153268814087\n",
      "Epoch 11/100, Iteration 38/38, Loss: 1.0747454166412354\n",
      "Epoch 12/100, Iteration 1/38, Loss: 1.1011676788330078\n",
      "Epoch 12/100, Iteration 2/38, Loss: 1.0906744003295898\n",
      "Epoch 12/100, Iteration 3/38, Loss: 1.1046528816223145\n",
      "Epoch 12/100, Iteration 4/38, Loss: 1.0897746086120605\n",
      "Epoch 12/100, Iteration 5/38, Loss: 1.070732831954956\n",
      "Epoch 12/100, Iteration 6/38, Loss: 1.0974165201187134\n",
      "Epoch 12/100, Iteration 7/38, Loss: 1.0895514488220215\n",
      "Epoch 12/100, Iteration 8/38, Loss: 1.0984667539596558\n",
      "Epoch 12/100, Iteration 9/38, Loss: 1.0813301801681519\n",
      "Epoch 12/100, Iteration 10/38, Loss: 1.0934021472930908\n",
      "Epoch 12/100, Iteration 11/38, Loss: 1.1134942770004272\n",
      "Epoch 12/100, Iteration 12/38, Loss: 1.0910234451293945\n",
      "Epoch 12/100, Iteration 13/38, Loss: 1.0722702741622925\n",
      "Epoch 12/100, Iteration 14/38, Loss: 1.0920417308807373\n",
      "Epoch 12/100, Iteration 15/38, Loss: 1.084512710571289\n",
      "Epoch 12/100, Iteration 16/38, Loss: 1.0914275646209717\n",
      "Epoch 12/100, Iteration 17/38, Loss: 1.081267237663269\n",
      "Epoch 12/100, Iteration 18/38, Loss: 1.0804340839385986\n",
      "Epoch 12/100, Iteration 19/38, Loss: 1.1027733087539673\n",
      "Epoch 12/100, Iteration 20/38, Loss: 1.0851012468338013\n",
      "Epoch 12/100, Iteration 21/38, Loss: 1.0959703922271729\n",
      "Epoch 12/100, Iteration 22/38, Loss: 1.0904544591903687\n",
      "Epoch 12/100, Iteration 23/38, Loss: 1.075640320777893\n",
      "Epoch 12/100, Iteration 24/38, Loss: 1.0799129009246826\n",
      "Epoch 12/100, Iteration 25/38, Loss: 1.0919736623764038\n",
      "Epoch 12/100, Iteration 26/38, Loss: 1.1065915822982788\n",
      "Epoch 12/100, Iteration 27/38, Loss: 1.0931518077850342\n",
      "Epoch 12/100, Iteration 28/38, Loss: 1.0803139209747314\n",
      "Epoch 12/100, Iteration 29/38, Loss: 1.0706419944763184\n",
      "Epoch 12/100, Iteration 30/38, Loss: 1.0971180200576782\n",
      "Epoch 12/100, Iteration 31/38, Loss: 1.0794905424118042\n",
      "Epoch 12/100, Iteration 32/38, Loss: 1.0777888298034668\n",
      "Epoch 12/100, Iteration 33/38, Loss: 1.0696872472763062\n",
      "Epoch 12/100, Iteration 34/38, Loss: 1.06461763381958\n",
      "Epoch 12/100, Iteration 35/38, Loss: 1.1000531911849976\n",
      "Epoch 12/100, Iteration 36/38, Loss: 1.1036750078201294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Iteration 37/38, Loss: 1.1037369966506958\n",
      "Epoch 12/100, Iteration 38/38, Loss: 1.082364559173584\n",
      "Epoch 13/100, Iteration 1/38, Loss: 1.0918837785720825\n",
      "Epoch 13/100, Iteration 2/38, Loss: 1.080838918685913\n",
      "Epoch 13/100, Iteration 3/38, Loss: 1.0709891319274902\n",
      "Epoch 13/100, Iteration 4/38, Loss: 1.105708360671997\n",
      "Epoch 13/100, Iteration 5/38, Loss: 1.0840033292770386\n",
      "Epoch 13/100, Iteration 6/38, Loss: 1.1176432371139526\n",
      "Epoch 13/100, Iteration 7/38, Loss: 1.0940353870391846\n",
      "Epoch 13/100, Iteration 8/38, Loss: 1.1057820320129395\n",
      "Epoch 13/100, Iteration 9/38, Loss: 1.0752590894699097\n",
      "Epoch 13/100, Iteration 10/38, Loss: 1.075276494026184\n",
      "Epoch 13/100, Iteration 11/38, Loss: 1.0808693170547485\n",
      "Epoch 13/100, Iteration 12/38, Loss: 1.1023128032684326\n",
      "Epoch 13/100, Iteration 13/38, Loss: 1.0891114473342896\n",
      "Epoch 13/100, Iteration 14/38, Loss: 1.0710551738739014\n",
      "Epoch 13/100, Iteration 15/38, Loss: 1.0705952644348145\n",
      "Epoch 13/100, Iteration 16/38, Loss: 1.085893988609314\n",
      "Epoch 13/100, Iteration 17/38, Loss: 1.0831263065338135\n",
      "Epoch 13/100, Iteration 18/38, Loss: 1.0863136053085327\n",
      "Epoch 13/100, Iteration 19/38, Loss: 1.0766620635986328\n",
      "Epoch 13/100, Iteration 20/38, Loss: 1.0888175964355469\n",
      "Epoch 13/100, Iteration 21/38, Loss: 1.0880764722824097\n",
      "Epoch 13/100, Iteration 22/38, Loss: 1.0823426246643066\n",
      "Epoch 13/100, Iteration 23/38, Loss: 1.0960079431533813\n",
      "Epoch 13/100, Iteration 24/38, Loss: 1.112191915512085\n",
      "Epoch 13/100, Iteration 25/38, Loss: 1.1011009216308594\n",
      "Epoch 13/100, Iteration 26/38, Loss: 1.0978736877441406\n",
      "Epoch 13/100, Iteration 27/38, Loss: 1.1089468002319336\n",
      "Epoch 13/100, Iteration 28/38, Loss: 1.0918995141983032\n",
      "Epoch 13/100, Iteration 29/38, Loss: 1.0941945314407349\n",
      "Epoch 13/100, Iteration 30/38, Loss: 1.0941094160079956\n",
      "Epoch 13/100, Iteration 31/38, Loss: 1.0854532718658447\n",
      "Epoch 13/100, Iteration 32/38, Loss: 1.074486494064331\n",
      "Epoch 13/100, Iteration 33/38, Loss: 1.0787596702575684\n",
      "Epoch 13/100, Iteration 34/38, Loss: 1.0869027376174927\n",
      "Epoch 13/100, Iteration 35/38, Loss: 1.085457444190979\n",
      "Epoch 13/100, Iteration 36/38, Loss: 1.0960333347320557\n",
      "Epoch 13/100, Iteration 37/38, Loss: 1.0896178483963013\n",
      "Epoch 13/100, Iteration 38/38, Loss: 1.060950517654419\n",
      "Epoch 14/100, Iteration 1/38, Loss: 1.0756816864013672\n",
      "Epoch 14/100, Iteration 2/38, Loss: 1.0556492805480957\n",
      "Epoch 14/100, Iteration 3/38, Loss: 1.1002644300460815\n",
      "Epoch 14/100, Iteration 4/38, Loss: 1.0954588651657104\n",
      "Epoch 14/100, Iteration 5/38, Loss: 1.0999397039413452\n",
      "Epoch 14/100, Iteration 6/38, Loss: 1.0812933444976807\n",
      "Epoch 14/100, Iteration 7/38, Loss: 1.0881786346435547\n",
      "Epoch 14/100, Iteration 8/38, Loss: 1.0804038047790527\n",
      "Epoch 14/100, Iteration 9/38, Loss: 1.0616620779037476\n",
      "Epoch 14/100, Iteration 10/38, Loss: 1.0741418600082397\n",
      "Epoch 14/100, Iteration 11/38, Loss: 1.1010104417800903\n",
      "Epoch 14/100, Iteration 12/38, Loss: 1.0910309553146362\n",
      "Epoch 14/100, Iteration 13/38, Loss: 1.074507713317871\n",
      "Epoch 14/100, Iteration 14/38, Loss: 1.0852967500686646\n",
      "Epoch 14/100, Iteration 15/38, Loss: 1.0876103639602661\n",
      "Epoch 14/100, Iteration 16/38, Loss: 1.0758923292160034\n",
      "Epoch 14/100, Iteration 17/38, Loss: 1.1111690998077393\n",
      "Epoch 14/100, Iteration 18/38, Loss: 1.084937572479248\n",
      "Epoch 14/100, Iteration 19/38, Loss: 1.0826289653778076\n",
      "Epoch 14/100, Iteration 20/38, Loss: 1.094637393951416\n",
      "Epoch 14/100, Iteration 21/38, Loss: 1.0812631845474243\n",
      "Epoch 14/100, Iteration 22/38, Loss: 1.0955880880355835\n",
      "Epoch 14/100, Iteration 23/38, Loss: 1.0531871318817139\n",
      "Epoch 14/100, Iteration 24/38, Loss: 1.0688889026641846\n",
      "Epoch 14/100, Iteration 25/38, Loss: 1.0846558809280396\n",
      "Epoch 14/100, Iteration 26/38, Loss: 1.0875234603881836\n",
      "Epoch 14/100, Iteration 27/38, Loss: 1.0958460569381714\n",
      "Epoch 14/100, Iteration 28/38, Loss: 1.0708839893341064\n",
      "Epoch 14/100, Iteration 29/38, Loss: 1.1122252941131592\n",
      "Epoch 14/100, Iteration 30/38, Loss: 1.0868020057678223\n",
      "Epoch 14/100, Iteration 31/38, Loss: 1.0586483478546143\n",
      "Epoch 14/100, Iteration 32/38, Loss: 1.0735645294189453\n",
      "Epoch 14/100, Iteration 33/38, Loss: 1.0967662334442139\n",
      "Epoch 14/100, Iteration 34/38, Loss: 1.1105953454971313\n",
      "Epoch 14/100, Iteration 35/38, Loss: 1.0697717666625977\n",
      "Epoch 14/100, Iteration 36/38, Loss: 1.1018130779266357\n",
      "Epoch 14/100, Iteration 37/38, Loss: 1.080570936203003\n",
      "Epoch 14/100, Iteration 38/38, Loss: 1.0959248542785645\n",
      "Epoch 15/100, Iteration 1/38, Loss: 1.0641369819641113\n",
      "Epoch 15/100, Iteration 2/38, Loss: 1.0565850734710693\n",
      "Epoch 15/100, Iteration 3/38, Loss: 1.0809979438781738\n",
      "Epoch 15/100, Iteration 4/38, Loss: 1.0861567258834839\n",
      "Epoch 15/100, Iteration 5/38, Loss: 1.065869688987732\n",
      "Epoch 15/100, Iteration 6/38, Loss: 1.0883729457855225\n",
      "Epoch 15/100, Iteration 7/38, Loss: 1.0860236883163452\n",
      "Epoch 15/100, Iteration 8/38, Loss: 1.089674949645996\n",
      "Epoch 15/100, Iteration 9/38, Loss: 1.0637657642364502\n",
      "Epoch 15/100, Iteration 10/38, Loss: 1.123284935951233\n",
      "Epoch 15/100, Iteration 11/38, Loss: 1.0606766939163208\n",
      "Epoch 15/100, Iteration 12/38, Loss: 1.1041074991226196\n",
      "Epoch 15/100, Iteration 13/38, Loss: 1.06008780002594\n",
      "Epoch 15/100, Iteration 14/38, Loss: 1.11573326587677\n",
      "Epoch 15/100, Iteration 15/38, Loss: 1.1098331212997437\n",
      "Epoch 15/100, Iteration 16/38, Loss: 1.0949074029922485\n",
      "Epoch 15/100, Iteration 17/38, Loss: 1.112169623374939\n",
      "Epoch 15/100, Iteration 18/38, Loss: 1.0947203636169434\n",
      "Epoch 15/100, Iteration 19/38, Loss: 1.0970499515533447\n",
      "Epoch 15/100, Iteration 20/38, Loss: 1.0655287504196167\n",
      "Epoch 15/100, Iteration 21/38, Loss: 1.077691674232483\n",
      "Epoch 15/100, Iteration 22/38, Loss: 1.07554292678833\n",
      "Epoch 15/100, Iteration 23/38, Loss: 1.0651220083236694\n",
      "Epoch 15/100, Iteration 24/38, Loss: 1.1256612539291382\n",
      "Epoch 15/100, Iteration 25/38, Loss: 1.0928043127059937\n",
      "Epoch 15/100, Iteration 26/38, Loss: 1.0631003379821777\n",
      "Epoch 15/100, Iteration 27/38, Loss: 1.0860315561294556\n",
      "Epoch 15/100, Iteration 28/38, Loss: 1.0804386138916016\n",
      "Epoch 15/100, Iteration 29/38, Loss: 1.1190983057022095\n",
      "Epoch 15/100, Iteration 30/38, Loss: 1.073859691619873\n",
      "Epoch 15/100, Iteration 31/38, Loss: 1.0999069213867188\n",
      "Epoch 15/100, Iteration 32/38, Loss: 1.0805964469909668\n",
      "Epoch 15/100, Iteration 33/38, Loss: 1.069454550743103\n",
      "Epoch 15/100, Iteration 34/38, Loss: 1.0632498264312744\n",
      "Epoch 15/100, Iteration 35/38, Loss: 1.032689094543457\n",
      "Epoch 15/100, Iteration 36/38, Loss: 1.0814509391784668\n",
      "Epoch 15/100, Iteration 37/38, Loss: 1.0785456895828247\n",
      "Epoch 15/100, Iteration 38/38, Loss: 1.07264244556427\n",
      "Epoch 16/100, Iteration 1/38, Loss: 1.138602375984192\n",
      "Epoch 16/100, Iteration 2/38, Loss: 1.0594563484191895\n",
      "Epoch 16/100, Iteration 3/38, Loss: 1.0721118450164795\n",
      "Epoch 16/100, Iteration 4/38, Loss: 1.094778299331665\n",
      "Epoch 16/100, Iteration 5/38, Loss: 1.059219479560852\n",
      "Epoch 16/100, Iteration 6/38, Loss: 1.0634526014328003\n",
      "Epoch 16/100, Iteration 7/38, Loss: 1.0894989967346191\n",
      "Epoch 16/100, Iteration 8/38, Loss: 1.0724740028381348\n",
      "Epoch 16/100, Iteration 9/38, Loss: 0.9911231398582458\n",
      "Epoch 16/100, Iteration 10/38, Loss: 1.1531563997268677\n",
      "Epoch 16/100, Iteration 11/38, Loss: 1.0849345922470093\n",
      "Epoch 16/100, Iteration 12/38, Loss: 1.0635614395141602\n",
      "Epoch 16/100, Iteration 13/38, Loss: 1.0913960933685303\n",
      "Epoch 16/100, Iteration 14/38, Loss: 1.072605013847351\n",
      "Epoch 16/100, Iteration 15/38, Loss: 1.0928667783737183\n",
      "Epoch 16/100, Iteration 16/38, Loss: 1.058842420578003\n",
      "Epoch 16/100, Iteration 17/38, Loss: 1.089902400970459\n",
      "Epoch 16/100, Iteration 18/38, Loss: 1.078464388847351\n",
      "Epoch 16/100, Iteration 19/38, Loss: 1.070456624031067\n",
      "Epoch 16/100, Iteration 20/38, Loss: 1.1170625686645508\n",
      "Epoch 16/100, Iteration 21/38, Loss: 1.1143219470977783\n",
      "Epoch 16/100, Iteration 22/38, Loss: 1.0524479150772095\n",
      "Epoch 16/100, Iteration 23/38, Loss: 1.0833818912506104\n",
      "Epoch 16/100, Iteration 24/38, Loss: 1.0712206363677979\n",
      "Epoch 16/100, Iteration 25/38, Loss: 1.0860090255737305\n",
      "Epoch 16/100, Iteration 26/38, Loss: 1.1067216396331787\n",
      "Epoch 16/100, Iteration 27/38, Loss: 1.1014171838760376\n",
      "Epoch 16/100, Iteration 28/38, Loss: 1.075637698173523\n",
      "Epoch 16/100, Iteration 29/38, Loss: 1.0504517555236816\n",
      "Epoch 16/100, Iteration 30/38, Loss: 1.1243540048599243\n",
      "Epoch 16/100, Iteration 31/38, Loss: 1.1194959878921509\n",
      "Epoch 16/100, Iteration 32/38, Loss: 1.049631118774414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Iteration 33/38, Loss: 1.0348573923110962\n",
      "Epoch 16/100, Iteration 34/38, Loss: 1.055853247642517\n",
      "Epoch 16/100, Iteration 35/38, Loss: 1.0887961387634277\n",
      "Epoch 16/100, Iteration 36/38, Loss: 1.1021441221237183\n",
      "Epoch 16/100, Iteration 37/38, Loss: 0.9905057549476624\n",
      "Epoch 16/100, Iteration 38/38, Loss: 1.0867127180099487\n",
      "Epoch 17/100, Iteration 1/38, Loss: 1.1237578392028809\n",
      "Epoch 17/100, Iteration 2/38, Loss: 1.0630134344100952\n",
      "Epoch 17/100, Iteration 3/38, Loss: 1.0138473510742188\n",
      "Epoch 17/100, Iteration 4/38, Loss: 1.0384573936462402\n",
      "Epoch 17/100, Iteration 5/38, Loss: 0.9842451214790344\n",
      "Epoch 17/100, Iteration 6/38, Loss: 1.0635805130004883\n",
      "Epoch 17/100, Iteration 7/38, Loss: 1.1358336210250854\n",
      "Epoch 17/100, Iteration 8/38, Loss: 1.0615065097808838\n",
      "Epoch 17/100, Iteration 9/38, Loss: 1.033698558807373\n",
      "Epoch 17/100, Iteration 10/38, Loss: 1.1683825254440308\n",
      "Epoch 17/100, Iteration 11/38, Loss: 1.0690761804580688\n",
      "Epoch 17/100, Iteration 12/38, Loss: 1.10080885887146\n",
      "Epoch 17/100, Iteration 13/38, Loss: 1.0782443284988403\n",
      "Epoch 17/100, Iteration 14/38, Loss: 1.0889259576797485\n",
      "Epoch 17/100, Iteration 15/38, Loss: 1.0552787780761719\n",
      "Epoch 17/100, Iteration 16/38, Loss: 1.0846104621887207\n",
      "Epoch 17/100, Iteration 17/38, Loss: 1.0874720811843872\n",
      "Epoch 17/100, Iteration 18/38, Loss: 1.0855377912521362\n",
      "Epoch 17/100, Iteration 19/38, Loss: 1.0414292812347412\n",
      "Epoch 17/100, Iteration 20/38, Loss: 1.0961161851882935\n",
      "Epoch 17/100, Iteration 21/38, Loss: 1.089951515197754\n",
      "Epoch 17/100, Iteration 22/38, Loss: 1.1119601726531982\n",
      "Epoch 17/100, Iteration 23/38, Loss: 1.1203014850616455\n",
      "Epoch 17/100, Iteration 24/38, Loss: 1.0523797273635864\n",
      "Epoch 17/100, Iteration 25/38, Loss: 1.0330495834350586\n",
      "Epoch 17/100, Iteration 26/38, Loss: 1.0804446935653687\n",
      "Epoch 17/100, Iteration 27/38, Loss: 1.0967735052108765\n",
      "Epoch 17/100, Iteration 28/38, Loss: 1.1333279609680176\n",
      "Epoch 17/100, Iteration 29/38, Loss: 1.0773508548736572\n",
      "Epoch 17/100, Iteration 30/38, Loss: 1.0936354398727417\n",
      "Epoch 17/100, Iteration 31/38, Loss: 1.0592470169067383\n",
      "Epoch 17/100, Iteration 32/38, Loss: 1.1253764629364014\n",
      "Epoch 17/100, Iteration 33/38, Loss: 1.0463625192642212\n",
      "Epoch 17/100, Iteration 34/38, Loss: 1.0625790357589722\n",
      "Epoch 17/100, Iteration 35/38, Loss: 1.0545787811279297\n",
      "Epoch 17/100, Iteration 36/38, Loss: 1.11246657371521\n",
      "Epoch 17/100, Iteration 37/38, Loss: 1.0487680435180664\n",
      "Epoch 17/100, Iteration 38/38, Loss: 1.071579933166504\n",
      "Epoch 18/100, Iteration 1/38, Loss: 1.033678650856018\n",
      "Epoch 18/100, Iteration 2/38, Loss: 1.0168447494506836\n",
      "Epoch 18/100, Iteration 3/38, Loss: 1.1507478952407837\n",
      "Epoch 18/100, Iteration 4/38, Loss: 1.129709005355835\n",
      "Epoch 18/100, Iteration 5/38, Loss: 1.0457288026809692\n",
      "Epoch 18/100, Iteration 6/38, Loss: 1.02506685256958\n",
      "Epoch 18/100, Iteration 7/38, Loss: 1.0786701440811157\n",
      "Epoch 18/100, Iteration 8/38, Loss: 1.0388683080673218\n",
      "Epoch 18/100, Iteration 9/38, Loss: 1.0826114416122437\n",
      "Epoch 18/100, Iteration 10/38, Loss: 1.0650506019592285\n",
      "Epoch 18/100, Iteration 11/38, Loss: 1.1163573265075684\n",
      "Epoch 18/100, Iteration 12/38, Loss: 1.015256404876709\n",
      "Epoch 18/100, Iteration 13/38, Loss: 1.087136149406433\n",
      "Epoch 18/100, Iteration 14/38, Loss: 1.0959646701812744\n",
      "Epoch 18/100, Iteration 15/38, Loss: 1.0990760326385498\n",
      "Epoch 18/100, Iteration 16/38, Loss: 1.1039917469024658\n",
      "Epoch 18/100, Iteration 17/38, Loss: 1.123005747795105\n",
      "Epoch 18/100, Iteration 18/38, Loss: 1.1370130777359009\n",
      "Epoch 18/100, Iteration 19/38, Loss: 1.0891560316085815\n",
      "Epoch 18/100, Iteration 20/38, Loss: 1.0637574195861816\n",
      "Epoch 18/100, Iteration 21/38, Loss: 1.0166540145874023\n",
      "Epoch 18/100, Iteration 22/38, Loss: 1.1122993230819702\n",
      "Epoch 18/100, Iteration 23/38, Loss: 1.073380947113037\n",
      "Epoch 18/100, Iteration 24/38, Loss: 1.0631229877471924\n",
      "Epoch 18/100, Iteration 25/38, Loss: 1.0643247365951538\n",
      "Epoch 18/100, Iteration 26/38, Loss: 1.0675472021102905\n",
      "Epoch 18/100, Iteration 27/38, Loss: 1.062195062637329\n",
      "Epoch 18/100, Iteration 28/38, Loss: 1.1086716651916504\n",
      "Epoch 18/100, Iteration 29/38, Loss: 1.0658214092254639\n",
      "Epoch 18/100, Iteration 30/38, Loss: 1.0776933431625366\n",
      "Epoch 18/100, Iteration 31/38, Loss: 1.0079281330108643\n",
      "Epoch 18/100, Iteration 32/38, Loss: 1.0739424228668213\n",
      "Epoch 18/100, Iteration 33/38, Loss: 1.0672496557235718\n",
      "Epoch 18/100, Iteration 34/38, Loss: 1.0525063276290894\n",
      "Epoch 18/100, Iteration 35/38, Loss: 1.1065614223480225\n",
      "Epoch 18/100, Iteration 36/38, Loss: 1.0712049007415771\n",
      "Epoch 18/100, Iteration 37/38, Loss: 1.0234911441802979\n",
      "Epoch 18/100, Iteration 38/38, Loss: 1.0186973810195923\n",
      "Epoch 19/100, Iteration 1/38, Loss: 1.0695703029632568\n",
      "Epoch 19/100, Iteration 2/38, Loss: 1.1046661138534546\n",
      "Epoch 19/100, Iteration 3/38, Loss: 1.047914743423462\n",
      "Epoch 19/100, Iteration 4/38, Loss: 1.066763997077942\n",
      "Epoch 19/100, Iteration 5/38, Loss: 1.0937753915786743\n",
      "Epoch 19/100, Iteration 6/38, Loss: 1.0602728128433228\n",
      "Epoch 19/100, Iteration 7/38, Loss: 1.120987057685852\n",
      "Epoch 19/100, Iteration 8/38, Loss: 1.0941284894943237\n",
      "Epoch 19/100, Iteration 9/38, Loss: 1.0351781845092773\n",
      "Epoch 19/100, Iteration 10/38, Loss: 1.0802861452102661\n",
      "Epoch 19/100, Iteration 11/38, Loss: 1.0527453422546387\n",
      "Epoch 19/100, Iteration 12/38, Loss: 1.0887556076049805\n",
      "Epoch 19/100, Iteration 13/38, Loss: 1.0945682525634766\n",
      "Epoch 19/100, Iteration 14/38, Loss: 1.0496275424957275\n",
      "Epoch 19/100, Iteration 15/38, Loss: 1.1028432846069336\n",
      "Epoch 19/100, Iteration 16/38, Loss: 1.0352380275726318\n",
      "Epoch 19/100, Iteration 17/38, Loss: 0.9957730174064636\n",
      "Epoch 19/100, Iteration 18/38, Loss: 1.0234118700027466\n",
      "Epoch 19/100, Iteration 19/38, Loss: 1.1202678680419922\n",
      "Epoch 19/100, Iteration 20/38, Loss: 1.0764964818954468\n",
      "Epoch 19/100, Iteration 21/38, Loss: 1.0633865594863892\n",
      "Epoch 19/100, Iteration 22/38, Loss: 1.0298823118209839\n",
      "Epoch 19/100, Iteration 23/38, Loss: 1.0946985483169556\n",
      "Epoch 19/100, Iteration 24/38, Loss: 1.069063663482666\n",
      "Epoch 19/100, Iteration 25/38, Loss: 1.0465171337127686\n",
      "Epoch 19/100, Iteration 26/38, Loss: 1.0229965448379517\n",
      "Epoch 19/100, Iteration 27/38, Loss: 1.108515739440918\n",
      "Epoch 19/100, Iteration 28/38, Loss: 1.0770844221115112\n",
      "Epoch 19/100, Iteration 29/38, Loss: 1.0345462560653687\n",
      "Epoch 19/100, Iteration 30/38, Loss: 1.069803237915039\n",
      "Epoch 19/100, Iteration 31/38, Loss: 1.093359351158142\n",
      "Epoch 19/100, Iteration 32/38, Loss: 1.0531587600708008\n",
      "Epoch 19/100, Iteration 33/38, Loss: 1.0374236106872559\n",
      "Epoch 19/100, Iteration 34/38, Loss: 1.0672036409378052\n",
      "Epoch 19/100, Iteration 35/38, Loss: 1.028859257698059\n",
      "Epoch 19/100, Iteration 36/38, Loss: 1.121280550956726\n",
      "Epoch 19/100, Iteration 37/38, Loss: 1.1128677129745483\n",
      "Epoch 19/100, Iteration 38/38, Loss: 1.0439419746398926\n",
      "Epoch 20/100, Iteration 1/38, Loss: 1.1060106754302979\n",
      "Epoch 20/100, Iteration 2/38, Loss: 1.081138253211975\n",
      "Epoch 20/100, Iteration 3/38, Loss: 1.0646014213562012\n",
      "Epoch 20/100, Iteration 4/38, Loss: 1.0430907011032104\n",
      "Epoch 20/100, Iteration 5/38, Loss: 1.0671025514602661\n",
      "Epoch 20/100, Iteration 6/38, Loss: 1.0832074880599976\n",
      "Epoch 20/100, Iteration 7/38, Loss: 1.071347951889038\n",
      "Epoch 20/100, Iteration 8/38, Loss: 1.097676396369934\n",
      "Epoch 20/100, Iteration 9/38, Loss: 1.0742887258529663\n",
      "Epoch 20/100, Iteration 10/38, Loss: 1.0543642044067383\n",
      "Epoch 20/100, Iteration 11/38, Loss: 1.150308609008789\n",
      "Epoch 20/100, Iteration 12/38, Loss: 1.0273128747940063\n",
      "Epoch 20/100, Iteration 13/38, Loss: 1.0415573120117188\n",
      "Epoch 20/100, Iteration 14/38, Loss: 1.0174323320388794\n",
      "Epoch 20/100, Iteration 15/38, Loss: 1.0822646617889404\n",
      "Epoch 20/100, Iteration 16/38, Loss: 1.1404592990875244\n",
      "Epoch 20/100, Iteration 17/38, Loss: 1.0570253133773804\n",
      "Epoch 20/100, Iteration 18/38, Loss: 1.0841453075408936\n",
      "Epoch 20/100, Iteration 19/38, Loss: 1.103335976600647\n",
      "Epoch 20/100, Iteration 20/38, Loss: 1.095255732536316\n",
      "Epoch 20/100, Iteration 21/38, Loss: 1.0551080703735352\n",
      "Epoch 20/100, Iteration 22/38, Loss: 1.0095425844192505\n",
      "Epoch 20/100, Iteration 23/38, Loss: 1.0804178714752197\n",
      "Epoch 20/100, Iteration 24/38, Loss: 1.0285388231277466\n",
      "Epoch 20/100, Iteration 25/38, Loss: 1.0791600942611694\n",
      "Epoch 20/100, Iteration 26/38, Loss: 1.0995922088623047\n",
      "Epoch 20/100, Iteration 27/38, Loss: 1.0153990983963013\n",
      "Epoch 20/100, Iteration 28/38, Loss: 1.0356230735778809\n",
      "Epoch 20/100, Iteration 29/38, Loss: 1.0835591554641724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Iteration 30/38, Loss: 1.050193190574646\n",
      "Epoch 20/100, Iteration 31/38, Loss: 1.0527302026748657\n",
      "Epoch 20/100, Iteration 32/38, Loss: 1.1767746210098267\n",
      "Epoch 20/100, Iteration 33/38, Loss: 1.0733404159545898\n",
      "Epoch 20/100, Iteration 34/38, Loss: 1.0602879524230957\n",
      "Epoch 20/100, Iteration 35/38, Loss: 1.1097495555877686\n",
      "Epoch 20/100, Iteration 36/38, Loss: 1.0284942388534546\n",
      "Epoch 20/100, Iteration 37/38, Loss: 1.0041905641555786\n",
      "Epoch 20/100, Iteration 38/38, Loss: 1.0788733959197998\n",
      "Epoch 21/100, Iteration 1/38, Loss: 1.07753324508667\n",
      "Epoch 21/100, Iteration 2/38, Loss: 1.0868276357650757\n",
      "Epoch 21/100, Iteration 3/38, Loss: 1.0701099634170532\n",
      "Epoch 21/100, Iteration 4/38, Loss: 1.0656752586364746\n",
      "Epoch 21/100, Iteration 5/38, Loss: 1.034180998802185\n",
      "Epoch 21/100, Iteration 6/38, Loss: 1.0772955417633057\n",
      "Epoch 21/100, Iteration 7/38, Loss: 0.9790307283401489\n",
      "Epoch 21/100, Iteration 8/38, Loss: 1.158502221107483\n",
      "Epoch 21/100, Iteration 9/38, Loss: 1.1174635887145996\n",
      "Epoch 21/100, Iteration 10/38, Loss: 1.0051288604736328\n",
      "Epoch 21/100, Iteration 11/38, Loss: 0.9525101184844971\n",
      "Epoch 21/100, Iteration 12/38, Loss: 1.0566290616989136\n",
      "Epoch 21/100, Iteration 13/38, Loss: 1.045163869857788\n",
      "Epoch 21/100, Iteration 14/38, Loss: 1.0279711484909058\n",
      "Epoch 21/100, Iteration 15/38, Loss: 1.052439570426941\n",
      "Epoch 21/100, Iteration 16/38, Loss: 1.080459713935852\n",
      "Epoch 21/100, Iteration 17/38, Loss: 1.1356924772262573\n",
      "Epoch 21/100, Iteration 18/38, Loss: 1.0153343677520752\n",
      "Epoch 21/100, Iteration 19/38, Loss: 1.1068081855773926\n",
      "Epoch 21/100, Iteration 20/38, Loss: 1.0544593334197998\n",
      "Epoch 21/100, Iteration 21/38, Loss: 1.1141939163208008\n",
      "Epoch 21/100, Iteration 22/38, Loss: 1.0706721544265747\n",
      "Epoch 21/100, Iteration 23/38, Loss: 1.0828458070755005\n",
      "Epoch 21/100, Iteration 24/38, Loss: 1.129728078842163\n",
      "Epoch 21/100, Iteration 25/38, Loss: 1.085558295249939\n",
      "Epoch 21/100, Iteration 26/38, Loss: 1.0598820447921753\n",
      "Epoch 21/100, Iteration 27/38, Loss: 1.093970775604248\n",
      "Epoch 21/100, Iteration 28/38, Loss: 1.0194222927093506\n",
      "Epoch 21/100, Iteration 29/38, Loss: 0.9987315535545349\n",
      "Epoch 21/100, Iteration 30/38, Loss: 1.0869885683059692\n",
      "Epoch 21/100, Iteration 31/38, Loss: 1.052094578742981\n",
      "Epoch 21/100, Iteration 32/38, Loss: 1.0002917051315308\n",
      "Epoch 21/100, Iteration 33/38, Loss: 1.1258275508880615\n",
      "Epoch 21/100, Iteration 34/38, Loss: 1.0194090604782104\n",
      "Epoch 21/100, Iteration 35/38, Loss: 0.9755498170852661\n",
      "Epoch 21/100, Iteration 36/38, Loss: 0.9995874762535095\n",
      "Epoch 21/100, Iteration 37/38, Loss: 1.1452229022979736\n",
      "Epoch 21/100, Iteration 38/38, Loss: 1.0203197002410889\n",
      "Epoch 22/100, Iteration 1/38, Loss: 1.0426502227783203\n",
      "Epoch 22/100, Iteration 2/38, Loss: 1.2063181400299072\n",
      "Epoch 22/100, Iteration 3/38, Loss: 1.0773913860321045\n",
      "Epoch 22/100, Iteration 4/38, Loss: 1.1277480125427246\n",
      "Epoch 22/100, Iteration 5/38, Loss: 1.0244874954223633\n",
      "Epoch 22/100, Iteration 6/38, Loss: 1.0588270425796509\n",
      "Epoch 22/100, Iteration 7/38, Loss: 1.096242904663086\n",
      "Epoch 22/100, Iteration 8/38, Loss: 1.025466799736023\n",
      "Epoch 22/100, Iteration 9/38, Loss: 1.041276454925537\n",
      "Epoch 22/100, Iteration 10/38, Loss: 1.055619716644287\n",
      "Epoch 22/100, Iteration 11/38, Loss: 1.0897998809814453\n",
      "Epoch 22/100, Iteration 12/38, Loss: 1.0968211889266968\n",
      "Epoch 22/100, Iteration 13/38, Loss: 1.0423355102539062\n",
      "Epoch 22/100, Iteration 14/38, Loss: 1.1154274940490723\n",
      "Epoch 22/100, Iteration 15/38, Loss: 1.0087976455688477\n",
      "Epoch 22/100, Iteration 16/38, Loss: 1.095473051071167\n",
      "Epoch 22/100, Iteration 17/38, Loss: 1.0432772636413574\n",
      "Epoch 22/100, Iteration 18/38, Loss: 1.1205761432647705\n",
      "Epoch 22/100, Iteration 19/38, Loss: 1.0330026149749756\n",
      "Epoch 22/100, Iteration 20/38, Loss: 1.025789737701416\n",
      "Epoch 22/100, Iteration 21/38, Loss: 1.0956798791885376\n",
      "Epoch 22/100, Iteration 22/38, Loss: 1.0522308349609375\n",
      "Epoch 22/100, Iteration 23/38, Loss: 1.0421555042266846\n",
      "Epoch 22/100, Iteration 24/38, Loss: 1.0592150688171387\n",
      "Epoch 22/100, Iteration 25/38, Loss: 1.0710535049438477\n",
      "Epoch 22/100, Iteration 26/38, Loss: 1.0857375860214233\n",
      "Epoch 22/100, Iteration 27/38, Loss: 0.9652036428451538\n",
      "Epoch 22/100, Iteration 28/38, Loss: 1.070228099822998\n",
      "Epoch 22/100, Iteration 29/38, Loss: 1.049789309501648\n",
      "Epoch 22/100, Iteration 30/38, Loss: 1.0729999542236328\n",
      "Epoch 22/100, Iteration 31/38, Loss: 1.0781548023223877\n",
      "Epoch 22/100, Iteration 32/38, Loss: 1.030185580253601\n",
      "Epoch 22/100, Iteration 33/38, Loss: 1.0957248210906982\n",
      "Epoch 22/100, Iteration 34/38, Loss: 1.0472077131271362\n",
      "Epoch 22/100, Iteration 35/38, Loss: 1.0462805032730103\n",
      "Epoch 22/100, Iteration 36/38, Loss: 1.0027050971984863\n",
      "Epoch 22/100, Iteration 37/38, Loss: 1.1287167072296143\n",
      "Epoch 22/100, Iteration 38/38, Loss: 0.9910727739334106\n",
      "Epoch 23/100, Iteration 1/38, Loss: 0.9998031258583069\n",
      "Epoch 23/100, Iteration 2/38, Loss: 1.019914150238037\n",
      "Epoch 23/100, Iteration 3/38, Loss: 1.001476526260376\n",
      "Epoch 23/100, Iteration 4/38, Loss: 1.0959041118621826\n",
      "Epoch 23/100, Iteration 5/38, Loss: 1.04764723777771\n",
      "Epoch 23/100, Iteration 6/38, Loss: 1.0975980758666992\n",
      "Epoch 23/100, Iteration 7/38, Loss: 1.0554660558700562\n",
      "Epoch 23/100, Iteration 8/38, Loss: 1.0403610467910767\n",
      "Epoch 23/100, Iteration 9/38, Loss: 1.0124151706695557\n",
      "Epoch 23/100, Iteration 10/38, Loss: 1.1352862119674683\n",
      "Epoch 23/100, Iteration 11/38, Loss: 1.0391347408294678\n",
      "Epoch 23/100, Iteration 12/38, Loss: 1.0969537496566772\n",
      "Epoch 23/100, Iteration 13/38, Loss: 1.1059179306030273\n",
      "Epoch 23/100, Iteration 14/38, Loss: 1.037328839302063\n",
      "Epoch 23/100, Iteration 15/38, Loss: 1.0688467025756836\n",
      "Epoch 23/100, Iteration 16/38, Loss: 1.0383951663970947\n",
      "Epoch 23/100, Iteration 17/38, Loss: 1.0658528804779053\n",
      "Epoch 23/100, Iteration 18/38, Loss: 1.0886045694351196\n",
      "Epoch 23/100, Iteration 19/38, Loss: 1.0886284112930298\n",
      "Epoch 23/100, Iteration 20/38, Loss: 1.0488545894622803\n",
      "Epoch 23/100, Iteration 21/38, Loss: 1.0428365468978882\n",
      "Epoch 23/100, Iteration 22/38, Loss: 1.110711693763733\n",
      "Epoch 23/100, Iteration 23/38, Loss: 1.0113332271575928\n",
      "Epoch 23/100, Iteration 24/38, Loss: 1.0434939861297607\n",
      "Epoch 23/100, Iteration 25/38, Loss: 1.0496327877044678\n",
      "Epoch 23/100, Iteration 26/38, Loss: 0.99838787317276\n",
      "Epoch 23/100, Iteration 27/38, Loss: 0.9969773292541504\n",
      "Epoch 23/100, Iteration 28/38, Loss: 1.1253398656845093\n",
      "Epoch 23/100, Iteration 29/38, Loss: 1.0282537937164307\n",
      "Epoch 23/100, Iteration 30/38, Loss: 1.0224816799163818\n",
      "Epoch 23/100, Iteration 31/38, Loss: 1.0486578941345215\n",
      "Epoch 23/100, Iteration 32/38, Loss: 1.0683869123458862\n",
      "Epoch 23/100, Iteration 33/38, Loss: 1.104604959487915\n",
      "Epoch 23/100, Iteration 34/38, Loss: 1.0190260410308838\n",
      "Epoch 23/100, Iteration 35/38, Loss: 1.0506590604782104\n",
      "Epoch 23/100, Iteration 36/38, Loss: 0.9586917757987976\n",
      "Epoch 23/100, Iteration 37/38, Loss: 1.0556584596633911\n",
      "Epoch 23/100, Iteration 38/38, Loss: 1.1448633670806885\n",
      "Epoch 24/100, Iteration 1/38, Loss: 1.0838210582733154\n",
      "Epoch 24/100, Iteration 2/38, Loss: 1.0705424547195435\n",
      "Epoch 24/100, Iteration 3/38, Loss: 1.0273756980895996\n",
      "Epoch 24/100, Iteration 4/38, Loss: 1.099579930305481\n",
      "Epoch 24/100, Iteration 5/38, Loss: 1.0664304494857788\n",
      "Epoch 24/100, Iteration 6/38, Loss: 0.9804500341415405\n",
      "Epoch 24/100, Iteration 7/38, Loss: 1.029566764831543\n",
      "Epoch 24/100, Iteration 8/38, Loss: 1.0428848266601562\n",
      "Epoch 24/100, Iteration 9/38, Loss: 1.0660723447799683\n",
      "Epoch 24/100, Iteration 10/38, Loss: 0.9884816408157349\n",
      "Epoch 24/100, Iteration 11/38, Loss: 1.0413628816604614\n",
      "Epoch 24/100, Iteration 12/38, Loss: 0.9657452702522278\n",
      "Epoch 24/100, Iteration 13/38, Loss: 1.0376441478729248\n",
      "Epoch 24/100, Iteration 14/38, Loss: 1.105811357498169\n",
      "Epoch 24/100, Iteration 15/38, Loss: 1.07112455368042\n",
      "Epoch 24/100, Iteration 16/38, Loss: 1.107580542564392\n",
      "Epoch 24/100, Iteration 17/38, Loss: 1.0162465572357178\n",
      "Epoch 24/100, Iteration 18/38, Loss: 1.0776084661483765\n",
      "Epoch 24/100, Iteration 19/38, Loss: 1.0357141494750977\n",
      "Epoch 24/100, Iteration 20/38, Loss: 1.0515077114105225\n",
      "Epoch 24/100, Iteration 21/38, Loss: 1.0557277202606201\n",
      "Epoch 24/100, Iteration 22/38, Loss: 1.009066104888916\n",
      "Epoch 24/100, Iteration 23/38, Loss: 1.016990303993225\n",
      "Epoch 24/100, Iteration 24/38, Loss: 1.0773555040359497\n",
      "Epoch 24/100, Iteration 25/38, Loss: 1.1200379133224487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Iteration 26/38, Loss: 1.0646743774414062\n",
      "Epoch 24/100, Iteration 27/38, Loss: 1.0547571182250977\n",
      "Epoch 24/100, Iteration 28/38, Loss: 1.057906985282898\n",
      "Epoch 24/100, Iteration 29/38, Loss: 1.048778772354126\n",
      "Epoch 24/100, Iteration 30/38, Loss: 1.0958375930786133\n",
      "Epoch 24/100, Iteration 31/38, Loss: 1.061188817024231\n",
      "Epoch 24/100, Iteration 32/38, Loss: 1.0242351293563843\n",
      "Epoch 24/100, Iteration 33/38, Loss: 1.0637784004211426\n",
      "Epoch 24/100, Iteration 34/38, Loss: 0.9818851351737976\n",
      "Epoch 24/100, Iteration 35/38, Loss: 1.0019867420196533\n",
      "Epoch 24/100, Iteration 36/38, Loss: 1.0302321910858154\n",
      "Epoch 24/100, Iteration 37/38, Loss: 1.1158016920089722\n",
      "Epoch 24/100, Iteration 38/38, Loss: 1.0515739917755127\n",
      "Epoch 25/100, Iteration 1/38, Loss: 1.0770264863967896\n",
      "Epoch 25/100, Iteration 2/38, Loss: 1.0263848304748535\n",
      "Epoch 25/100, Iteration 3/38, Loss: 1.0506417751312256\n",
      "Epoch 25/100, Iteration 4/38, Loss: 1.112787127494812\n",
      "Epoch 25/100, Iteration 5/38, Loss: 1.079633116722107\n",
      "Epoch 25/100, Iteration 6/38, Loss: 0.9986199140548706\n",
      "Epoch 25/100, Iteration 7/38, Loss: 0.9799163937568665\n",
      "Epoch 25/100, Iteration 8/38, Loss: 0.977505624294281\n",
      "Epoch 25/100, Iteration 9/38, Loss: 1.0977168083190918\n",
      "Epoch 25/100, Iteration 10/38, Loss: 1.0224248170852661\n",
      "Epoch 25/100, Iteration 11/38, Loss: 1.0587670803070068\n",
      "Epoch 25/100, Iteration 12/38, Loss: 1.073781132698059\n",
      "Epoch 25/100, Iteration 13/38, Loss: 1.074398159980774\n",
      "Epoch 25/100, Iteration 14/38, Loss: 1.0705209970474243\n",
      "Epoch 25/100, Iteration 15/38, Loss: 1.046167016029358\n",
      "Epoch 25/100, Iteration 16/38, Loss: 0.9880445003509521\n",
      "Epoch 25/100, Iteration 17/38, Loss: 1.0603488683700562\n",
      "Epoch 25/100, Iteration 18/38, Loss: 0.9760992527008057\n",
      "Epoch 25/100, Iteration 19/38, Loss: 0.998681366443634\n",
      "Epoch 25/100, Iteration 20/38, Loss: 0.9844373464584351\n",
      "Epoch 25/100, Iteration 21/38, Loss: 1.0208014249801636\n",
      "Epoch 25/100, Iteration 22/38, Loss: 1.0696920156478882\n",
      "Epoch 25/100, Iteration 23/38, Loss: 1.006197214126587\n",
      "Epoch 25/100, Iteration 24/38, Loss: 1.0018178224563599\n",
      "Epoch 25/100, Iteration 25/38, Loss: 1.1115998029708862\n",
      "Epoch 25/100, Iteration 26/38, Loss: 1.035739779472351\n",
      "Epoch 25/100, Iteration 27/38, Loss: 1.0589169263839722\n",
      "Epoch 25/100, Iteration 28/38, Loss: 1.1169235706329346\n",
      "Epoch 25/100, Iteration 29/38, Loss: 1.0000282526016235\n",
      "Epoch 25/100, Iteration 30/38, Loss: 0.9732871055603027\n",
      "Epoch 25/100, Iteration 31/38, Loss: 1.0119919776916504\n",
      "Epoch 25/100, Iteration 32/38, Loss: 0.999262809753418\n",
      "Epoch 25/100, Iteration 33/38, Loss: 1.0323638916015625\n",
      "Epoch 25/100, Iteration 34/38, Loss: 1.0591120719909668\n",
      "Epoch 25/100, Iteration 35/38, Loss: 1.0574530363082886\n",
      "Epoch 25/100, Iteration 36/38, Loss: 1.1100088357925415\n",
      "Epoch 25/100, Iteration 37/38, Loss: 0.9701768159866333\n",
      "Epoch 25/100, Iteration 38/38, Loss: 0.9914516806602478\n",
      "Epoch 26/100, Iteration 1/38, Loss: 1.0166114568710327\n",
      "Epoch 26/100, Iteration 2/38, Loss: 0.9957914352416992\n",
      "Epoch 26/100, Iteration 3/38, Loss: 0.9954844117164612\n",
      "Epoch 26/100, Iteration 4/38, Loss: 1.0619041919708252\n",
      "Epoch 26/100, Iteration 5/38, Loss: 1.1373190879821777\n",
      "Epoch 26/100, Iteration 6/38, Loss: 1.0758713483810425\n",
      "Epoch 26/100, Iteration 7/38, Loss: 1.0123990774154663\n",
      "Epoch 26/100, Iteration 8/38, Loss: 1.1204410791397095\n",
      "Epoch 26/100, Iteration 9/38, Loss: 1.0149478912353516\n",
      "Epoch 26/100, Iteration 10/38, Loss: 1.0046850442886353\n",
      "Epoch 26/100, Iteration 11/38, Loss: 1.0744556188583374\n",
      "Epoch 26/100, Iteration 12/38, Loss: 1.0509897470474243\n",
      "Epoch 26/100, Iteration 13/38, Loss: 1.0948714017868042\n",
      "Epoch 26/100, Iteration 14/38, Loss: 1.0260181427001953\n",
      "Epoch 26/100, Iteration 15/38, Loss: 1.0140460729599\n",
      "Epoch 26/100, Iteration 16/38, Loss: 1.0176371335983276\n",
      "Epoch 26/100, Iteration 17/38, Loss: 1.0182265043258667\n",
      "Epoch 26/100, Iteration 18/38, Loss: 1.0396153926849365\n",
      "Epoch 26/100, Iteration 19/38, Loss: 1.0672378540039062\n",
      "Epoch 26/100, Iteration 20/38, Loss: 1.0891519784927368\n",
      "Epoch 26/100, Iteration 21/38, Loss: 1.0721900463104248\n",
      "Epoch 26/100, Iteration 22/38, Loss: 0.9663223624229431\n",
      "Epoch 26/100, Iteration 23/38, Loss: 1.067730188369751\n",
      "Epoch 26/100, Iteration 24/38, Loss: 1.0311108827590942\n",
      "Epoch 26/100, Iteration 25/38, Loss: 0.9948556423187256\n",
      "Epoch 26/100, Iteration 26/38, Loss: 1.007227897644043\n",
      "Epoch 26/100, Iteration 27/38, Loss: 1.1141769886016846\n",
      "Epoch 26/100, Iteration 28/38, Loss: 0.9894154667854309\n",
      "Epoch 26/100, Iteration 29/38, Loss: 1.066262125968933\n",
      "Epoch 26/100, Iteration 30/38, Loss: 0.997952938079834\n",
      "Epoch 26/100, Iteration 31/38, Loss: 1.105703592300415\n",
      "Epoch 26/100, Iteration 32/38, Loss: 0.9602410197257996\n",
      "Epoch 26/100, Iteration 33/38, Loss: 1.0214457511901855\n",
      "Epoch 26/100, Iteration 34/38, Loss: 1.0341770648956299\n",
      "Epoch 26/100, Iteration 35/38, Loss: 0.9340478777885437\n",
      "Epoch 26/100, Iteration 36/38, Loss: 1.0175261497497559\n",
      "Epoch 26/100, Iteration 37/38, Loss: 1.0669981241226196\n",
      "Epoch 26/100, Iteration 38/38, Loss: 1.0047398805618286\n",
      "Epoch 27/100, Iteration 1/38, Loss: 1.0032026767730713\n",
      "Epoch 27/100, Iteration 2/38, Loss: 1.02555251121521\n",
      "Epoch 27/100, Iteration 3/38, Loss: 1.1114757061004639\n",
      "Epoch 27/100, Iteration 4/38, Loss: 1.0601862668991089\n",
      "Epoch 27/100, Iteration 5/38, Loss: 1.0159201622009277\n",
      "Epoch 27/100, Iteration 6/38, Loss: 1.0421483516693115\n",
      "Epoch 27/100, Iteration 7/38, Loss: 0.984589159488678\n",
      "Epoch 27/100, Iteration 8/38, Loss: 1.0718798637390137\n",
      "Epoch 27/100, Iteration 9/38, Loss: 0.9874061942100525\n",
      "Epoch 27/100, Iteration 10/38, Loss: 0.9970464110374451\n",
      "Epoch 27/100, Iteration 11/38, Loss: 0.9475514888763428\n",
      "Epoch 27/100, Iteration 12/38, Loss: 1.012176275253296\n",
      "Epoch 27/100, Iteration 13/38, Loss: 1.0048627853393555\n",
      "Epoch 27/100, Iteration 14/38, Loss: 1.0572503805160522\n",
      "Epoch 27/100, Iteration 15/38, Loss: 1.0321643352508545\n",
      "Epoch 27/100, Iteration 16/38, Loss: 1.1249438524246216\n",
      "Epoch 27/100, Iteration 17/38, Loss: 0.9511685371398926\n",
      "Epoch 27/100, Iteration 18/38, Loss: 0.9821540713310242\n",
      "Epoch 27/100, Iteration 19/38, Loss: 1.077662467956543\n",
      "Epoch 27/100, Iteration 20/38, Loss: 1.1873570680618286\n",
      "Epoch 27/100, Iteration 21/38, Loss: 1.13955557346344\n",
      "Epoch 27/100, Iteration 22/38, Loss: 0.9650483727455139\n",
      "Epoch 27/100, Iteration 23/38, Loss: 1.0059278011322021\n",
      "Epoch 27/100, Iteration 24/38, Loss: 0.9604412317276001\n",
      "Epoch 27/100, Iteration 25/38, Loss: 0.9411163330078125\n",
      "Epoch 27/100, Iteration 26/38, Loss: 1.0088679790496826\n",
      "Epoch 27/100, Iteration 27/38, Loss: 0.9574848413467407\n",
      "Epoch 27/100, Iteration 28/38, Loss: 0.9812566637992859\n",
      "Epoch 27/100, Iteration 29/38, Loss: 1.0546051263809204\n",
      "Epoch 27/100, Iteration 30/38, Loss: 1.0355011224746704\n",
      "Epoch 27/100, Iteration 31/38, Loss: 0.9974915981292725\n",
      "Epoch 27/100, Iteration 32/38, Loss: 1.047753930091858\n",
      "Epoch 27/100, Iteration 33/38, Loss: 1.025507926940918\n",
      "Epoch 27/100, Iteration 34/38, Loss: 1.1207839250564575\n",
      "Epoch 27/100, Iteration 35/38, Loss: 0.9942392110824585\n",
      "Epoch 27/100, Iteration 36/38, Loss: 0.9976116418838501\n",
      "Epoch 27/100, Iteration 37/38, Loss: 1.0114967823028564\n",
      "Epoch 27/100, Iteration 38/38, Loss: 1.0224636793136597\n",
      "Epoch 28/100, Iteration 1/38, Loss: 0.9885262250900269\n",
      "Epoch 28/100, Iteration 2/38, Loss: 1.0055663585662842\n",
      "Epoch 28/100, Iteration 3/38, Loss: 1.0144013166427612\n",
      "Epoch 28/100, Iteration 4/38, Loss: 1.0144084692001343\n",
      "Epoch 28/100, Iteration 5/38, Loss: 0.9376149773597717\n",
      "Epoch 28/100, Iteration 6/38, Loss: 0.9394687414169312\n",
      "Epoch 28/100, Iteration 7/38, Loss: 1.0057541131973267\n",
      "Epoch 28/100, Iteration 8/38, Loss: 0.9983652830123901\n",
      "Epoch 28/100, Iteration 9/38, Loss: 1.0419507026672363\n",
      "Epoch 28/100, Iteration 10/38, Loss: 0.9704564213752747\n",
      "Epoch 28/100, Iteration 11/38, Loss: 1.0628647804260254\n",
      "Epoch 28/100, Iteration 12/38, Loss: 0.9673393368721008\n",
      "Epoch 28/100, Iteration 13/38, Loss: 1.024746060371399\n",
      "Epoch 28/100, Iteration 14/38, Loss: 1.053174614906311\n",
      "Epoch 28/100, Iteration 15/38, Loss: 1.0126956701278687\n",
      "Epoch 28/100, Iteration 16/38, Loss: 1.074196696281433\n",
      "Epoch 28/100, Iteration 17/38, Loss: 1.0261669158935547\n",
      "Epoch 28/100, Iteration 18/38, Loss: 1.1379386186599731\n",
      "Epoch 28/100, Iteration 19/38, Loss: 1.0268229246139526\n",
      "Epoch 28/100, Iteration 20/38, Loss: 0.9550727605819702\n",
      "Epoch 28/100, Iteration 21/38, Loss: 1.049505591392517\n",
      "Epoch 28/100, Iteration 22/38, Loss: 1.0077781677246094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Iteration 23/38, Loss: 1.044751763343811\n",
      "Epoch 28/100, Iteration 24/38, Loss: 0.9819455146789551\n",
      "Epoch 28/100, Iteration 25/38, Loss: 1.030385971069336\n",
      "Epoch 28/100, Iteration 26/38, Loss: 0.906139612197876\n",
      "Epoch 28/100, Iteration 27/38, Loss: 1.0630242824554443\n",
      "Epoch 28/100, Iteration 28/38, Loss: 1.0144933462142944\n",
      "Epoch 28/100, Iteration 29/38, Loss: 1.0163214206695557\n",
      "Epoch 28/100, Iteration 30/38, Loss: 1.0182650089263916\n",
      "Epoch 28/100, Iteration 31/38, Loss: 0.9861479997634888\n",
      "Epoch 28/100, Iteration 32/38, Loss: 1.0069586038589478\n",
      "Epoch 28/100, Iteration 33/38, Loss: 0.9983333945274353\n",
      "Epoch 28/100, Iteration 34/38, Loss: 1.077676773071289\n",
      "Epoch 28/100, Iteration 35/38, Loss: 1.0892852544784546\n",
      "Epoch 28/100, Iteration 36/38, Loss: 1.0073316097259521\n",
      "Epoch 28/100, Iteration 37/38, Loss: 1.1679155826568604\n",
      "Epoch 28/100, Iteration 38/38, Loss: 0.9995415806770325\n",
      "Epoch 29/100, Iteration 1/38, Loss: 0.9620580673217773\n",
      "Epoch 29/100, Iteration 2/38, Loss: 1.0937583446502686\n",
      "Epoch 29/100, Iteration 3/38, Loss: 1.075506567955017\n",
      "Epoch 29/100, Iteration 4/38, Loss: 1.0032795667648315\n",
      "Epoch 29/100, Iteration 5/38, Loss: 0.927275538444519\n",
      "Epoch 29/100, Iteration 6/38, Loss: 1.0515613555908203\n",
      "Epoch 29/100, Iteration 7/38, Loss: 1.051452875137329\n",
      "Epoch 29/100, Iteration 8/38, Loss: 0.8662606477737427\n",
      "Epoch 29/100, Iteration 9/38, Loss: 0.989729642868042\n",
      "Epoch 29/100, Iteration 10/38, Loss: 1.022571325302124\n",
      "Epoch 29/100, Iteration 11/38, Loss: 0.9830777645111084\n",
      "Epoch 29/100, Iteration 12/38, Loss: 1.0370789766311646\n",
      "Epoch 29/100, Iteration 13/38, Loss: 0.9364141821861267\n",
      "Epoch 29/100, Iteration 14/38, Loss: 0.9443119168281555\n",
      "Epoch 29/100, Iteration 15/38, Loss: 1.0572834014892578\n",
      "Epoch 29/100, Iteration 16/38, Loss: 0.9987088441848755\n",
      "Epoch 29/100, Iteration 17/38, Loss: 1.0219111442565918\n",
      "Epoch 29/100, Iteration 18/38, Loss: 0.9241242408752441\n",
      "Epoch 29/100, Iteration 19/38, Loss: 1.1612800359725952\n",
      "Epoch 29/100, Iteration 20/38, Loss: 1.0007234811782837\n",
      "Epoch 29/100, Iteration 21/38, Loss: 1.0122050046920776\n",
      "Epoch 29/100, Iteration 22/38, Loss: 1.0908645391464233\n",
      "Epoch 29/100, Iteration 23/38, Loss: 1.0570024251937866\n",
      "Epoch 29/100, Iteration 24/38, Loss: 0.8783777952194214\n",
      "Epoch 29/100, Iteration 25/38, Loss: 0.9878974556922913\n",
      "Epoch 29/100, Iteration 26/38, Loss: 1.0162819623947144\n",
      "Epoch 29/100, Iteration 27/38, Loss: 0.9314661622047424\n",
      "Epoch 29/100, Iteration 28/38, Loss: 0.9719167351722717\n",
      "Epoch 29/100, Iteration 29/38, Loss: 1.0524711608886719\n",
      "Epoch 29/100, Iteration 30/38, Loss: 1.0692583322525024\n",
      "Epoch 29/100, Iteration 31/38, Loss: 1.0762553215026855\n",
      "Epoch 29/100, Iteration 32/38, Loss: 0.9867234826087952\n",
      "Epoch 29/100, Iteration 33/38, Loss: 1.0194518566131592\n",
      "Epoch 29/100, Iteration 34/38, Loss: 1.0553385019302368\n",
      "Epoch 29/100, Iteration 35/38, Loss: 0.9680160880088806\n",
      "Epoch 29/100, Iteration 36/38, Loss: 0.9139435887336731\n",
      "Epoch 29/100, Iteration 37/38, Loss: 0.9570341110229492\n",
      "Epoch 29/100, Iteration 38/38, Loss: 1.0600605010986328\n",
      "Epoch 30/100, Iteration 1/38, Loss: 0.9597706198692322\n",
      "Epoch 30/100, Iteration 2/38, Loss: 1.0715508460998535\n",
      "Epoch 30/100, Iteration 3/38, Loss: 1.0344183444976807\n",
      "Epoch 30/100, Iteration 4/38, Loss: 0.9995740652084351\n",
      "Epoch 30/100, Iteration 5/38, Loss: 0.9575159549713135\n",
      "Epoch 30/100, Iteration 6/38, Loss: 0.9014857411384583\n",
      "Epoch 30/100, Iteration 7/38, Loss: 0.9475749731063843\n",
      "Epoch 30/100, Iteration 8/38, Loss: 1.0417369604110718\n",
      "Epoch 30/100, Iteration 9/38, Loss: 0.8917707800865173\n",
      "Epoch 30/100, Iteration 10/38, Loss: 0.924881100654602\n",
      "Epoch 30/100, Iteration 11/38, Loss: 0.8955045342445374\n",
      "Epoch 30/100, Iteration 12/38, Loss: 1.102336049079895\n",
      "Epoch 30/100, Iteration 13/38, Loss: 1.0007034540176392\n",
      "Epoch 30/100, Iteration 14/38, Loss: 1.1680817604064941\n",
      "Epoch 30/100, Iteration 15/38, Loss: 0.9593206644058228\n",
      "Epoch 30/100, Iteration 16/38, Loss: 0.9217395782470703\n",
      "Epoch 30/100, Iteration 17/38, Loss: 1.0084344148635864\n",
      "Epoch 30/100, Iteration 18/38, Loss: 0.994907021522522\n",
      "Epoch 30/100, Iteration 19/38, Loss: 1.004388689994812\n",
      "Epoch 30/100, Iteration 20/38, Loss: 0.933600902557373\n",
      "Epoch 30/100, Iteration 21/38, Loss: 1.0387542247772217\n",
      "Epoch 30/100, Iteration 22/38, Loss: 0.9687856435775757\n",
      "Epoch 30/100, Iteration 23/38, Loss: 1.0092073678970337\n",
      "Epoch 30/100, Iteration 24/38, Loss: 1.0007518529891968\n",
      "Epoch 30/100, Iteration 25/38, Loss: 0.9997619986534119\n",
      "Epoch 30/100, Iteration 26/38, Loss: 0.9385510683059692\n",
      "Epoch 30/100, Iteration 27/38, Loss: 1.0183920860290527\n",
      "Epoch 30/100, Iteration 28/38, Loss: 0.9698430299758911\n",
      "Epoch 30/100, Iteration 29/38, Loss: 0.9333205223083496\n",
      "Epoch 30/100, Iteration 30/38, Loss: 0.9278684258460999\n",
      "Epoch 30/100, Iteration 31/38, Loss: 0.9779289364814758\n",
      "Epoch 30/100, Iteration 32/38, Loss: 1.0447355508804321\n",
      "Epoch 30/100, Iteration 33/38, Loss: 0.9705310463905334\n",
      "Epoch 30/100, Iteration 34/38, Loss: 0.9804639220237732\n",
      "Epoch 30/100, Iteration 35/38, Loss: 0.9969899654388428\n",
      "Epoch 30/100, Iteration 36/38, Loss: 1.1028287410736084\n",
      "Epoch 30/100, Iteration 37/38, Loss: 0.9910483360290527\n",
      "Epoch 30/100, Iteration 38/38, Loss: 0.9302924275398254\n",
      "Epoch 31/100, Iteration 1/38, Loss: 0.9165951609611511\n",
      "Epoch 31/100, Iteration 2/38, Loss: 1.040162444114685\n",
      "Epoch 31/100, Iteration 3/38, Loss: 0.940864086151123\n",
      "Epoch 31/100, Iteration 4/38, Loss: 0.99199378490448\n",
      "Epoch 31/100, Iteration 5/38, Loss: 1.0096490383148193\n",
      "Epoch 31/100, Iteration 6/38, Loss: 0.9883690476417542\n",
      "Epoch 31/100, Iteration 7/38, Loss: 0.921658992767334\n",
      "Epoch 31/100, Iteration 8/38, Loss: 0.9935717582702637\n",
      "Epoch 31/100, Iteration 9/38, Loss: 0.9834226369857788\n",
      "Epoch 31/100, Iteration 10/38, Loss: 0.9953763484954834\n",
      "Epoch 31/100, Iteration 11/38, Loss: 1.0025966167449951\n",
      "Epoch 31/100, Iteration 12/38, Loss: 0.956269383430481\n",
      "Epoch 31/100, Iteration 13/38, Loss: 0.924319863319397\n",
      "Epoch 31/100, Iteration 14/38, Loss: 1.1008012294769287\n",
      "Epoch 31/100, Iteration 15/38, Loss: 0.9588557481765747\n",
      "Epoch 31/100, Iteration 16/38, Loss: 0.9838443398475647\n",
      "Epoch 31/100, Iteration 17/38, Loss: 1.0004976987838745\n",
      "Epoch 31/100, Iteration 18/38, Loss: 0.9455122947692871\n",
      "Epoch 31/100, Iteration 19/38, Loss: 0.9953736662864685\n",
      "Epoch 31/100, Iteration 20/38, Loss: 0.956474781036377\n",
      "Epoch 31/100, Iteration 21/38, Loss: 0.9102093577384949\n",
      "Epoch 31/100, Iteration 22/38, Loss: 1.0085630416870117\n",
      "Epoch 31/100, Iteration 23/38, Loss: 1.0183316469192505\n",
      "Epoch 31/100, Iteration 24/38, Loss: 1.036694049835205\n",
      "Epoch 31/100, Iteration 25/38, Loss: 1.008216381072998\n",
      "Epoch 31/100, Iteration 26/38, Loss: 1.0067607164382935\n",
      "Epoch 31/100, Iteration 27/38, Loss: 1.020566701889038\n",
      "Epoch 31/100, Iteration 28/38, Loss: 1.054755687713623\n",
      "Epoch 31/100, Iteration 29/38, Loss: 0.9160089492797852\n",
      "Epoch 31/100, Iteration 30/38, Loss: 0.965290904045105\n",
      "Epoch 31/100, Iteration 31/38, Loss: 0.9914606809616089\n",
      "Epoch 31/100, Iteration 32/38, Loss: 0.9987256526947021\n",
      "Epoch 31/100, Iteration 33/38, Loss: 0.992274284362793\n",
      "Epoch 31/100, Iteration 34/38, Loss: 1.0689334869384766\n",
      "Epoch 31/100, Iteration 35/38, Loss: 0.8798244595527649\n",
      "Epoch 31/100, Iteration 36/38, Loss: 1.0049662590026855\n",
      "Epoch 31/100, Iteration 37/38, Loss: 0.9730417132377625\n",
      "Epoch 31/100, Iteration 38/38, Loss: 0.9415202736854553\n",
      "Epoch 32/100, Iteration 1/38, Loss: 1.0820753574371338\n",
      "Epoch 32/100, Iteration 2/38, Loss: 1.0936946868896484\n",
      "Epoch 32/100, Iteration 3/38, Loss: 1.0485504865646362\n",
      "Epoch 32/100, Iteration 4/38, Loss: 0.9587395787239075\n",
      "Epoch 32/100, Iteration 5/38, Loss: 0.9076458215713501\n",
      "Epoch 32/100, Iteration 6/38, Loss: 0.9737643003463745\n",
      "Epoch 32/100, Iteration 7/38, Loss: 1.0801230669021606\n",
      "Epoch 32/100, Iteration 8/38, Loss: 0.8494255542755127\n",
      "Epoch 32/100, Iteration 9/38, Loss: 0.9891238808631897\n",
      "Epoch 32/100, Iteration 10/38, Loss: 0.9981288909912109\n",
      "Epoch 32/100, Iteration 11/38, Loss: 0.9276665449142456\n",
      "Epoch 32/100, Iteration 12/38, Loss: 0.9021044373512268\n",
      "Epoch 32/100, Iteration 13/38, Loss: 0.9259095191955566\n",
      "Epoch 32/100, Iteration 14/38, Loss: 0.968518078327179\n",
      "Epoch 32/100, Iteration 15/38, Loss: 1.0011543035507202\n",
      "Epoch 32/100, Iteration 16/38, Loss: 0.9366225004196167\n",
      "Epoch 32/100, Iteration 17/38, Loss: 0.9830636978149414\n",
      "Epoch 32/100, Iteration 18/38, Loss: 0.9497252106666565\n",
      "Epoch 32/100, Iteration 19/38, Loss: 0.9753947854042053\n",
      "Epoch 32/100, Iteration 20/38, Loss: 1.05296790599823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100, Iteration 21/38, Loss: 0.9511170387268066\n",
      "Epoch 32/100, Iteration 22/38, Loss: 0.9803724884986877\n",
      "Epoch 32/100, Iteration 23/38, Loss: 0.9355993866920471\n",
      "Epoch 32/100, Iteration 24/38, Loss: 1.0263876914978027\n",
      "Epoch 32/100, Iteration 25/38, Loss: 0.9521530866622925\n",
      "Epoch 32/100, Iteration 26/38, Loss: 1.0065176486968994\n",
      "Epoch 32/100, Iteration 27/38, Loss: 1.0436161756515503\n",
      "Epoch 32/100, Iteration 28/38, Loss: 0.936253547668457\n",
      "Epoch 32/100, Iteration 29/38, Loss: 1.023919939994812\n",
      "Epoch 32/100, Iteration 30/38, Loss: 1.0802114009857178\n",
      "Epoch 32/100, Iteration 31/38, Loss: 0.9777281284332275\n",
      "Epoch 32/100, Iteration 32/38, Loss: 0.9178277850151062\n",
      "Epoch 32/100, Iteration 33/38, Loss: 1.067418098449707\n",
      "Epoch 32/100, Iteration 34/38, Loss: 1.0324010848999023\n",
      "Epoch 32/100, Iteration 35/38, Loss: 0.9913948774337769\n",
      "Epoch 32/100, Iteration 36/38, Loss: 1.0109918117523193\n",
      "Epoch 32/100, Iteration 37/38, Loss: 0.870185911655426\n",
      "Epoch 32/100, Iteration 38/38, Loss: 0.8200855255126953\n",
      "Epoch 33/100, Iteration 1/38, Loss: 0.9537611603736877\n",
      "Epoch 33/100, Iteration 2/38, Loss: 0.9624643325805664\n",
      "Epoch 33/100, Iteration 3/38, Loss: 1.023484468460083\n",
      "Epoch 33/100, Iteration 4/38, Loss: 1.049061894416809\n",
      "Epoch 33/100, Iteration 5/38, Loss: 1.0460894107818604\n",
      "Epoch 33/100, Iteration 6/38, Loss: 0.894318699836731\n",
      "Epoch 33/100, Iteration 7/38, Loss: 0.8639556169509888\n",
      "Epoch 33/100, Iteration 8/38, Loss: 0.9341002702713013\n",
      "Epoch 33/100, Iteration 9/38, Loss: 0.9387128949165344\n",
      "Epoch 33/100, Iteration 10/38, Loss: 0.97075355052948\n",
      "Epoch 33/100, Iteration 11/38, Loss: 0.9113306999206543\n",
      "Epoch 33/100, Iteration 12/38, Loss: 0.8999785780906677\n",
      "Epoch 33/100, Iteration 13/38, Loss: 1.0965831279754639\n",
      "Epoch 33/100, Iteration 14/38, Loss: 0.973260760307312\n",
      "Epoch 33/100, Iteration 15/38, Loss: 0.9604467153549194\n",
      "Epoch 33/100, Iteration 16/38, Loss: 0.9841281771659851\n",
      "Epoch 33/100, Iteration 17/38, Loss: 1.0108505487442017\n",
      "Epoch 33/100, Iteration 18/38, Loss: 0.9982456564903259\n",
      "Epoch 33/100, Iteration 19/38, Loss: 0.9137905240058899\n",
      "Epoch 33/100, Iteration 20/38, Loss: 0.9830881953239441\n",
      "Epoch 33/100, Iteration 21/38, Loss: 0.9231200814247131\n",
      "Epoch 33/100, Iteration 22/38, Loss: 0.9913639426231384\n",
      "Epoch 33/100, Iteration 23/38, Loss: 0.9887990951538086\n",
      "Epoch 33/100, Iteration 24/38, Loss: 0.9097155332565308\n",
      "Epoch 33/100, Iteration 25/38, Loss: 0.8942909836769104\n",
      "Epoch 33/100, Iteration 26/38, Loss: 0.9088854789733887\n",
      "Epoch 33/100, Iteration 27/38, Loss: 0.9941126108169556\n",
      "Epoch 33/100, Iteration 28/38, Loss: 1.0155164003372192\n",
      "Epoch 33/100, Iteration 29/38, Loss: 1.071134328842163\n",
      "Epoch 33/100, Iteration 30/38, Loss: 0.9100508689880371\n",
      "Epoch 33/100, Iteration 31/38, Loss: 1.0299800634384155\n",
      "Epoch 33/100, Iteration 32/38, Loss: 0.9492483139038086\n",
      "Epoch 33/100, Iteration 33/38, Loss: 1.0400688648223877\n",
      "Epoch 33/100, Iteration 34/38, Loss: 1.0973560810089111\n",
      "Epoch 33/100, Iteration 35/38, Loss: 1.000617265701294\n",
      "Epoch 33/100, Iteration 36/38, Loss: 0.9287590384483337\n",
      "Epoch 33/100, Iteration 37/38, Loss: 1.0646979808807373\n",
      "Epoch 33/100, Iteration 38/38, Loss: 0.9714779257774353\n",
      "Epoch 34/100, Iteration 1/38, Loss: 0.9910362958908081\n",
      "Epoch 34/100, Iteration 2/38, Loss: 0.932867169380188\n",
      "Epoch 34/100, Iteration 3/38, Loss: 0.9166918396949768\n",
      "Epoch 34/100, Iteration 4/38, Loss: 0.9252162575721741\n",
      "Epoch 34/100, Iteration 5/38, Loss: 0.9540040493011475\n",
      "Epoch 34/100, Iteration 6/38, Loss: 1.0257946252822876\n",
      "Epoch 34/100, Iteration 7/38, Loss: 0.8111028075218201\n",
      "Epoch 34/100, Iteration 8/38, Loss: 1.0086451768875122\n",
      "Epoch 34/100, Iteration 9/38, Loss: 1.0738255977630615\n",
      "Epoch 34/100, Iteration 10/38, Loss: 1.0739483833312988\n",
      "Epoch 34/100, Iteration 11/38, Loss: 0.9455099701881409\n",
      "Epoch 34/100, Iteration 12/38, Loss: 1.0026980638504028\n",
      "Epoch 34/100, Iteration 13/38, Loss: 1.1051408052444458\n",
      "Epoch 34/100, Iteration 14/38, Loss: 0.8848593831062317\n",
      "Epoch 34/100, Iteration 15/38, Loss: 0.9882398843765259\n",
      "Epoch 34/100, Iteration 16/38, Loss: 0.9932200908660889\n",
      "Epoch 34/100, Iteration 17/38, Loss: 0.8888880014419556\n",
      "Epoch 34/100, Iteration 18/38, Loss: 1.068699598312378\n",
      "Epoch 34/100, Iteration 19/38, Loss: 1.0011117458343506\n",
      "Epoch 34/100, Iteration 20/38, Loss: 0.9871389865875244\n",
      "Epoch 34/100, Iteration 21/38, Loss: 0.8890206813812256\n",
      "Epoch 34/100, Iteration 22/38, Loss: 0.8505180478096008\n",
      "Epoch 34/100, Iteration 23/38, Loss: 0.9899217486381531\n",
      "Epoch 34/100, Iteration 24/38, Loss: 0.9154288172721863\n",
      "Epoch 34/100, Iteration 25/38, Loss: 1.0433398485183716\n",
      "Epoch 34/100, Iteration 26/38, Loss: 0.9424804449081421\n",
      "Epoch 34/100, Iteration 27/38, Loss: 0.9895035624504089\n",
      "Epoch 34/100, Iteration 28/38, Loss: 0.9852239489555359\n",
      "Epoch 34/100, Iteration 29/38, Loss: 0.9549094438552856\n",
      "Epoch 34/100, Iteration 30/38, Loss: 0.9912641644477844\n",
      "Epoch 34/100, Iteration 31/38, Loss: 0.9145696759223938\n",
      "Epoch 34/100, Iteration 32/38, Loss: 0.944364607334137\n",
      "Epoch 34/100, Iteration 33/38, Loss: 1.0288006067276\n",
      "Epoch 34/100, Iteration 34/38, Loss: 0.9111803770065308\n",
      "Epoch 34/100, Iteration 35/38, Loss: 0.9502792358398438\n",
      "Epoch 34/100, Iteration 36/38, Loss: 0.9605490565299988\n",
      "Epoch 34/100, Iteration 37/38, Loss: 1.1113123893737793\n",
      "Epoch 34/100, Iteration 38/38, Loss: 0.9716119766235352\n",
      "Epoch 35/100, Iteration 1/38, Loss: 0.9880598187446594\n",
      "Epoch 35/100, Iteration 2/38, Loss: 1.0043083429336548\n",
      "Epoch 35/100, Iteration 3/38, Loss: 1.040505290031433\n",
      "Epoch 35/100, Iteration 4/38, Loss: 0.9114558696746826\n",
      "Epoch 35/100, Iteration 5/38, Loss: 0.9842013716697693\n",
      "Epoch 35/100, Iteration 6/38, Loss: 0.9612447023391724\n",
      "Epoch 35/100, Iteration 7/38, Loss: 0.8910877108573914\n",
      "Epoch 35/100, Iteration 8/38, Loss: 0.9966059923171997\n",
      "Epoch 35/100, Iteration 9/38, Loss: 0.8896158933639526\n",
      "Epoch 35/100, Iteration 10/38, Loss: 0.9214382767677307\n",
      "Epoch 35/100, Iteration 11/38, Loss: 0.9528700709342957\n",
      "Epoch 35/100, Iteration 12/38, Loss: 0.9397190809249878\n",
      "Epoch 35/100, Iteration 13/38, Loss: 0.9740527868270874\n",
      "Epoch 35/100, Iteration 14/38, Loss: 0.9466618895530701\n",
      "Epoch 35/100, Iteration 15/38, Loss: 0.9504777789115906\n",
      "Epoch 35/100, Iteration 16/38, Loss: 0.8589075207710266\n",
      "Epoch 35/100, Iteration 17/38, Loss: 1.041919231414795\n",
      "Epoch 35/100, Iteration 18/38, Loss: 0.9409449100494385\n",
      "Epoch 35/100, Iteration 19/38, Loss: 0.9570463299751282\n",
      "Epoch 35/100, Iteration 20/38, Loss: 0.91570645570755\n",
      "Epoch 35/100, Iteration 21/38, Loss: 0.9928820133209229\n",
      "Epoch 35/100, Iteration 22/38, Loss: 1.0503764152526855\n",
      "Epoch 35/100, Iteration 23/38, Loss: 0.9617728590965271\n",
      "Epoch 35/100, Iteration 24/38, Loss: 0.9283217787742615\n",
      "Epoch 35/100, Iteration 25/38, Loss: 1.0542449951171875\n",
      "Epoch 35/100, Iteration 26/38, Loss: 0.9202688336372375\n",
      "Epoch 35/100, Iteration 27/38, Loss: 0.945891261100769\n",
      "Epoch 35/100, Iteration 28/38, Loss: 0.9539043307304382\n",
      "Epoch 35/100, Iteration 29/38, Loss: 0.9466103315353394\n",
      "Epoch 35/100, Iteration 30/38, Loss: 0.9548761248588562\n",
      "Epoch 35/100, Iteration 31/38, Loss: 0.9788192510604858\n",
      "Epoch 35/100, Iteration 32/38, Loss: 0.8977652788162231\n",
      "Epoch 35/100, Iteration 33/38, Loss: 0.9001126885414124\n",
      "Epoch 35/100, Iteration 34/38, Loss: 1.0105059146881104\n",
      "Epoch 35/100, Iteration 35/38, Loss: 1.0497944355010986\n",
      "Epoch 35/100, Iteration 36/38, Loss: 0.9111469388008118\n",
      "Epoch 35/100, Iteration 37/38, Loss: 1.0239413976669312\n",
      "Epoch 35/100, Iteration 38/38, Loss: 0.8734481930732727\n",
      "Epoch 36/100, Iteration 1/38, Loss: 1.0293174982070923\n",
      "Epoch 36/100, Iteration 2/38, Loss: 0.9666499495506287\n",
      "Epoch 36/100, Iteration 3/38, Loss: 0.8890278935432434\n",
      "Epoch 36/100, Iteration 4/38, Loss: 0.8861521482467651\n",
      "Epoch 36/100, Iteration 5/38, Loss: 0.9855426549911499\n",
      "Epoch 36/100, Iteration 6/38, Loss: 0.9682192206382751\n",
      "Epoch 36/100, Iteration 7/38, Loss: 0.8483843803405762\n",
      "Epoch 36/100, Iteration 8/38, Loss: 0.8804305195808411\n",
      "Epoch 36/100, Iteration 9/38, Loss: 0.864749550819397\n",
      "Epoch 36/100, Iteration 10/38, Loss: 0.9116218686103821\n",
      "Epoch 36/100, Iteration 11/38, Loss: 0.880985677242279\n",
      "Epoch 36/100, Iteration 12/38, Loss: 1.052436113357544\n",
      "Epoch 36/100, Iteration 13/38, Loss: 1.0352082252502441\n",
      "Epoch 36/100, Iteration 14/38, Loss: 0.9505631327629089\n",
      "Epoch 36/100, Iteration 15/38, Loss: 0.8105758428573608\n",
      "Epoch 36/100, Iteration 16/38, Loss: 0.9028029441833496\n",
      "Epoch 36/100, Iteration 17/38, Loss: 0.9184707999229431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100, Iteration 18/38, Loss: 0.96180260181427\n",
      "Epoch 36/100, Iteration 19/38, Loss: 1.0466580390930176\n",
      "Epoch 36/100, Iteration 20/38, Loss: 0.9710838794708252\n",
      "Epoch 36/100, Iteration 21/38, Loss: 1.0114047527313232\n",
      "Epoch 36/100, Iteration 22/38, Loss: 0.8829113245010376\n",
      "Epoch 36/100, Iteration 23/38, Loss: 1.0403752326965332\n",
      "Epoch 36/100, Iteration 24/38, Loss: 0.8425211906433105\n",
      "Epoch 36/100, Iteration 25/38, Loss: 1.0784651041030884\n",
      "Epoch 36/100, Iteration 26/38, Loss: 1.0370734930038452\n",
      "Epoch 36/100, Iteration 27/38, Loss: 0.873657763004303\n",
      "Epoch 36/100, Iteration 28/38, Loss: 0.9210882186889648\n",
      "Epoch 36/100, Iteration 29/38, Loss: 0.8161748647689819\n",
      "Epoch 36/100, Iteration 30/38, Loss: 0.9792763590812683\n",
      "Epoch 36/100, Iteration 31/38, Loss: 1.0223901271820068\n",
      "Epoch 36/100, Iteration 32/38, Loss: 0.9404082298278809\n",
      "Epoch 36/100, Iteration 33/38, Loss: 0.9076067805290222\n",
      "Epoch 36/100, Iteration 34/38, Loss: 1.0475598573684692\n",
      "Epoch 36/100, Iteration 35/38, Loss: 1.0280232429504395\n",
      "Epoch 36/100, Iteration 36/38, Loss: 0.9919224977493286\n",
      "Epoch 36/100, Iteration 37/38, Loss: 0.8535666465759277\n",
      "Epoch 36/100, Iteration 38/38, Loss: 0.7623229026794434\n",
      "Epoch 37/100, Iteration 1/38, Loss: 0.8874468207359314\n",
      "Epoch 37/100, Iteration 2/38, Loss: 1.0047228336334229\n",
      "Epoch 37/100, Iteration 3/38, Loss: 0.915093719959259\n",
      "Epoch 37/100, Iteration 4/38, Loss: 0.888120174407959\n",
      "Epoch 37/100, Iteration 5/38, Loss: 0.9408813118934631\n",
      "Epoch 37/100, Iteration 6/38, Loss: 1.0593011379241943\n",
      "Epoch 37/100, Iteration 7/38, Loss: 1.0372458696365356\n",
      "Epoch 37/100, Iteration 8/38, Loss: 0.9249836206436157\n",
      "Epoch 37/100, Iteration 9/38, Loss: 0.9251906871795654\n",
      "Epoch 37/100, Iteration 10/38, Loss: 0.8531583547592163\n",
      "Epoch 37/100, Iteration 11/38, Loss: 1.0371671915054321\n",
      "Epoch 37/100, Iteration 12/38, Loss: 0.846748411655426\n",
      "Epoch 37/100, Iteration 13/38, Loss: 0.9270534515380859\n",
      "Epoch 37/100, Iteration 14/38, Loss: 0.9237623810768127\n",
      "Epoch 37/100, Iteration 15/38, Loss: 1.008602261543274\n",
      "Epoch 37/100, Iteration 16/38, Loss: 0.8386944532394409\n",
      "Epoch 37/100, Iteration 17/38, Loss: 0.9911826848983765\n",
      "Epoch 37/100, Iteration 18/38, Loss: 0.9794272780418396\n",
      "Epoch 37/100, Iteration 19/38, Loss: 1.054696798324585\n",
      "Epoch 37/100, Iteration 20/38, Loss: 0.9148607850074768\n",
      "Epoch 37/100, Iteration 21/38, Loss: 0.7989407777786255\n",
      "Epoch 37/100, Iteration 22/38, Loss: 0.9539417624473572\n",
      "Epoch 37/100, Iteration 23/38, Loss: 0.9266238212585449\n",
      "Epoch 37/100, Iteration 24/38, Loss: 1.0234124660491943\n",
      "Epoch 37/100, Iteration 25/38, Loss: 0.8415780067443848\n",
      "Epoch 37/100, Iteration 26/38, Loss: 0.9306700229644775\n",
      "Epoch 37/100, Iteration 27/38, Loss: 1.0362228155136108\n",
      "Epoch 37/100, Iteration 28/38, Loss: 0.9732370972633362\n",
      "Epoch 37/100, Iteration 29/38, Loss: 0.8784748911857605\n",
      "Epoch 37/100, Iteration 30/38, Loss: 0.869429349899292\n",
      "Epoch 37/100, Iteration 31/38, Loss: 0.9318499565124512\n",
      "Epoch 37/100, Iteration 32/38, Loss: 1.0021601915359497\n",
      "Epoch 37/100, Iteration 33/38, Loss: 0.976120114326477\n",
      "Epoch 37/100, Iteration 34/38, Loss: 0.8998659253120422\n",
      "Epoch 37/100, Iteration 35/38, Loss: 0.9404392242431641\n",
      "Epoch 37/100, Iteration 36/38, Loss: 0.8194053173065186\n",
      "Epoch 37/100, Iteration 37/38, Loss: 0.9193289875984192\n",
      "Epoch 37/100, Iteration 38/38, Loss: 0.7725086212158203\n",
      "Epoch 38/100, Iteration 1/38, Loss: 0.8818499445915222\n",
      "Epoch 38/100, Iteration 2/38, Loss: 0.8365625143051147\n",
      "Epoch 38/100, Iteration 3/38, Loss: 0.848562479019165\n",
      "Epoch 38/100, Iteration 4/38, Loss: 1.0723140239715576\n",
      "Epoch 38/100, Iteration 5/38, Loss: 0.9917945265769958\n",
      "Epoch 38/100, Iteration 6/38, Loss: 0.9099420309066772\n",
      "Epoch 38/100, Iteration 7/38, Loss: 0.880416214466095\n",
      "Epoch 38/100, Iteration 8/38, Loss: 1.023525357246399\n",
      "Epoch 38/100, Iteration 9/38, Loss: 0.9266324639320374\n",
      "Epoch 38/100, Iteration 10/38, Loss: 0.8247054815292358\n",
      "Epoch 38/100, Iteration 11/38, Loss: 0.9751348495483398\n",
      "Epoch 38/100, Iteration 12/38, Loss: 0.8857245445251465\n",
      "Epoch 38/100, Iteration 13/38, Loss: 0.8733764290809631\n",
      "Epoch 38/100, Iteration 14/38, Loss: 0.9723965525627136\n",
      "Epoch 38/100, Iteration 15/38, Loss: 0.9806600213050842\n",
      "Epoch 38/100, Iteration 16/38, Loss: 1.0008302927017212\n",
      "Epoch 38/100, Iteration 17/38, Loss: 0.9551756978034973\n",
      "Epoch 38/100, Iteration 18/38, Loss: 0.8881765007972717\n",
      "Epoch 38/100, Iteration 19/38, Loss: 0.9564930200576782\n",
      "Epoch 38/100, Iteration 20/38, Loss: 0.8407713770866394\n",
      "Epoch 38/100, Iteration 21/38, Loss: 0.9250084757804871\n",
      "Epoch 38/100, Iteration 22/38, Loss: 0.8596632480621338\n",
      "Epoch 38/100, Iteration 23/38, Loss: 1.0541545152664185\n",
      "Epoch 38/100, Iteration 24/38, Loss: 0.9680014252662659\n",
      "Epoch 38/100, Iteration 25/38, Loss: 0.8546684980392456\n",
      "Epoch 38/100, Iteration 26/38, Loss: 0.8896199464797974\n",
      "Epoch 38/100, Iteration 27/38, Loss: 0.9904519319534302\n",
      "Epoch 38/100, Iteration 28/38, Loss: 0.9945321083068848\n",
      "Epoch 38/100, Iteration 29/38, Loss: 0.8154486417770386\n",
      "Epoch 38/100, Iteration 30/38, Loss: 0.8644748330116272\n",
      "Epoch 38/100, Iteration 31/38, Loss: 0.8419895768165588\n",
      "Epoch 38/100, Iteration 32/38, Loss: 0.9943596720695496\n",
      "Epoch 38/100, Iteration 33/38, Loss: 1.0084376335144043\n",
      "Epoch 38/100, Iteration 34/38, Loss: 0.9499672055244446\n",
      "Epoch 38/100, Iteration 35/38, Loss: 0.7883616089820862\n",
      "Epoch 38/100, Iteration 36/38, Loss: 1.005204439163208\n",
      "Epoch 38/100, Iteration 37/38, Loss: 0.9915733933448792\n",
      "Epoch 38/100, Iteration 38/38, Loss: 0.9237470030784607\n",
      "Epoch 39/100, Iteration 1/38, Loss: 1.1036556959152222\n",
      "Epoch 39/100, Iteration 2/38, Loss: 0.8265752792358398\n",
      "Epoch 39/100, Iteration 3/38, Loss: 1.0186535120010376\n",
      "Epoch 39/100, Iteration 4/38, Loss: 1.0630658864974976\n",
      "Epoch 39/100, Iteration 5/38, Loss: 0.8977819085121155\n",
      "Epoch 39/100, Iteration 6/38, Loss: 0.9127892851829529\n",
      "Epoch 39/100, Iteration 7/38, Loss: 0.935849666595459\n",
      "Epoch 39/100, Iteration 8/38, Loss: 0.9927120804786682\n",
      "Epoch 39/100, Iteration 9/38, Loss: 0.852310061454773\n",
      "Epoch 39/100, Iteration 10/38, Loss: 0.90006422996521\n",
      "Epoch 39/100, Iteration 11/38, Loss: 0.8905328512191772\n",
      "Epoch 39/100, Iteration 12/38, Loss: 0.975281834602356\n",
      "Epoch 39/100, Iteration 13/38, Loss: 0.8935220241546631\n",
      "Epoch 39/100, Iteration 14/38, Loss: 0.9398475885391235\n",
      "Epoch 39/100, Iteration 15/38, Loss: 0.9967886805534363\n",
      "Epoch 39/100, Iteration 16/38, Loss: 0.9276064038276672\n",
      "Epoch 39/100, Iteration 17/38, Loss: 0.9842771291732788\n",
      "Epoch 39/100, Iteration 18/38, Loss: 0.9973574280738831\n",
      "Epoch 39/100, Iteration 19/38, Loss: 0.9276548027992249\n",
      "Epoch 39/100, Iteration 20/38, Loss: 0.8735655546188354\n",
      "Epoch 39/100, Iteration 21/38, Loss: 0.9571552276611328\n",
      "Epoch 39/100, Iteration 22/38, Loss: 1.0076253414154053\n",
      "Epoch 39/100, Iteration 23/38, Loss: 0.9807731509208679\n",
      "Epoch 39/100, Iteration 24/38, Loss: 0.9044190049171448\n",
      "Epoch 39/100, Iteration 25/38, Loss: 0.9305466413497925\n",
      "Epoch 39/100, Iteration 26/38, Loss: 0.7444209456443787\n",
      "Epoch 39/100, Iteration 27/38, Loss: 0.8319761753082275\n",
      "Epoch 39/100, Iteration 28/38, Loss: 1.0110026597976685\n",
      "Epoch 39/100, Iteration 29/38, Loss: 0.847644031047821\n",
      "Epoch 39/100, Iteration 30/38, Loss: 0.9020408391952515\n",
      "Epoch 39/100, Iteration 31/38, Loss: 0.9369357228279114\n",
      "Epoch 39/100, Iteration 32/38, Loss: 0.7387100458145142\n",
      "Epoch 39/100, Iteration 33/38, Loss: 0.9359336495399475\n",
      "Epoch 39/100, Iteration 34/38, Loss: 0.839927613735199\n",
      "Epoch 39/100, Iteration 35/38, Loss: 0.8738139271736145\n",
      "Epoch 39/100, Iteration 36/38, Loss: 0.8773903250694275\n",
      "Epoch 39/100, Iteration 37/38, Loss: 0.8240509629249573\n",
      "Epoch 39/100, Iteration 38/38, Loss: 0.8946288824081421\n",
      "Epoch 40/100, Iteration 1/38, Loss: 0.9621537923812866\n",
      "Epoch 40/100, Iteration 2/38, Loss: 0.8964647650718689\n",
      "Epoch 40/100, Iteration 3/38, Loss: 0.9389787316322327\n",
      "Epoch 40/100, Iteration 4/38, Loss: 0.9715021252632141\n",
      "Epoch 40/100, Iteration 5/38, Loss: 0.9078727960586548\n",
      "Epoch 40/100, Iteration 6/38, Loss: 0.7827150821685791\n",
      "Epoch 40/100, Iteration 7/38, Loss: 0.9018861651420593\n",
      "Epoch 40/100, Iteration 8/38, Loss: 0.8696208000183105\n",
      "Epoch 40/100, Iteration 9/38, Loss: 0.9502751231193542\n",
      "Epoch 40/100, Iteration 10/38, Loss: 0.7940043807029724\n",
      "Epoch 40/100, Iteration 11/38, Loss: 0.9175917506217957\n",
      "Epoch 40/100, Iteration 12/38, Loss: 0.9545708298683167\n",
      "Epoch 40/100, Iteration 13/38, Loss: 0.8801730275154114\n",
      "Epoch 40/100, Iteration 14/38, Loss: 0.9059392213821411\n",
      "Epoch 40/100, Iteration 15/38, Loss: 0.8941362500190735\n",
      "Epoch 40/100, Iteration 16/38, Loss: 0.9436109066009521\n",
      "Epoch 40/100, Iteration 17/38, Loss: 0.9279155731201172\n",
      "Epoch 40/100, Iteration 18/38, Loss: 0.9358073472976685\n",
      "Epoch 40/100, Iteration 19/38, Loss: 0.8377854228019714\n",
      "Epoch 40/100, Iteration 20/38, Loss: 0.9039645791053772\n",
      "Epoch 40/100, Iteration 21/38, Loss: 0.7763497829437256\n",
      "Epoch 40/100, Iteration 22/38, Loss: 0.9654345512390137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Iteration 23/38, Loss: 0.9432430863380432\n",
      "Epoch 40/100, Iteration 24/38, Loss: 1.0372401475906372\n",
      "Epoch 40/100, Iteration 25/38, Loss: 0.9390869140625\n",
      "Epoch 40/100, Iteration 26/38, Loss: 0.9692628979682922\n",
      "Epoch 40/100, Iteration 27/38, Loss: 0.9570208191871643\n",
      "Epoch 40/100, Iteration 28/38, Loss: 0.8560559153556824\n",
      "Epoch 40/100, Iteration 29/38, Loss: 0.9686801433563232\n",
      "Epoch 40/100, Iteration 30/38, Loss: 0.8424633145332336\n",
      "Epoch 40/100, Iteration 31/38, Loss: 0.9650067090988159\n",
      "Epoch 40/100, Iteration 32/38, Loss: 0.9112768769264221\n",
      "Epoch 40/100, Iteration 33/38, Loss: 1.0246365070343018\n",
      "Epoch 40/100, Iteration 34/38, Loss: 0.7736160159111023\n",
      "Epoch 40/100, Iteration 35/38, Loss: 0.9259162545204163\n",
      "Epoch 40/100, Iteration 36/38, Loss: 0.8537166714668274\n",
      "Epoch 40/100, Iteration 37/38, Loss: 0.8636981248855591\n",
      "Epoch 40/100, Iteration 38/38, Loss: 0.8311017751693726\n",
      "Epoch 41/100, Iteration 1/38, Loss: 0.8773190975189209\n",
      "Epoch 41/100, Iteration 2/38, Loss: 0.934567391872406\n",
      "Epoch 41/100, Iteration 3/38, Loss: 0.9469354748725891\n",
      "Epoch 41/100, Iteration 4/38, Loss: 0.856795072555542\n",
      "Epoch 41/100, Iteration 5/38, Loss: 0.8018984198570251\n",
      "Epoch 41/100, Iteration 6/38, Loss: 0.8897789716720581\n",
      "Epoch 41/100, Iteration 7/38, Loss: 0.9824315309524536\n",
      "Epoch 41/100, Iteration 8/38, Loss: 0.7969962954521179\n",
      "Epoch 41/100, Iteration 9/38, Loss: 1.0153428316116333\n",
      "Epoch 41/100, Iteration 10/38, Loss: 0.9459909200668335\n",
      "Epoch 41/100, Iteration 11/38, Loss: 0.949131190776825\n",
      "Epoch 41/100, Iteration 12/38, Loss: 0.8438891768455505\n",
      "Epoch 41/100, Iteration 13/38, Loss: 0.8952847719192505\n",
      "Epoch 41/100, Iteration 14/38, Loss: 0.8590119481086731\n",
      "Epoch 41/100, Iteration 15/38, Loss: 0.8615034818649292\n",
      "Epoch 41/100, Iteration 16/38, Loss: 0.8373845815658569\n",
      "Epoch 41/100, Iteration 17/38, Loss: 1.0195701122283936\n",
      "Epoch 41/100, Iteration 18/38, Loss: 0.9616323709487915\n",
      "Epoch 41/100, Iteration 19/38, Loss: 1.0353080034255981\n",
      "Epoch 41/100, Iteration 20/38, Loss: 0.8533432483673096\n",
      "Epoch 41/100, Iteration 21/38, Loss: 0.9276651740074158\n",
      "Epoch 41/100, Iteration 22/38, Loss: 0.8388049602508545\n",
      "Epoch 41/100, Iteration 23/38, Loss: 0.9194273948669434\n",
      "Epoch 41/100, Iteration 24/38, Loss: 0.916219174861908\n",
      "Epoch 41/100, Iteration 25/38, Loss: 0.766913115978241\n",
      "Epoch 41/100, Iteration 26/38, Loss: 0.7666023373603821\n",
      "Epoch 41/100, Iteration 27/38, Loss: 0.8507280349731445\n",
      "Epoch 41/100, Iteration 28/38, Loss: 0.8842329382896423\n",
      "Epoch 41/100, Iteration 29/38, Loss: 0.8693161606788635\n",
      "Epoch 41/100, Iteration 30/38, Loss: 0.886353611946106\n",
      "Epoch 41/100, Iteration 31/38, Loss: 1.0267882347106934\n",
      "Epoch 41/100, Iteration 32/38, Loss: 0.8727543354034424\n",
      "Epoch 41/100, Iteration 33/38, Loss: 0.8707119226455688\n",
      "Epoch 41/100, Iteration 34/38, Loss: 1.1543837785720825\n",
      "Epoch 41/100, Iteration 35/38, Loss: 0.8775451183319092\n",
      "Epoch 41/100, Iteration 36/38, Loss: 1.012278437614441\n",
      "Epoch 41/100, Iteration 37/38, Loss: 0.8933248519897461\n",
      "Epoch 41/100, Iteration 38/38, Loss: 0.9147337079048157\n",
      "Epoch 42/100, Iteration 1/38, Loss: 1.1179920434951782\n",
      "Epoch 42/100, Iteration 2/38, Loss: 0.8688927292823792\n",
      "Epoch 42/100, Iteration 3/38, Loss: 0.92469722032547\n",
      "Epoch 42/100, Iteration 4/38, Loss: 0.8415200114250183\n",
      "Epoch 42/100, Iteration 5/38, Loss: 0.774802029132843\n",
      "Epoch 42/100, Iteration 6/38, Loss: 0.8759088516235352\n",
      "Epoch 42/100, Iteration 7/38, Loss: 1.0016692876815796\n",
      "Epoch 42/100, Iteration 8/38, Loss: 1.0858327150344849\n",
      "Epoch 42/100, Iteration 9/38, Loss: 1.0395972728729248\n",
      "Epoch 42/100, Iteration 10/38, Loss: 0.9565944671630859\n",
      "Epoch 42/100, Iteration 11/38, Loss: 0.9668557643890381\n",
      "Epoch 42/100, Iteration 12/38, Loss: 0.8406509757041931\n",
      "Epoch 42/100, Iteration 13/38, Loss: 0.9225136637687683\n",
      "Epoch 42/100, Iteration 14/38, Loss: 0.8104594349861145\n",
      "Epoch 42/100, Iteration 15/38, Loss: 0.8410784602165222\n",
      "Epoch 42/100, Iteration 16/38, Loss: 0.9589453935623169\n",
      "Epoch 42/100, Iteration 17/38, Loss: 0.907960057258606\n",
      "Epoch 42/100, Iteration 18/38, Loss: 0.7800090312957764\n",
      "Epoch 42/100, Iteration 19/38, Loss: 0.9321771860122681\n",
      "Epoch 42/100, Iteration 20/38, Loss: 0.8683815598487854\n",
      "Epoch 42/100, Iteration 21/38, Loss: 1.015228271484375\n",
      "Epoch 42/100, Iteration 22/38, Loss: 0.8431555032730103\n",
      "Epoch 42/100, Iteration 23/38, Loss: 0.8733280897140503\n",
      "Epoch 42/100, Iteration 24/38, Loss: 0.880807101726532\n",
      "Epoch 42/100, Iteration 25/38, Loss: 0.902881920337677\n",
      "Epoch 42/100, Iteration 26/38, Loss: 0.8650645613670349\n",
      "Epoch 42/100, Iteration 27/38, Loss: 0.8582875728607178\n",
      "Epoch 42/100, Iteration 28/38, Loss: 0.7565499544143677\n",
      "Epoch 42/100, Iteration 29/38, Loss: 0.8084166049957275\n",
      "Epoch 42/100, Iteration 30/38, Loss: 0.9035598635673523\n",
      "Epoch 42/100, Iteration 31/38, Loss: 0.8333830833435059\n",
      "Epoch 42/100, Iteration 32/38, Loss: 0.9287121891975403\n",
      "Epoch 42/100, Iteration 33/38, Loss: 0.8951927423477173\n",
      "Epoch 42/100, Iteration 34/38, Loss: 0.9754929542541504\n",
      "Epoch 42/100, Iteration 35/38, Loss: 1.0076271295547485\n",
      "Epoch 42/100, Iteration 36/38, Loss: 0.7999780774116516\n",
      "Epoch 42/100, Iteration 37/38, Loss: 0.9433718919754028\n",
      "Epoch 42/100, Iteration 38/38, Loss: 0.8242126107215881\n",
      "Epoch 43/100, Iteration 1/38, Loss: 0.9302729368209839\n",
      "Epoch 43/100, Iteration 2/38, Loss: 0.7590623497962952\n",
      "Epoch 43/100, Iteration 3/38, Loss: 0.9760802388191223\n",
      "Epoch 43/100, Iteration 4/38, Loss: 0.8633471131324768\n",
      "Epoch 43/100, Iteration 5/38, Loss: 0.8711649775505066\n",
      "Epoch 43/100, Iteration 6/38, Loss: 0.910243570804596\n",
      "Epoch 43/100, Iteration 7/38, Loss: 0.9348971247673035\n",
      "Epoch 43/100, Iteration 8/38, Loss: 0.8841413259506226\n",
      "Epoch 43/100, Iteration 9/38, Loss: 0.8538432717323303\n",
      "Epoch 43/100, Iteration 10/38, Loss: 0.8265790343284607\n",
      "Epoch 43/100, Iteration 11/38, Loss: 0.9071677923202515\n",
      "Epoch 43/100, Iteration 12/38, Loss: 0.9715210795402527\n",
      "Epoch 43/100, Iteration 13/38, Loss: 0.9690287709236145\n",
      "Epoch 43/100, Iteration 14/38, Loss: 0.8728047609329224\n",
      "Epoch 43/100, Iteration 15/38, Loss: 0.8978830575942993\n",
      "Epoch 43/100, Iteration 16/38, Loss: 0.8973478078842163\n",
      "Epoch 43/100, Iteration 17/38, Loss: 0.8673014044761658\n",
      "Epoch 43/100, Iteration 18/38, Loss: 0.97637540102005\n",
      "Epoch 43/100, Iteration 19/38, Loss: 0.8804909586906433\n",
      "Epoch 43/100, Iteration 20/38, Loss: 0.8832516074180603\n",
      "Epoch 43/100, Iteration 21/38, Loss: 0.8600494861602783\n",
      "Epoch 43/100, Iteration 22/38, Loss: 0.9894923567771912\n",
      "Epoch 43/100, Iteration 23/38, Loss: 0.9081431031227112\n",
      "Epoch 43/100, Iteration 24/38, Loss: 0.778247594833374\n",
      "Epoch 43/100, Iteration 25/38, Loss: 0.9392749071121216\n",
      "Epoch 43/100, Iteration 26/38, Loss: 0.9120268225669861\n",
      "Epoch 43/100, Iteration 27/38, Loss: 0.8420138955116272\n",
      "Epoch 43/100, Iteration 28/38, Loss: 0.8246908187866211\n",
      "Epoch 43/100, Iteration 29/38, Loss: 0.909398078918457\n",
      "Epoch 43/100, Iteration 30/38, Loss: 0.7590987682342529\n",
      "Epoch 43/100, Iteration 31/38, Loss: 0.7413108944892883\n",
      "Epoch 43/100, Iteration 32/38, Loss: 0.8356322050094604\n",
      "Epoch 43/100, Iteration 33/38, Loss: 0.9406450986862183\n",
      "Epoch 43/100, Iteration 34/38, Loss: 0.8755639791488647\n",
      "Epoch 43/100, Iteration 35/38, Loss: 0.9028674364089966\n",
      "Epoch 43/100, Iteration 36/38, Loss: 0.894102931022644\n",
      "Epoch 43/100, Iteration 37/38, Loss: 0.8343169689178467\n",
      "Epoch 43/100, Iteration 38/38, Loss: 0.80109041929245\n",
      "Epoch 44/100, Iteration 1/38, Loss: 1.1171200275421143\n",
      "Epoch 44/100, Iteration 2/38, Loss: 0.8450605869293213\n",
      "Epoch 44/100, Iteration 3/38, Loss: 0.8605659008026123\n",
      "Epoch 44/100, Iteration 4/38, Loss: 0.954210638999939\n",
      "Epoch 44/100, Iteration 5/38, Loss: 0.7907137870788574\n",
      "Epoch 44/100, Iteration 6/38, Loss: 0.7707642316818237\n",
      "Epoch 44/100, Iteration 7/38, Loss: 0.8758043646812439\n",
      "Epoch 44/100, Iteration 8/38, Loss: 0.9241905808448792\n",
      "Epoch 44/100, Iteration 9/38, Loss: 0.8940044641494751\n",
      "Epoch 44/100, Iteration 10/38, Loss: 0.8746769428253174\n",
      "Epoch 44/100, Iteration 11/38, Loss: 0.916024386882782\n",
      "Epoch 44/100, Iteration 12/38, Loss: 0.857478141784668\n",
      "Epoch 44/100, Iteration 13/38, Loss: 0.89975506067276\n",
      "Epoch 44/100, Iteration 14/38, Loss: 0.8523086309432983\n",
      "Epoch 44/100, Iteration 15/38, Loss: 0.7519981265068054\n",
      "Epoch 44/100, Iteration 16/38, Loss: 0.8671673536300659\n",
      "Epoch 44/100, Iteration 17/38, Loss: 0.9668579697608948\n",
      "Epoch 44/100, Iteration 18/38, Loss: 0.8677138090133667\n",
      "Epoch 44/100, Iteration 19/38, Loss: 0.923757791519165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100, Iteration 20/38, Loss: 0.8552477359771729\n",
      "Epoch 44/100, Iteration 21/38, Loss: 0.7726690173149109\n",
      "Epoch 44/100, Iteration 22/38, Loss: 0.8500679135322571\n",
      "Epoch 44/100, Iteration 23/38, Loss: 0.7617373466491699\n",
      "Epoch 44/100, Iteration 24/38, Loss: 0.9315295219421387\n",
      "Epoch 44/100, Iteration 25/38, Loss: 0.8679707646369934\n",
      "Epoch 44/100, Iteration 26/38, Loss: 0.8757904171943665\n",
      "Epoch 44/100, Iteration 27/38, Loss: 0.8650168180465698\n",
      "Epoch 44/100, Iteration 28/38, Loss: 0.9091101884841919\n",
      "Epoch 44/100, Iteration 29/38, Loss: 1.0462137460708618\n",
      "Epoch 44/100, Iteration 30/38, Loss: 0.8337926864624023\n",
      "Epoch 44/100, Iteration 31/38, Loss: 1.0147552490234375\n",
      "Epoch 44/100, Iteration 32/38, Loss: 0.9632304906845093\n",
      "Epoch 44/100, Iteration 33/38, Loss: 0.8746333718299866\n",
      "Epoch 44/100, Iteration 34/38, Loss: 0.9544141888618469\n",
      "Epoch 44/100, Iteration 35/38, Loss: 1.0526127815246582\n",
      "Epoch 44/100, Iteration 36/38, Loss: 0.8189140558242798\n",
      "Epoch 44/100, Iteration 37/38, Loss: 0.9040084481239319\n",
      "Epoch 44/100, Iteration 38/38, Loss: 1.0931074619293213\n",
      "Epoch 45/100, Iteration 1/38, Loss: 0.9170545935630798\n",
      "Epoch 45/100, Iteration 2/38, Loss: 0.8051369190216064\n",
      "Epoch 45/100, Iteration 3/38, Loss: 0.8708560466766357\n",
      "Epoch 45/100, Iteration 4/38, Loss: 0.9790247082710266\n",
      "Epoch 45/100, Iteration 5/38, Loss: 0.8551097512245178\n",
      "Epoch 45/100, Iteration 6/38, Loss: 0.9422607421875\n",
      "Epoch 45/100, Iteration 7/38, Loss: 0.8841773271560669\n",
      "Epoch 45/100, Iteration 8/38, Loss: 0.9202354550361633\n",
      "Epoch 45/100, Iteration 9/38, Loss: 0.7094155550003052\n",
      "Epoch 45/100, Iteration 10/38, Loss: 0.8617897033691406\n",
      "Epoch 45/100, Iteration 11/38, Loss: 0.8192218542098999\n",
      "Epoch 45/100, Iteration 12/38, Loss: 0.7977825999259949\n",
      "Epoch 45/100, Iteration 13/38, Loss: 0.8313543200492859\n",
      "Epoch 45/100, Iteration 14/38, Loss: 0.8146044611930847\n",
      "Epoch 45/100, Iteration 15/38, Loss: 0.9771458506584167\n",
      "Epoch 45/100, Iteration 16/38, Loss: 0.9337477684020996\n",
      "Epoch 45/100, Iteration 17/38, Loss: 1.0391860008239746\n",
      "Epoch 45/100, Iteration 18/38, Loss: 0.9091401100158691\n",
      "Epoch 45/100, Iteration 19/38, Loss: 0.8627533912658691\n",
      "Epoch 45/100, Iteration 20/38, Loss: 0.919694185256958\n",
      "Epoch 45/100, Iteration 21/38, Loss: 0.9555084109306335\n",
      "Epoch 45/100, Iteration 22/38, Loss: 0.9491422176361084\n",
      "Epoch 45/100, Iteration 23/38, Loss: 0.9177072048187256\n",
      "Epoch 45/100, Iteration 24/38, Loss: 0.763592541217804\n",
      "Epoch 45/100, Iteration 25/38, Loss: 0.793895959854126\n",
      "Epoch 45/100, Iteration 26/38, Loss: 0.9792448878288269\n",
      "Epoch 45/100, Iteration 27/38, Loss: 0.825340986251831\n",
      "Epoch 45/100, Iteration 28/38, Loss: 0.8581333160400391\n",
      "Epoch 45/100, Iteration 29/38, Loss: 0.7774641513824463\n",
      "Epoch 45/100, Iteration 30/38, Loss: 0.9656234383583069\n",
      "Epoch 45/100, Iteration 31/38, Loss: 0.7855460047721863\n",
      "Epoch 45/100, Iteration 32/38, Loss: 0.8804375529289246\n",
      "Epoch 45/100, Iteration 33/38, Loss: 0.7966066598892212\n",
      "Epoch 45/100, Iteration 34/38, Loss: 0.8184189796447754\n",
      "Epoch 45/100, Iteration 35/38, Loss: 0.9127426743507385\n",
      "Epoch 45/100, Iteration 36/38, Loss: 0.9025282859802246\n",
      "Epoch 45/100, Iteration 37/38, Loss: 0.8438913226127625\n",
      "Epoch 45/100, Iteration 38/38, Loss: 0.8446088433265686\n",
      "Epoch 46/100, Iteration 1/38, Loss: 0.848595380783081\n",
      "Epoch 46/100, Iteration 2/38, Loss: 0.824788510799408\n",
      "Epoch 46/100, Iteration 3/38, Loss: 0.8051311373710632\n",
      "Epoch 46/100, Iteration 4/38, Loss: 0.8204149603843689\n",
      "Epoch 46/100, Iteration 5/38, Loss: 0.815373420715332\n",
      "Epoch 46/100, Iteration 6/38, Loss: 0.8305823802947998\n",
      "Epoch 46/100, Iteration 7/38, Loss: 0.8132227659225464\n",
      "Epoch 46/100, Iteration 8/38, Loss: 0.8378040790557861\n",
      "Epoch 46/100, Iteration 9/38, Loss: 0.8653416633605957\n",
      "Epoch 46/100, Iteration 10/38, Loss: 0.7920836806297302\n",
      "Epoch 46/100, Iteration 11/38, Loss: 0.8046581149101257\n",
      "Epoch 46/100, Iteration 12/38, Loss: 0.784203052520752\n",
      "Epoch 46/100, Iteration 13/38, Loss: 0.9120798110961914\n",
      "Epoch 46/100, Iteration 14/38, Loss: 0.8321679830551147\n",
      "Epoch 46/100, Iteration 15/38, Loss: 0.9445210695266724\n",
      "Epoch 46/100, Iteration 16/38, Loss: 0.8528082966804504\n",
      "Epoch 46/100, Iteration 17/38, Loss: 0.9278134107589722\n",
      "Epoch 46/100, Iteration 18/38, Loss: 0.9907211065292358\n",
      "Epoch 46/100, Iteration 19/38, Loss: 0.8991379737854004\n",
      "Epoch 46/100, Iteration 20/38, Loss: 0.7610607743263245\n",
      "Epoch 46/100, Iteration 21/38, Loss: 0.8340383768081665\n",
      "Epoch 46/100, Iteration 22/38, Loss: 0.6980854272842407\n",
      "Epoch 46/100, Iteration 23/38, Loss: 0.8677232265472412\n",
      "Epoch 46/100, Iteration 24/38, Loss: 0.9016820192337036\n",
      "Epoch 46/100, Iteration 25/38, Loss: 0.9164988994598389\n",
      "Epoch 46/100, Iteration 26/38, Loss: 0.9063704013824463\n",
      "Epoch 46/100, Iteration 27/38, Loss: 0.9992836117744446\n",
      "Epoch 46/100, Iteration 28/38, Loss: 0.9523836374282837\n",
      "Epoch 46/100, Iteration 29/38, Loss: 0.9236757159233093\n",
      "Epoch 46/100, Iteration 30/38, Loss: 0.9017302393913269\n",
      "Epoch 46/100, Iteration 31/38, Loss: 0.8910525441169739\n",
      "Epoch 46/100, Iteration 32/38, Loss: 0.8513022065162659\n",
      "Epoch 46/100, Iteration 33/38, Loss: 0.8159660696983337\n",
      "Epoch 46/100, Iteration 34/38, Loss: 0.8527845740318298\n",
      "Epoch 46/100, Iteration 35/38, Loss: 1.0084867477416992\n",
      "Epoch 46/100, Iteration 36/38, Loss: 0.8560390472412109\n",
      "Epoch 46/100, Iteration 37/38, Loss: 0.905862033367157\n",
      "Epoch 46/100, Iteration 38/38, Loss: 0.7417086958885193\n",
      "Epoch 47/100, Iteration 1/38, Loss: 0.8704901337623596\n",
      "Epoch 47/100, Iteration 2/38, Loss: 0.8831311464309692\n",
      "Epoch 47/100, Iteration 3/38, Loss: 0.8285222053527832\n",
      "Epoch 47/100, Iteration 4/38, Loss: 0.8728009462356567\n",
      "Epoch 47/100, Iteration 5/38, Loss: 0.9313229322433472\n",
      "Epoch 47/100, Iteration 6/38, Loss: 0.9326493144035339\n",
      "Epoch 47/100, Iteration 7/38, Loss: 0.9140312075614929\n",
      "Epoch 47/100, Iteration 8/38, Loss: 0.8193442225456238\n",
      "Epoch 47/100, Iteration 9/38, Loss: 0.7956552505493164\n",
      "Epoch 47/100, Iteration 10/38, Loss: 0.9103728532791138\n",
      "Epoch 47/100, Iteration 11/38, Loss: 0.7980589270591736\n",
      "Epoch 47/100, Iteration 12/38, Loss: 0.8682273030281067\n",
      "Epoch 47/100, Iteration 13/38, Loss: 0.751973569393158\n",
      "Epoch 47/100, Iteration 14/38, Loss: 0.8892098665237427\n",
      "Epoch 47/100, Iteration 15/38, Loss: 0.8237000703811646\n",
      "Epoch 47/100, Iteration 16/38, Loss: 0.8794132471084595\n",
      "Epoch 47/100, Iteration 17/38, Loss: 0.9130921363830566\n",
      "Epoch 47/100, Iteration 18/38, Loss: 0.7538357377052307\n",
      "Epoch 47/100, Iteration 19/38, Loss: 0.7327942848205566\n",
      "Epoch 47/100, Iteration 20/38, Loss: 0.8931309580802917\n",
      "Epoch 47/100, Iteration 21/38, Loss: 0.8859487175941467\n",
      "Epoch 47/100, Iteration 22/38, Loss: 0.8960151076316833\n",
      "Epoch 47/100, Iteration 23/38, Loss: 0.8671613335609436\n",
      "Epoch 47/100, Iteration 24/38, Loss: 0.7255234718322754\n",
      "Epoch 47/100, Iteration 25/38, Loss: 0.8411986231803894\n",
      "Epoch 47/100, Iteration 26/38, Loss: 0.892471194267273\n",
      "Epoch 47/100, Iteration 27/38, Loss: 0.8289191722869873\n",
      "Epoch 47/100, Iteration 28/38, Loss: 0.9528772830963135\n",
      "Epoch 47/100, Iteration 29/38, Loss: 0.9664398431777954\n",
      "Epoch 47/100, Iteration 30/38, Loss: 0.8390437364578247\n",
      "Epoch 47/100, Iteration 31/38, Loss: 0.8020153641700745\n",
      "Epoch 47/100, Iteration 32/38, Loss: 0.8800740838050842\n",
      "Epoch 47/100, Iteration 33/38, Loss: 0.6468020081520081\n",
      "Epoch 47/100, Iteration 34/38, Loss: 0.9879350662231445\n",
      "Epoch 47/100, Iteration 35/38, Loss: 0.9620780944824219\n",
      "Epoch 47/100, Iteration 36/38, Loss: 0.9446216225624084\n",
      "Epoch 47/100, Iteration 37/38, Loss: 0.8995359539985657\n",
      "Epoch 47/100, Iteration 38/38, Loss: 0.7753442525863647\n",
      "Epoch 48/100, Iteration 1/38, Loss: 0.7501407861709595\n",
      "Epoch 48/100, Iteration 2/38, Loss: 0.7950277924537659\n",
      "Epoch 48/100, Iteration 3/38, Loss: 0.9078356027603149\n",
      "Epoch 48/100, Iteration 4/38, Loss: 0.9928184747695923\n",
      "Epoch 48/100, Iteration 5/38, Loss: 0.9689398407936096\n",
      "Epoch 48/100, Iteration 6/38, Loss: 0.8752817511558533\n",
      "Epoch 48/100, Iteration 7/38, Loss: 0.7705707550048828\n",
      "Epoch 48/100, Iteration 8/38, Loss: 0.9530088901519775\n",
      "Epoch 48/100, Iteration 9/38, Loss: 0.7747879028320312\n",
      "Epoch 48/100, Iteration 10/38, Loss: 0.7899006605148315\n",
      "Epoch 48/100, Iteration 11/38, Loss: 0.9152765274047852\n",
      "Epoch 48/100, Iteration 12/38, Loss: 0.8467809557914734\n",
      "Epoch 48/100, Iteration 13/38, Loss: 0.7837182879447937\n",
      "Epoch 48/100, Iteration 14/38, Loss: 0.8364940881729126\n",
      "Epoch 48/100, Iteration 15/38, Loss: 0.7799983024597168\n",
      "Epoch 48/100, Iteration 16/38, Loss: 0.9096773266792297\n",
      "Epoch 48/100, Iteration 17/38, Loss: 0.8983199596405029\n",
      "Epoch 48/100, Iteration 18/38, Loss: 0.8681155443191528\n",
      "Epoch 48/100, Iteration 19/38, Loss: 0.8260498046875\n",
      "Epoch 48/100, Iteration 20/38, Loss: 0.8049478530883789\n",
      "Epoch 48/100, Iteration 21/38, Loss: 0.868708074092865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100, Iteration 22/38, Loss: 0.8217691779136658\n",
      "Epoch 48/100, Iteration 23/38, Loss: 0.8508680462837219\n",
      "Epoch 48/100, Iteration 24/38, Loss: 0.8881112933158875\n",
      "Epoch 48/100, Iteration 25/38, Loss: 0.9306352138519287\n",
      "Epoch 48/100, Iteration 26/38, Loss: 0.7273693084716797\n",
      "Epoch 48/100, Iteration 27/38, Loss: 0.7771380543708801\n",
      "Epoch 48/100, Iteration 28/38, Loss: 0.8894051313400269\n",
      "Epoch 48/100, Iteration 29/38, Loss: 0.8492679595947266\n",
      "Epoch 48/100, Iteration 30/38, Loss: 0.7656720876693726\n",
      "Epoch 48/100, Iteration 31/38, Loss: 0.819784939289093\n",
      "Epoch 48/100, Iteration 32/38, Loss: 0.8209732174873352\n",
      "Epoch 48/100, Iteration 33/38, Loss: 0.7874785661697388\n",
      "Epoch 48/100, Iteration 34/38, Loss: 0.8902745842933655\n",
      "Epoch 48/100, Iteration 35/38, Loss: 0.8595635294914246\n",
      "Epoch 48/100, Iteration 36/38, Loss: 0.8161245584487915\n",
      "Epoch 48/100, Iteration 37/38, Loss: 0.952817976474762\n",
      "Epoch 48/100, Iteration 38/38, Loss: 0.8824360966682434\n",
      "Epoch 49/100, Iteration 1/38, Loss: 0.9703820943832397\n",
      "Epoch 49/100, Iteration 2/38, Loss: 0.8513919115066528\n",
      "Epoch 49/100, Iteration 3/38, Loss: 0.7880550622940063\n",
      "Epoch 49/100, Iteration 4/38, Loss: 0.904140055179596\n",
      "Epoch 49/100, Iteration 5/38, Loss: 0.9175089001655579\n",
      "Epoch 49/100, Iteration 6/38, Loss: 0.8925455808639526\n",
      "Epoch 49/100, Iteration 7/38, Loss: 0.8315126895904541\n",
      "Epoch 49/100, Iteration 8/38, Loss: 0.852645993232727\n",
      "Epoch 49/100, Iteration 9/38, Loss: 1.002659797668457\n",
      "Epoch 49/100, Iteration 10/38, Loss: 0.8621708154678345\n",
      "Epoch 49/100, Iteration 11/38, Loss: 0.7637892961502075\n",
      "Epoch 49/100, Iteration 12/38, Loss: 0.7157604098320007\n",
      "Epoch 49/100, Iteration 13/38, Loss: 0.8571438789367676\n",
      "Epoch 49/100, Iteration 14/38, Loss: 0.9691537618637085\n",
      "Epoch 49/100, Iteration 15/38, Loss: 0.8632214069366455\n",
      "Epoch 49/100, Iteration 16/38, Loss: 0.8261262774467468\n",
      "Epoch 49/100, Iteration 17/38, Loss: 0.8078757524490356\n",
      "Epoch 49/100, Iteration 18/38, Loss: 0.7420458197593689\n",
      "Epoch 49/100, Iteration 19/38, Loss: 0.8323502540588379\n",
      "Epoch 49/100, Iteration 20/38, Loss: 0.8135387897491455\n",
      "Epoch 49/100, Iteration 21/38, Loss: 0.7911524176597595\n",
      "Epoch 49/100, Iteration 22/38, Loss: 0.8714615106582642\n",
      "Epoch 49/100, Iteration 23/38, Loss: 0.9011151790618896\n",
      "Epoch 49/100, Iteration 24/38, Loss: 0.7490971088409424\n",
      "Epoch 49/100, Iteration 25/38, Loss: 0.8085435628890991\n",
      "Epoch 49/100, Iteration 26/38, Loss: 0.7685381770133972\n",
      "Epoch 49/100, Iteration 27/38, Loss: 0.7860535383224487\n",
      "Epoch 49/100, Iteration 28/38, Loss: 0.8523848652839661\n",
      "Epoch 49/100, Iteration 29/38, Loss: 0.8354024291038513\n",
      "Epoch 49/100, Iteration 30/38, Loss: 0.7942181825637817\n",
      "Epoch 49/100, Iteration 31/38, Loss: 0.719825029373169\n",
      "Epoch 49/100, Iteration 32/38, Loss: 0.7864552736282349\n",
      "Epoch 49/100, Iteration 33/38, Loss: 0.9459964632987976\n",
      "Epoch 49/100, Iteration 34/38, Loss: 0.885614812374115\n",
      "Epoch 49/100, Iteration 35/38, Loss: 0.9063003659248352\n",
      "Epoch 49/100, Iteration 36/38, Loss: 0.8040856719017029\n",
      "Epoch 49/100, Iteration 37/38, Loss: 0.8493885397911072\n",
      "Epoch 49/100, Iteration 38/38, Loss: 0.8293671011924744\n",
      "Epoch 50/100, Iteration 1/38, Loss: 0.662079393863678\n",
      "Epoch 50/100, Iteration 2/38, Loss: 0.8562420606613159\n",
      "Epoch 50/100, Iteration 3/38, Loss: 0.9165090322494507\n",
      "Epoch 50/100, Iteration 4/38, Loss: 0.7896443009376526\n",
      "Epoch 50/100, Iteration 5/38, Loss: 0.7176500558853149\n",
      "Epoch 50/100, Iteration 6/38, Loss: 0.7944864630699158\n",
      "Epoch 50/100, Iteration 7/38, Loss: 0.8367905020713806\n",
      "Epoch 50/100, Iteration 8/38, Loss: 1.0151020288467407\n",
      "Epoch 50/100, Iteration 9/38, Loss: 0.8173602819442749\n",
      "Epoch 50/100, Iteration 10/38, Loss: 0.8852070569992065\n",
      "Epoch 50/100, Iteration 11/38, Loss: 0.802603542804718\n",
      "Epoch 50/100, Iteration 12/38, Loss: 0.6664476990699768\n",
      "Epoch 50/100, Iteration 13/38, Loss: 0.8692806363105774\n",
      "Epoch 50/100, Iteration 14/38, Loss: 0.8054224252700806\n",
      "Epoch 50/100, Iteration 15/38, Loss: 0.8531488180160522\n",
      "Epoch 50/100, Iteration 16/38, Loss: 0.8153345584869385\n",
      "Epoch 50/100, Iteration 17/38, Loss: 0.9589793682098389\n",
      "Epoch 50/100, Iteration 18/38, Loss: 0.802254855632782\n",
      "Epoch 50/100, Iteration 19/38, Loss: 0.8813589811325073\n",
      "Epoch 50/100, Iteration 20/38, Loss: 0.8388259410858154\n",
      "Epoch 50/100, Iteration 21/38, Loss: 0.8098942041397095\n",
      "Epoch 50/100, Iteration 22/38, Loss: 0.8292056322097778\n",
      "Epoch 50/100, Iteration 23/38, Loss: 0.900920033454895\n",
      "Epoch 50/100, Iteration 24/38, Loss: 0.7708579301834106\n",
      "Epoch 50/100, Iteration 25/38, Loss: 0.7310041189193726\n",
      "Epoch 50/100, Iteration 26/38, Loss: 0.8469793796539307\n",
      "Epoch 50/100, Iteration 27/38, Loss: 0.7743527889251709\n",
      "Epoch 50/100, Iteration 28/38, Loss: 0.7279596924781799\n",
      "Epoch 50/100, Iteration 29/38, Loss: 0.847826361656189\n",
      "Epoch 50/100, Iteration 30/38, Loss: 0.8214638233184814\n",
      "Epoch 50/100, Iteration 31/38, Loss: 0.8390438556671143\n",
      "Epoch 50/100, Iteration 32/38, Loss: 0.8349915742874146\n",
      "Epoch 50/100, Iteration 33/38, Loss: 0.6616105437278748\n",
      "Epoch 50/100, Iteration 34/38, Loss: 0.8382136225700378\n",
      "Epoch 50/100, Iteration 35/38, Loss: 0.8826276063919067\n",
      "Epoch 50/100, Iteration 36/38, Loss: 0.8477131128311157\n",
      "Epoch 50/100, Iteration 37/38, Loss: 0.7787025570869446\n",
      "Epoch 50/100, Iteration 38/38, Loss: 1.010542392730713\n",
      "Epoch 51/100, Iteration 1/38, Loss: 0.8335891366004944\n",
      "Epoch 51/100, Iteration 2/38, Loss: 0.8347302079200745\n",
      "Epoch 51/100, Iteration 3/38, Loss: 0.744333803653717\n",
      "Epoch 51/100, Iteration 4/38, Loss: 0.8091418743133545\n",
      "Epoch 51/100, Iteration 5/38, Loss: 0.895194947719574\n",
      "Epoch 51/100, Iteration 6/38, Loss: 0.8591524362564087\n",
      "Epoch 51/100, Iteration 7/38, Loss: 0.9669973254203796\n",
      "Epoch 51/100, Iteration 8/38, Loss: 0.6727112531661987\n",
      "Epoch 51/100, Iteration 9/38, Loss: 0.763164758682251\n",
      "Epoch 51/100, Iteration 10/38, Loss: 0.9183721542358398\n",
      "Epoch 51/100, Iteration 11/38, Loss: 0.9272368550300598\n",
      "Epoch 51/100, Iteration 12/38, Loss: 0.8318908214569092\n",
      "Epoch 51/100, Iteration 13/38, Loss: 0.7531099319458008\n",
      "Epoch 51/100, Iteration 14/38, Loss: 0.7658981084823608\n",
      "Epoch 51/100, Iteration 15/38, Loss: 0.7522100210189819\n",
      "Epoch 51/100, Iteration 16/38, Loss: 0.8040374517440796\n",
      "Epoch 51/100, Iteration 17/38, Loss: 0.7976537942886353\n",
      "Epoch 51/100, Iteration 18/38, Loss: 0.9177396893501282\n",
      "Epoch 51/100, Iteration 19/38, Loss: 0.7724440097808838\n",
      "Epoch 51/100, Iteration 20/38, Loss: 0.8624284267425537\n",
      "Epoch 51/100, Iteration 21/38, Loss: 0.820415735244751\n",
      "Epoch 51/100, Iteration 22/38, Loss: 0.7863650321960449\n",
      "Epoch 51/100, Iteration 23/38, Loss: 0.7955130338668823\n",
      "Epoch 51/100, Iteration 24/38, Loss: 0.9033511877059937\n",
      "Epoch 51/100, Iteration 25/38, Loss: 0.7579889297485352\n",
      "Epoch 51/100, Iteration 26/38, Loss: 0.7968834042549133\n",
      "Epoch 51/100, Iteration 27/38, Loss: 0.8418700695037842\n",
      "Epoch 51/100, Iteration 28/38, Loss: 0.8363820910453796\n",
      "Epoch 51/100, Iteration 29/38, Loss: 0.7857184410095215\n",
      "Epoch 51/100, Iteration 30/38, Loss: 0.942044198513031\n",
      "Epoch 51/100, Iteration 31/38, Loss: 0.7948705554008484\n",
      "Epoch 51/100, Iteration 32/38, Loss: 0.8660733699798584\n",
      "Epoch 51/100, Iteration 33/38, Loss: 0.8203161954879761\n",
      "Epoch 51/100, Iteration 34/38, Loss: 0.6899429559707642\n",
      "Epoch 51/100, Iteration 35/38, Loss: 0.7679735422134399\n",
      "Epoch 51/100, Iteration 36/38, Loss: 0.803036630153656\n",
      "Epoch 51/100, Iteration 37/38, Loss: 0.8607966303825378\n",
      "Epoch 51/100, Iteration 38/38, Loss: 0.8896997570991516\n",
      "Epoch 52/100, Iteration 1/38, Loss: 0.7246963977813721\n",
      "Epoch 52/100, Iteration 2/38, Loss: 0.7379320859909058\n",
      "Epoch 52/100, Iteration 3/38, Loss: 0.8998546600341797\n",
      "Epoch 52/100, Iteration 4/38, Loss: 0.8120324611663818\n",
      "Epoch 52/100, Iteration 5/38, Loss: 0.7989433407783508\n",
      "Epoch 52/100, Iteration 6/38, Loss: 0.8094549775123596\n",
      "Epoch 52/100, Iteration 7/38, Loss: 0.8936359882354736\n",
      "Epoch 52/100, Iteration 8/38, Loss: 0.7582700252532959\n",
      "Epoch 52/100, Iteration 9/38, Loss: 0.8686532378196716\n",
      "Epoch 52/100, Iteration 10/38, Loss: 0.8258625864982605\n",
      "Epoch 52/100, Iteration 11/38, Loss: 0.9021939635276794\n",
      "Epoch 52/100, Iteration 12/38, Loss: 0.8179661631584167\n",
      "Epoch 52/100, Iteration 13/38, Loss: 0.8655555248260498\n",
      "Epoch 52/100, Iteration 14/38, Loss: 0.8037248253822327\n",
      "Epoch 52/100, Iteration 15/38, Loss: 0.9899033308029175\n",
      "Epoch 52/100, Iteration 16/38, Loss: 0.7556971311569214\n",
      "Epoch 52/100, Iteration 17/38, Loss: 0.7270418405532837\n",
      "Epoch 52/100, Iteration 18/38, Loss: 0.7508702278137207\n",
      "Epoch 52/100, Iteration 19/38, Loss: 0.8791574239730835\n",
      "Epoch 52/100, Iteration 20/38, Loss: 0.765727162361145\n",
      "Epoch 52/100, Iteration 21/38, Loss: 0.8348996639251709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100, Iteration 22/38, Loss: 0.7991806864738464\n",
      "Epoch 52/100, Iteration 23/38, Loss: 0.7337936162948608\n",
      "Epoch 52/100, Iteration 24/38, Loss: 0.9162099957466125\n",
      "Epoch 52/100, Iteration 25/38, Loss: 0.7897281050682068\n",
      "Epoch 52/100, Iteration 26/38, Loss: 0.8196683526039124\n",
      "Epoch 52/100, Iteration 27/38, Loss: 0.7741267085075378\n",
      "Epoch 52/100, Iteration 28/38, Loss: 0.6905685067176819\n",
      "Epoch 52/100, Iteration 29/38, Loss: 0.7499306201934814\n",
      "Epoch 52/100, Iteration 30/38, Loss: 0.781880795955658\n",
      "Epoch 52/100, Iteration 31/38, Loss: 0.7375226616859436\n",
      "Epoch 52/100, Iteration 32/38, Loss: 0.8771677613258362\n",
      "Epoch 52/100, Iteration 33/38, Loss: 0.8498626947402954\n",
      "Epoch 52/100, Iteration 34/38, Loss: 0.8397127985954285\n",
      "Epoch 52/100, Iteration 35/38, Loss: 0.7700504660606384\n",
      "Epoch 52/100, Iteration 36/38, Loss: 0.897921621799469\n",
      "Epoch 52/100, Iteration 37/38, Loss: 0.7988505363464355\n",
      "Epoch 52/100, Iteration 38/38, Loss: 0.6346842646598816\n",
      "Epoch 53/100, Iteration 1/38, Loss: 0.7975167036056519\n",
      "Epoch 53/100, Iteration 2/38, Loss: 0.6796430945396423\n",
      "Epoch 53/100, Iteration 3/38, Loss: 0.8577485084533691\n",
      "Epoch 53/100, Iteration 4/38, Loss: 0.8767918348312378\n",
      "Epoch 53/100, Iteration 5/38, Loss: 0.7404392957687378\n",
      "Epoch 53/100, Iteration 6/38, Loss: 0.7313365340232849\n",
      "Epoch 53/100, Iteration 7/38, Loss: 0.7708261609077454\n",
      "Epoch 53/100, Iteration 8/38, Loss: 0.7587196230888367\n",
      "Epoch 53/100, Iteration 9/38, Loss: 0.872124969959259\n",
      "Epoch 53/100, Iteration 10/38, Loss: 0.9776735901832581\n",
      "Epoch 53/100, Iteration 11/38, Loss: 0.8112215399742126\n",
      "Epoch 53/100, Iteration 12/38, Loss: 0.740130603313446\n",
      "Epoch 53/100, Iteration 13/38, Loss: 0.8390116095542908\n",
      "Epoch 53/100, Iteration 14/38, Loss: 0.8674015402793884\n",
      "Epoch 53/100, Iteration 15/38, Loss: 0.8232959508895874\n",
      "Epoch 53/100, Iteration 16/38, Loss: 0.8363785147666931\n",
      "Epoch 53/100, Iteration 17/38, Loss: 0.6541814804077148\n",
      "Epoch 53/100, Iteration 18/38, Loss: 0.7737910747528076\n",
      "Epoch 53/100, Iteration 19/38, Loss: 0.8614229559898376\n",
      "Epoch 53/100, Iteration 20/38, Loss: 0.9940598607063293\n",
      "Epoch 53/100, Iteration 21/38, Loss: 0.9661994576454163\n",
      "Epoch 53/100, Iteration 22/38, Loss: 0.7686691284179688\n",
      "Epoch 53/100, Iteration 23/38, Loss: 0.7695303559303284\n",
      "Epoch 53/100, Iteration 24/38, Loss: 0.7432734966278076\n",
      "Epoch 53/100, Iteration 25/38, Loss: 0.8702100515365601\n",
      "Epoch 53/100, Iteration 26/38, Loss: 0.7885850071907043\n",
      "Epoch 53/100, Iteration 27/38, Loss: 0.8808477520942688\n",
      "Epoch 53/100, Iteration 28/38, Loss: 0.7784450054168701\n",
      "Epoch 53/100, Iteration 29/38, Loss: 0.8446072936058044\n",
      "Epoch 53/100, Iteration 30/38, Loss: 0.8311305046081543\n",
      "Epoch 53/100, Iteration 31/38, Loss: 0.8540656566619873\n",
      "Epoch 53/100, Iteration 32/38, Loss: 0.8123953938484192\n",
      "Epoch 53/100, Iteration 33/38, Loss: 0.7909483909606934\n",
      "Epoch 53/100, Iteration 34/38, Loss: 0.8035325407981873\n",
      "Epoch 53/100, Iteration 35/38, Loss: 0.710066556930542\n",
      "Epoch 53/100, Iteration 36/38, Loss: 0.7319523096084595\n",
      "Epoch 53/100, Iteration 37/38, Loss: 0.8092217445373535\n",
      "Epoch 53/100, Iteration 38/38, Loss: 0.582476019859314\n",
      "Epoch 54/100, Iteration 1/38, Loss: 0.7758397459983826\n",
      "Epoch 54/100, Iteration 2/38, Loss: 0.8174130320549011\n",
      "Epoch 54/100, Iteration 3/38, Loss: 0.7857581377029419\n",
      "Epoch 54/100, Iteration 4/38, Loss: 0.7655858993530273\n",
      "Epoch 54/100, Iteration 5/38, Loss: 0.7465623021125793\n",
      "Epoch 54/100, Iteration 6/38, Loss: 0.7598755955696106\n",
      "Epoch 54/100, Iteration 7/38, Loss: 0.8568092584609985\n",
      "Epoch 54/100, Iteration 8/38, Loss: 0.7670156955718994\n",
      "Epoch 54/100, Iteration 9/38, Loss: 0.7772336602210999\n",
      "Epoch 54/100, Iteration 10/38, Loss: 0.7127312421798706\n",
      "Epoch 54/100, Iteration 11/38, Loss: 0.7838295102119446\n",
      "Epoch 54/100, Iteration 12/38, Loss: 0.6797705888748169\n",
      "Epoch 54/100, Iteration 13/38, Loss: 0.7172687649726868\n",
      "Epoch 54/100, Iteration 14/38, Loss: 0.7988693714141846\n",
      "Epoch 54/100, Iteration 15/38, Loss: 0.8684206604957581\n",
      "Epoch 54/100, Iteration 16/38, Loss: 0.7713097333908081\n",
      "Epoch 54/100, Iteration 17/38, Loss: 0.8249684572219849\n",
      "Epoch 54/100, Iteration 18/38, Loss: 0.819155216217041\n",
      "Epoch 54/100, Iteration 19/38, Loss: 0.7675124406814575\n",
      "Epoch 54/100, Iteration 20/38, Loss: 0.7930131554603577\n",
      "Epoch 54/100, Iteration 21/38, Loss: 0.8389049768447876\n",
      "Epoch 54/100, Iteration 22/38, Loss: 0.8063846826553345\n",
      "Epoch 54/100, Iteration 23/38, Loss: 0.7963639497756958\n",
      "Epoch 54/100, Iteration 24/38, Loss: 0.7703877091407776\n",
      "Epoch 54/100, Iteration 25/38, Loss: 0.7812831997871399\n",
      "Epoch 54/100, Iteration 26/38, Loss: 0.8085820078849792\n",
      "Epoch 54/100, Iteration 27/38, Loss: 0.6988052129745483\n",
      "Epoch 54/100, Iteration 28/38, Loss: 0.8312774300575256\n",
      "Epoch 54/100, Iteration 29/38, Loss: 0.6880389451980591\n",
      "Epoch 54/100, Iteration 30/38, Loss: 0.8553414344787598\n",
      "Epoch 54/100, Iteration 31/38, Loss: 0.6894067525863647\n",
      "Epoch 54/100, Iteration 32/38, Loss: 0.7069219350814819\n",
      "Epoch 54/100, Iteration 33/38, Loss: 0.8348214626312256\n",
      "Epoch 54/100, Iteration 34/38, Loss: 0.7691826224327087\n",
      "Epoch 54/100, Iteration 35/38, Loss: 0.8376527428627014\n",
      "Epoch 54/100, Iteration 36/38, Loss: 0.8977463245391846\n",
      "Epoch 54/100, Iteration 37/38, Loss: 0.7882761359214783\n",
      "Epoch 54/100, Iteration 38/38, Loss: 0.7685738801956177\n",
      "Epoch 55/100, Iteration 1/38, Loss: 0.8846830129623413\n",
      "Epoch 55/100, Iteration 2/38, Loss: 0.8368720412254333\n",
      "Epoch 55/100, Iteration 3/38, Loss: 0.8979256749153137\n",
      "Epoch 55/100, Iteration 4/38, Loss: 0.7158886194229126\n",
      "Epoch 55/100, Iteration 5/38, Loss: 0.8419625759124756\n",
      "Epoch 55/100, Iteration 6/38, Loss: 0.7700674533843994\n",
      "Epoch 55/100, Iteration 7/38, Loss: 0.8519208431243896\n",
      "Epoch 55/100, Iteration 8/38, Loss: 0.8079347610473633\n",
      "Epoch 55/100, Iteration 9/38, Loss: 0.9085496068000793\n",
      "Epoch 55/100, Iteration 10/38, Loss: 0.6987572312355042\n",
      "Epoch 55/100, Iteration 11/38, Loss: 0.6492113471031189\n",
      "Epoch 55/100, Iteration 12/38, Loss: 0.8073069453239441\n",
      "Epoch 55/100, Iteration 13/38, Loss: 0.7587892413139343\n",
      "Epoch 55/100, Iteration 14/38, Loss: 0.7084160447120667\n",
      "Epoch 55/100, Iteration 15/38, Loss: 0.7308349609375\n",
      "Epoch 55/100, Iteration 16/38, Loss: 0.7680128812789917\n",
      "Epoch 55/100, Iteration 17/38, Loss: 0.8015796542167664\n",
      "Epoch 55/100, Iteration 18/38, Loss: 0.7760791778564453\n",
      "Epoch 55/100, Iteration 19/38, Loss: 0.8659572601318359\n",
      "Epoch 55/100, Iteration 20/38, Loss: 0.7682763338088989\n",
      "Epoch 55/100, Iteration 21/38, Loss: 0.6814030408859253\n",
      "Epoch 55/100, Iteration 22/38, Loss: 0.8186228275299072\n",
      "Epoch 55/100, Iteration 23/38, Loss: 0.7910274267196655\n",
      "Epoch 55/100, Iteration 24/38, Loss: 0.7085079550743103\n",
      "Epoch 55/100, Iteration 25/38, Loss: 0.7893685102462769\n",
      "Epoch 55/100, Iteration 26/38, Loss: 0.6954522132873535\n",
      "Epoch 55/100, Iteration 27/38, Loss: 0.8033539652824402\n",
      "Epoch 55/100, Iteration 28/38, Loss: 0.9051384925842285\n",
      "Epoch 55/100, Iteration 29/38, Loss: 0.8810646533966064\n",
      "Epoch 55/100, Iteration 30/38, Loss: 0.9202181100845337\n",
      "Epoch 55/100, Iteration 31/38, Loss: 0.8311506509780884\n",
      "Epoch 55/100, Iteration 32/38, Loss: 0.8072139024734497\n",
      "Epoch 55/100, Iteration 33/38, Loss: 0.6815989017486572\n",
      "Epoch 55/100, Iteration 34/38, Loss: 0.8621939420700073\n",
      "Epoch 55/100, Iteration 35/38, Loss: 0.7588933706283569\n",
      "Epoch 55/100, Iteration 36/38, Loss: 0.7865146398544312\n",
      "Epoch 55/100, Iteration 37/38, Loss: 0.8367420434951782\n",
      "Epoch 55/100, Iteration 38/38, Loss: 0.86546790599823\n",
      "Epoch 56/100, Iteration 1/38, Loss: 0.8285500407218933\n",
      "Epoch 56/100, Iteration 2/38, Loss: 0.6432334184646606\n",
      "Epoch 56/100, Iteration 3/38, Loss: 0.7381559014320374\n",
      "Epoch 56/100, Iteration 4/38, Loss: 0.7851493954658508\n",
      "Epoch 56/100, Iteration 5/38, Loss: 0.7564201354980469\n",
      "Epoch 56/100, Iteration 6/38, Loss: 0.6111496090888977\n",
      "Epoch 56/100, Iteration 7/38, Loss: 0.6757234334945679\n",
      "Epoch 56/100, Iteration 8/38, Loss: 0.7239313125610352\n",
      "Epoch 56/100, Iteration 9/38, Loss: 0.8160350918769836\n",
      "Epoch 56/100, Iteration 10/38, Loss: 0.8805956840515137\n",
      "Epoch 56/100, Iteration 11/38, Loss: 0.7698395252227783\n",
      "Epoch 56/100, Iteration 12/38, Loss: 0.7505520582199097\n",
      "Epoch 56/100, Iteration 13/38, Loss: 0.9090670943260193\n",
      "Epoch 56/100, Iteration 14/38, Loss: 0.7152355909347534\n",
      "Epoch 56/100, Iteration 15/38, Loss: 0.7732197642326355\n",
      "Epoch 56/100, Iteration 16/38, Loss: 0.892854630947113\n",
      "Epoch 56/100, Iteration 17/38, Loss: 0.859762966632843\n",
      "Epoch 56/100, Iteration 18/38, Loss: 0.7845006585121155\n",
      "Epoch 56/100, Iteration 19/38, Loss: 0.7572396993637085\n",
      "Epoch 56/100, Iteration 20/38, Loss: 0.8060806393623352\n",
      "Epoch 56/100, Iteration 21/38, Loss: 0.7319104671478271\n",
      "Epoch 56/100, Iteration 22/38, Loss: 0.7663718461990356\n",
      "Epoch 56/100, Iteration 23/38, Loss: 0.821967363357544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100, Iteration 24/38, Loss: 0.780285120010376\n",
      "Epoch 56/100, Iteration 25/38, Loss: 0.8552166223526001\n",
      "Epoch 56/100, Iteration 26/38, Loss: 0.7452706694602966\n",
      "Epoch 56/100, Iteration 27/38, Loss: 0.7778919339179993\n",
      "Epoch 56/100, Iteration 28/38, Loss: 0.8293855786323547\n",
      "Epoch 56/100, Iteration 29/38, Loss: 0.814228355884552\n",
      "Epoch 56/100, Iteration 30/38, Loss: 0.7589678764343262\n",
      "Epoch 56/100, Iteration 31/38, Loss: 0.8835257291793823\n",
      "Epoch 56/100, Iteration 32/38, Loss: 0.937584638595581\n",
      "Epoch 56/100, Iteration 33/38, Loss: 0.8043020367622375\n",
      "Epoch 56/100, Iteration 34/38, Loss: 0.7877626419067383\n",
      "Epoch 56/100, Iteration 35/38, Loss: 0.7975913882255554\n",
      "Epoch 56/100, Iteration 36/38, Loss: 0.7084516286849976\n",
      "Epoch 56/100, Iteration 37/38, Loss: 0.7223066091537476\n",
      "Epoch 56/100, Iteration 38/38, Loss: 0.7499370574951172\n",
      "Epoch 57/100, Iteration 1/38, Loss: 0.8340199589729309\n",
      "Epoch 57/100, Iteration 2/38, Loss: 0.867821991443634\n",
      "Epoch 57/100, Iteration 3/38, Loss: 0.8341296315193176\n",
      "Epoch 57/100, Iteration 4/38, Loss: 0.7825654745101929\n",
      "Epoch 57/100, Iteration 5/38, Loss: 0.9759299755096436\n",
      "Epoch 57/100, Iteration 6/38, Loss: 0.8200257420539856\n",
      "Epoch 57/100, Iteration 7/38, Loss: 0.724394679069519\n",
      "Epoch 57/100, Iteration 8/38, Loss: 0.743864119052887\n",
      "Epoch 57/100, Iteration 9/38, Loss: 0.8424765467643738\n",
      "Epoch 57/100, Iteration 10/38, Loss: 0.7122901082038879\n",
      "Epoch 57/100, Iteration 11/38, Loss: 0.7878759503364563\n",
      "Epoch 57/100, Iteration 12/38, Loss: 0.8548246622085571\n",
      "Epoch 57/100, Iteration 13/38, Loss: 0.7180427312850952\n",
      "Epoch 57/100, Iteration 14/38, Loss: 0.7041599750518799\n",
      "Epoch 57/100, Iteration 15/38, Loss: 0.840935468673706\n",
      "Epoch 57/100, Iteration 16/38, Loss: 0.7124572396278381\n",
      "Epoch 57/100, Iteration 17/38, Loss: 0.7521318793296814\n",
      "Epoch 57/100, Iteration 18/38, Loss: 0.7706761956214905\n",
      "Epoch 57/100, Iteration 19/38, Loss: 0.6833224296569824\n",
      "Epoch 57/100, Iteration 20/38, Loss: 0.8086085915565491\n",
      "Epoch 57/100, Iteration 21/38, Loss: 0.7575479745864868\n",
      "Epoch 57/100, Iteration 22/38, Loss: 0.7297515273094177\n",
      "Epoch 57/100, Iteration 23/38, Loss: 0.7916604280471802\n",
      "Epoch 57/100, Iteration 24/38, Loss: 0.6517044305801392\n",
      "Epoch 57/100, Iteration 25/38, Loss: 0.8330191969871521\n",
      "Epoch 57/100, Iteration 26/38, Loss: 0.8780288696289062\n",
      "Epoch 57/100, Iteration 27/38, Loss: 0.791561484336853\n",
      "Epoch 57/100, Iteration 28/38, Loss: 0.8488889932632446\n",
      "Epoch 57/100, Iteration 29/38, Loss: 0.7918099164962769\n",
      "Epoch 57/100, Iteration 30/38, Loss: 0.7581540942192078\n",
      "Epoch 57/100, Iteration 31/38, Loss: 0.8763542175292969\n",
      "Epoch 57/100, Iteration 32/38, Loss: 0.6560739874839783\n",
      "Epoch 57/100, Iteration 33/38, Loss: 0.8780797123908997\n",
      "Epoch 57/100, Iteration 34/38, Loss: 0.6708082556724548\n",
      "Epoch 57/100, Iteration 35/38, Loss: 0.7330816984176636\n",
      "Epoch 57/100, Iteration 36/38, Loss: 0.6245344877243042\n",
      "Epoch 57/100, Iteration 37/38, Loss: 0.737246036529541\n",
      "Epoch 57/100, Iteration 38/38, Loss: 0.6261022686958313\n",
      "Epoch 58/100, Iteration 1/38, Loss: 0.7079606056213379\n",
      "Epoch 58/100, Iteration 2/38, Loss: 0.7940611243247986\n",
      "Epoch 58/100, Iteration 3/38, Loss: 0.6384823322296143\n",
      "Epoch 58/100, Iteration 4/38, Loss: 0.7673932313919067\n",
      "Epoch 58/100, Iteration 5/38, Loss: 0.6870062351226807\n",
      "Epoch 58/100, Iteration 6/38, Loss: 0.749362587928772\n",
      "Epoch 58/100, Iteration 7/38, Loss: 0.6498149633407593\n",
      "Epoch 58/100, Iteration 8/38, Loss: 0.6219079494476318\n",
      "Epoch 58/100, Iteration 9/38, Loss: 0.6878587603569031\n",
      "Epoch 58/100, Iteration 10/38, Loss: 0.7602519392967224\n",
      "Epoch 58/100, Iteration 11/38, Loss: 0.7806921005249023\n",
      "Epoch 58/100, Iteration 12/38, Loss: 0.7443224787712097\n",
      "Epoch 58/100, Iteration 13/38, Loss: 0.7886136174201965\n",
      "Epoch 58/100, Iteration 14/38, Loss: 0.6360496282577515\n",
      "Epoch 58/100, Iteration 15/38, Loss: 0.7005518674850464\n",
      "Epoch 58/100, Iteration 16/38, Loss: 0.7121890783309937\n",
      "Epoch 58/100, Iteration 17/38, Loss: 0.8702311515808105\n",
      "Epoch 58/100, Iteration 18/38, Loss: 0.6770012378692627\n",
      "Epoch 58/100, Iteration 19/38, Loss: 0.7853109836578369\n",
      "Epoch 58/100, Iteration 20/38, Loss: 0.7768841981887817\n",
      "Epoch 58/100, Iteration 21/38, Loss: 0.7599427700042725\n",
      "Epoch 58/100, Iteration 22/38, Loss: 0.8822978734970093\n",
      "Epoch 58/100, Iteration 23/38, Loss: 0.7111067175865173\n",
      "Epoch 58/100, Iteration 24/38, Loss: 0.7036553025245667\n",
      "Epoch 58/100, Iteration 25/38, Loss: 0.715774655342102\n",
      "Epoch 58/100, Iteration 26/38, Loss: 0.8222300410270691\n",
      "Epoch 58/100, Iteration 27/38, Loss: 0.876382052898407\n",
      "Epoch 58/100, Iteration 28/38, Loss: 0.765735387802124\n",
      "Epoch 58/100, Iteration 29/38, Loss: 0.6924901604652405\n",
      "Epoch 58/100, Iteration 30/38, Loss: 0.8249412178993225\n",
      "Epoch 58/100, Iteration 31/38, Loss: 0.7872389554977417\n",
      "Epoch 58/100, Iteration 32/38, Loss: 0.7684282064437866\n",
      "Epoch 58/100, Iteration 33/38, Loss: 0.752392590045929\n",
      "Epoch 58/100, Iteration 34/38, Loss: 0.7131564617156982\n",
      "Epoch 58/100, Iteration 35/38, Loss: 0.7851458787918091\n",
      "Epoch 58/100, Iteration 36/38, Loss: 0.7849861979484558\n",
      "Epoch 58/100, Iteration 37/38, Loss: 0.7645790576934814\n",
      "Epoch 58/100, Iteration 38/38, Loss: 0.7482215166091919\n",
      "Epoch 59/100, Iteration 1/38, Loss: 0.7233582139015198\n",
      "Epoch 59/100, Iteration 2/38, Loss: 0.7093729972839355\n",
      "Epoch 59/100, Iteration 3/38, Loss: 0.7072107791900635\n",
      "Epoch 59/100, Iteration 4/38, Loss: 0.7074310183525085\n",
      "Epoch 59/100, Iteration 5/38, Loss: 0.7508722543716431\n",
      "Epoch 59/100, Iteration 6/38, Loss: 0.8068090081214905\n",
      "Epoch 59/100, Iteration 7/38, Loss: 0.820077121257782\n",
      "Epoch 59/100, Iteration 8/38, Loss: 0.8319084048271179\n",
      "Epoch 59/100, Iteration 9/38, Loss: 0.7159556150436401\n",
      "Epoch 59/100, Iteration 10/38, Loss: 0.6391897201538086\n",
      "Epoch 59/100, Iteration 11/38, Loss: 0.7876217365264893\n",
      "Epoch 59/100, Iteration 12/38, Loss: 0.7151421904563904\n",
      "Epoch 59/100, Iteration 13/38, Loss: 0.77436763048172\n",
      "Epoch 59/100, Iteration 14/38, Loss: 0.7186392545700073\n",
      "Epoch 59/100, Iteration 15/38, Loss: 0.7006665468215942\n",
      "Epoch 59/100, Iteration 16/38, Loss: 0.6979042887687683\n",
      "Epoch 59/100, Iteration 17/38, Loss: 0.8020020127296448\n",
      "Epoch 59/100, Iteration 18/38, Loss: 0.7232996225357056\n",
      "Epoch 59/100, Iteration 19/38, Loss: 0.6814148426055908\n",
      "Epoch 59/100, Iteration 20/38, Loss: 0.7892862558364868\n",
      "Epoch 59/100, Iteration 21/38, Loss: 0.675995945930481\n",
      "Epoch 59/100, Iteration 22/38, Loss: 0.7326604723930359\n",
      "Epoch 59/100, Iteration 23/38, Loss: 0.831928014755249\n",
      "Epoch 59/100, Iteration 24/38, Loss: 0.7309426069259644\n",
      "Epoch 59/100, Iteration 25/38, Loss: 0.8051396012306213\n",
      "Epoch 59/100, Iteration 26/38, Loss: 0.8089423179626465\n",
      "Epoch 59/100, Iteration 27/38, Loss: 0.7404014468193054\n",
      "Epoch 59/100, Iteration 28/38, Loss: 0.7588381767272949\n",
      "Epoch 59/100, Iteration 29/38, Loss: 0.7442312240600586\n",
      "Epoch 59/100, Iteration 30/38, Loss: 0.7766103148460388\n",
      "Epoch 59/100, Iteration 31/38, Loss: 0.7168934345245361\n",
      "Epoch 59/100, Iteration 32/38, Loss: 0.7670958638191223\n",
      "Epoch 59/100, Iteration 33/38, Loss: 0.6486481428146362\n",
      "Epoch 59/100, Iteration 34/38, Loss: 0.7775470614433289\n",
      "Epoch 59/100, Iteration 35/38, Loss: 0.7523690462112427\n",
      "Epoch 59/100, Iteration 36/38, Loss: 0.7883870005607605\n",
      "Epoch 59/100, Iteration 37/38, Loss: 0.7242461442947388\n",
      "Epoch 59/100, Iteration 38/38, Loss: 0.7220921516418457\n",
      "Epoch 60/100, Iteration 1/38, Loss: 0.7332503199577332\n",
      "Epoch 60/100, Iteration 2/38, Loss: 0.797992467880249\n",
      "Epoch 60/100, Iteration 3/38, Loss: 0.6645874381065369\n",
      "Epoch 60/100, Iteration 4/38, Loss: 0.6362133622169495\n",
      "Epoch 60/100, Iteration 5/38, Loss: 0.7443054914474487\n",
      "Epoch 60/100, Iteration 6/38, Loss: 0.7887974381446838\n",
      "Epoch 60/100, Iteration 7/38, Loss: 0.903518557548523\n",
      "Epoch 60/100, Iteration 8/38, Loss: 0.6857514977455139\n",
      "Epoch 60/100, Iteration 9/38, Loss: 0.8420557975769043\n",
      "Epoch 60/100, Iteration 10/38, Loss: 0.73263019323349\n",
      "Epoch 60/100, Iteration 11/38, Loss: 0.8450396060943604\n",
      "Epoch 60/100, Iteration 12/38, Loss: 0.8566356897354126\n",
      "Epoch 60/100, Iteration 13/38, Loss: 0.8105806112289429\n",
      "Epoch 60/100, Iteration 14/38, Loss: 0.5965423583984375\n",
      "Epoch 60/100, Iteration 15/38, Loss: 0.7472879886627197\n",
      "Epoch 60/100, Iteration 16/38, Loss: 0.7365087270736694\n",
      "Epoch 60/100, Iteration 17/38, Loss: 0.7264381647109985\n",
      "Epoch 60/100, Iteration 18/38, Loss: 0.7218449115753174\n",
      "Epoch 60/100, Iteration 19/38, Loss: 0.7243263721466064\n",
      "Epoch 60/100, Iteration 20/38, Loss: 0.694153904914856\n",
      "Epoch 60/100, Iteration 21/38, Loss: 0.8494230508804321\n",
      "Epoch 60/100, Iteration 22/38, Loss: 0.678866446018219\n",
      "Epoch 60/100, Iteration 23/38, Loss: 0.7569107413291931\n",
      "Epoch 60/100, Iteration 24/38, Loss: 0.7971096634864807\n",
      "Epoch 60/100, Iteration 25/38, Loss: 0.8482575416564941\n",
      "Epoch 60/100, Iteration 26/38, Loss: 0.7720388174057007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Iteration 27/38, Loss: 0.8277713656425476\n",
      "Epoch 60/100, Iteration 28/38, Loss: 0.7499425411224365\n",
      "Epoch 60/100, Iteration 29/38, Loss: 0.6547642350196838\n",
      "Epoch 60/100, Iteration 30/38, Loss: 0.7556192874908447\n",
      "Epoch 60/100, Iteration 31/38, Loss: 0.7164149880409241\n",
      "Epoch 60/100, Iteration 32/38, Loss: 0.7108349204063416\n",
      "Epoch 60/100, Iteration 33/38, Loss: 0.7872022986412048\n",
      "Epoch 60/100, Iteration 34/38, Loss: 0.7359662652015686\n",
      "Epoch 60/100, Iteration 35/38, Loss: 0.868578314781189\n",
      "Epoch 60/100, Iteration 36/38, Loss: 0.7881834506988525\n",
      "Epoch 60/100, Iteration 37/38, Loss: 0.7220909595489502\n",
      "Epoch 60/100, Iteration 38/38, Loss: 0.6555582284927368\n",
      "Epoch 61/100, Iteration 1/38, Loss: 0.7683213949203491\n",
      "Epoch 61/100, Iteration 2/38, Loss: 0.7618809938430786\n",
      "Epoch 61/100, Iteration 3/38, Loss: 0.6748865842819214\n",
      "Epoch 61/100, Iteration 4/38, Loss: 0.7055954933166504\n",
      "Epoch 61/100, Iteration 5/38, Loss: 0.706509530544281\n",
      "Epoch 61/100, Iteration 6/38, Loss: 0.6752442121505737\n",
      "Epoch 61/100, Iteration 7/38, Loss: 0.7451955676078796\n",
      "Epoch 61/100, Iteration 8/38, Loss: 0.7804203629493713\n",
      "Epoch 61/100, Iteration 9/38, Loss: 0.648672878742218\n",
      "Epoch 61/100, Iteration 10/38, Loss: 0.6946201324462891\n",
      "Epoch 61/100, Iteration 11/38, Loss: 0.754801332950592\n",
      "Epoch 61/100, Iteration 12/38, Loss: 0.6311966776847839\n",
      "Epoch 61/100, Iteration 13/38, Loss: 0.6789240837097168\n",
      "Epoch 61/100, Iteration 14/38, Loss: 0.7104840874671936\n",
      "Epoch 61/100, Iteration 15/38, Loss: 0.6048446893692017\n",
      "Epoch 61/100, Iteration 16/38, Loss: 0.6194904446601868\n",
      "Epoch 61/100, Iteration 17/38, Loss: 0.7348036170005798\n",
      "Epoch 61/100, Iteration 18/38, Loss: 0.7299000024795532\n",
      "Epoch 61/100, Iteration 19/38, Loss: 0.7450003027915955\n",
      "Epoch 61/100, Iteration 20/38, Loss: 0.6894208788871765\n",
      "Epoch 61/100, Iteration 21/38, Loss: 0.7390587329864502\n",
      "Epoch 61/100, Iteration 22/38, Loss: 0.7335216403007507\n",
      "Epoch 61/100, Iteration 23/38, Loss: 0.6975222229957581\n",
      "Epoch 61/100, Iteration 24/38, Loss: 0.7763698697090149\n",
      "Epoch 61/100, Iteration 25/38, Loss: 0.778820812702179\n",
      "Epoch 61/100, Iteration 26/38, Loss: 0.7420855760574341\n",
      "Epoch 61/100, Iteration 27/38, Loss: 0.7660441994667053\n",
      "Epoch 61/100, Iteration 28/38, Loss: 0.7423980832099915\n",
      "Epoch 61/100, Iteration 29/38, Loss: 0.6357936263084412\n",
      "Epoch 61/100, Iteration 30/38, Loss: 0.7154850363731384\n",
      "Epoch 61/100, Iteration 31/38, Loss: 0.8344507813453674\n",
      "Epoch 61/100, Iteration 32/38, Loss: 0.705267608165741\n",
      "Epoch 61/100, Iteration 33/38, Loss: 0.6944657564163208\n",
      "Epoch 61/100, Iteration 34/38, Loss: 0.7842100858688354\n",
      "Epoch 61/100, Iteration 35/38, Loss: 0.6301835179328918\n",
      "Epoch 61/100, Iteration 36/38, Loss: 0.7062694430351257\n",
      "Epoch 61/100, Iteration 37/38, Loss: 0.9087311625480652\n",
      "Epoch 61/100, Iteration 38/38, Loss: 0.9241694211959839\n",
      "Epoch 62/100, Iteration 1/38, Loss: 0.6845198273658752\n",
      "Epoch 62/100, Iteration 2/38, Loss: 0.8675632476806641\n",
      "Epoch 62/100, Iteration 3/38, Loss: 0.841517984867096\n",
      "Epoch 62/100, Iteration 4/38, Loss: 0.7192918062210083\n",
      "Epoch 62/100, Iteration 5/38, Loss: 0.7306026220321655\n",
      "Epoch 62/100, Iteration 6/38, Loss: 0.689236044883728\n",
      "Epoch 62/100, Iteration 7/38, Loss: 0.7026359438896179\n",
      "Epoch 62/100, Iteration 8/38, Loss: 0.6973010301589966\n",
      "Epoch 62/100, Iteration 9/38, Loss: 0.817324161529541\n",
      "Epoch 62/100, Iteration 10/38, Loss: 0.7538306713104248\n",
      "Epoch 62/100, Iteration 11/38, Loss: 0.6609928011894226\n",
      "Epoch 62/100, Iteration 12/38, Loss: 0.7432692050933838\n",
      "Epoch 62/100, Iteration 13/38, Loss: 0.6114356517791748\n",
      "Epoch 62/100, Iteration 14/38, Loss: 0.6292412877082825\n",
      "Epoch 62/100, Iteration 15/38, Loss: 0.832379162311554\n",
      "Epoch 62/100, Iteration 16/38, Loss: 0.7543651461601257\n",
      "Epoch 62/100, Iteration 17/38, Loss: 0.6905022859573364\n",
      "Epoch 62/100, Iteration 18/38, Loss: 0.819145679473877\n",
      "Epoch 62/100, Iteration 19/38, Loss: 0.7153613567352295\n",
      "Epoch 62/100, Iteration 20/38, Loss: 0.6860962510108948\n",
      "Epoch 62/100, Iteration 21/38, Loss: 0.8081938624382019\n",
      "Epoch 62/100, Iteration 22/38, Loss: 0.821014404296875\n",
      "Epoch 62/100, Iteration 23/38, Loss: 0.6222839951515198\n",
      "Epoch 62/100, Iteration 24/38, Loss: 0.6565684676170349\n",
      "Epoch 62/100, Iteration 25/38, Loss: 0.7838290333747864\n",
      "Epoch 62/100, Iteration 26/38, Loss: 0.7951073050498962\n",
      "Epoch 62/100, Iteration 27/38, Loss: 0.7671030163764954\n",
      "Epoch 62/100, Iteration 28/38, Loss: 0.8441516757011414\n",
      "Epoch 62/100, Iteration 29/38, Loss: 0.7599616050720215\n",
      "Epoch 62/100, Iteration 30/38, Loss: 0.7010416388511658\n",
      "Epoch 62/100, Iteration 31/38, Loss: 0.9687961339950562\n",
      "Epoch 62/100, Iteration 32/38, Loss: 0.7977309823036194\n",
      "Epoch 62/100, Iteration 33/38, Loss: 0.7701683044433594\n",
      "Epoch 62/100, Iteration 34/38, Loss: 0.7647827863693237\n",
      "Epoch 62/100, Iteration 35/38, Loss: 0.7861050963401794\n",
      "Epoch 62/100, Iteration 36/38, Loss: 0.6217895150184631\n",
      "Epoch 62/100, Iteration 37/38, Loss: 0.7000735402107239\n",
      "Epoch 62/100, Iteration 38/38, Loss: 0.7420579791069031\n",
      "Epoch 63/100, Iteration 1/38, Loss: 0.7489428520202637\n",
      "Epoch 63/100, Iteration 2/38, Loss: 0.7347624897956848\n",
      "Epoch 63/100, Iteration 3/38, Loss: 0.6124036908149719\n",
      "Epoch 63/100, Iteration 4/38, Loss: 0.7504911422729492\n",
      "Epoch 63/100, Iteration 5/38, Loss: 0.6263707876205444\n",
      "Epoch 63/100, Iteration 6/38, Loss: 0.7718477845191956\n",
      "Epoch 63/100, Iteration 7/38, Loss: 0.7044475078582764\n",
      "Epoch 63/100, Iteration 8/38, Loss: 0.7108213901519775\n",
      "Epoch 63/100, Iteration 9/38, Loss: 0.7575458884239197\n",
      "Epoch 63/100, Iteration 10/38, Loss: 0.6440770030021667\n",
      "Epoch 63/100, Iteration 11/38, Loss: 0.6309541463851929\n",
      "Epoch 63/100, Iteration 12/38, Loss: 0.7282376289367676\n",
      "Epoch 63/100, Iteration 13/38, Loss: 0.7287270426750183\n",
      "Epoch 63/100, Iteration 14/38, Loss: 0.6273473501205444\n",
      "Epoch 63/100, Iteration 15/38, Loss: 0.6359025835990906\n",
      "Epoch 63/100, Iteration 16/38, Loss: 0.6797980070114136\n",
      "Epoch 63/100, Iteration 17/38, Loss: 0.6460200548171997\n",
      "Epoch 63/100, Iteration 18/38, Loss: 0.6871617436408997\n",
      "Epoch 63/100, Iteration 19/38, Loss: 0.8129777312278748\n",
      "Epoch 63/100, Iteration 20/38, Loss: 0.7346484065055847\n",
      "Epoch 63/100, Iteration 21/38, Loss: 0.7264483571052551\n",
      "Epoch 63/100, Iteration 22/38, Loss: 0.7014315128326416\n",
      "Epoch 63/100, Iteration 23/38, Loss: 0.7324066758155823\n",
      "Epoch 63/100, Iteration 24/38, Loss: 0.7518617510795593\n",
      "Epoch 63/100, Iteration 25/38, Loss: 0.717756450176239\n",
      "Epoch 63/100, Iteration 26/38, Loss: 0.7958698868751526\n",
      "Epoch 63/100, Iteration 27/38, Loss: 0.7610981464385986\n",
      "Epoch 63/100, Iteration 28/38, Loss: 0.732469379901886\n",
      "Epoch 63/100, Iteration 29/38, Loss: 0.7400163412094116\n",
      "Epoch 63/100, Iteration 30/38, Loss: 0.7217223048210144\n",
      "Epoch 63/100, Iteration 31/38, Loss: 0.711516797542572\n",
      "Epoch 63/100, Iteration 32/38, Loss: 0.8010581731796265\n",
      "Epoch 63/100, Iteration 33/38, Loss: 0.7354352474212646\n",
      "Epoch 63/100, Iteration 34/38, Loss: 0.7066306471824646\n",
      "Epoch 63/100, Iteration 35/38, Loss: 0.6891099214553833\n",
      "Epoch 63/100, Iteration 36/38, Loss: 0.7978523373603821\n",
      "Epoch 63/100, Iteration 37/38, Loss: 0.6948206424713135\n",
      "Epoch 63/100, Iteration 38/38, Loss: 0.664664089679718\n",
      "Epoch 64/100, Iteration 1/38, Loss: 0.7422500848770142\n",
      "Epoch 64/100, Iteration 2/38, Loss: 0.6298194527626038\n",
      "Epoch 64/100, Iteration 3/38, Loss: 0.6625100374221802\n",
      "Epoch 64/100, Iteration 4/38, Loss: 0.6861618161201477\n",
      "Epoch 64/100, Iteration 5/38, Loss: 0.6841012239456177\n",
      "Epoch 64/100, Iteration 6/38, Loss: 0.7043827176094055\n",
      "Epoch 64/100, Iteration 7/38, Loss: 0.7638160586357117\n",
      "Epoch 64/100, Iteration 8/38, Loss: 0.6540524363517761\n",
      "Epoch 64/100, Iteration 9/38, Loss: 0.7717657089233398\n",
      "Epoch 64/100, Iteration 10/38, Loss: 0.7254185080528259\n",
      "Epoch 64/100, Iteration 11/38, Loss: 0.643982470035553\n",
      "Epoch 64/100, Iteration 12/38, Loss: 0.6980082392692566\n",
      "Epoch 64/100, Iteration 13/38, Loss: 0.7959915399551392\n",
      "Epoch 64/100, Iteration 14/38, Loss: 0.731265127658844\n",
      "Epoch 64/100, Iteration 15/38, Loss: 0.7498825788497925\n",
      "Epoch 64/100, Iteration 16/38, Loss: 0.6736044883728027\n",
      "Epoch 64/100, Iteration 17/38, Loss: 0.7106402516365051\n",
      "Epoch 64/100, Iteration 18/38, Loss: 0.7474793195724487\n",
      "Epoch 64/100, Iteration 19/38, Loss: 0.6831712126731873\n",
      "Epoch 64/100, Iteration 20/38, Loss: 0.6968138813972473\n",
      "Epoch 64/100, Iteration 21/38, Loss: 0.7011573910713196\n",
      "Epoch 64/100, Iteration 22/38, Loss: 0.7153381705284119\n",
      "Epoch 64/100, Iteration 23/38, Loss: 0.717968225479126\n",
      "Epoch 64/100, Iteration 24/38, Loss: 0.7105578184127808\n",
      "Epoch 64/100, Iteration 25/38, Loss: 0.7366639375686646\n",
      "Epoch 64/100, Iteration 26/38, Loss: 0.6379464864730835\n",
      "Epoch 64/100, Iteration 27/38, Loss: 0.7433522343635559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100, Iteration 28/38, Loss: 0.6212101578712463\n",
      "Epoch 64/100, Iteration 29/38, Loss: 0.6295968890190125\n",
      "Epoch 64/100, Iteration 30/38, Loss: 0.6874189376831055\n",
      "Epoch 64/100, Iteration 31/38, Loss: 0.6606851816177368\n",
      "Epoch 64/100, Iteration 32/38, Loss: 0.6885613799095154\n",
      "Epoch 64/100, Iteration 33/38, Loss: 0.6586999297142029\n",
      "Epoch 64/100, Iteration 34/38, Loss: 0.759547233581543\n",
      "Epoch 64/100, Iteration 35/38, Loss: 0.7504300475120544\n",
      "Epoch 64/100, Iteration 36/38, Loss: 0.702536404132843\n",
      "Epoch 64/100, Iteration 37/38, Loss: 0.8459904789924622\n",
      "Epoch 64/100, Iteration 38/38, Loss: 0.6297574043273926\n",
      "Epoch 65/100, Iteration 1/38, Loss: 0.747808575630188\n",
      "Epoch 65/100, Iteration 2/38, Loss: 0.7001772522926331\n",
      "Epoch 65/100, Iteration 3/38, Loss: 0.716505229473114\n",
      "Epoch 65/100, Iteration 4/38, Loss: 0.8010878562927246\n",
      "Epoch 65/100, Iteration 5/38, Loss: 0.5616822242736816\n",
      "Epoch 65/100, Iteration 6/38, Loss: 0.687942624092102\n",
      "Epoch 65/100, Iteration 7/38, Loss: 0.7002426981925964\n",
      "Epoch 65/100, Iteration 8/38, Loss: 0.632229745388031\n",
      "Epoch 65/100, Iteration 9/38, Loss: 0.7495679259300232\n",
      "Epoch 65/100, Iteration 10/38, Loss: 0.6964656710624695\n",
      "Epoch 65/100, Iteration 11/38, Loss: 0.75730299949646\n",
      "Epoch 65/100, Iteration 12/38, Loss: 0.7048001289367676\n",
      "Epoch 65/100, Iteration 13/38, Loss: 0.7471070289611816\n",
      "Epoch 65/100, Iteration 14/38, Loss: 0.6846638917922974\n",
      "Epoch 65/100, Iteration 15/38, Loss: 0.7573303580284119\n",
      "Epoch 65/100, Iteration 16/38, Loss: 0.8139007091522217\n",
      "Epoch 65/100, Iteration 17/38, Loss: 0.640252947807312\n",
      "Epoch 65/100, Iteration 18/38, Loss: 0.6879737973213196\n",
      "Epoch 65/100, Iteration 19/38, Loss: 0.6596695780754089\n",
      "Epoch 65/100, Iteration 20/38, Loss: 0.6808840036392212\n",
      "Epoch 65/100, Iteration 21/38, Loss: 0.6930429339408875\n",
      "Epoch 65/100, Iteration 22/38, Loss: 0.6330318450927734\n",
      "Epoch 65/100, Iteration 23/38, Loss: 0.6766926646232605\n",
      "Epoch 65/100, Iteration 24/38, Loss: 0.6838347911834717\n",
      "Epoch 65/100, Iteration 25/38, Loss: 0.7171999216079712\n",
      "Epoch 65/100, Iteration 26/38, Loss: 0.7752388715744019\n",
      "Epoch 65/100, Iteration 27/38, Loss: 0.6845204830169678\n",
      "Epoch 65/100, Iteration 28/38, Loss: 0.6460190415382385\n",
      "Epoch 65/100, Iteration 29/38, Loss: 0.742792010307312\n",
      "Epoch 65/100, Iteration 30/38, Loss: 0.7014521360397339\n",
      "Epoch 65/100, Iteration 31/38, Loss: 0.6469457149505615\n",
      "Epoch 65/100, Iteration 32/38, Loss: 0.6666846871376038\n",
      "Epoch 65/100, Iteration 33/38, Loss: 0.6912004947662354\n",
      "Epoch 65/100, Iteration 34/38, Loss: 0.639986515045166\n",
      "Epoch 65/100, Iteration 35/38, Loss: 0.6667848229408264\n",
      "Epoch 65/100, Iteration 36/38, Loss: 0.6441134810447693\n",
      "Epoch 65/100, Iteration 37/38, Loss: 0.6016153693199158\n",
      "Epoch 65/100, Iteration 38/38, Loss: 0.5593899488449097\n",
      "Epoch 66/100, Iteration 1/38, Loss: 0.5957409143447876\n",
      "Epoch 66/100, Iteration 2/38, Loss: 0.7450306415557861\n",
      "Epoch 66/100, Iteration 3/38, Loss: 0.6834613680839539\n",
      "Epoch 66/100, Iteration 4/38, Loss: 0.6218891739845276\n",
      "Epoch 66/100, Iteration 5/38, Loss: 0.7959071397781372\n",
      "Epoch 66/100, Iteration 6/38, Loss: 0.6474974155426025\n",
      "Epoch 66/100, Iteration 7/38, Loss: 0.6152428984642029\n",
      "Epoch 66/100, Iteration 8/38, Loss: 0.6805043816566467\n",
      "Epoch 66/100, Iteration 9/38, Loss: 0.7521588206291199\n",
      "Epoch 66/100, Iteration 10/38, Loss: 0.6853822469711304\n",
      "Epoch 66/100, Iteration 11/38, Loss: 0.6773509383201599\n",
      "Epoch 66/100, Iteration 12/38, Loss: 0.5872176289558411\n",
      "Epoch 66/100, Iteration 13/38, Loss: 0.7155370712280273\n",
      "Epoch 66/100, Iteration 14/38, Loss: 0.5857639312744141\n",
      "Epoch 66/100, Iteration 15/38, Loss: 0.6493435502052307\n",
      "Epoch 66/100, Iteration 16/38, Loss: 0.8674611449241638\n",
      "Epoch 66/100, Iteration 17/38, Loss: 0.7396475672721863\n",
      "Epoch 66/100, Iteration 18/38, Loss: 0.7137370109558105\n",
      "Epoch 66/100, Iteration 19/38, Loss: 0.6541624069213867\n",
      "Epoch 66/100, Iteration 20/38, Loss: 0.713962197303772\n",
      "Epoch 66/100, Iteration 21/38, Loss: 0.6923857927322388\n",
      "Epoch 66/100, Iteration 22/38, Loss: 0.7150401473045349\n",
      "Epoch 66/100, Iteration 23/38, Loss: 0.7483977675437927\n",
      "Epoch 66/100, Iteration 24/38, Loss: 0.6583373546600342\n",
      "Epoch 66/100, Iteration 25/38, Loss: 0.7466136813163757\n",
      "Epoch 66/100, Iteration 26/38, Loss: 0.6691003441810608\n",
      "Epoch 66/100, Iteration 27/38, Loss: 0.6054431200027466\n",
      "Epoch 66/100, Iteration 28/38, Loss: 0.6799938678741455\n",
      "Epoch 66/100, Iteration 29/38, Loss: 0.6821832060813904\n",
      "Epoch 66/100, Iteration 30/38, Loss: 0.7452573776245117\n",
      "Epoch 66/100, Iteration 31/38, Loss: 0.6619376540184021\n",
      "Epoch 66/100, Iteration 32/38, Loss: 0.7087830901145935\n",
      "Epoch 66/100, Iteration 33/38, Loss: 0.7244622111320496\n",
      "Epoch 66/100, Iteration 34/38, Loss: 0.6961537003517151\n",
      "Epoch 66/100, Iteration 35/38, Loss: 0.8089076280593872\n",
      "Epoch 66/100, Iteration 36/38, Loss: 0.7462353706359863\n",
      "Epoch 66/100, Iteration 37/38, Loss: 0.7838364839553833\n",
      "Epoch 66/100, Iteration 38/38, Loss: 0.6915424466133118\n",
      "Epoch 67/100, Iteration 1/38, Loss: 0.8339651226997375\n",
      "Epoch 67/100, Iteration 2/38, Loss: 0.8006046414375305\n",
      "Epoch 67/100, Iteration 3/38, Loss: 0.6770334243774414\n",
      "Epoch 67/100, Iteration 4/38, Loss: 0.6461008787155151\n",
      "Epoch 67/100, Iteration 5/38, Loss: 0.5892360806465149\n",
      "Epoch 67/100, Iteration 6/38, Loss: 0.6608723402023315\n",
      "Epoch 67/100, Iteration 7/38, Loss: 0.683281660079956\n",
      "Epoch 67/100, Iteration 8/38, Loss: 0.6625776290893555\n",
      "Epoch 67/100, Iteration 9/38, Loss: 0.691794216632843\n",
      "Epoch 67/100, Iteration 10/38, Loss: 0.6551380753517151\n",
      "Epoch 67/100, Iteration 11/38, Loss: 0.6479299664497375\n",
      "Epoch 67/100, Iteration 12/38, Loss: 0.6982951760292053\n",
      "Epoch 67/100, Iteration 13/38, Loss: 0.7123739123344421\n",
      "Epoch 67/100, Iteration 14/38, Loss: 0.6549677848815918\n",
      "Epoch 67/100, Iteration 15/38, Loss: 0.5943427085876465\n",
      "Epoch 67/100, Iteration 16/38, Loss: 0.7391402721405029\n",
      "Epoch 67/100, Iteration 17/38, Loss: 0.6386304497718811\n",
      "Epoch 67/100, Iteration 18/38, Loss: 0.6172402501106262\n",
      "Epoch 67/100, Iteration 19/38, Loss: 0.7244290709495544\n",
      "Epoch 67/100, Iteration 20/38, Loss: 0.6333284974098206\n",
      "Epoch 67/100, Iteration 21/38, Loss: 0.7535731196403503\n",
      "Epoch 67/100, Iteration 22/38, Loss: 0.6585001349449158\n",
      "Epoch 67/100, Iteration 23/38, Loss: 0.7048498392105103\n",
      "Epoch 67/100, Iteration 24/38, Loss: 0.7451686263084412\n",
      "Epoch 67/100, Iteration 25/38, Loss: 0.758014976978302\n",
      "Epoch 67/100, Iteration 26/38, Loss: 0.788547933101654\n",
      "Epoch 67/100, Iteration 27/38, Loss: 0.6359953880310059\n",
      "Epoch 67/100, Iteration 28/38, Loss: 0.6550067067146301\n",
      "Epoch 67/100, Iteration 29/38, Loss: 0.6779474020004272\n",
      "Epoch 67/100, Iteration 30/38, Loss: 0.7641091346740723\n",
      "Epoch 67/100, Iteration 31/38, Loss: 0.7317392826080322\n",
      "Epoch 67/100, Iteration 32/38, Loss: 0.6188335418701172\n",
      "Epoch 67/100, Iteration 33/38, Loss: 0.6766725778579712\n",
      "Epoch 67/100, Iteration 34/38, Loss: 0.5772265195846558\n",
      "Epoch 67/100, Iteration 35/38, Loss: 0.8324587345123291\n",
      "Epoch 67/100, Iteration 36/38, Loss: 0.7244306802749634\n",
      "Epoch 67/100, Iteration 37/38, Loss: 0.7139669060707092\n",
      "Epoch 67/100, Iteration 38/38, Loss: 0.6578875780105591\n",
      "Epoch 68/100, Iteration 1/38, Loss: 0.6157020926475525\n",
      "Epoch 68/100, Iteration 2/38, Loss: 0.7607184052467346\n",
      "Epoch 68/100, Iteration 3/38, Loss: 0.7103847861289978\n",
      "Epoch 68/100, Iteration 4/38, Loss: 0.7093144059181213\n",
      "Epoch 68/100, Iteration 5/38, Loss: 0.6826570630073547\n",
      "Epoch 68/100, Iteration 6/38, Loss: 0.7233079075813293\n",
      "Epoch 68/100, Iteration 7/38, Loss: 0.7179460525512695\n",
      "Epoch 68/100, Iteration 8/38, Loss: 0.6650267839431763\n",
      "Epoch 68/100, Iteration 9/38, Loss: 0.7882057428359985\n",
      "Epoch 68/100, Iteration 10/38, Loss: 0.6571911573410034\n",
      "Epoch 68/100, Iteration 11/38, Loss: 0.6423139572143555\n",
      "Epoch 68/100, Iteration 12/38, Loss: 0.5683380365371704\n",
      "Epoch 68/100, Iteration 13/38, Loss: 0.7692332863807678\n",
      "Epoch 68/100, Iteration 14/38, Loss: 0.6263805627822876\n",
      "Epoch 68/100, Iteration 15/38, Loss: 0.5872273445129395\n",
      "Epoch 68/100, Iteration 16/38, Loss: 0.6862931847572327\n",
      "Epoch 68/100, Iteration 17/38, Loss: 0.7441355586051941\n",
      "Epoch 68/100, Iteration 18/38, Loss: 0.6464570760726929\n",
      "Epoch 68/100, Iteration 19/38, Loss: 0.6828970313072205\n",
      "Epoch 68/100, Iteration 20/38, Loss: 0.6913192272186279\n",
      "Epoch 68/100, Iteration 21/38, Loss: 0.752856969833374\n",
      "Epoch 68/100, Iteration 22/38, Loss: 0.644819974899292\n",
      "Epoch 68/100, Iteration 23/38, Loss: 0.71258544921875\n",
      "Epoch 68/100, Iteration 24/38, Loss: 0.6553667783737183\n",
      "Epoch 68/100, Iteration 25/38, Loss: 0.7122248411178589\n",
      "Epoch 68/100, Iteration 26/38, Loss: 0.7079397439956665\n",
      "Epoch 68/100, Iteration 27/38, Loss: 0.6452328562736511\n",
      "Epoch 68/100, Iteration 28/38, Loss: 0.5893093347549438\n",
      "Epoch 68/100, Iteration 29/38, Loss: 0.7402492761611938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100, Iteration 30/38, Loss: 0.5847352147102356\n",
      "Epoch 68/100, Iteration 31/38, Loss: 0.6655289530754089\n",
      "Epoch 68/100, Iteration 32/38, Loss: 0.7182874083518982\n",
      "Epoch 68/100, Iteration 33/38, Loss: 0.6527621746063232\n",
      "Epoch 68/100, Iteration 34/38, Loss: 0.7124203443527222\n",
      "Epoch 68/100, Iteration 35/38, Loss: 0.6529676914215088\n",
      "Epoch 68/100, Iteration 36/38, Loss: 0.6192713379859924\n",
      "Epoch 68/100, Iteration 37/38, Loss: 0.6178387999534607\n",
      "Epoch 68/100, Iteration 38/38, Loss: 0.7395362257957458\n",
      "Epoch 69/100, Iteration 1/38, Loss: 0.6472926139831543\n",
      "Epoch 69/100, Iteration 2/38, Loss: 0.6791213154792786\n",
      "Epoch 69/100, Iteration 3/38, Loss: 0.6337656378746033\n",
      "Epoch 69/100, Iteration 4/38, Loss: 0.6441842317581177\n",
      "Epoch 69/100, Iteration 5/38, Loss: 0.6644489765167236\n",
      "Epoch 69/100, Iteration 6/38, Loss: 0.6316232085227966\n",
      "Epoch 69/100, Iteration 7/38, Loss: 0.7414853572845459\n",
      "Epoch 69/100, Iteration 8/38, Loss: 0.803893506526947\n",
      "Epoch 69/100, Iteration 9/38, Loss: 0.7429974675178528\n",
      "Epoch 69/100, Iteration 10/38, Loss: 0.618624746799469\n",
      "Epoch 69/100, Iteration 11/38, Loss: 0.6175336837768555\n",
      "Epoch 69/100, Iteration 12/38, Loss: 0.8031620979309082\n",
      "Epoch 69/100, Iteration 13/38, Loss: 0.633624792098999\n",
      "Epoch 69/100, Iteration 14/38, Loss: 0.6159116625785828\n",
      "Epoch 69/100, Iteration 15/38, Loss: 0.7026684880256653\n",
      "Epoch 69/100, Iteration 16/38, Loss: 0.6214675307273865\n",
      "Epoch 69/100, Iteration 17/38, Loss: 0.6523727178573608\n",
      "Epoch 69/100, Iteration 18/38, Loss: 0.7025130987167358\n",
      "Epoch 69/100, Iteration 19/38, Loss: 0.6611503958702087\n",
      "Epoch 69/100, Iteration 20/38, Loss: 0.805367112159729\n",
      "Epoch 69/100, Iteration 21/38, Loss: 0.7762703895568848\n",
      "Epoch 69/100, Iteration 22/38, Loss: 0.6913391351699829\n",
      "Epoch 69/100, Iteration 23/38, Loss: 0.6339719295501709\n",
      "Epoch 69/100, Iteration 24/38, Loss: 0.6981052160263062\n",
      "Epoch 69/100, Iteration 25/38, Loss: 0.6730780601501465\n",
      "Epoch 69/100, Iteration 26/38, Loss: 0.7434993386268616\n",
      "Epoch 69/100, Iteration 27/38, Loss: 0.7778816819190979\n",
      "Epoch 69/100, Iteration 28/38, Loss: 0.6524537205696106\n",
      "Epoch 69/100, Iteration 29/38, Loss: 0.7386577129364014\n",
      "Epoch 69/100, Iteration 30/38, Loss: 0.7965914607048035\n",
      "Epoch 69/100, Iteration 31/38, Loss: 0.6234131455421448\n",
      "Epoch 69/100, Iteration 32/38, Loss: 0.6166003942489624\n",
      "Epoch 69/100, Iteration 33/38, Loss: 0.7362470626831055\n",
      "Epoch 69/100, Iteration 34/38, Loss: 0.6585197448730469\n",
      "Epoch 69/100, Iteration 35/38, Loss: 0.6522560119628906\n",
      "Epoch 69/100, Iteration 36/38, Loss: 0.69504314661026\n",
      "Epoch 69/100, Iteration 37/38, Loss: 0.670992374420166\n",
      "Epoch 69/100, Iteration 38/38, Loss: 0.6255562901496887\n",
      "Epoch 70/100, Iteration 1/38, Loss: 0.6546242833137512\n",
      "Epoch 70/100, Iteration 2/38, Loss: 0.7411110401153564\n",
      "Epoch 70/100, Iteration 3/38, Loss: 0.8044101595878601\n",
      "Epoch 70/100, Iteration 4/38, Loss: 0.6799071431159973\n",
      "Epoch 70/100, Iteration 5/38, Loss: 0.6620023250579834\n",
      "Epoch 70/100, Iteration 6/38, Loss: 0.6754283308982849\n",
      "Epoch 70/100, Iteration 7/38, Loss: 0.6784688234329224\n",
      "Epoch 70/100, Iteration 8/38, Loss: 0.6784542798995972\n",
      "Epoch 70/100, Iteration 9/38, Loss: 0.6509900689125061\n",
      "Epoch 70/100, Iteration 10/38, Loss: 0.670499324798584\n",
      "Epoch 70/100, Iteration 11/38, Loss: 0.7720649242401123\n",
      "Epoch 70/100, Iteration 12/38, Loss: 0.5955947041511536\n",
      "Epoch 70/100, Iteration 13/38, Loss: 0.6517003774642944\n",
      "Epoch 70/100, Iteration 14/38, Loss: 0.706773579120636\n",
      "Epoch 70/100, Iteration 15/38, Loss: 0.6175060868263245\n",
      "Epoch 70/100, Iteration 16/38, Loss: 0.6511444449424744\n",
      "Epoch 70/100, Iteration 17/38, Loss: 0.7086405754089355\n",
      "Epoch 70/100, Iteration 18/38, Loss: 0.6503090262413025\n",
      "Epoch 70/100, Iteration 19/38, Loss: 0.7109617590904236\n",
      "Epoch 70/100, Iteration 20/38, Loss: 0.6619547009468079\n",
      "Epoch 70/100, Iteration 21/38, Loss: 0.6931255459785461\n",
      "Epoch 70/100, Iteration 22/38, Loss: 0.5903350710868835\n",
      "Epoch 70/100, Iteration 23/38, Loss: 0.6212125420570374\n",
      "Epoch 70/100, Iteration 24/38, Loss: 0.7222989201545715\n",
      "Epoch 70/100, Iteration 25/38, Loss: 0.6267374157905579\n",
      "Epoch 70/100, Iteration 26/38, Loss: 0.7494646906852722\n",
      "Epoch 70/100, Iteration 27/38, Loss: 0.671178936958313\n",
      "Epoch 70/100, Iteration 28/38, Loss: 0.6313607692718506\n",
      "Epoch 70/100, Iteration 29/38, Loss: 0.7137110829353333\n",
      "Epoch 70/100, Iteration 30/38, Loss: 0.6129558086395264\n",
      "Epoch 70/100, Iteration 31/38, Loss: 0.6771904230117798\n",
      "Epoch 70/100, Iteration 32/38, Loss: 0.6502763628959656\n",
      "Epoch 70/100, Iteration 33/38, Loss: 0.6375731825828552\n",
      "Epoch 70/100, Iteration 34/38, Loss: 0.5839550495147705\n",
      "Epoch 70/100, Iteration 35/38, Loss: 0.6914232969284058\n",
      "Epoch 70/100, Iteration 36/38, Loss: 0.6513848304748535\n",
      "Epoch 70/100, Iteration 37/38, Loss: 0.7388113141059875\n",
      "Epoch 70/100, Iteration 38/38, Loss: 0.6146693229675293\n",
      "Epoch 71/100, Iteration 1/38, Loss: 0.6301557421684265\n",
      "Epoch 71/100, Iteration 2/38, Loss: 0.7242122888565063\n",
      "Epoch 71/100, Iteration 3/38, Loss: 0.6304391026496887\n",
      "Epoch 71/100, Iteration 4/38, Loss: 0.7511764168739319\n",
      "Epoch 71/100, Iteration 5/38, Loss: 0.7782195210456848\n",
      "Epoch 71/100, Iteration 6/38, Loss: 0.6510329246520996\n",
      "Epoch 71/100, Iteration 7/38, Loss: 0.688035249710083\n",
      "Epoch 71/100, Iteration 8/38, Loss: 0.753301739692688\n",
      "Epoch 71/100, Iteration 9/38, Loss: 0.5918970704078674\n",
      "Epoch 71/100, Iteration 10/38, Loss: 0.7121167182922363\n",
      "Epoch 71/100, Iteration 11/38, Loss: 0.6760686635971069\n",
      "Epoch 71/100, Iteration 12/38, Loss: 0.6796767115592957\n",
      "Epoch 71/100, Iteration 13/38, Loss: 0.6275947093963623\n",
      "Epoch 71/100, Iteration 14/38, Loss: 0.5866977572441101\n",
      "Epoch 71/100, Iteration 15/38, Loss: 0.7104787826538086\n",
      "Epoch 71/100, Iteration 16/38, Loss: 0.5855341553688049\n",
      "Epoch 71/100, Iteration 17/38, Loss: 0.6463122963905334\n",
      "Epoch 71/100, Iteration 18/38, Loss: 0.6483290195465088\n",
      "Epoch 71/100, Iteration 19/38, Loss: 0.6758376359939575\n",
      "Epoch 71/100, Iteration 20/38, Loss: 0.7386536002159119\n",
      "Epoch 71/100, Iteration 21/38, Loss: 0.5542805790901184\n",
      "Epoch 71/100, Iteration 22/38, Loss: 0.704923689365387\n",
      "Epoch 71/100, Iteration 23/38, Loss: 0.7470484375953674\n",
      "Epoch 71/100, Iteration 24/38, Loss: 0.6135765910148621\n",
      "Epoch 71/100, Iteration 25/38, Loss: 0.6451199054718018\n",
      "Epoch 71/100, Iteration 26/38, Loss: 0.6457083225250244\n",
      "Epoch 71/100, Iteration 27/38, Loss: 0.6168977618217468\n",
      "Epoch 71/100, Iteration 28/38, Loss: 0.588699221611023\n",
      "Epoch 71/100, Iteration 29/38, Loss: 0.6748424172401428\n",
      "Epoch 71/100, Iteration 30/38, Loss: 0.7052149772644043\n",
      "Epoch 71/100, Iteration 31/38, Loss: 0.6471971273422241\n",
      "Epoch 71/100, Iteration 32/38, Loss: 0.7151445150375366\n",
      "Epoch 71/100, Iteration 33/38, Loss: 0.709228515625\n",
      "Epoch 71/100, Iteration 34/38, Loss: 0.6038222312927246\n",
      "Epoch 71/100, Iteration 35/38, Loss: 0.6290583610534668\n",
      "Epoch 71/100, Iteration 36/38, Loss: 0.6525461077690125\n",
      "Epoch 71/100, Iteration 37/38, Loss: 0.5589631795883179\n",
      "Epoch 71/100, Iteration 38/38, Loss: 0.7352546453475952\n",
      "Epoch 72/100, Iteration 1/38, Loss: 0.6415059566497803\n",
      "Epoch 72/100, Iteration 2/38, Loss: 0.6158392429351807\n",
      "Epoch 72/100, Iteration 3/38, Loss: 0.617255449295044\n",
      "Epoch 72/100, Iteration 4/38, Loss: 0.7395013570785522\n",
      "Epoch 72/100, Iteration 5/38, Loss: 0.6463931798934937\n",
      "Epoch 72/100, Iteration 6/38, Loss: 0.6793787479400635\n",
      "Epoch 72/100, Iteration 7/38, Loss: 0.6265587210655212\n",
      "Epoch 72/100, Iteration 8/38, Loss: 0.6185837984085083\n",
      "Epoch 72/100, Iteration 9/38, Loss: 0.7361000776290894\n",
      "Epoch 72/100, Iteration 10/38, Loss: 0.6902875900268555\n",
      "Epoch 72/100, Iteration 11/38, Loss: 0.6506202220916748\n",
      "Epoch 72/100, Iteration 12/38, Loss: 0.6412101984024048\n",
      "Epoch 72/100, Iteration 13/38, Loss: 0.6225003004074097\n",
      "Epoch 72/100, Iteration 14/38, Loss: 0.6296565532684326\n",
      "Epoch 72/100, Iteration 15/38, Loss: 0.6779981255531311\n",
      "Epoch 72/100, Iteration 16/38, Loss: 0.6195615530014038\n",
      "Epoch 72/100, Iteration 17/38, Loss: 0.7415504455566406\n",
      "Epoch 72/100, Iteration 18/38, Loss: 0.6180824637413025\n",
      "Epoch 72/100, Iteration 19/38, Loss: 0.6172743439674377\n",
      "Epoch 72/100, Iteration 20/38, Loss: 0.7385306358337402\n",
      "Epoch 72/100, Iteration 21/38, Loss: 0.7130399346351624\n",
      "Epoch 72/100, Iteration 22/38, Loss: 0.6251205801963806\n",
      "Epoch 72/100, Iteration 23/38, Loss: 0.7085832357406616\n",
      "Epoch 72/100, Iteration 24/38, Loss: 0.6729199886322021\n",
      "Epoch 72/100, Iteration 25/38, Loss: 0.6489975452423096\n",
      "Epoch 72/100, Iteration 26/38, Loss: 0.5522189140319824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100, Iteration 27/38, Loss: 0.6566367745399475\n",
      "Epoch 72/100, Iteration 28/38, Loss: 0.6366851925849915\n",
      "Epoch 72/100, Iteration 29/38, Loss: 0.5859513878822327\n",
      "Epoch 72/100, Iteration 30/38, Loss: 0.6756761074066162\n",
      "Epoch 72/100, Iteration 31/38, Loss: 0.6774405837059021\n",
      "Epoch 72/100, Iteration 32/38, Loss: 0.663830041885376\n",
      "Epoch 72/100, Iteration 33/38, Loss: 0.5957005023956299\n",
      "Epoch 72/100, Iteration 34/38, Loss: 0.7335310578346252\n",
      "Epoch 72/100, Iteration 35/38, Loss: 0.6799549460411072\n",
      "Epoch 72/100, Iteration 36/38, Loss: 0.6865081191062927\n",
      "Epoch 72/100, Iteration 37/38, Loss: 0.7937296032905579\n",
      "Epoch 72/100, Iteration 38/38, Loss: 0.8219993710517883\n",
      "Epoch 73/100, Iteration 1/38, Loss: 0.7042924165725708\n",
      "Epoch 73/100, Iteration 2/38, Loss: 0.7533025741577148\n",
      "Epoch 73/100, Iteration 3/38, Loss: 0.6844714879989624\n",
      "Epoch 73/100, Iteration 4/38, Loss: 0.6197229623794556\n",
      "Epoch 73/100, Iteration 5/38, Loss: 0.6512420177459717\n",
      "Epoch 73/100, Iteration 6/38, Loss: 0.7530301809310913\n",
      "Epoch 73/100, Iteration 7/38, Loss: 0.6520970463752747\n",
      "Epoch 73/100, Iteration 8/38, Loss: 0.6439157128334045\n",
      "Epoch 73/100, Iteration 9/38, Loss: 0.7667950391769409\n",
      "Epoch 73/100, Iteration 10/38, Loss: 0.6626408696174622\n",
      "Epoch 73/100, Iteration 11/38, Loss: 0.6557038426399231\n",
      "Epoch 73/100, Iteration 12/38, Loss: 0.6224783062934875\n",
      "Epoch 73/100, Iteration 13/38, Loss: 0.7062487602233887\n",
      "Epoch 73/100, Iteration 14/38, Loss: 0.5875710844993591\n",
      "Epoch 73/100, Iteration 15/38, Loss: 0.5852229595184326\n",
      "Epoch 73/100, Iteration 16/38, Loss: 0.5831138491630554\n",
      "Epoch 73/100, Iteration 17/38, Loss: 0.7661125659942627\n",
      "Epoch 73/100, Iteration 18/38, Loss: 0.7134267091751099\n",
      "Epoch 73/100, Iteration 19/38, Loss: 0.7051085233688354\n",
      "Epoch 73/100, Iteration 20/38, Loss: 0.6782637238502502\n",
      "Epoch 73/100, Iteration 21/38, Loss: 0.736054539680481\n",
      "Epoch 73/100, Iteration 22/38, Loss: 0.5918580889701843\n",
      "Epoch 73/100, Iteration 23/38, Loss: 0.6778347492218018\n",
      "Epoch 73/100, Iteration 24/38, Loss: 0.6554564237594604\n",
      "Epoch 73/100, Iteration 25/38, Loss: 0.7661552429199219\n",
      "Epoch 73/100, Iteration 26/38, Loss: 0.6543306112289429\n",
      "Epoch 73/100, Iteration 27/38, Loss: 0.6244484782218933\n",
      "Epoch 73/100, Iteration 28/38, Loss: 0.6798135638237\n",
      "Epoch 73/100, Iteration 29/38, Loss: 0.624967098236084\n",
      "Epoch 73/100, Iteration 30/38, Loss: 0.6365171074867249\n",
      "Epoch 73/100, Iteration 31/38, Loss: 0.7432242631912231\n",
      "Epoch 73/100, Iteration 32/38, Loss: 0.5890709161758423\n",
      "Epoch 73/100, Iteration 33/38, Loss: 0.6159258484840393\n",
      "Epoch 73/100, Iteration 34/38, Loss: 0.5848938822746277\n",
      "Epoch 73/100, Iteration 35/38, Loss: 0.7745475172996521\n",
      "Epoch 73/100, Iteration 36/38, Loss: 0.6754192113876343\n",
      "Epoch 73/100, Iteration 37/38, Loss: 0.6453839540481567\n",
      "Epoch 73/100, Iteration 38/38, Loss: 0.5871599316596985\n",
      "Epoch 74/100, Iteration 1/38, Loss: 0.7089797258377075\n",
      "Epoch 74/100, Iteration 2/38, Loss: 0.6793901324272156\n",
      "Epoch 74/100, Iteration 3/38, Loss: 0.5880723595619202\n",
      "Epoch 74/100, Iteration 4/38, Loss: 0.6407875418663025\n",
      "Epoch 74/100, Iteration 5/38, Loss: 0.6434434056282043\n",
      "Epoch 74/100, Iteration 6/38, Loss: 0.6523622274398804\n",
      "Epoch 74/100, Iteration 7/38, Loss: 0.6207340955734253\n",
      "Epoch 74/100, Iteration 8/38, Loss: 0.6163980960845947\n",
      "Epoch 74/100, Iteration 9/38, Loss: 0.5824369192123413\n",
      "Epoch 74/100, Iteration 10/38, Loss: 0.5622562170028687\n",
      "Epoch 74/100, Iteration 11/38, Loss: 0.6783000826835632\n",
      "Epoch 74/100, Iteration 12/38, Loss: 0.7388318181037903\n",
      "Epoch 74/100, Iteration 13/38, Loss: 0.7172636389732361\n",
      "Epoch 74/100, Iteration 14/38, Loss: 0.625691294670105\n",
      "Epoch 74/100, Iteration 15/38, Loss: 0.6163667440414429\n",
      "Epoch 74/100, Iteration 16/38, Loss: 0.6509338617324829\n",
      "Epoch 74/100, Iteration 17/38, Loss: 0.6498669981956482\n",
      "Epoch 74/100, Iteration 18/38, Loss: 0.6164186000823975\n",
      "Epoch 74/100, Iteration 19/38, Loss: 0.6446830630302429\n",
      "Epoch 74/100, Iteration 20/38, Loss: 0.614349365234375\n",
      "Epoch 74/100, Iteration 21/38, Loss: 0.6754308342933655\n",
      "Epoch 74/100, Iteration 22/38, Loss: 0.6771260499954224\n",
      "Epoch 74/100, Iteration 23/38, Loss: 0.7967936396598816\n",
      "Epoch 74/100, Iteration 24/38, Loss: 0.7762956023216248\n",
      "Epoch 74/100, Iteration 25/38, Loss: 0.6664203405380249\n",
      "Epoch 74/100, Iteration 26/38, Loss: 0.5794686675071716\n",
      "Epoch 74/100, Iteration 27/38, Loss: 0.5923311114311218\n",
      "Epoch 74/100, Iteration 28/38, Loss: 0.6483919620513916\n",
      "Epoch 74/100, Iteration 29/38, Loss: 0.7638756632804871\n",
      "Epoch 74/100, Iteration 30/38, Loss: 0.606923520565033\n",
      "Epoch 74/100, Iteration 31/38, Loss: 0.7720934152603149\n",
      "Epoch 74/100, Iteration 32/38, Loss: 0.6175744533538818\n",
      "Epoch 74/100, Iteration 33/38, Loss: 0.6164909601211548\n",
      "Epoch 74/100, Iteration 34/38, Loss: 0.7046014070510864\n",
      "Epoch 74/100, Iteration 35/38, Loss: 0.6953483819961548\n",
      "Epoch 74/100, Iteration 36/38, Loss: 0.6771746277809143\n",
      "Epoch 74/100, Iteration 37/38, Loss: 0.7072681188583374\n",
      "Epoch 74/100, Iteration 38/38, Loss: 0.5529353022575378\n",
      "Epoch 75/100, Iteration 1/38, Loss: 0.5847793221473694\n",
      "Epoch 75/100, Iteration 2/38, Loss: 0.6190294623374939\n",
      "Epoch 75/100, Iteration 3/38, Loss: 0.7057106494903564\n",
      "Epoch 75/100, Iteration 4/38, Loss: 0.5833585858345032\n",
      "Epoch 75/100, Iteration 5/38, Loss: 0.6455016732215881\n",
      "Epoch 75/100, Iteration 6/38, Loss: 0.5843787789344788\n",
      "Epoch 75/100, Iteration 7/38, Loss: 0.7648081183433533\n",
      "Epoch 75/100, Iteration 8/38, Loss: 0.7077217102050781\n",
      "Epoch 75/100, Iteration 9/38, Loss: 0.7039018869400024\n",
      "Epoch 75/100, Iteration 10/38, Loss: 0.5527035593986511\n",
      "Epoch 75/100, Iteration 11/38, Loss: 0.7032607197761536\n",
      "Epoch 75/100, Iteration 12/38, Loss: 0.6678228974342346\n",
      "Epoch 75/100, Iteration 13/38, Loss: 0.6491531133651733\n",
      "Epoch 75/100, Iteration 14/38, Loss: 0.709918737411499\n",
      "Epoch 75/100, Iteration 15/38, Loss: 0.7061267495155334\n",
      "Epoch 75/100, Iteration 16/38, Loss: 0.6161032915115356\n",
      "Epoch 75/100, Iteration 17/38, Loss: 0.6170238852500916\n",
      "Epoch 75/100, Iteration 18/38, Loss: 0.6447566151618958\n",
      "Epoch 75/100, Iteration 19/38, Loss: 0.6478491425514221\n",
      "Epoch 75/100, Iteration 20/38, Loss: 0.5806475877761841\n",
      "Epoch 75/100, Iteration 21/38, Loss: 0.6172322034835815\n",
      "Epoch 75/100, Iteration 22/38, Loss: 0.6764155030250549\n",
      "Epoch 75/100, Iteration 23/38, Loss: 0.6460633277893066\n",
      "Epoch 75/100, Iteration 24/38, Loss: 0.72959303855896\n",
      "Epoch 75/100, Iteration 25/38, Loss: 0.6170088052749634\n",
      "Epoch 75/100, Iteration 26/38, Loss: 0.6966725587844849\n",
      "Epoch 75/100, Iteration 27/38, Loss: 0.5899885296821594\n",
      "Epoch 75/100, Iteration 28/38, Loss: 0.6117333173751831\n",
      "Epoch 75/100, Iteration 29/38, Loss: 0.7343006134033203\n",
      "Epoch 75/100, Iteration 30/38, Loss: 0.6464263796806335\n",
      "Epoch 75/100, Iteration 31/38, Loss: 0.7708097100257874\n",
      "Epoch 75/100, Iteration 32/38, Loss: 0.6482081413269043\n",
      "Epoch 75/100, Iteration 33/38, Loss: 0.6138495802879333\n",
      "Epoch 75/100, Iteration 34/38, Loss: 0.7372063994407654\n",
      "Epoch 75/100, Iteration 35/38, Loss: 0.583564043045044\n",
      "Epoch 75/100, Iteration 36/38, Loss: 0.5832188129425049\n",
      "Epoch 75/100, Iteration 37/38, Loss: 0.6140792369842529\n",
      "Epoch 75/100, Iteration 38/38, Loss: 0.7344070076942444\n",
      "Epoch 76/100, Iteration 1/38, Loss: 0.6428921222686768\n",
      "Epoch 76/100, Iteration 2/38, Loss: 0.7097499966621399\n",
      "Epoch 76/100, Iteration 3/38, Loss: 0.7061328291893005\n",
      "Epoch 76/100, Iteration 4/38, Loss: 0.5991743206977844\n",
      "Epoch 76/100, Iteration 5/38, Loss: 0.6750734448432922\n",
      "Epoch 76/100, Iteration 6/38, Loss: 0.7483956217765808\n",
      "Epoch 76/100, Iteration 7/38, Loss: 0.7786573171615601\n",
      "Epoch 76/100, Iteration 8/38, Loss: 0.7585510611534119\n",
      "Epoch 76/100, Iteration 9/38, Loss: 0.6773391962051392\n",
      "Epoch 76/100, Iteration 10/38, Loss: 0.6460726857185364\n",
      "Epoch 76/100, Iteration 11/38, Loss: 0.6842593550682068\n",
      "Epoch 76/100, Iteration 12/38, Loss: 0.6032025814056396\n",
      "Epoch 76/100, Iteration 13/38, Loss: 0.7438589334487915\n",
      "Epoch 76/100, Iteration 14/38, Loss: 0.6452764272689819\n",
      "Epoch 76/100, Iteration 15/38, Loss: 0.70945143699646\n",
      "Epoch 76/100, Iteration 16/38, Loss: 0.6567270755767822\n",
      "Epoch 76/100, Iteration 17/38, Loss: 0.6954553127288818\n",
      "Epoch 76/100, Iteration 18/38, Loss: 0.6832513809204102\n",
      "Epoch 76/100, Iteration 19/38, Loss: 0.6162315607070923\n",
      "Epoch 76/100, Iteration 20/38, Loss: 0.7148930430412292\n",
      "Epoch 76/100, Iteration 21/38, Loss: 0.6452019214630127\n",
      "Epoch 76/100, Iteration 22/38, Loss: 0.5895107984542847\n",
      "Epoch 76/100, Iteration 23/38, Loss: 0.6318988800048828\n",
      "Epoch 76/100, Iteration 24/38, Loss: 0.6019377708435059\n",
      "Epoch 76/100, Iteration 25/38, Loss: 0.7138728499412537\n",
      "Epoch 76/100, Iteration 26/38, Loss: 0.6946336030960083\n",
      "Epoch 76/100, Iteration 27/38, Loss: 0.6905827522277832\n",
      "Epoch 76/100, Iteration 28/38, Loss: 0.7386403679847717\n",
      "Epoch 76/100, Iteration 29/38, Loss: 0.6157078742980957\n",
      "Epoch 76/100, Iteration 30/38, Loss: 0.5922296643257141\n",
      "Epoch 76/100, Iteration 31/38, Loss: 0.6587716937065125\n",
      "Epoch 76/100, Iteration 32/38, Loss: 0.8167413473129272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100, Iteration 33/38, Loss: 0.7802298069000244\n",
      "Epoch 76/100, Iteration 34/38, Loss: 0.7159754633903503\n",
      "Epoch 76/100, Iteration 35/38, Loss: 0.5872507095336914\n",
      "Epoch 76/100, Iteration 36/38, Loss: 0.6011869311332703\n",
      "Epoch 76/100, Iteration 37/38, Loss: 0.6531011462211609\n",
      "Epoch 76/100, Iteration 38/38, Loss: 0.6682505011558533\n",
      "Epoch 77/100, Iteration 1/38, Loss: 0.6102457642555237\n",
      "Epoch 77/100, Iteration 2/38, Loss: 0.6524649262428284\n",
      "Epoch 77/100, Iteration 3/38, Loss: 0.6471947431564331\n",
      "Epoch 77/100, Iteration 4/38, Loss: 0.7737457752227783\n",
      "Epoch 77/100, Iteration 5/38, Loss: 0.5882862210273743\n",
      "Epoch 77/100, Iteration 6/38, Loss: 0.6451655030250549\n",
      "Epoch 77/100, Iteration 7/38, Loss: 0.6207558512687683\n",
      "Epoch 77/100, Iteration 8/38, Loss: 0.5935971736907959\n",
      "Epoch 77/100, Iteration 9/38, Loss: 0.6982488632202148\n",
      "Epoch 77/100, Iteration 10/38, Loss: 0.6128931641578674\n",
      "Epoch 77/100, Iteration 11/38, Loss: 0.6793004274368286\n",
      "Epoch 77/100, Iteration 12/38, Loss: 0.5851180553436279\n",
      "Epoch 77/100, Iteration 13/38, Loss: 0.7373801469802856\n",
      "Epoch 77/100, Iteration 14/38, Loss: 0.6314828991889954\n",
      "Epoch 77/100, Iteration 15/38, Loss: 0.6777894496917725\n",
      "Epoch 77/100, Iteration 16/38, Loss: 0.6519482731819153\n",
      "Epoch 77/100, Iteration 17/38, Loss: 0.7353095412254333\n",
      "Epoch 77/100, Iteration 18/38, Loss: 0.6178225874900818\n",
      "Epoch 77/100, Iteration 19/38, Loss: 0.6181933879852295\n",
      "Epoch 77/100, Iteration 20/38, Loss: 0.7376394867897034\n",
      "Epoch 77/100, Iteration 21/38, Loss: 0.7117751836776733\n",
      "Epoch 77/100, Iteration 22/38, Loss: 0.6515477895736694\n",
      "Epoch 77/100, Iteration 23/38, Loss: 0.707170844078064\n",
      "Epoch 77/100, Iteration 24/38, Loss: 0.6455915570259094\n",
      "Epoch 77/100, Iteration 25/38, Loss: 0.584094762802124\n",
      "Epoch 77/100, Iteration 26/38, Loss: 0.7053542733192444\n",
      "Epoch 77/100, Iteration 27/38, Loss: 0.7687245011329651\n",
      "Epoch 77/100, Iteration 28/38, Loss: 0.7394536137580872\n",
      "Epoch 77/100, Iteration 29/38, Loss: 0.6467907428741455\n",
      "Epoch 77/100, Iteration 30/38, Loss: 0.6772189736366272\n",
      "Epoch 77/100, Iteration 31/38, Loss: 0.6771065592765808\n",
      "Epoch 77/100, Iteration 32/38, Loss: 0.6218545436859131\n",
      "Epoch 77/100, Iteration 33/38, Loss: 0.5648676156997681\n",
      "Epoch 77/100, Iteration 34/38, Loss: 0.5887382626533508\n",
      "Epoch 77/100, Iteration 35/38, Loss: 0.553135335445404\n",
      "Epoch 77/100, Iteration 36/38, Loss: 0.6156909465789795\n",
      "Epoch 77/100, Iteration 37/38, Loss: 0.678554892539978\n",
      "Epoch 77/100, Iteration 38/38, Loss: 0.6151604652404785\n",
      "Epoch 78/100, Iteration 1/38, Loss: 0.6153210401535034\n",
      "Epoch 78/100, Iteration 2/38, Loss: 0.6518533825874329\n",
      "Epoch 78/100, Iteration 3/38, Loss: 0.616414487361908\n",
      "Epoch 78/100, Iteration 4/38, Loss: 0.636443555355072\n",
      "Epoch 78/100, Iteration 5/38, Loss: 0.6109875440597534\n",
      "Epoch 78/100, Iteration 6/38, Loss: 0.5637434124946594\n",
      "Epoch 78/100, Iteration 7/38, Loss: 0.6459810137748718\n",
      "Epoch 78/100, Iteration 8/38, Loss: 0.6163577437400818\n",
      "Epoch 78/100, Iteration 9/38, Loss: 0.6744897365570068\n",
      "Epoch 78/100, Iteration 10/38, Loss: 0.7570938467979431\n",
      "Epoch 78/100, Iteration 11/38, Loss: 0.860222578048706\n",
      "Epoch 78/100, Iteration 12/38, Loss: 0.7432544231414795\n",
      "Epoch 78/100, Iteration 13/38, Loss: 0.7618672847747803\n",
      "Epoch 78/100, Iteration 14/38, Loss: 0.7663323283195496\n",
      "Epoch 78/100, Iteration 15/38, Loss: 0.6378839015960693\n",
      "Epoch 78/100, Iteration 16/38, Loss: 0.6894073486328125\n",
      "Epoch 78/100, Iteration 17/38, Loss: 0.7013352513313293\n",
      "Epoch 78/100, Iteration 18/38, Loss: 0.6359965205192566\n",
      "Epoch 78/100, Iteration 19/38, Loss: 0.7051792144775391\n",
      "Epoch 78/100, Iteration 20/38, Loss: 0.5951337218284607\n",
      "Epoch 78/100, Iteration 21/38, Loss: 0.7846575975418091\n",
      "Epoch 78/100, Iteration 22/38, Loss: 0.6606543064117432\n",
      "Epoch 78/100, Iteration 23/38, Loss: 0.6220249533653259\n",
      "Epoch 78/100, Iteration 24/38, Loss: 0.5538228154182434\n",
      "Epoch 78/100, Iteration 25/38, Loss: 0.6645921468734741\n",
      "Epoch 78/100, Iteration 26/38, Loss: 0.6160379648208618\n",
      "Epoch 78/100, Iteration 27/38, Loss: 0.8018505573272705\n",
      "Epoch 78/100, Iteration 28/38, Loss: 0.5887994170188904\n",
      "Epoch 78/100, Iteration 29/38, Loss: 0.5578168034553528\n",
      "Epoch 78/100, Iteration 30/38, Loss: 0.5948800444602966\n",
      "Epoch 78/100, Iteration 31/38, Loss: 0.6496148705482483\n",
      "Epoch 78/100, Iteration 32/38, Loss: 0.6777018308639526\n",
      "Epoch 78/100, Iteration 33/38, Loss: 0.6478505730628967\n",
      "Epoch 78/100, Iteration 34/38, Loss: 0.6952919960021973\n",
      "Epoch 78/100, Iteration 35/38, Loss: 0.7105764150619507\n",
      "Epoch 78/100, Iteration 36/38, Loss: 0.6502331495285034\n",
      "Epoch 78/100, Iteration 37/38, Loss: 0.5897007584571838\n",
      "Epoch 78/100, Iteration 38/38, Loss: 0.6833814382553101\n",
      "Epoch 79/100, Iteration 1/38, Loss: 0.6446628570556641\n",
      "Epoch 79/100, Iteration 2/38, Loss: 0.6477945446968079\n",
      "Epoch 79/100, Iteration 3/38, Loss: 0.6531305909156799\n",
      "Epoch 79/100, Iteration 4/38, Loss: 0.5525063872337341\n",
      "Epoch 79/100, Iteration 5/38, Loss: 0.6476461291313171\n",
      "Epoch 79/100, Iteration 6/38, Loss: 0.5839759111404419\n",
      "Epoch 79/100, Iteration 7/38, Loss: 0.6762612462043762\n",
      "Epoch 79/100, Iteration 8/38, Loss: 0.5863223075866699\n",
      "Epoch 79/100, Iteration 9/38, Loss: 0.6477658152580261\n",
      "Epoch 79/100, Iteration 10/38, Loss: 0.8151348233222961\n",
      "Epoch 79/100, Iteration 11/38, Loss: 0.6652775406837463\n",
      "Epoch 79/100, Iteration 12/38, Loss: 0.8342678546905518\n",
      "Epoch 79/100, Iteration 13/38, Loss: 0.738140344619751\n",
      "Epoch 79/100, Iteration 14/38, Loss: 0.646461546421051\n",
      "Epoch 79/100, Iteration 15/38, Loss: 0.5629277229309082\n",
      "Epoch 79/100, Iteration 16/38, Loss: 0.6529920101165771\n",
      "Epoch 79/100, Iteration 17/38, Loss: 0.7949668169021606\n",
      "Epoch 79/100, Iteration 18/38, Loss: 0.8481259942054749\n",
      "Epoch 79/100, Iteration 19/38, Loss: 0.907124936580658\n",
      "Epoch 79/100, Iteration 20/38, Loss: 0.7657422423362732\n",
      "Epoch 79/100, Iteration 21/38, Loss: 0.6635997295379639\n",
      "Epoch 79/100, Iteration 22/38, Loss: 0.5963920950889587\n",
      "Epoch 79/100, Iteration 23/38, Loss: 0.7179434299468994\n",
      "Epoch 79/100, Iteration 24/38, Loss: 0.6345100402832031\n",
      "Epoch 79/100, Iteration 25/38, Loss: 0.6955349445343018\n",
      "Epoch 79/100, Iteration 26/38, Loss: 0.6547088027000427\n",
      "Epoch 79/100, Iteration 27/38, Loss: 0.6398005485534668\n",
      "Epoch 79/100, Iteration 28/38, Loss: 0.7147696614265442\n",
      "Epoch 79/100, Iteration 29/38, Loss: 0.6524723172187805\n",
      "Epoch 79/100, Iteration 30/38, Loss: 0.6423763036727905\n",
      "Epoch 79/100, Iteration 31/38, Loss: 0.7152215242385864\n",
      "Epoch 79/100, Iteration 32/38, Loss: 0.6304943561553955\n",
      "Epoch 79/100, Iteration 33/38, Loss: 0.7127166390419006\n",
      "Epoch 79/100, Iteration 34/38, Loss: 0.6762050986289978\n",
      "Epoch 79/100, Iteration 35/38, Loss: 0.7078775763511658\n",
      "Epoch 79/100, Iteration 36/38, Loss: 0.7002032399177551\n",
      "Epoch 79/100, Iteration 37/38, Loss: 0.604975700378418\n",
      "Epoch 79/100, Iteration 38/38, Loss: 0.614347517490387\n",
      "Epoch 80/100, Iteration 1/38, Loss: 0.5868363976478577\n",
      "Epoch 80/100, Iteration 2/38, Loss: 0.6499037742614746\n",
      "Epoch 80/100, Iteration 3/38, Loss: 0.6475664377212524\n",
      "Epoch 80/100, Iteration 4/38, Loss: 0.6415148377418518\n",
      "Epoch 80/100, Iteration 5/38, Loss: 0.6171256303787231\n",
      "Epoch 80/100, Iteration 6/38, Loss: 0.7153186798095703\n",
      "Epoch 80/100, Iteration 7/38, Loss: 0.7074808478355408\n",
      "Epoch 80/100, Iteration 8/38, Loss: 0.7073925137519836\n",
      "Epoch 80/100, Iteration 9/38, Loss: 0.5536155104637146\n",
      "Epoch 80/100, Iteration 10/38, Loss: 0.7089776992797852\n",
      "Epoch 80/100, Iteration 11/38, Loss: 0.5872591137886047\n",
      "Epoch 80/100, Iteration 12/38, Loss: 0.6782611012458801\n",
      "Epoch 80/100, Iteration 13/38, Loss: 0.7045047283172607\n",
      "Epoch 80/100, Iteration 14/38, Loss: 0.6449136734008789\n",
      "Epoch 80/100, Iteration 15/38, Loss: 0.5978070497512817\n",
      "Epoch 80/100, Iteration 16/38, Loss: 0.5636076331138611\n",
      "Epoch 80/100, Iteration 17/38, Loss: 0.7107910513877869\n",
      "Epoch 80/100, Iteration 18/38, Loss: 0.5853739976882935\n",
      "Epoch 80/100, Iteration 19/38, Loss: 0.6152867674827576\n",
      "Epoch 80/100, Iteration 20/38, Loss: 0.6811746954917908\n",
      "Epoch 80/100, Iteration 21/38, Loss: 0.7076972723007202\n",
      "Epoch 80/100, Iteration 22/38, Loss: 0.6848299503326416\n",
      "Epoch 80/100, Iteration 23/38, Loss: 0.6272457242012024\n",
      "Epoch 80/100, Iteration 24/38, Loss: 0.6759082674980164\n",
      "Epoch 80/100, Iteration 25/38, Loss: 0.7082346081733704\n",
      "Epoch 80/100, Iteration 26/38, Loss: 0.6467220783233643\n",
      "Epoch 80/100, Iteration 27/38, Loss: 0.6179246306419373\n",
      "Epoch 80/100, Iteration 28/38, Loss: 0.6762509942054749\n",
      "Epoch 80/100, Iteration 29/38, Loss: 0.6175883412361145\n",
      "Epoch 80/100, Iteration 30/38, Loss: 0.6156861186027527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Iteration 31/38, Loss: 0.6763098835945129\n",
      "Epoch 80/100, Iteration 32/38, Loss: 0.7354194521903992\n",
      "Epoch 80/100, Iteration 33/38, Loss: 0.6767278909683228\n",
      "Epoch 80/100, Iteration 34/38, Loss: 0.6161114573478699\n",
      "Epoch 80/100, Iteration 35/38, Loss: 0.6167055368423462\n",
      "Epoch 80/100, Iteration 36/38, Loss: 0.5858450531959534\n",
      "Epoch 80/100, Iteration 37/38, Loss: 0.6175436973571777\n",
      "Epoch 80/100, Iteration 38/38, Loss: 0.664199709892273\n",
      "Epoch 81/100, Iteration 1/38, Loss: 0.6139768362045288\n",
      "Epoch 81/100, Iteration 2/38, Loss: 0.7101964950561523\n",
      "Epoch 81/100, Iteration 3/38, Loss: 0.6647164225578308\n",
      "Epoch 81/100, Iteration 4/38, Loss: 0.6412325501441956\n",
      "Epoch 81/100, Iteration 5/38, Loss: 0.6445672512054443\n",
      "Epoch 81/100, Iteration 6/38, Loss: 0.6768968105316162\n",
      "Epoch 81/100, Iteration 7/38, Loss: 0.5835840106010437\n",
      "Epoch 81/100, Iteration 8/38, Loss: 0.7078809142112732\n",
      "Epoch 81/100, Iteration 9/38, Loss: 0.6452900171279907\n",
      "Epoch 81/100, Iteration 10/38, Loss: 0.6462744474411011\n",
      "Epoch 81/100, Iteration 11/38, Loss: 0.7358932495117188\n",
      "Epoch 81/100, Iteration 12/38, Loss: 0.6812646389007568\n",
      "Epoch 81/100, Iteration 13/38, Loss: 0.7385721802711487\n",
      "Epoch 81/100, Iteration 14/38, Loss: 0.6798951625823975\n",
      "Epoch 81/100, Iteration 15/38, Loss: 0.5925570726394653\n",
      "Epoch 81/100, Iteration 16/38, Loss: 0.5538198351860046\n",
      "Epoch 81/100, Iteration 17/38, Loss: 0.7449793815612793\n",
      "Epoch 81/100, Iteration 18/38, Loss: 0.585202157497406\n",
      "Epoch 81/100, Iteration 19/38, Loss: 0.5845564603805542\n",
      "Epoch 81/100, Iteration 20/38, Loss: 0.6153891086578369\n",
      "Epoch 81/100, Iteration 21/38, Loss: 0.6791331171989441\n",
      "Epoch 81/100, Iteration 22/38, Loss: 0.7124165892601013\n",
      "Epoch 81/100, Iteration 23/38, Loss: 0.6461382508277893\n",
      "Epoch 81/100, Iteration 24/38, Loss: 0.5925409197807312\n",
      "Epoch 81/100, Iteration 25/38, Loss: 0.6784681081771851\n",
      "Epoch 81/100, Iteration 26/38, Loss: 0.6443315744400024\n",
      "Epoch 81/100, Iteration 27/38, Loss: 0.6751244068145752\n",
      "Epoch 81/100, Iteration 28/38, Loss: 0.6444213390350342\n",
      "Epoch 81/100, Iteration 29/38, Loss: 0.5857781171798706\n",
      "Epoch 81/100, Iteration 30/38, Loss: 0.6160326600074768\n",
      "Epoch 81/100, Iteration 31/38, Loss: 0.6445537209510803\n",
      "Epoch 81/100, Iteration 32/38, Loss: 0.5867357850074768\n",
      "Epoch 81/100, Iteration 33/38, Loss: 0.6443243026733398\n",
      "Epoch 81/100, Iteration 34/38, Loss: 0.615039050579071\n",
      "Epoch 81/100, Iteration 35/38, Loss: 0.5843179821968079\n",
      "Epoch 81/100, Iteration 36/38, Loss: 0.667999267578125\n",
      "Epoch 81/100, Iteration 37/38, Loss: 0.6747860908508301\n",
      "Epoch 81/100, Iteration 38/38, Loss: 0.686714231967926\n",
      "Epoch 82/100, Iteration 1/38, Loss: 0.6145650744438171\n",
      "Epoch 82/100, Iteration 2/38, Loss: 0.6545001268386841\n",
      "Epoch 82/100, Iteration 3/38, Loss: 0.7095378637313843\n",
      "Epoch 82/100, Iteration 4/38, Loss: 0.6089157462120056\n",
      "Epoch 82/100, Iteration 5/38, Loss: 0.656516969203949\n",
      "Epoch 82/100, Iteration 6/38, Loss: 0.6175483465194702\n",
      "Epoch 82/100, Iteration 7/38, Loss: 0.5859807133674622\n",
      "Epoch 82/100, Iteration 8/38, Loss: 0.6468759775161743\n",
      "Epoch 82/100, Iteration 9/38, Loss: 0.6173107028007507\n",
      "Epoch 82/100, Iteration 10/38, Loss: 0.6180726885795593\n",
      "Epoch 82/100, Iteration 11/38, Loss: 0.5834007263183594\n",
      "Epoch 82/100, Iteration 12/38, Loss: 0.6758340001106262\n",
      "Epoch 82/100, Iteration 13/38, Loss: 0.7313977479934692\n",
      "Epoch 82/100, Iteration 14/38, Loss: 0.6444159150123596\n",
      "Epoch 82/100, Iteration 15/38, Loss: 0.6169177889823914\n",
      "Epoch 82/100, Iteration 16/38, Loss: 0.6466122269630432\n",
      "Epoch 82/100, Iteration 17/38, Loss: 0.5832144618034363\n",
      "Epoch 82/100, Iteration 18/38, Loss: 0.6108680367469788\n",
      "Epoch 82/100, Iteration 19/38, Loss: 0.618911623954773\n",
      "Epoch 82/100, Iteration 20/38, Loss: 0.6185187101364136\n",
      "Epoch 82/100, Iteration 21/38, Loss: 0.6779963970184326\n",
      "Epoch 82/100, Iteration 22/38, Loss: 0.7049403786659241\n",
      "Epoch 82/100, Iteration 23/38, Loss: 0.6475411653518677\n",
      "Epoch 82/100, Iteration 24/38, Loss: 0.7072644233703613\n",
      "Epoch 82/100, Iteration 25/38, Loss: 0.6138921976089478\n",
      "Epoch 82/100, Iteration 26/38, Loss: 0.6463648080825806\n",
      "Epoch 82/100, Iteration 27/38, Loss: 0.7335477471351624\n",
      "Epoch 82/100, Iteration 28/38, Loss: 0.6773026585578918\n",
      "Epoch 82/100, Iteration 29/38, Loss: 0.613306999206543\n",
      "Epoch 82/100, Iteration 30/38, Loss: 0.5841403603553772\n",
      "Epoch 82/100, Iteration 31/38, Loss: 0.6726576089859009\n",
      "Epoch 82/100, Iteration 32/38, Loss: 0.7390562295913696\n",
      "Epoch 82/100, Iteration 33/38, Loss: 0.6140772700309753\n",
      "Epoch 82/100, Iteration 34/38, Loss: 0.6126047372817993\n",
      "Epoch 82/100, Iteration 35/38, Loss: 0.6147398352622986\n",
      "Epoch 82/100, Iteration 36/38, Loss: 0.6126485466957092\n",
      "Epoch 82/100, Iteration 37/38, Loss: 0.6746200919151306\n",
      "Epoch 82/100, Iteration 38/38, Loss: 0.6155368685722351\n",
      "Epoch 83/100, Iteration 1/38, Loss: 0.5825867056846619\n",
      "Epoch 83/100, Iteration 2/38, Loss: 0.58375483751297\n",
      "Epoch 83/100, Iteration 3/38, Loss: 0.6147632002830505\n",
      "Epoch 83/100, Iteration 4/38, Loss: 0.552422046661377\n",
      "Epoch 83/100, Iteration 5/38, Loss: 0.6752559542655945\n",
      "Epoch 83/100, Iteration 6/38, Loss: 0.7400358319282532\n",
      "Epoch 83/100, Iteration 7/38, Loss: 0.6427513360977173\n",
      "Epoch 83/100, Iteration 8/38, Loss: 0.5833580493927002\n",
      "Epoch 83/100, Iteration 9/38, Loss: 0.7018029689788818\n",
      "Epoch 83/100, Iteration 10/38, Loss: 0.707095742225647\n",
      "Epoch 83/100, Iteration 11/38, Loss: 0.6128181219100952\n",
      "Epoch 83/100, Iteration 12/38, Loss: 0.6117904782295227\n",
      "Epoch 83/100, Iteration 13/38, Loss: 0.6737139821052551\n",
      "Epoch 83/100, Iteration 14/38, Loss: 0.7388878464698792\n",
      "Epoch 83/100, Iteration 15/38, Loss: 0.6147044897079468\n",
      "Epoch 83/100, Iteration 16/38, Loss: 0.6434641480445862\n",
      "Epoch 83/100, Iteration 17/38, Loss: 0.7046416401863098\n",
      "Epoch 83/100, Iteration 18/38, Loss: 0.6432721614837646\n",
      "Epoch 83/100, Iteration 19/38, Loss: 0.7035344839096069\n",
      "Epoch 83/100, Iteration 20/38, Loss: 0.6458806395530701\n",
      "Epoch 83/100, Iteration 21/38, Loss: 0.5832699537277222\n",
      "Epoch 83/100, Iteration 22/38, Loss: 0.7051407098770142\n",
      "Epoch 83/100, Iteration 23/38, Loss: 0.6117889881134033\n",
      "Epoch 83/100, Iteration 24/38, Loss: 0.6152244210243225\n",
      "Epoch 83/100, Iteration 25/38, Loss: 0.6126337647438049\n",
      "Epoch 83/100, Iteration 26/38, Loss: 0.7081204652786255\n",
      "Epoch 83/100, Iteration 27/38, Loss: 0.7058354616165161\n",
      "Epoch 83/100, Iteration 28/38, Loss: 0.5866826176643372\n",
      "Epoch 83/100, Iteration 29/38, Loss: 0.6438290476799011\n",
      "Epoch 83/100, Iteration 30/38, Loss: 0.6458263993263245\n",
      "Epoch 83/100, Iteration 31/38, Loss: 0.6194170117378235\n",
      "Epoch 83/100, Iteration 32/38, Loss: 0.614778459072113\n",
      "Epoch 83/100, Iteration 33/38, Loss: 0.6738656759262085\n",
      "Epoch 83/100, Iteration 34/38, Loss: 0.5838223695755005\n",
      "Epoch 83/100, Iteration 35/38, Loss: 0.6436115503311157\n",
      "Epoch 83/100, Iteration 36/38, Loss: 0.6163200736045837\n",
      "Epoch 83/100, Iteration 37/38, Loss: 0.6126439571380615\n",
      "Epoch 83/100, Iteration 38/38, Loss: 0.5537208914756775\n",
      "Epoch 84/100, Iteration 1/38, Loss: 0.5836077928543091\n",
      "Epoch 84/100, Iteration 2/38, Loss: 0.7658555507659912\n",
      "Epoch 84/100, Iteration 3/38, Loss: 0.5529603362083435\n",
      "Epoch 84/100, Iteration 4/38, Loss: 0.5815874934196472\n",
      "Epoch 84/100, Iteration 5/38, Loss: 0.6433010697364807\n",
      "Epoch 84/100, Iteration 6/38, Loss: 0.6443746089935303\n",
      "Epoch 84/100, Iteration 7/38, Loss: 0.6742756962776184\n",
      "Epoch 84/100, Iteration 8/38, Loss: 0.6154161095619202\n",
      "Epoch 84/100, Iteration 9/38, Loss: 0.6461679935455322\n",
      "Epoch 84/100, Iteration 10/38, Loss: 0.6431617140769958\n",
      "Epoch 84/100, Iteration 11/38, Loss: 0.6126850843429565\n",
      "Epoch 84/100, Iteration 12/38, Loss: 0.611504852771759\n",
      "Epoch 84/100, Iteration 13/38, Loss: 0.6409834623336792\n",
      "Epoch 84/100, Iteration 14/38, Loss: 0.6475943922996521\n",
      "Epoch 84/100, Iteration 15/38, Loss: 0.6428070664405823\n",
      "Epoch 84/100, Iteration 16/38, Loss: 0.5832374095916748\n",
      "Epoch 84/100, Iteration 17/38, Loss: 0.6403354406356812\n",
      "Epoch 84/100, Iteration 18/38, Loss: 0.648025393486023\n",
      "Epoch 84/100, Iteration 19/38, Loss: 0.5832613706588745\n",
      "Epoch 84/100, Iteration 20/38, Loss: 0.6768280267715454\n",
      "Epoch 84/100, Iteration 21/38, Loss: 0.61238032579422\n",
      "Epoch 84/100, Iteration 22/38, Loss: 0.7095228433609009\n",
      "Epoch 84/100, Iteration 23/38, Loss: 0.6140792369842529\n",
      "Epoch 84/100, Iteration 24/38, Loss: 0.5848845839500427\n",
      "Epoch 84/100, Iteration 25/38, Loss: 0.6738195419311523\n",
      "Epoch 84/100, Iteration 26/38, Loss: 0.6140269637107849\n",
      "Epoch 84/100, Iteration 27/38, Loss: 0.6394607424736023\n",
      "Epoch 84/100, Iteration 28/38, Loss: 0.7026016116142273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100, Iteration 29/38, Loss: 0.7051825523376465\n",
      "Epoch 84/100, Iteration 30/38, Loss: 0.6126394867897034\n",
      "Epoch 84/100, Iteration 31/38, Loss: 0.6432228684425354\n",
      "Epoch 84/100, Iteration 32/38, Loss: 0.6117074489593506\n",
      "Epoch 84/100, Iteration 33/38, Loss: 0.6429826021194458\n",
      "Epoch 84/100, Iteration 34/38, Loss: 0.6436606645584106\n",
      "Epoch 84/100, Iteration 35/38, Loss: 0.6432641744613647\n",
      "Epoch 84/100, Iteration 36/38, Loss: 0.643332302570343\n",
      "Epoch 84/100, Iteration 37/38, Loss: 0.7692312002182007\n",
      "Epoch 84/100, Iteration 38/38, Loss: 0.6158459782600403\n",
      "Epoch 85/100, Iteration 1/38, Loss: 0.6145504117012024\n",
      "Epoch 85/100, Iteration 2/38, Loss: 0.5833101868629456\n",
      "Epoch 85/100, Iteration 3/38, Loss: 0.6116134524345398\n",
      "Epoch 85/100, Iteration 4/38, Loss: 0.6437332630157471\n",
      "Epoch 85/100, Iteration 5/38, Loss: 0.5839483737945557\n",
      "Epoch 85/100, Iteration 6/38, Loss: 0.7027848958969116\n",
      "Epoch 85/100, Iteration 7/38, Loss: 0.7061577439308167\n",
      "Epoch 85/100, Iteration 8/38, Loss: 0.6106745600700378\n",
      "Epoch 85/100, Iteration 9/38, Loss: 0.6452803611755371\n",
      "Epoch 85/100, Iteration 10/38, Loss: 0.7028527855873108\n",
      "Epoch 85/100, Iteration 11/38, Loss: 0.700873613357544\n",
      "Epoch 85/100, Iteration 12/38, Loss: 0.6137225031852722\n",
      "Epoch 85/100, Iteration 13/38, Loss: 0.6460782289505005\n",
      "Epoch 85/100, Iteration 14/38, Loss: 0.6738097667694092\n",
      "Epoch 85/100, Iteration 15/38, Loss: 0.6417385339736938\n",
      "Epoch 85/100, Iteration 16/38, Loss: 0.6453616619110107\n",
      "Epoch 85/100, Iteration 17/38, Loss: 0.6427881717681885\n",
      "Epoch 85/100, Iteration 18/38, Loss: 0.5522429943084717\n",
      "Epoch 85/100, Iteration 19/38, Loss: 0.6427955031394958\n",
      "Epoch 85/100, Iteration 20/38, Loss: 0.5527693629264832\n",
      "Epoch 85/100, Iteration 21/38, Loss: 0.6715294122695923\n",
      "Epoch 85/100, Iteration 22/38, Loss: 0.7050146460533142\n",
      "Epoch 85/100, Iteration 23/38, Loss: 0.6119533777236938\n",
      "Epoch 85/100, Iteration 24/38, Loss: 0.6768830418586731\n",
      "Epoch 85/100, Iteration 25/38, Loss: 0.6146053075790405\n",
      "Epoch 85/100, Iteration 26/38, Loss: 0.6735495924949646\n",
      "Epoch 85/100, Iteration 27/38, Loss: 0.583598792552948\n",
      "Epoch 85/100, Iteration 28/38, Loss: 0.6100655794143677\n",
      "Epoch 85/100, Iteration 29/38, Loss: 0.5831570625305176\n",
      "Epoch 85/100, Iteration 30/38, Loss: 0.6743305325508118\n",
      "Epoch 85/100, Iteration 31/38, Loss: 0.6142423152923584\n",
      "Epoch 85/100, Iteration 32/38, Loss: 0.6456029415130615\n",
      "Epoch 85/100, Iteration 33/38, Loss: 0.6437711119651794\n",
      "Epoch 85/100, Iteration 34/38, Loss: 0.7044259905815125\n",
      "Epoch 85/100, Iteration 35/38, Loss: 0.6777113676071167\n",
      "Epoch 85/100, Iteration 36/38, Loss: 0.6455473899841309\n",
      "Epoch 85/100, Iteration 37/38, Loss: 0.6148263812065125\n",
      "Epoch 85/100, Iteration 38/38, Loss: 0.6143051385879517\n",
      "Epoch 86/100, Iteration 1/38, Loss: 0.6116915941238403\n",
      "Epoch 86/100, Iteration 2/38, Loss: 0.614915132522583\n",
      "Epoch 86/100, Iteration 3/38, Loss: 0.7033967971801758\n",
      "Epoch 86/100, Iteration 4/38, Loss: 0.6754727363586426\n",
      "Epoch 86/100, Iteration 5/38, Loss: 0.5832018852233887\n",
      "Epoch 86/100, Iteration 6/38, Loss: 0.5826209783554077\n",
      "Epoch 86/100, Iteration 7/38, Loss: 0.5518827438354492\n",
      "Epoch 86/100, Iteration 8/38, Loss: 0.6112625002861023\n",
      "Epoch 86/100, Iteration 9/38, Loss: 0.6761741638183594\n",
      "Epoch 86/100, Iteration 10/38, Loss: 0.6432456970214844\n",
      "Epoch 86/100, Iteration 11/38, Loss: 0.6778982281684875\n",
      "Epoch 86/100, Iteration 12/38, Loss: 0.6740546226501465\n",
      "Epoch 86/100, Iteration 13/38, Loss: 0.6427282691001892\n",
      "Epoch 86/100, Iteration 14/38, Loss: 0.7040202021598816\n",
      "Epoch 86/100, Iteration 15/38, Loss: 0.5832332372665405\n",
      "Epoch 86/100, Iteration 16/38, Loss: 0.5838114023208618\n",
      "Epoch 86/100, Iteration 17/38, Loss: 0.6686235666275024\n",
      "Epoch 86/100, Iteration 18/38, Loss: 0.6143688559532166\n",
      "Epoch 86/100, Iteration 19/38, Loss: 0.6451638340950012\n",
      "Epoch 86/100, Iteration 20/38, Loss: 0.7065263390541077\n",
      "Epoch 86/100, Iteration 21/38, Loss: 0.7349766492843628\n",
      "Epoch 86/100, Iteration 22/38, Loss: 0.6148462891578674\n",
      "Epoch 86/100, Iteration 23/38, Loss: 0.5834277272224426\n",
      "Epoch 86/100, Iteration 24/38, Loss: 0.6158732771873474\n",
      "Epoch 86/100, Iteration 25/38, Loss: 0.6718060970306396\n",
      "Epoch 86/100, Iteration 26/38, Loss: 0.7025261521339417\n",
      "Epoch 86/100, Iteration 27/38, Loss: 0.6455796957015991\n",
      "Epoch 86/100, Iteration 28/38, Loss: 0.6426548361778259\n",
      "Epoch 86/100, Iteration 29/38, Loss: 0.612716555595398\n",
      "Epoch 86/100, Iteration 30/38, Loss: 0.702365517616272\n",
      "Epoch 86/100, Iteration 31/38, Loss: 0.615170419216156\n",
      "Epoch 86/100, Iteration 32/38, Loss: 0.6690133810043335\n",
      "Epoch 86/100, Iteration 33/38, Loss: 0.6745361685752869\n",
      "Epoch 86/100, Iteration 34/38, Loss: 0.5830255150794983\n",
      "Epoch 86/100, Iteration 35/38, Loss: 0.6739533543586731\n",
      "Epoch 86/100, Iteration 36/38, Loss: 0.5830888748168945\n",
      "Epoch 86/100, Iteration 37/38, Loss: 0.6142333745956421\n",
      "Epoch 86/100, Iteration 38/38, Loss: 0.5533640384674072\n",
      "Epoch 87/100, Iteration 1/38, Loss: 0.6461458206176758\n",
      "Epoch 87/100, Iteration 2/38, Loss: 0.6089227199554443\n",
      "Epoch 87/100, Iteration 3/38, Loss: 0.6436375379562378\n",
      "Epoch 87/100, Iteration 4/38, Loss: 0.6461050510406494\n",
      "Epoch 87/100, Iteration 5/38, Loss: 0.6454190611839294\n",
      "Epoch 87/100, Iteration 6/38, Loss: 0.5805695652961731\n",
      "Epoch 87/100, Iteration 7/38, Loss: 0.6913368701934814\n",
      "Epoch 87/100, Iteration 8/38, Loss: 0.7017750144004822\n",
      "Epoch 87/100, Iteration 9/38, Loss: 0.5832695960998535\n",
      "Epoch 87/100, Iteration 10/38, Loss: 0.6435441374778748\n",
      "Epoch 87/100, Iteration 11/38, Loss: 0.646350085735321\n",
      "Epoch 87/100, Iteration 12/38, Loss: 0.7028063535690308\n",
      "Epoch 87/100, Iteration 13/38, Loss: 0.6149415373802185\n",
      "Epoch 87/100, Iteration 14/38, Loss: 0.7371959090232849\n",
      "Epoch 87/100, Iteration 15/38, Loss: 0.6395678520202637\n",
      "Epoch 87/100, Iteration 16/38, Loss: 0.6149736046791077\n",
      "Epoch 87/100, Iteration 17/38, Loss: 0.646356999874115\n",
      "Epoch 87/100, Iteration 18/38, Loss: 0.6741373538970947\n",
      "Epoch 87/100, Iteration 19/38, Loss: 0.6736056208610535\n",
      "Epoch 87/100, Iteration 20/38, Loss: 0.5834681391716003\n",
      "Epoch 87/100, Iteration 21/38, Loss: 0.6744332313537598\n",
      "Epoch 87/100, Iteration 22/38, Loss: 0.6709367036819458\n",
      "Epoch 87/100, Iteration 23/38, Loss: 0.7058892250061035\n",
      "Epoch 87/100, Iteration 24/38, Loss: 0.5833402276039124\n",
      "Epoch 87/100, Iteration 25/38, Loss: 0.7057502269744873\n",
      "Epoch 87/100, Iteration 26/38, Loss: 0.7039632201194763\n",
      "Epoch 87/100, Iteration 27/38, Loss: 0.6404719948768616\n",
      "Epoch 87/100, Iteration 28/38, Loss: 0.6446503400802612\n",
      "Epoch 87/100, Iteration 29/38, Loss: 0.5835235118865967\n",
      "Epoch 87/100, Iteration 30/38, Loss: 0.6444387435913086\n",
      "Epoch 87/100, Iteration 31/38, Loss: 0.5838027596473694\n",
      "Epoch 87/100, Iteration 32/38, Loss: 0.5838292241096497\n",
      "Epoch 87/100, Iteration 33/38, Loss: 0.6120741963386536\n",
      "Epoch 87/100, Iteration 34/38, Loss: 0.67658531665802\n",
      "Epoch 87/100, Iteration 35/38, Loss: 0.6098160743713379\n",
      "Epoch 87/100, Iteration 36/38, Loss: 0.5517940521240234\n",
      "Epoch 87/100, Iteration 37/38, Loss: 0.5833284258842468\n",
      "Epoch 87/100, Iteration 38/38, Loss: 0.5521494746208191\n",
      "Epoch 88/100, Iteration 1/38, Loss: 0.6457251906394958\n",
      "Epoch 88/100, Iteration 2/38, Loss: 0.614159345626831\n",
      "Epoch 88/100, Iteration 3/38, Loss: 0.6744630932807922\n",
      "Epoch 88/100, Iteration 4/38, Loss: 0.5831959843635559\n",
      "Epoch 88/100, Iteration 5/38, Loss: 0.6146873831748962\n",
      "Epoch 88/100, Iteration 6/38, Loss: 0.5521441102027893\n",
      "Epoch 88/100, Iteration 7/38, Loss: 0.5801199674606323\n",
      "Epoch 88/100, Iteration 8/38, Loss: 0.7048550844192505\n",
      "Epoch 88/100, Iteration 9/38, Loss: 0.6470939517021179\n",
      "Epoch 88/100, Iteration 10/38, Loss: 0.6711742877960205\n",
      "Epoch 88/100, Iteration 11/38, Loss: 0.646145761013031\n",
      "Epoch 88/100, Iteration 12/38, Loss: 0.6763495206832886\n",
      "Epoch 88/100, Iteration 13/38, Loss: 0.6692513823509216\n",
      "Epoch 88/100, Iteration 14/38, Loss: 0.6441501379013062\n",
      "Epoch 88/100, Iteration 15/38, Loss: 0.6728962659835815\n",
      "Epoch 88/100, Iteration 16/38, Loss: 0.6757116317749023\n",
      "Epoch 88/100, Iteration 17/38, Loss: 0.7608426213264465\n",
      "Epoch 88/100, Iteration 18/38, Loss: 0.5803166031837463\n",
      "Epoch 88/100, Iteration 19/38, Loss: 0.5835895538330078\n",
      "Epoch 88/100, Iteration 20/38, Loss: 0.6437367796897888\n",
      "Epoch 88/100, Iteration 21/38, Loss: 0.6442777514457703\n",
      "Epoch 88/100, Iteration 22/38, Loss: 0.6437194347381592\n",
      "Epoch 88/100, Iteration 23/38, Loss: 0.6101080775260925\n",
      "Epoch 88/100, Iteration 24/38, Loss: 0.6459360718727112\n",
      "Epoch 88/100, Iteration 25/38, Loss: 0.6767629981040955\n",
      "Epoch 88/100, Iteration 26/38, Loss: 0.5830870866775513\n",
      "Epoch 88/100, Iteration 27/38, Loss: 0.5521246194839478\n",
      "Epoch 88/100, Iteration 28/38, Loss: 0.6146315336227417\n",
      "Epoch 88/100, Iteration 29/38, Loss: 0.6117749214172363\n",
      "Epoch 88/100, Iteration 30/38, Loss: 0.6412879228591919\n",
      "Epoch 88/100, Iteration 31/38, Loss: 0.6436115503311157\n",
      "Epoch 88/100, Iteration 32/38, Loss: 0.6137576103210449\n",
      "Epoch 88/100, Iteration 33/38, Loss: 0.6450597643852234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100, Iteration 34/38, Loss: 0.5833593010902405\n",
      "Epoch 88/100, Iteration 35/38, Loss: 0.7287307977676392\n",
      "Epoch 88/100, Iteration 36/38, Loss: 0.7054104804992676\n",
      "Epoch 88/100, Iteration 37/38, Loss: 0.6124500036239624\n",
      "Epoch 88/100, Iteration 38/38, Loss: 0.6766003966331482\n",
      "Epoch 89/100, Iteration 1/38, Loss: 0.5519095659255981\n",
      "Epoch 89/100, Iteration 2/38, Loss: 0.5523531436920166\n",
      "Epoch 89/100, Iteration 3/38, Loss: 0.5831915736198425\n",
      "Epoch 89/100, Iteration 4/38, Loss: 0.643221378326416\n",
      "Epoch 89/100, Iteration 5/38, Loss: 0.6132451891899109\n",
      "Epoch 89/100, Iteration 6/38, Loss: 0.6418497562408447\n",
      "Epoch 89/100, Iteration 7/38, Loss: 0.6444260478019714\n",
      "Epoch 89/100, Iteration 8/38, Loss: 0.6763362884521484\n",
      "Epoch 89/100, Iteration 9/38, Loss: 0.6456876993179321\n",
      "Epoch 89/100, Iteration 10/38, Loss: 0.6426973938941956\n",
      "Epoch 89/100, Iteration 11/38, Loss: 0.5830866694450378\n",
      "Epoch 89/100, Iteration 12/38, Loss: 0.6428201198577881\n",
      "Epoch 89/100, Iteration 13/38, Loss: 0.6372548341751099\n",
      "Epoch 89/100, Iteration 14/38, Loss: 0.6165196299552917\n",
      "Epoch 89/100, Iteration 15/38, Loss: 0.6120739579200745\n",
      "Epoch 89/100, Iteration 16/38, Loss: 0.7059757709503174\n",
      "Epoch 89/100, Iteration 17/38, Loss: 0.6109141111373901\n",
      "Epoch 89/100, Iteration 18/38, Loss: 0.6129809021949768\n",
      "Epoch 89/100, Iteration 19/38, Loss: 0.615024745464325\n",
      "Epoch 89/100, Iteration 20/38, Loss: 0.7686335444450378\n",
      "Epoch 89/100, Iteration 21/38, Loss: 0.614603579044342\n",
      "Epoch 89/100, Iteration 22/38, Loss: 0.8253908753395081\n",
      "Epoch 89/100, Iteration 23/38, Loss: 0.613048255443573\n",
      "Epoch 89/100, Iteration 24/38, Loss: 0.6461277008056641\n",
      "Epoch 89/100, Iteration 25/38, Loss: 0.6161872744560242\n",
      "Epoch 89/100, Iteration 26/38, Loss: 0.6994879245758057\n",
      "Epoch 89/100, Iteration 27/38, Loss: 0.6760015487670898\n",
      "Epoch 89/100, Iteration 28/38, Loss: 0.5806994438171387\n",
      "Epoch 89/100, Iteration 29/38, Loss: 0.674328625202179\n",
      "Epoch 89/100, Iteration 30/38, Loss: 0.645079493522644\n",
      "Epoch 89/100, Iteration 31/38, Loss: 0.6425382494926453\n",
      "Epoch 89/100, Iteration 32/38, Loss: 0.6148298382759094\n",
      "Epoch 89/100, Iteration 33/38, Loss: 0.7081795930862427\n",
      "Epoch 89/100, Iteration 34/38, Loss: 0.6117441654205322\n",
      "Epoch 89/100, Iteration 35/38, Loss: 0.6119887232780457\n",
      "Epoch 89/100, Iteration 36/38, Loss: 0.614322304725647\n",
      "Epoch 89/100, Iteration 37/38, Loss: 0.6423895359039307\n",
      "Epoch 89/100, Iteration 38/38, Loss: 0.5520042777061462\n",
      "Epoch 90/100, Iteration 1/38, Loss: 0.6445973515510559\n",
      "Epoch 90/100, Iteration 2/38, Loss: 0.6143581867218018\n",
      "Epoch 90/100, Iteration 3/38, Loss: 0.7061585783958435\n",
      "Epoch 90/100, Iteration 4/38, Loss: 0.6458588242530823\n",
      "Epoch 90/100, Iteration 5/38, Loss: 0.6148254871368408\n",
      "Epoch 90/100, Iteration 6/38, Loss: 0.6756802797317505\n",
      "Epoch 90/100, Iteration 7/38, Loss: 0.6431269645690918\n",
      "Epoch 90/100, Iteration 8/38, Loss: 0.6105529069900513\n",
      "Epoch 90/100, Iteration 9/38, Loss: 0.7335373759269714\n",
      "Epoch 90/100, Iteration 10/38, Loss: 0.6130846738815308\n",
      "Epoch 90/100, Iteration 11/38, Loss: 0.6746793389320374\n",
      "Epoch 90/100, Iteration 12/38, Loss: 0.5518902540206909\n",
      "Epoch 90/100, Iteration 13/38, Loss: 0.6429523229598999\n",
      "Epoch 90/100, Iteration 14/38, Loss: 0.6116650104522705\n",
      "Epoch 90/100, Iteration 15/38, Loss: 0.6442427635192871\n",
      "Epoch 90/100, Iteration 16/38, Loss: 0.6131523251533508\n",
      "Epoch 90/100, Iteration 17/38, Loss: 0.552579402923584\n",
      "Epoch 90/100, Iteration 18/38, Loss: 0.583260178565979\n",
      "Epoch 90/100, Iteration 19/38, Loss: 0.7369037866592407\n",
      "Epoch 90/100, Iteration 20/38, Loss: 0.6737730503082275\n",
      "Epoch 90/100, Iteration 21/38, Loss: 0.6625402569770813\n",
      "Epoch 90/100, Iteration 22/38, Loss: 0.614650309085846\n",
      "Epoch 90/100, Iteration 23/38, Loss: 0.7376278638839722\n",
      "Epoch 90/100, Iteration 24/38, Loss: 0.6454718112945557\n",
      "Epoch 90/100, Iteration 25/38, Loss: 0.6412032246589661\n",
      "Epoch 90/100, Iteration 26/38, Loss: 0.5849006772041321\n",
      "Epoch 90/100, Iteration 27/38, Loss: 0.7361570000648499\n",
      "Epoch 90/100, Iteration 28/38, Loss: 0.6748625040054321\n",
      "Epoch 90/100, Iteration 29/38, Loss: 0.6121140718460083\n",
      "Epoch 90/100, Iteration 30/38, Loss: 0.5525735020637512\n",
      "Epoch 90/100, Iteration 31/38, Loss: 0.6445114612579346\n",
      "Epoch 90/100, Iteration 32/38, Loss: 0.6097182631492615\n",
      "Epoch 90/100, Iteration 33/38, Loss: 0.6433851718902588\n",
      "Epoch 90/100, Iteration 34/38, Loss: 0.6118471622467041\n",
      "Epoch 90/100, Iteration 35/38, Loss: 0.5835180282592773\n",
      "Epoch 90/100, Iteration 36/38, Loss: 0.5521870255470276\n",
      "Epoch 90/100, Iteration 37/38, Loss: 0.6681459546089172\n",
      "Epoch 90/100, Iteration 38/38, Loss: 0.6701595783233643\n",
      "Epoch 91/100, Iteration 1/38, Loss: 0.6130078434944153\n",
      "Epoch 91/100, Iteration 2/38, Loss: 0.6418539881706238\n",
      "Epoch 91/100, Iteration 3/38, Loss: 0.7347765564918518\n",
      "Epoch 91/100, Iteration 4/38, Loss: 0.6418793201446533\n",
      "Epoch 91/100, Iteration 5/38, Loss: 0.6115853786468506\n",
      "Epoch 91/100, Iteration 6/38, Loss: 0.614705502986908\n",
      "Epoch 91/100, Iteration 7/38, Loss: 0.6445298790931702\n",
      "Epoch 91/100, Iteration 8/38, Loss: 0.6167576313018799\n",
      "Epoch 91/100, Iteration 9/38, Loss: 0.6423102617263794\n",
      "Epoch 91/100, Iteration 10/38, Loss: 0.6458186507225037\n",
      "Epoch 91/100, Iteration 11/38, Loss: 0.643280565738678\n",
      "Epoch 91/100, Iteration 12/38, Loss: 0.7671939730644226\n",
      "Epoch 91/100, Iteration 13/38, Loss: 0.6456406116485596\n",
      "Epoch 91/100, Iteration 14/38, Loss: 0.6714099049568176\n",
      "Epoch 91/100, Iteration 15/38, Loss: 0.6338117122650146\n",
      "Epoch 91/100, Iteration 16/38, Loss: 0.5849792957305908\n",
      "Epoch 91/100, Iteration 17/38, Loss: 0.6723376512527466\n",
      "Epoch 91/100, Iteration 18/38, Loss: 0.6161478161811829\n",
      "Epoch 91/100, Iteration 19/38, Loss: 0.5905797481536865\n",
      "Epoch 91/100, Iteration 20/38, Loss: 0.6355071067810059\n",
      "Epoch 91/100, Iteration 21/38, Loss: 0.6199084520339966\n",
      "Epoch 91/100, Iteration 22/38, Loss: 0.64588463306427\n",
      "Epoch 91/100, Iteration 23/38, Loss: 0.6782981753349304\n",
      "Epoch 91/100, Iteration 24/38, Loss: 0.6779762506484985\n",
      "Epoch 91/100, Iteration 25/38, Loss: 0.6102283596992493\n",
      "Epoch 91/100, Iteration 26/38, Loss: 0.581203043460846\n",
      "Epoch 91/100, Iteration 27/38, Loss: 0.5870605707168579\n",
      "Epoch 91/100, Iteration 28/38, Loss: 0.643341064453125\n",
      "Epoch 91/100, Iteration 29/38, Loss: 0.6459413766860962\n",
      "Epoch 91/100, Iteration 30/38, Loss: 0.6108176708221436\n",
      "Epoch 91/100, Iteration 31/38, Loss: 0.6111347079277039\n",
      "Epoch 91/100, Iteration 32/38, Loss: 0.679216206073761\n",
      "Epoch 91/100, Iteration 33/38, Loss: 0.6116927266120911\n",
      "Epoch 91/100, Iteration 34/38, Loss: 0.6087492108345032\n",
      "Epoch 91/100, Iteration 35/38, Loss: 0.615250289440155\n",
      "Epoch 91/100, Iteration 36/38, Loss: 0.647968590259552\n",
      "Epoch 91/100, Iteration 37/38, Loss: 0.6424903273582458\n",
      "Epoch 91/100, Iteration 38/38, Loss: 0.6153030395507812\n",
      "Epoch 92/100, Iteration 1/38, Loss: 0.6151064038276672\n",
      "Epoch 92/100, Iteration 2/38, Loss: 0.6466537117958069\n",
      "Epoch 92/100, Iteration 3/38, Loss: 0.6743800044059753\n",
      "Epoch 92/100, Iteration 4/38, Loss: 0.5517177581787109\n",
      "Epoch 92/100, Iteration 5/38, Loss: 0.6122323274612427\n",
      "Epoch 92/100, Iteration 6/38, Loss: 0.6430184841156006\n",
      "Epoch 92/100, Iteration 7/38, Loss: 0.6434401869773865\n",
      "Epoch 92/100, Iteration 8/38, Loss: 0.6136322021484375\n",
      "Epoch 92/100, Iteration 9/38, Loss: 0.6768787503242493\n",
      "Epoch 92/100, Iteration 10/38, Loss: 0.6767897605895996\n",
      "Epoch 92/100, Iteration 11/38, Loss: 0.5801945924758911\n",
      "Epoch 92/100, Iteration 12/38, Loss: 0.6412053108215332\n",
      "Epoch 92/100, Iteration 13/38, Loss: 0.6767640113830566\n",
      "Epoch 92/100, Iteration 14/38, Loss: 0.5546230673789978\n",
      "Epoch 92/100, Iteration 15/38, Loss: 0.6359646320343018\n",
      "Epoch 92/100, Iteration 16/38, Loss: 0.6406967043876648\n",
      "Epoch 92/100, Iteration 17/38, Loss: 0.6444675326347351\n",
      "Epoch 92/100, Iteration 18/38, Loss: 0.6457664370536804\n",
      "Epoch 92/100, Iteration 19/38, Loss: 0.6989158987998962\n",
      "Epoch 92/100, Iteration 20/38, Loss: 0.6450228691101074\n",
      "Epoch 92/100, Iteration 21/38, Loss: 0.6743233799934387\n",
      "Epoch 92/100, Iteration 22/38, Loss: 0.5813089609146118\n",
      "Epoch 92/100, Iteration 23/38, Loss: 0.6130411028862\n",
      "Epoch 92/100, Iteration 24/38, Loss: 0.6125021576881409\n",
      "Epoch 92/100, Iteration 25/38, Loss: 0.7075865864753723\n",
      "Epoch 92/100, Iteration 26/38, Loss: 0.6748705506324768\n",
      "Epoch 92/100, Iteration 27/38, Loss: 0.6132407784461975\n",
      "Epoch 92/100, Iteration 28/38, Loss: 0.5823146104812622\n",
      "Epoch 92/100, Iteration 29/38, Loss: 0.6148123145103455\n",
      "Epoch 92/100, Iteration 30/38, Loss: 0.643813967704773\n",
      "Epoch 92/100, Iteration 31/38, Loss: 0.6157459020614624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100, Iteration 32/38, Loss: 0.7035191655158997\n",
      "Epoch 92/100, Iteration 33/38, Loss: 0.642069935798645\n",
      "Epoch 92/100, Iteration 34/38, Loss: 0.5520333051681519\n",
      "Epoch 92/100, Iteration 35/38, Loss: 0.6469534039497375\n",
      "Epoch 92/100, Iteration 36/38, Loss: 0.6411722898483276\n",
      "Epoch 92/100, Iteration 37/38, Loss: 0.6436905860900879\n",
      "Epoch 92/100, Iteration 38/38, Loss: 0.6776273250579834\n",
      "Epoch 93/100, Iteration 1/38, Loss: 0.5840677618980408\n",
      "Epoch 93/100, Iteration 2/38, Loss: 0.6453245878219604\n",
      "Epoch 93/100, Iteration 3/38, Loss: 0.6740599274635315\n",
      "Epoch 93/100, Iteration 4/38, Loss: 0.6741501092910767\n",
      "Epoch 93/100, Iteration 5/38, Loss: 0.6406538486480713\n",
      "Epoch 93/100, Iteration 6/38, Loss: 0.6151351928710938\n",
      "Epoch 93/100, Iteration 7/38, Loss: 0.5832090377807617\n",
      "Epoch 93/100, Iteration 8/38, Loss: 0.5536106824874878\n",
      "Epoch 93/100, Iteration 9/38, Loss: 0.7375155091285706\n",
      "Epoch 93/100, Iteration 10/38, Loss: 0.5518897175788879\n",
      "Epoch 93/100, Iteration 11/38, Loss: 0.6141250729560852\n",
      "Epoch 93/100, Iteration 12/38, Loss: 0.7048965096473694\n",
      "Epoch 93/100, Iteration 13/38, Loss: 0.6148420572280884\n",
      "Epoch 93/100, Iteration 14/38, Loss: 0.7377414107322693\n",
      "Epoch 93/100, Iteration 15/38, Loss: 0.6716972589492798\n",
      "Epoch 93/100, Iteration 16/38, Loss: 0.6674696803092957\n",
      "Epoch 93/100, Iteration 17/38, Loss: 0.6174225211143494\n",
      "Epoch 93/100, Iteration 18/38, Loss: 0.6386139988899231\n",
      "Epoch 93/100, Iteration 19/38, Loss: 0.6115909814834595\n",
      "Epoch 93/100, Iteration 20/38, Loss: 0.6752878427505493\n",
      "Epoch 93/100, Iteration 21/38, Loss: 0.645655632019043\n",
      "Epoch 93/100, Iteration 22/38, Loss: 0.5805086493492126\n",
      "Epoch 93/100, Iteration 23/38, Loss: 0.6136879920959473\n",
      "Epoch 93/100, Iteration 24/38, Loss: 0.6164372563362122\n",
      "Epoch 93/100, Iteration 25/38, Loss: 0.6751992106437683\n",
      "Epoch 93/100, Iteration 26/38, Loss: 0.6112987995147705\n",
      "Epoch 93/100, Iteration 27/38, Loss: 0.6732930541038513\n",
      "Epoch 93/100, Iteration 28/38, Loss: 0.6132482886314392\n",
      "Epoch 93/100, Iteration 29/38, Loss: 0.6122136116027832\n",
      "Epoch 93/100, Iteration 30/38, Loss: 0.6425028443336487\n",
      "Epoch 93/100, Iteration 31/38, Loss: 0.676784873008728\n",
      "Epoch 93/100, Iteration 32/38, Loss: 0.5805169939994812\n",
      "Epoch 93/100, Iteration 33/38, Loss: 0.6117234230041504\n",
      "Epoch 93/100, Iteration 34/38, Loss: 0.7073116898536682\n",
      "Epoch 93/100, Iteration 35/38, Loss: 0.6716972589492798\n",
      "Epoch 93/100, Iteration 36/38, Loss: 0.6146239042282104\n",
      "Epoch 93/100, Iteration 37/38, Loss: 0.5802937150001526\n",
      "Epoch 93/100, Iteration 38/38, Loss: 0.5525286793708801\n",
      "Epoch 94/100, Iteration 1/38, Loss: 0.6745851039886475\n",
      "Epoch 94/100, Iteration 2/38, Loss: 0.6439485549926758\n",
      "Epoch 94/100, Iteration 3/38, Loss: 0.6140726208686829\n",
      "Epoch 94/100, Iteration 4/38, Loss: 0.6440042853355408\n",
      "Epoch 94/100, Iteration 5/38, Loss: 0.5805988311767578\n",
      "Epoch 94/100, Iteration 6/38, Loss: 0.6742069721221924\n",
      "Epoch 94/100, Iteration 7/38, Loss: 0.6778872609138489\n",
      "Epoch 94/100, Iteration 8/38, Loss: 0.582964301109314\n",
      "Epoch 94/100, Iteration 9/38, Loss: 0.6095108985900879\n",
      "Epoch 94/100, Iteration 10/38, Loss: 0.6737637519836426\n",
      "Epoch 94/100, Iteration 11/38, Loss: 0.7031800150871277\n",
      "Epoch 94/100, Iteration 12/38, Loss: 0.6422135233879089\n",
      "Epoch 94/100, Iteration 13/38, Loss: 0.6427729725837708\n",
      "Epoch 94/100, Iteration 14/38, Loss: 0.5517919659614563\n",
      "Epoch 94/100, Iteration 15/38, Loss: 0.6399831771850586\n",
      "Epoch 94/100, Iteration 16/38, Loss: 0.6734355688095093\n",
      "Epoch 94/100, Iteration 17/38, Loss: 0.7382023334503174\n",
      "Epoch 94/100, Iteration 18/38, Loss: 0.6433036923408508\n",
      "Epoch 94/100, Iteration 19/38, Loss: 0.6176883578300476\n",
      "Epoch 94/100, Iteration 20/38, Loss: 0.6149636507034302\n",
      "Epoch 94/100, Iteration 21/38, Loss: 0.7059183716773987\n",
      "Epoch 94/100, Iteration 22/38, Loss: 0.5519090890884399\n",
      "Epoch 94/100, Iteration 23/38, Loss: 0.6126208901405334\n",
      "Epoch 94/100, Iteration 24/38, Loss: 0.6433089971542358\n",
      "Epoch 94/100, Iteration 25/38, Loss: 0.6146798133850098\n",
      "Epoch 94/100, Iteration 26/38, Loss: 0.643687903881073\n",
      "Epoch 94/100, Iteration 27/38, Loss: 0.5801669359207153\n",
      "Epoch 94/100, Iteration 28/38, Loss: 0.6400101184844971\n",
      "Epoch 94/100, Iteration 29/38, Loss: 0.6456990838050842\n",
      "Epoch 94/100, Iteration 30/38, Loss: 0.6127896308898926\n",
      "Epoch 94/100, Iteration 31/38, Loss: 0.6443360447883606\n",
      "Epoch 94/100, Iteration 32/38, Loss: 0.646394670009613\n",
      "Epoch 94/100, Iteration 33/38, Loss: 0.551984965801239\n",
      "Epoch 94/100, Iteration 34/38, Loss: 0.6449894309043884\n",
      "Epoch 94/100, Iteration 35/38, Loss: 0.6434623003005981\n",
      "Epoch 94/100, Iteration 36/38, Loss: 0.6438028812408447\n",
      "Epoch 94/100, Iteration 37/38, Loss: 0.6142967939376831\n",
      "Epoch 94/100, Iteration 38/38, Loss: 0.6134313941001892\n",
      "Epoch 95/100, Iteration 1/38, Loss: 0.6399121880531311\n",
      "Epoch 95/100, Iteration 2/38, Loss: 0.7080955505371094\n",
      "Epoch 95/100, Iteration 3/38, Loss: 0.609382152557373\n",
      "Epoch 95/100, Iteration 4/38, Loss: 0.6724708676338196\n",
      "Epoch 95/100, Iteration 5/38, Loss: 0.676816999912262\n",
      "Epoch 95/100, Iteration 6/38, Loss: 0.6121498346328735\n",
      "Epoch 95/100, Iteration 7/38, Loss: 0.6435250639915466\n",
      "Epoch 95/100, Iteration 8/38, Loss: 0.5840151906013489\n",
      "Epoch 95/100, Iteration 9/38, Loss: 0.6423788666725159\n",
      "Epoch 95/100, Iteration 10/38, Loss: 0.6459997892379761\n",
      "Epoch 95/100, Iteration 11/38, Loss: 0.5833457112312317\n",
      "Epoch 95/100, Iteration 12/38, Loss: 0.671208381652832\n",
      "Epoch 95/100, Iteration 13/38, Loss: 0.5519346594810486\n",
      "Epoch 95/100, Iteration 14/38, Loss: 0.6416473388671875\n",
      "Epoch 95/100, Iteration 15/38, Loss: 0.5818583369255066\n",
      "Epoch 95/100, Iteration 16/38, Loss: 0.583182156085968\n",
      "Epoch 95/100, Iteration 17/38, Loss: 0.5519734621047974\n",
      "Epoch 95/100, Iteration 18/38, Loss: 0.5830504298210144\n",
      "Epoch 95/100, Iteration 19/38, Loss: 0.5831122398376465\n",
      "Epoch 95/100, Iteration 20/38, Loss: 0.5804337859153748\n",
      "Epoch 95/100, Iteration 21/38, Loss: 0.6143250465393066\n",
      "Epoch 95/100, Iteration 22/38, Loss: 0.5831760764122009\n",
      "Epoch 95/100, Iteration 23/38, Loss: 0.6735948324203491\n",
      "Epoch 95/100, Iteration 24/38, Loss: 0.6417316794395447\n",
      "Epoch 95/100, Iteration 25/38, Loss: 0.6770389676094055\n",
      "Epoch 95/100, Iteration 26/38, Loss: 0.6428868174552917\n",
      "Epoch 95/100, Iteration 27/38, Loss: 0.612007200717926\n",
      "Epoch 95/100, Iteration 28/38, Loss: 0.7064014077186584\n",
      "Epoch 95/100, Iteration 29/38, Loss: 0.7347874641418457\n",
      "Epoch 95/100, Iteration 30/38, Loss: 0.6444398164749146\n",
      "Epoch 95/100, Iteration 31/38, Loss: 0.644143283367157\n",
      "Epoch 95/100, Iteration 32/38, Loss: 0.6149284839630127\n",
      "Epoch 95/100, Iteration 33/38, Loss: 0.7596657276153564\n",
      "Epoch 95/100, Iteration 34/38, Loss: 0.7029446959495544\n",
      "Epoch 95/100, Iteration 35/38, Loss: 0.6410316824913025\n",
      "Epoch 95/100, Iteration 36/38, Loss: 0.6150823831558228\n",
      "Epoch 95/100, Iteration 37/38, Loss: 0.6145192384719849\n",
      "Epoch 95/100, Iteration 38/38, Loss: 0.6141112446784973\n",
      "Epoch 96/100, Iteration 1/38, Loss: 0.6123824119567871\n",
      "Epoch 96/100, Iteration 2/38, Loss: 0.6141477227210999\n",
      "Epoch 96/100, Iteration 3/38, Loss: 0.6741387844085693\n",
      "Epoch 96/100, Iteration 4/38, Loss: 0.6777103543281555\n",
      "Epoch 96/100, Iteration 5/38, Loss: 0.706620454788208\n",
      "Epoch 96/100, Iteration 6/38, Loss: 0.6145178079605103\n",
      "Epoch 96/100, Iteration 7/38, Loss: 0.6089355945587158\n",
      "Epoch 96/100, Iteration 8/38, Loss: 0.6432755589485168\n",
      "Epoch 96/100, Iteration 9/38, Loss: 0.7050617933273315\n",
      "Epoch 96/100, Iteration 10/38, Loss: 0.5809975862503052\n",
      "Epoch 96/100, Iteration 11/38, Loss: 0.5832056999206543\n",
      "Epoch 96/100, Iteration 12/38, Loss: 0.6449595093727112\n",
      "Epoch 96/100, Iteration 13/38, Loss: 0.5806687474250793\n",
      "Epoch 96/100, Iteration 14/38, Loss: 0.6725648641586304\n",
      "Epoch 96/100, Iteration 15/38, Loss: 0.6118764281272888\n",
      "Epoch 96/100, Iteration 16/38, Loss: 0.6455159187316895\n",
      "Epoch 96/100, Iteration 17/38, Loss: 0.6118130683898926\n",
      "Epoch 96/100, Iteration 18/38, Loss: 0.5802631378173828\n",
      "Epoch 96/100, Iteration 19/38, Loss: 0.6091383695602417\n",
      "Epoch 96/100, Iteration 20/38, Loss: 0.6078601479530334\n",
      "Epoch 96/100, Iteration 21/38, Loss: 0.6394434571266174\n",
      "Epoch 96/100, Iteration 22/38, Loss: 0.7370036840438843\n",
      "Epoch 96/100, Iteration 23/38, Loss: 0.6745144724845886\n",
      "Epoch 96/100, Iteration 24/38, Loss: 0.617099404335022\n",
      "Epoch 96/100, Iteration 25/38, Loss: 0.55214923620224\n",
      "Epoch 96/100, Iteration 26/38, Loss: 0.6713864803314209\n",
      "Epoch 96/100, Iteration 27/38, Loss: 0.7353413105010986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100, Iteration 28/38, Loss: 0.6141887903213501\n",
      "Epoch 96/100, Iteration 29/38, Loss: 0.6116254329681396\n",
      "Epoch 96/100, Iteration 30/38, Loss: 0.6127201318740845\n",
      "Epoch 96/100, Iteration 31/38, Loss: 0.6146210432052612\n",
      "Epoch 96/100, Iteration 32/38, Loss: 0.7032940983772278\n",
      "Epoch 96/100, Iteration 33/38, Loss: 0.6414225101470947\n",
      "Epoch 96/100, Iteration 34/38, Loss: 0.6766545176506042\n",
      "Epoch 96/100, Iteration 35/38, Loss: 0.6737673282623291\n",
      "Epoch 96/100, Iteration 36/38, Loss: 0.5803689956665039\n",
      "Epoch 96/100, Iteration 37/38, Loss: 0.5805637240409851\n",
      "Epoch 96/100, Iteration 38/38, Loss: 0.5522295832633972\n",
      "Epoch 97/100, Iteration 1/38, Loss: 0.6452049612998962\n",
      "Epoch 97/100, Iteration 2/38, Loss: 0.6430579423904419\n",
      "Epoch 97/100, Iteration 3/38, Loss: 0.6442119479179382\n",
      "Epoch 97/100, Iteration 4/38, Loss: 0.6135693788528442\n",
      "Epoch 97/100, Iteration 5/38, Loss: 0.6120125651359558\n",
      "Epoch 97/100, Iteration 6/38, Loss: 0.6753172278404236\n",
      "Epoch 97/100, Iteration 7/38, Loss: 0.6146323680877686\n",
      "Epoch 97/100, Iteration 8/38, Loss: 0.7054893374443054\n",
      "Epoch 97/100, Iteration 9/38, Loss: 0.6119779944419861\n",
      "Epoch 97/100, Iteration 10/38, Loss: 0.6114922761917114\n",
      "Epoch 97/100, Iteration 11/38, Loss: 0.6432069540023804\n",
      "Epoch 97/100, Iteration 12/38, Loss: 0.6456001996994019\n",
      "Epoch 97/100, Iteration 13/38, Loss: 0.7035393118858337\n",
      "Epoch 97/100, Iteration 14/38, Loss: 0.5833377242088318\n",
      "Epoch 97/100, Iteration 15/38, Loss: 0.7053698897361755\n",
      "Epoch 97/100, Iteration 16/38, Loss: 0.6742503643035889\n",
      "Epoch 97/100, Iteration 17/38, Loss: 0.6454386711120605\n",
      "Epoch 97/100, Iteration 18/38, Loss: 0.672653317451477\n",
      "Epoch 97/100, Iteration 19/38, Loss: 0.6148638725280762\n",
      "Epoch 97/100, Iteration 20/38, Loss: 0.5833057165145874\n",
      "Epoch 97/100, Iteration 21/38, Loss: 0.6444064974784851\n",
      "Epoch 97/100, Iteration 22/38, Loss: 0.6114445924758911\n",
      "Epoch 97/100, Iteration 23/38, Loss: 0.6111266613006592\n",
      "Epoch 97/100, Iteration 24/38, Loss: 0.6705012917518616\n",
      "Epoch 97/100, Iteration 25/38, Loss: 0.7065833806991577\n",
      "Epoch 97/100, Iteration 26/38, Loss: 0.5521912574768066\n",
      "Epoch 97/100, Iteration 27/38, Loss: 0.6144811511039734\n",
      "Epoch 97/100, Iteration 28/38, Loss: 0.6428843140602112\n",
      "Epoch 97/100, Iteration 29/38, Loss: 0.6127244830131531\n",
      "Epoch 97/100, Iteration 30/38, Loss: 0.6149138808250427\n",
      "Epoch 97/100, Iteration 31/38, Loss: 0.6433916687965393\n",
      "Epoch 97/100, Iteration 32/38, Loss: 0.6448742747306824\n",
      "Epoch 97/100, Iteration 33/38, Loss: 0.6112115383148193\n",
      "Epoch 97/100, Iteration 34/38, Loss: 0.5836428999900818\n",
      "Epoch 97/100, Iteration 35/38, Loss: 0.5516679883003235\n",
      "Epoch 97/100, Iteration 36/38, Loss: 0.5834376811981201\n",
      "Epoch 97/100, Iteration 37/38, Loss: 0.6416295170783997\n",
      "Epoch 97/100, Iteration 38/38, Loss: 0.7398881912231445\n",
      "Epoch 98/100, Iteration 1/38, Loss: 0.6120272874832153\n",
      "Epoch 98/100, Iteration 2/38, Loss: 0.643360435962677\n",
      "Epoch 98/100, Iteration 3/38, Loss: 0.7050750255584717\n",
      "Epoch 98/100, Iteration 4/38, Loss: 0.5528011918067932\n",
      "Epoch 98/100, Iteration 5/38, Loss: 0.6772109270095825\n",
      "Epoch 98/100, Iteration 6/38, Loss: 0.5805589556694031\n",
      "Epoch 98/100, Iteration 7/38, Loss: 0.6118562817573547\n",
      "Epoch 98/100, Iteration 8/38, Loss: 0.7363870739936829\n",
      "Epoch 98/100, Iteration 9/38, Loss: 0.5832048058509827\n",
      "Epoch 98/100, Iteration 10/38, Loss: 0.5806068778038025\n",
      "Epoch 98/100, Iteration 11/38, Loss: 0.643579363822937\n",
      "Epoch 98/100, Iteration 12/38, Loss: 0.7374783754348755\n",
      "Epoch 98/100, Iteration 13/38, Loss: 0.6455496549606323\n",
      "Epoch 98/100, Iteration 14/38, Loss: 0.5520369410514832\n",
      "Epoch 98/100, Iteration 15/38, Loss: 0.5800464153289795\n",
      "Epoch 98/100, Iteration 16/38, Loss: 0.6118640303611755\n",
      "Epoch 98/100, Iteration 17/38, Loss: 0.6719251871109009\n",
      "Epoch 98/100, Iteration 18/38, Loss: 0.6764442920684814\n",
      "Epoch 98/100, Iteration 19/38, Loss: 0.6429874897003174\n",
      "Epoch 98/100, Iteration 20/38, Loss: 0.6443240642547607\n",
      "Epoch 98/100, Iteration 21/38, Loss: 0.674348771572113\n",
      "Epoch 98/100, Iteration 22/38, Loss: 0.6760118007659912\n",
      "Epoch 98/100, Iteration 23/38, Loss: 0.5839611887931824\n",
      "Epoch 98/100, Iteration 24/38, Loss: 0.6434412002563477\n",
      "Epoch 98/100, Iteration 25/38, Loss: 0.5836561322212219\n",
      "Epoch 98/100, Iteration 26/38, Loss: 0.5816371440887451\n",
      "Epoch 98/100, Iteration 27/38, Loss: 0.6144360899925232\n",
      "Epoch 98/100, Iteration 28/38, Loss: 0.5519068241119385\n",
      "Epoch 98/100, Iteration 29/38, Loss: 0.6146197319030762\n",
      "Epoch 98/100, Iteration 30/38, Loss: 0.5826813578605652\n",
      "Epoch 98/100, Iteration 31/38, Loss: 0.6142247319221497\n",
      "Epoch 98/100, Iteration 32/38, Loss: 0.7066723108291626\n",
      "Epoch 98/100, Iteration 33/38, Loss: 0.6737619638442993\n",
      "Epoch 98/100, Iteration 34/38, Loss: 0.6139253377914429\n",
      "Epoch 98/100, Iteration 35/38, Loss: 0.6582241654396057\n",
      "Epoch 98/100, Iteration 36/38, Loss: 0.739248514175415\n",
      "Epoch 98/100, Iteration 37/38, Loss: 0.6730682849884033\n",
      "Epoch 98/100, Iteration 38/38, Loss: 0.5517508387565613\n",
      "Epoch 99/100, Iteration 1/38, Loss: 0.6148074865341187\n",
      "Epoch 99/100, Iteration 2/38, Loss: 0.5833151936531067\n",
      "Epoch 99/100, Iteration 3/38, Loss: 0.6118655800819397\n",
      "Epoch 99/100, Iteration 4/38, Loss: 0.5846166610717773\n",
      "Epoch 99/100, Iteration 5/38, Loss: 0.6405707597732544\n",
      "Epoch 99/100, Iteration 6/38, Loss: 0.583077609539032\n",
      "Epoch 99/100, Iteration 7/38, Loss: 0.672205924987793\n",
      "Epoch 99/100, Iteration 8/38, Loss: 0.6429330706596375\n",
      "Epoch 99/100, Iteration 9/38, Loss: 0.6705355644226074\n",
      "Epoch 99/100, Iteration 10/38, Loss: 0.551859438419342\n",
      "Epoch 99/100, Iteration 11/38, Loss: 0.6149959564208984\n",
      "Epoch 99/100, Iteration 12/38, Loss: 0.5830660462379456\n",
      "Epoch 99/100, Iteration 13/38, Loss: 0.7385626435279846\n",
      "Epoch 99/100, Iteration 14/38, Loss: 0.6431846022605896\n",
      "Epoch 99/100, Iteration 15/38, Loss: 0.6459239721298218\n",
      "Epoch 99/100, Iteration 16/38, Loss: 0.6769858002662659\n",
      "Epoch 99/100, Iteration 17/38, Loss: 0.6430692672729492\n",
      "Epoch 99/100, Iteration 18/38, Loss: 0.7050480246543884\n",
      "Epoch 99/100, Iteration 19/38, Loss: 0.6143498420715332\n",
      "Epoch 99/100, Iteration 20/38, Loss: 0.6399904489517212\n",
      "Epoch 99/100, Iteration 21/38, Loss: 0.6149499416351318\n",
      "Epoch 99/100, Iteration 22/38, Loss: 0.6434121131896973\n",
      "Epoch 99/100, Iteration 23/38, Loss: 0.583023726940155\n",
      "Epoch 99/100, Iteration 24/38, Loss: 0.6413397192955017\n",
      "Epoch 99/100, Iteration 25/38, Loss: 0.7016369104385376\n",
      "Epoch 99/100, Iteration 26/38, Loss: 0.616550862789154\n",
      "Epoch 99/100, Iteration 27/38, Loss: 0.5522041916847229\n",
      "Epoch 99/100, Iteration 28/38, Loss: 0.6142357587814331\n",
      "Epoch 99/100, Iteration 29/38, Loss: 0.6693053841590881\n",
      "Epoch 99/100, Iteration 30/38, Loss: 0.5838055610656738\n",
      "Epoch 99/100, Iteration 31/38, Loss: 0.7375000715255737\n",
      "Epoch 99/100, Iteration 32/38, Loss: 0.675236701965332\n",
      "Epoch 99/100, Iteration 33/38, Loss: 0.5834803581237793\n",
      "Epoch 99/100, Iteration 34/38, Loss: 0.6764813661575317\n",
      "Epoch 99/100, Iteration 35/38, Loss: 0.6120008826255798\n",
      "Epoch 99/100, Iteration 36/38, Loss: 0.5802133679389954\n",
      "Epoch 99/100, Iteration 37/38, Loss: 0.6707834005355835\n",
      "Epoch 99/100, Iteration 38/38, Loss: 0.6142046451568604\n",
      "Epoch 100/100, Iteration 1/38, Loss: 0.7053121328353882\n",
      "Epoch 100/100, Iteration 2/38, Loss: 0.6145884990692139\n",
      "Epoch 100/100, Iteration 3/38, Loss: 0.6412441730499268\n",
      "Epoch 100/100, Iteration 4/38, Loss: 0.6144261956214905\n",
      "Epoch 100/100, Iteration 5/38, Loss: 0.7016676068305969\n",
      "Epoch 100/100, Iteration 6/38, Loss: 0.5828916430473328\n",
      "Epoch 100/100, Iteration 7/38, Loss: 0.6746649146080017\n",
      "Epoch 100/100, Iteration 8/38, Loss: 0.6439467668533325\n",
      "Epoch 100/100, Iteration 9/38, Loss: 0.6455901861190796\n",
      "Epoch 100/100, Iteration 10/38, Loss: 0.614096999168396\n",
      "Epoch 100/100, Iteration 11/38, Loss: 0.6450680494308472\n",
      "Epoch 100/100, Iteration 12/38, Loss: 0.612591564655304\n",
      "Epoch 100/100, Iteration 13/38, Loss: 0.6407489776611328\n",
      "Epoch 100/100, Iteration 14/38, Loss: 0.6149097084999084\n",
      "Epoch 100/100, Iteration 15/38, Loss: 0.6408290863037109\n",
      "Epoch 100/100, Iteration 16/38, Loss: 0.5517858862876892\n",
      "Epoch 100/100, Iteration 17/38, Loss: 0.5828860402107239\n",
      "Epoch 100/100, Iteration 18/38, Loss: 0.6117366552352905\n",
      "Epoch 100/100, Iteration 19/38, Loss: 0.642795741558075\n",
      "Epoch 100/100, Iteration 20/38, Loss: 0.645508885383606\n",
      "Epoch 100/100, Iteration 21/38, Loss: 0.7304962277412415\n",
      "Epoch 100/100, Iteration 22/38, Loss: 0.6396987438201904\n",
      "Epoch 100/100, Iteration 23/38, Loss: 0.6179165244102478\n",
      "Epoch 100/100, Iteration 24/38, Loss: 0.6431168913841248\n",
      "Epoch 100/100, Iteration 25/38, Loss: 0.6733613610267639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Iteration 26/38, Loss: 0.6433756947517395\n",
      "Epoch 100/100, Iteration 27/38, Loss: 0.5813895463943481\n",
      "Epoch 100/100, Iteration 28/38, Loss: 0.6442281007766724\n",
      "Epoch 100/100, Iteration 29/38, Loss: 0.640535831451416\n",
      "Epoch 100/100, Iteration 30/38, Loss: 0.6740553975105286\n",
      "Epoch 100/100, Iteration 31/38, Loss: 0.6460669636726379\n",
      "Epoch 100/100, Iteration 32/38, Loss: 0.5830175280570984\n",
      "Epoch 100/100, Iteration 33/38, Loss: 0.582900881767273\n",
      "Epoch 100/100, Iteration 34/38, Loss: 0.6740070581436157\n",
      "Epoch 100/100, Iteration 35/38, Loss: 0.6120699644088745\n",
      "Epoch 100/100, Iteration 36/38, Loss: 0.6144831776618958\n",
      "Epoch 100/100, Iteration 37/38, Loss: 0.5832815766334534\n",
      "Epoch 100/100, Iteration 38/38, Loss: 0.6141819953918457\n",
      "CPU times: total: 3min 12s\n",
      "Wall time: 3min 17s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "cnn_classifier = Classifier_CNN_3_Layers().to(device)  \n",
    "# Update the model accordingly\n",
    "\n",
    "optimizer = optim.SGD(cnn_classifier.parameters(), lr=0.1)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    cnn_classifier.train()\n",
    "    ## iterate through images in labels in train data loader\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        ### zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_classifier(images)\n",
    "        \n",
    "        # Uncomment or comment to control predicted prints\n",
    "        # print(\"Predictions:\", torch.argmax(outputs, dim=1))\n",
    "        # print(\"True Labels:\", labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        ## send update weights\n",
    "        loss.backward()\n",
    "        ## \n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Iteration {i + 1}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd440b2-9415-46cd-8939-bce253aecf05",
   "metadata": {},
   "source": [
    "## Evaluate On train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5d37c23d-0902-4f57-ad55-c9f3b517c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "## evaluate train\n",
    "def evaluate_model(model, train_loader, device):\n",
    "    ## Set the model to evaluation mode\n",
    "    cnn_classifier.eval() \n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    # sk learn peformance metrics\n",
    "    accuracy  = accuracy_score(all_targets, all_predictions)\n",
    "    confmat   = confusion_matrix(y_true=all_targets, y_pred=all_predictions)\n",
    "    precision = precision_score(y_true=all_targets, y_pred=all_predictions, average='weighted', zero_division=1)\n",
    "    recall    = recall_score(y_true=all_targets, y_pred=all_predictions, average='weighted', zero_division=1)\n",
    "    f1 = f1_score(y_true=all_targets, y_pred=all_predictions, average='weighted')\n",
    "    # display sk learn peformance metrics\n",
    "    print(f'Confusion Matrix:\\n{confmat}')\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1-score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7350652f-e7ac-444d-a8a8-a7a0155b4421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[362  24   9]\n",
      " [ 21 365  21]\n",
      " [  3  21 374]]\n",
      "Accuracy: 0.92\n",
      "Precision: 0.92\n",
      "Recall: 0.92\n",
      "F1-score: 0.92\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "## evaluate model on train set\n",
    "evaluate_model(cnn_classifier, train_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49500900-c0cf-4225-8ebd-26ff25f247b8",
   "metadata": {},
   "source": [
    "## Evaluate On Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "431fb4f0-81be-499a-8b0c-2b83ca6cee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################\n",
    "## evaluate model based on test data loader\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    ## Set the model to evaluation mode\n",
    "    cnn_classifier.eval() \n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    # sk learn peformance metrics\n",
    "    accuracy  = accuracy_score(all_targets, all_predictions)\n",
    "    confmat   = confusion_matrix(y_true=all_targets, y_pred=all_predictions)\n",
    "    precision = precision_score(y_true=all_targets, y_pred=all_predictions, average='weighted', zero_division=1)\n",
    "    recall    = recall_score(y_true=all_targets, y_pred=all_predictions, average='weighted', zero_division=1)\n",
    "    f1 = f1_score(y_true=all_targets, y_pred=all_predictions, average='weighted')\n",
    "    # display sk learn peformance metrics\n",
    "    print(f'Confusion Matrix:\\n{confmat}')\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1-score: {f1:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0142328d-e0b8-4378-b591-927fa9015a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[53 16 36]\n",
      " [15 59 19]\n",
      " [27 20 55]]\n",
      "Accuracy: 0.56\n",
      "Precision: 0.56\n",
      "Recall: 0.56\n",
      "F1-score: 0.56\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(cnn_classifier, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921bfa51-9723-4550-9886-c96baac10eb4",
   "metadata": {},
   "source": [
    "\n",
    "## Test based off random image from train dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1d2494df-2587-4a60-90d5-9e97bca8512e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Class: Happy, Predicted Class: Happy, Correct: tensor([True], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "###########################\n",
    "## Test on train data\n",
    "cnn_classifier.eval()\n",
    "# Define class names\n",
    "class_names = [\"Fear\", \"Happy\", \"Sad\"]  # Add or modify as needed based on your classes\n",
    "# Get a random index from the test set\n",
    "random_index = random.randint(0, len(train_dataset) - 1)\n",
    "# Get the image and label at the random index\n",
    "image, label = train_dataset[random_index]\n",
    "image = image.to(device)\n",
    "label = label.to(device)\n",
    "\n",
    "output = cnn_classifier(image.unsqueeze(0))  # Unsqueeze to add batch dimension\n",
    "\n",
    "# Apply threshold for multiclass classification\n",
    "_, predicted_label = torch.max(output, 1)\n",
    "\n",
    "# Convert labels to class names\n",
    "actual_class = class_names[int(label)]\n",
    "predicted_class = class_names[int(predicted_label)]\n",
    "\n",
    "# Check if the prediction is correct\n",
    "is_correct = predicted_label == int(label)\n",
    "\n",
    "# Print results\n",
    "print(f\"Actual Class: {actual_class}, Predicted Class: {predicted_class}, Correct: {is_correct}\")\n",
    "\n",
    "# Display the image\n",
    "image = image.cpu().permute(1, 2, 0).numpy()  # Convert to numpy and rearrange dimensions\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Actual: {actual_class}, Predicted: {predicted_class}\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baddd437-a57d-4610-9c4e-0dda5ae827c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d63005d8-b53c-40b7-8c38-c13afe737e9c",
   "metadata": {},
   "source": [
    "\n",
    "## Test based off random image from test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f022dd36-1de2-4c15-aab8-ba1ed0e0b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############\n",
    "## call eval model\n",
    "cnn_classifier.eval()\n",
    "\n",
    "# Define class names\n",
    "class_names = [\"Fear\", \"Happy\" ,\"Sad\"]  # Add or modify as needed\n",
    "\n",
    "# Get a random index from the test set\n",
    "random_index = random.randint(0, len(test_dataset) - 1)\n",
    "\n",
    "# Get the image and label at the random index\n",
    "image, label = test_dataset[random_index]\n",
    "image = image.to(device)\n",
    "label = label.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ec483a24-8d73-4cab-b491-d90c4b008a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Class: Fear, Predicted Class: Fear, Correct: tensor([True], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "output = cnn_classifier(image.unsqueeze(0))  # Unsqueeze to add batch dimension\n",
    "\n",
    "# Apply threshold for multiclass classification\n",
    "_, predicted_label = torch.max(output, 1)\n",
    "\n",
    "# Convert labels to class names\n",
    "actual_class = class_names[int(label)]\n",
    "predicted_class = class_names[int(predicted_label)]\n",
    "\n",
    "# Check if the prediction is correct\n",
    "is_correct = predicted_label == int(label)\n",
    "\n",
    "# Print results\n",
    "print(f\"Actual Class: {actual_class}, Predicted Class: {predicted_class}, Correct: {is_correct}\")\n",
    "\n",
    "# Display the image\n",
    "image = image.cpu().permute(1, 2, 0).numpy()  # Convert to numpy and rearrange dimensions\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Actual: {actual_class}, Predicted: {predicted_class}\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae24909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5cd76984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "23337f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "394c01e6-2cee-40a0-bf67-c537912fb346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx as onnx\n",
    "import torchvision.models as models\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 48, 48).to(device)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "onnx_path = \"emotion_recognition_model.onnx\"\n",
    "torch.onnx.export(cnn_classifier, dummy_input, onnx_path, verbose=True, input_names=['input'], output_names=['output'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "84a6ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "#onnx_model = onnx.load(onnx_path)\n",
    "\n",
    "#create runtime session\n",
    "#ort_session = onnxruntime.InferenceSession(onnx_path)\n",
    "\n",
    "#fill with dummy data\n",
    "#input_data = dummy_input.cpu().numpy()\n",
    "\n",
    "#run model with ONNX runtime\n",
    "#ort_inputs={ort_session.get_inputs()[0].name: input_data}\n",
    "#ort_outputs=ort_session.run(None, ort_inputs)\n",
    "\n",
    "#print(\"Labels: \", train_loader)\n",
    "#print(\"ONNX Runtime outputs\", ort_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ccf98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2cb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
